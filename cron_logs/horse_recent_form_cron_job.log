2025-01-20 05:45:01 - Starting stat_type_update job
2025-01-20 05:45:01 - Environment variables loaded from /home/exx/myCode/horse-racing/FoxRiverAIRacing/config/.env
2025-01-20 05:45:01 - Running Python script: /home/exx/myCode/horse-racing/FoxRiverAIRacing/src/data_preprocessing/horse_recent_form.py
25/01/20 05:45:02 WARN Utils: Your hostname, mail.relufox.ai resolves to a loopback address: 127.0.0.1; using 192.168.4.25 instead (on interface eno2)
25/01/20 05:45:02 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
25/01/20 05:45:02 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
25/01/20 05:45:03 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).
25/01/20 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
[Stage 0:>                                                          (0 + 1) / 1]                                                                                [Stage 1:>                                                          (0 + 1) / 1]                                                                                [Stage 2:>                                                          (0 + 1) / 1][Stage 2:>                  (0 + 1) / 1][Stage 3:>                  (0 + 1) / 1][Stage 3:>                                                          (0 + 1) / 1][Stage 3:>                  (0 + 1) / 1][Stage 5:>                (0 + 28) / 28][Stage 3:>                  (0 + 1) / 1][Stage 5:=>               (3 + 25) / 28][Stage 3:>                                                          (0 + 1) / 1][Stage 9:>                                                        (0 + 66) / 66][Stage 9:=>                                                       (2 + 64) / 66][Stage 9:============================================>           (53 + 13) / 66]                                                                                [Stage 10:>                                                         (0 + 1) / 1][Stage 12:=>                                                      (1 + 30) / 31]                                                                                Spark session created successfully.
root
 |-- course_cd: string (nullable = true)
 |-- race_date: date (nullable = true)
 |-- race_number: integer (nullable = true)
 |-- saddle_cloth_number: string (nullable = true)
 |-- horse_id: integer (nullable = true)
 |-- todays_cls: long (nullable = true)
 |-- official_fin: integer (nullable = true)
 |-- speed_rating: integer (nullable = true)
 |-- running_time: double (nullable = true)
 |-- dist_bk_gate1: double (nullable = true)
 |-- dist_bk_gate2: double (nullable = true)
 |-- dist_bk_gate3: double (nullable = true)
 |-- dist_bk_gate4: double (nullable = true)
 |-- avg_speed_fullrace: double (nullable = true)
 |-- avg_stride_length: double (nullable = true)
 |-- strfreq_q1: double (nullable = true)
 |-- strfreq_q2: double (nullable = true)
 |-- strfreq_q3: double (nullable = true)
 |-- strfreq_q4: double (nullable = true)

root
 |-- course_cd: string (nullable = true)
 |-- race_date: date (nullable = true)
 |-- race_number: integer (nullable = true)
 |-- saddle_cloth_number: string (nullable = true)
 |-- horse_id: integer (nullable = true)
 |-- worknum: double (nullable = true)
 |-- days_back: double (nullable = true)
 |-- worktext: string (nullable = true)
 |-- ranking: double (nullable = true)
 |-- rank_group: double (nullable = true)

Executing: ALTER TABLE horse_recent_form ADD PRIMARY KEY (course_cd, race_date, race_number, saddle_cloth_number)
Executing: CREATE INDEX idx_horse_recent_form_horse_id ON horse_recent_form (horse_id)
DDL statements executed successfully.
Executing: ALTER TABLE horse_form_agg ADD PRIMARY KEY (horse_id, as_of_date)
Executing: CREATE INDEX idx_horse_form_agg_horse_id ON horse_form_agg (horse_id)
Executing: CREATE INDEX idx_horse_form_agg_as_of_date ON horse_form_agg (as_of_date)
DDL statements executed successfully.
2025-01-20 05:45:55 - Python script succeeded
2025-01-20 05:45:55 - Job completed
2025-01-21 05:45:01 - Starting stat_type_update job
2025-01-21 05:45:01 - Environment variables loaded from /home/exx/myCode/horse-racing/FoxRiverAIRacing/config/.env
2025-01-21 05:45:01 - Running Python script: /home/exx/myCode/horse-racing/FoxRiverAIRacing/src/data_preprocessing/horse_recent_form.py
25/01/21 05:45:02 WARN Utils: Your hostname, mail.relufox.ai resolves to a loopback address: 127.0.0.1; using 192.168.4.25 instead (on interface eno2)
25/01/21 05:45:02 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
25/01/21 05:45:02 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
25/01/21 05:45:02 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).
25/01/21 05:45:02 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
25/01/21 05:45:02 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.
[Stage 0:>                                                          (0 + 1) / 1]                                                                                [Stage 1:>                                                          (0 + 1) / 1]                                                                                [Stage 2:>                  (0 + 1) / 1][Stage 3:>                  (0 + 1) / 1][Stage 3:>                                                          (0 + 1) / 1][Stage 3:>                  (0 + 1) / 1][Stage 5:>                (0 + 28) / 28][Stage 3:>                  (0 + 1) / 1][Stage 5:>                (1 + 27) / 28][Stage 3:>                                                          (0 + 1) / 1][Stage 9:>                                                        (0 + 66) / 66][Stage 9:========>                                               (10 + 56) / 66][Stage 9:=============================>                          (35 + 31) / 66]                                                                                [Stage 10:>                                                         (0 + 1) / 1][Stage 12:>                                                       (0 + 31) / 31]                                                                                Spark session created successfully.
root
 |-- course_cd: string (nullable = true)
 |-- race_date: date (nullable = true)
 |-- race_number: integer (nullable = true)
 |-- saddle_cloth_number: string (nullable = true)
 |-- horse_id: integer (nullable = true)
 |-- todays_cls: long (nullable = true)
 |-- official_fin: integer (nullable = true)
 |-- speed_rating: integer (nullable = true)
 |-- running_time: double (nullable = true)
 |-- dist_bk_gate1: double (nullable = true)
 |-- dist_bk_gate2: double (nullable = true)
 |-- dist_bk_gate3: double (nullable = true)
 |-- dist_bk_gate4: double (nullable = true)
 |-- avg_speed_fullrace: double (nullable = true)
 |-- avg_stride_length: double (nullable = true)
 |-- strfreq_q1: double (nullable = true)
 |-- strfreq_q2: double (nullable = true)
 |-- strfreq_q3: double (nullable = true)
 |-- strfreq_q4: double (nullable = true)

root
 |-- course_cd: string (nullable = true)
 |-- race_date: date (nullable = true)
 |-- race_number: integer (nullable = true)
 |-- saddle_cloth_number: string (nullable = true)
 |-- horse_id: integer (nullable = true)
 |-- worknum: double (nullable = true)
 |-- days_back: double (nullable = true)
 |-- worktext: string (nullable = true)
 |-- ranking: double (nullable = true)
 |-- rank_group: double (nullable = true)

Executing: ALTER TABLE horse_recent_form ADD PRIMARY KEY (course_cd, race_date, race_number, saddle_cloth_number)
Executing: CREATE INDEX idx_horse_recent_form_horse_id ON horse_recent_form (horse_id)
DDL statements executed successfully.
Executing: ALTER TABLE horse_form_agg ADD PRIMARY KEY (horse_id, as_of_date)
Executing: CREATE INDEX idx_horse_form_agg_horse_id ON horse_form_agg (horse_id)
Executing: CREATE INDEX idx_horse_form_agg_as_of_date ON horse_form_agg (as_of_date)
DDL statements executed successfully.
2025-01-21 05:45:56 - Python script succeeded
2025-01-21 05:45:56 - Job completed
2025-01-22 05:45:01 - Starting stat_type_update job
2025-01-22 05:45:01 - Environment variables loaded from /home/exx/myCode/horse-racing/FoxRiverAIRacing/config/.env
2025-01-22 05:45:01 - Running Python script: /home/exx/myCode/horse-racing/FoxRiverAIRacing/src/data_preprocessing/horse_recent_form.py
25/01/22 05:45:02 WARN Utils: Your hostname, mail.relufox.ai resolves to a loopback address: 127.0.0.1; using 192.168.4.25 instead (on interface eno2)
25/01/22 05:45:02 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
25/01/22 05:45:02 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
25/01/22 05:45:03 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).
25/01/22 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
25/01/22 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.
[Stage 0:>                                                          (0 + 1) / 1]                                                                                [Stage 1:>                                                          (0 + 1) / 1]                                                                                [Stage 2:>                  (0 + 1) / 1][Stage 3:>                  (0 + 1) / 1][Stage 3:>                                                          (0 + 1) / 1][Stage 3:>                  (0 + 1) / 1][Stage 5:>                (0 + 28) / 28][Stage 3:>                  (0 + 1) / 1][Stage 5:>                (1 + 27) / 28][Stage 3:>                  (0 + 1) / 1][Stage 5:==>              (4 + 24) / 28][Stage 3:>                                                          (0 + 1) / 1][Stage 9:>                                                        (0 + 66) / 66][Stage 9:>                                                        (1 + 65) / 66][Stage 9:=>                                                       (2 + 64) / 66][Stage 9:====>                                                    (5 + 61) / 66][Stage 9:=====>                                                   (6 + 60) / 66][Stage 9:======>                                                  (7 + 59) / 66][Stage 9:========================>                               (29 + 37) / 66]                                                                                [Stage 10:>                                                         (0 + 1) / 1][Stage 12:>                                                       (0 + 31) / 31][Stage 12:==============================>                        (17 + 14) / 31]                                                                                Spark session created successfully.
root
 |-- course_cd: string (nullable = true)
 |-- race_date: date (nullable = true)
 |-- race_number: integer (nullable = true)
 |-- saddle_cloth_number: string (nullable = true)
 |-- horse_id: integer (nullable = true)
 |-- todays_cls: long (nullable = true)
 |-- official_fin: integer (nullable = true)
 |-- speed_rating: integer (nullable = true)
 |-- running_time: double (nullable = true)
 |-- dist_bk_gate1: double (nullable = true)
 |-- dist_bk_gate2: double (nullable = true)
 |-- dist_bk_gate3: double (nullable = true)
 |-- dist_bk_gate4: double (nullable = true)
 |-- avg_speed_fullrace: double (nullable = true)
 |-- avg_stride_length: double (nullable = true)
 |-- strfreq_q1: double (nullable = true)
 |-- strfreq_q2: double (nullable = true)
 |-- strfreq_q3: double (nullable = true)
 |-- strfreq_q4: double (nullable = true)

root
 |-- course_cd: string (nullable = true)
 |-- race_date: date (nullable = true)
 |-- race_number: integer (nullable = true)
 |-- saddle_cloth_number: string (nullable = true)
 |-- horse_id: integer (nullable = true)
 |-- worknum: double (nullable = true)
 |-- days_back: double (nullable = true)
 |-- worktext: string (nullable = true)
 |-- ranking: double (nullable = true)
 |-- rank_group: double (nullable = true)

Executing: ALTER TABLE horse_recent_form ADD PRIMARY KEY (course_cd, race_date, race_number, saddle_cloth_number)
Executing: CREATE INDEX idx_horse_recent_form_horse_id ON horse_recent_form (horse_id)
DDL statements executed successfully.
Executing: ALTER TABLE horse_form_agg ADD PRIMARY KEY (horse_id, as_of_date)
Executing: CREATE INDEX idx_horse_form_agg_horse_id ON horse_form_agg (horse_id)
Executing: CREATE INDEX idx_horse_form_agg_as_of_date ON horse_form_agg (as_of_date)
DDL statements executed successfully.
2025-01-22 05:45:56 - Python script succeeded
2025-01-22 05:45:56 - Job completed
2025-01-23 05:45:01 - Starting stat_type_update job
2025-01-23 05:45:01 - Environment variables loaded from /home/exx/myCode/horse-racing/FoxRiverAIRacing/config/.env
2025-01-23 05:45:01 - Running Python script: /home/exx/myCode/horse-racing/FoxRiverAIRacing/src/data_preprocessing/horse_recent_form.py
25/01/23 05:45:03 WARN Utils: Your hostname, mail.relufox.ai resolves to a loopback address: 127.0.0.1; using 192.168.4.25 instead (on interface eno2)
25/01/23 05:45:03 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
25/01/23 05:45:03 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
25/01/23 05:45:03 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).
25/01/23 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
[Stage 0:>                                                          (0 + 1) / 1]                                                                                [Stage 1:>                                                          (0 + 1) / 1]                                                                                [Stage 2:>                  (0 + 1) / 1][Stage 3:>                  (0 + 1) / 1][Stage 3:>                                                          (0 + 1) / 1][Stage 3:>                  (0 + 1) / 1][Stage 5:>                (0 + 28) / 28][Stage 3:>                  (0 + 1) / 1][Stage 5:>                (1 + 27) / 28][Stage 3:>                  (0 + 1) / 1][Stage 5:===>             (5 + 23) / 28][Stage 3:>                                                          (0 + 1) / 1][Stage 9:>                                                        (0 + 66) / 66][Stage 9:===================================================>     (60 + 6) / 66]                                                                                [Stage 10:>                                                         (0 + 1) / 1][Stage 12:>                                                       (0 + 31) / 31][Stage 12:=======>                                                (4 + 27) / 31]                                                                                Spark session created successfully.
root
 |-- course_cd: string (nullable = true)
 |-- race_date: date (nullable = true)
 |-- race_number: integer (nullable = true)
 |-- saddle_cloth_number: string (nullable = true)
 |-- horse_id: integer (nullable = true)
 |-- todays_cls: long (nullable = true)
 |-- official_fin: integer (nullable = true)
 |-- speed_rating: integer (nullable = true)
 |-- running_time: double (nullable = true)
 |-- dist_bk_gate1: double (nullable = true)
 |-- dist_bk_gate2: double (nullable = true)
 |-- dist_bk_gate3: double (nullable = true)
 |-- dist_bk_gate4: double (nullable = true)
 |-- avg_speed_fullrace: double (nullable = true)
 |-- avg_stride_length: double (nullable = true)
 |-- strfreq_q1: double (nullable = true)
 |-- strfreq_q2: double (nullable = true)
 |-- strfreq_q3: double (nullable = true)
 |-- strfreq_q4: double (nullable = true)

root
 |-- course_cd: string (nullable = true)
 |-- race_date: date (nullable = true)
 |-- race_number: integer (nullable = true)
 |-- saddle_cloth_number: string (nullable = true)
 |-- horse_id: integer (nullable = true)
 |-- worknum: double (nullable = true)
 |-- days_back: double (nullable = true)
 |-- worktext: string (nullable = true)
 |-- ranking: double (nullable = true)
 |-- rank_group: double (nullable = true)

Executing: ALTER TABLE horse_recent_form ADD PRIMARY KEY (course_cd, race_date, race_number, saddle_cloth_number)
Executing: CREATE INDEX idx_horse_recent_form_horse_id ON horse_recent_form (horse_id)
DDL statements executed successfully.
Executing: ALTER TABLE horse_form_agg ADD PRIMARY KEY (horse_id, as_of_date)
Executing: CREATE INDEX idx_horse_form_agg_horse_id ON horse_form_agg (horse_id)
Executing: CREATE INDEX idx_horse_form_agg_as_of_date ON horse_form_agg (as_of_date)
DDL statements executed successfully.
2025-01-23 05:45:57 - Python script succeeded
2025-01-23 05:45:57 - Job completed
2025-01-24 05:45:01 - Starting stat_type_update job
2025-01-24 05:45:01 - Environment variables loaded from /home/exx/myCode/horse-racing/FoxRiverAIRacing/config/.env
2025-01-24 05:45:01 - Running Python script: /home/exx/myCode/horse-racing/FoxRiverAIRacing/src/data_preprocessing/horse_recent_form.py
25/01/24 05:45:02 WARN Utils: Your hostname, mail.relufox.ai resolves to a loopback address: 127.0.0.1; using 192.168.4.25 instead (on interface eno2)
25/01/24 05:45:02 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
25/01/24 05:45:02 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
25/01/24 05:45:02 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).
25/01/24 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
[Stage 0:>                                                          (0 + 1) / 1]                                                                                [Stage 1:>                                                          (0 + 1) / 1]                                                                                [Stage 2:>                  (0 + 1) / 1][Stage 3:>                  (0 + 1) / 1][Stage 3:>                                                          (0 + 1) / 1][Stage 3:>                  (0 + 1) / 1][Stage 5:>                (0 + 28) / 28][Stage 3:>                  (0 + 1) / 1][Stage 5:=>               (2 + 26) / 28][Stage 3:>                  (0 + 1) / 1][Stage 5:=========>      (17 + 11) / 28][Stage 3:>                                                          (0 + 1) / 1][Stage 9:>                                                        (0 + 66) / 66][Stage 9:>                                                        (1 + 65) / 66][Stage 9:=================>                                      (21 + 45) / 66][Stage 9:=================================>                      (40 + 26) / 66]                                                                                [Stage 10:>                                                         (0 + 1) / 1][Stage 12:=======================>                               (13 + 18) / 31]                                                                                Spark session created successfully.
root
 |-- course_cd: string (nullable = true)
 |-- race_date: date (nullable = true)
 |-- race_number: integer (nullable = true)
 |-- saddle_cloth_number: string (nullable = true)
 |-- horse_id: integer (nullable = true)
 |-- todays_cls: long (nullable = true)
 |-- official_fin: integer (nullable = true)
 |-- speed_rating: integer (nullable = true)
 |-- running_time: double (nullable = true)
 |-- dist_bk_gate1: double (nullable = true)
 |-- dist_bk_gate2: double (nullable = true)
 |-- dist_bk_gate3: double (nullable = true)
 |-- dist_bk_gate4: double (nullable = true)
 |-- avg_speed_fullrace: double (nullable = true)
 |-- avg_stride_length: double (nullable = true)
 |-- strfreq_q1: double (nullable = true)
 |-- strfreq_q2: double (nullable = true)
 |-- strfreq_q3: double (nullable = true)
 |-- strfreq_q4: double (nullable = true)

root
 |-- course_cd: string (nullable = true)
 |-- race_date: date (nullable = true)
 |-- race_number: integer (nullable = true)
 |-- saddle_cloth_number: string (nullable = true)
 |-- horse_id: integer (nullable = true)
 |-- worknum: double (nullable = true)
 |-- days_back: double (nullable = true)
 |-- worktext: string (nullable = true)
 |-- ranking: double (nullable = true)
 |-- rank_group: double (nullable = true)

Executing: ALTER TABLE horse_recent_form ADD PRIMARY KEY (course_cd, race_date, race_number, saddle_cloth_number)
Executing: CREATE INDEX idx_horse_recent_form_horse_id ON horse_recent_form (horse_id)
DDL statements executed successfully.
Executing: ALTER TABLE horse_form_agg ADD PRIMARY KEY (horse_id, as_of_date)
Executing: CREATE INDEX idx_horse_form_agg_horse_id ON horse_form_agg (horse_id)
Executing: CREATE INDEX idx_horse_form_agg_as_of_date ON horse_form_agg (as_of_date)
DDL statements executed successfully.
2025-01-24 05:45:55 - Python script succeeded
2025-01-24 05:45:55 - Job completed
2025-01-25 05:45:01 - Starting stat_type_update job
2025-01-25 05:45:01 - Environment variables loaded from /home/exx/myCode/horse-racing/FoxRiverAIRacing/config/.env
2025-01-25 05:45:01 - Running Python script: /home/exx/myCode/horse-racing/FoxRiverAIRacing/src/data_preprocessing/horse_recent_form.py
25/01/25 05:45:03 WARN Utils: Your hostname, mail.relufox.ai resolves to a loopback address: 127.0.0.1; using 192.168.4.25 instead (on interface eno2)
25/01/25 05:45:03 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
25/01/25 05:45:03 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
25/01/25 05:45:03 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).
25/01/25 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
[Stage 0:>                                                          (0 + 1) / 1]                                                                                [Stage 1:>                                                          (0 + 1) / 1]                                                                                [Stage 2:>                  (0 + 1) / 1][Stage 3:>                  (0 + 1) / 1][Stage 3:>                                                          (0 + 1) / 1][Stage 3:>                  (0 + 1) / 1][Stage 5:>                (0 + 28) / 28][Stage 3:>                  (0 + 1) / 1][Stage 5:=>               (2 + 26) / 28][Stage 3:>                  (0 + 1) / 1][Stage 5:===>             (5 + 23) / 28][Stage 3:>                                                          (0 + 1) / 1][Stage 9:>                                                        (0 + 66) / 66][Stage 9:====>                                                    (5 + 61) / 66][Stage 9:==================>                                     (22 + 44) / 66]                                                                                [Stage 10:>                                                         (0 + 1) / 1][Stage 12:>                                                       (0 + 31) / 31][Stage 12:=>                                                      (1 + 30) / 31]                                                                                Spark session created successfully.
root
 |-- course_cd: string (nullable = true)
 |-- race_date: date (nullable = true)
 |-- race_number: integer (nullable = true)
 |-- saddle_cloth_number: string (nullable = true)
 |-- horse_id: integer (nullable = true)
 |-- todays_cls: long (nullable = true)
 |-- official_fin: integer (nullable = true)
 |-- speed_rating: integer (nullable = true)
 |-- running_time: double (nullable = true)
 |-- dist_bk_gate1: double (nullable = true)
 |-- dist_bk_gate2: double (nullable = true)
 |-- dist_bk_gate3: double (nullable = true)
 |-- dist_bk_gate4: double (nullable = true)
 |-- avg_speed_fullrace: double (nullable = true)
 |-- avg_stride_length: double (nullable = true)
 |-- strfreq_q1: double (nullable = true)
 |-- strfreq_q2: double (nullable = true)
 |-- strfreq_q3: double (nullable = true)
 |-- strfreq_q4: double (nullable = true)

root
 |-- course_cd: string (nullable = true)
 |-- race_date: date (nullable = true)
 |-- race_number: integer (nullable = true)
 |-- saddle_cloth_number: string (nullable = true)
 |-- horse_id: integer (nullable = true)
 |-- worknum: double (nullable = true)
 |-- days_back: double (nullable = true)
 |-- worktext: string (nullable = true)
 |-- ranking: double (nullable = true)
 |-- rank_group: double (nullable = true)

Executing: ALTER TABLE horse_recent_form ADD PRIMARY KEY (course_cd, race_date, race_number, saddle_cloth_number)
Executing: CREATE INDEX idx_horse_recent_form_horse_id ON horse_recent_form (horse_id)
DDL statements executed successfully.
Executing: ALTER TABLE horse_form_agg ADD PRIMARY KEY (horse_id, as_of_date)
Executing: CREATE INDEX idx_horse_form_agg_horse_id ON horse_form_agg (horse_id)
Executing: CREATE INDEX idx_horse_form_agg_as_of_date ON horse_form_agg (as_of_date)
DDL statements executed successfully.
2025-01-25 05:45:56 - Python script succeeded
2025-01-25 05:45:56 - Job completed
2025-01-26 05:45:01 - Starting stat_type_update job
2025-01-26 05:45:01 - Environment variables loaded from /home/exx/myCode/horse-racing/FoxRiverAIRacing/config/.env
2025-01-26 05:45:01 - Running Python script: /home/exx/myCode/horse-racing/FoxRiverAIRacing/src/data_preprocessing/horse_recent_form.py
25/01/26 05:45:02 WARN Utils: Your hostname, mail.relufox.ai resolves to a loopback address: 127.0.0.1; using 192.168.4.25 instead (on interface eno2)
25/01/26 05:45:02 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
25/01/26 05:45:02 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
25/01/26 05:45:02 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).
25/01/26 05:45:02 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
[Stage 0:>                                                          (0 + 1) / 1]                                                                                [Stage 1:>                                                          (0 + 1) / 1]                                                                                [Stage 2:>                  (0 + 1) / 1][Stage 3:>                  (0 + 1) / 1][Stage 3:>                                                          (0 + 1) / 1][Stage 3:>                  (0 + 1) / 1][Stage 5:>                (0 + 28) / 28][Stage 3:>                  (0 + 1) / 1][Stage 5:>                (1 + 27) / 28][Stage 3:>                  (0 + 1) / 1][Stage 5:============>    (20 + 8) / 28][Stage 3:>                                                          (0 + 1) / 1][Stage 9:>                                                        (0 + 66) / 66][Stage 9:===========>                                            (14 + 52) / 66][Stage 9:=======================================>                (46 + 20) / 66]                                                                                [Stage 10:>                                                         (0 + 1) / 1][Stage 12:>                                                       (0 + 31) / 31]                                                                                Spark session created successfully.
root
 |-- course_cd: string (nullable = true)
 |-- race_date: date (nullable = true)
 |-- race_number: integer (nullable = true)
 |-- saddle_cloth_number: string (nullable = true)
 |-- horse_id: integer (nullable = true)
 |-- todays_cls: long (nullable = true)
 |-- official_fin: integer (nullable = true)
 |-- speed_rating: integer (nullable = true)
 |-- running_time: double (nullable = true)
 |-- dist_bk_gate1: double (nullable = true)
 |-- dist_bk_gate2: double (nullable = true)
 |-- dist_bk_gate3: double (nullable = true)
 |-- dist_bk_gate4: double (nullable = true)
 |-- avg_speed_fullrace: double (nullable = true)
 |-- avg_stride_length: double (nullable = true)
 |-- strfreq_q1: double (nullable = true)
 |-- strfreq_q2: double (nullable = true)
 |-- strfreq_q3: double (nullable = true)
 |-- strfreq_q4: double (nullable = true)

root
 |-- course_cd: string (nullable = true)
 |-- race_date: date (nullable = true)
 |-- race_number: integer (nullable = true)
 |-- saddle_cloth_number: string (nullable = true)
 |-- horse_id: integer (nullable = true)
 |-- worknum: double (nullable = true)
 |-- days_back: double (nullable = true)
 |-- worktext: string (nullable = true)
 |-- ranking: double (nullable = true)
 |-- rank_group: double (nullable = true)

Executing: ALTER TABLE horse_recent_form ADD PRIMARY KEY (course_cd, race_date, race_number, saddle_cloth_number)
Executing: CREATE INDEX idx_horse_recent_form_horse_id ON horse_recent_form (horse_id)
DDL statements executed successfully.
Executing: ALTER TABLE horse_form_agg ADD PRIMARY KEY (horse_id, as_of_date)
Executing: CREATE INDEX idx_horse_form_agg_horse_id ON horse_form_agg (horse_id)
Executing: CREATE INDEX idx_horse_form_agg_as_of_date ON horse_form_agg (as_of_date)
DDL statements executed successfully.
2025-01-26 05:45:55 - Python script succeeded
2025-01-26 05:45:55 - Job completed
2025-01-27 05:45:01 - Starting stat_type_update job
2025-01-27 05:45:01 - Environment variables loaded from /home/exx/myCode/horse-racing/FoxRiverAIRacing/config/.env
2025-01-27 05:45:01 - Running Python script: /home/exx/myCode/horse-racing/FoxRiverAIRacing/src/data_preprocessing/horse_recent_form.py
25/01/27 05:45:02 WARN Utils: Your hostname, mail.relufox.ai resolves to a loopback address: 127.0.0.1; using 192.168.4.25 instead (on interface eno2)
25/01/27 05:45:02 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
25/01/27 05:45:02 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
25/01/27 05:45:03 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).
25/01/27 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
25/01/27 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.
[Stage 0:>                                                          (0 + 1) / 1]                                                                                [Stage 1:>                                                          (0 + 1) / 1]                                                                                [Stage 2:>                  (0 + 1) / 1][Stage 3:>                  (0 + 1) / 1][Stage 3:>                                                          (0 + 1) / 1][Stage 3:>                  (0 + 1) / 1][Stage 5:>                (0 + 28) / 28][Stage 3:>                  (0 + 1) / 1][Stage 5:=>               (2 + 26) / 28][Stage 3:>                                                          (0 + 1) / 1][Stage 9:>                                                        (0 + 66) / 66][Stage 9:=========================>                              (30 + 36) / 66]                                                                                [Stage 10:>                                                         (0 + 1) / 1][Stage 12:>                                                       (0 + 31) / 31][Stage 12:=>                                                      (1 + 30) / 31]                                                                                Spark session created successfully.
root
 |-- course_cd: string (nullable = true)
 |-- race_date: date (nullable = true)
 |-- race_number: integer (nullable = true)
 |-- saddle_cloth_number: string (nullable = true)
 |-- horse_id: integer (nullable = true)
 |-- todays_cls: long (nullable = true)
 |-- official_fin: integer (nullable = true)
 |-- speed_rating: integer (nullable = true)
 |-- running_time: double (nullable = true)
 |-- dist_bk_gate1: double (nullable = true)
 |-- dist_bk_gate2: double (nullable = true)
 |-- dist_bk_gate3: double (nullable = true)
 |-- dist_bk_gate4: double (nullable = true)
 |-- avg_speed_fullrace: double (nullable = true)
 |-- avg_stride_length: double (nullable = true)
 |-- strfreq_q1: double (nullable = true)
 |-- strfreq_q2: double (nullable = true)
 |-- strfreq_q3: double (nullable = true)
 |-- strfreq_q4: double (nullable = true)

root
 |-- course_cd: string (nullable = true)
 |-- race_date: date (nullable = true)
 |-- race_number: integer (nullable = true)
 |-- saddle_cloth_number: string (nullable = true)
 |-- horse_id: integer (nullable = true)
 |-- worknum: double (nullable = true)
 |-- days_back: double (nullable = true)
 |-- worktext: string (nullable = true)
 |-- ranking: double (nullable = true)
 |-- rank_group: double (nullable = true)

Executing: ALTER TABLE horse_recent_form ADD PRIMARY KEY (course_cd, race_date, race_number, saddle_cloth_number)
Executing: CREATE INDEX idx_horse_recent_form_horse_id ON horse_recent_form (horse_id)
DDL statements executed successfully.
Executing: ALTER TABLE horse_form_agg ADD PRIMARY KEY (horse_id, as_of_date)
Executing: CREATE INDEX idx_horse_form_agg_horse_id ON horse_form_agg (horse_id)
Executing: CREATE INDEX idx_horse_form_agg_as_of_date ON horse_form_agg (as_of_date)
DDL statements executed successfully.
2025-01-27 05:45:56 - Python script succeeded
2025-01-27 05:45:56 - Job completed
