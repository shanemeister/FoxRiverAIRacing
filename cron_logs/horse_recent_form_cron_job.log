2025-01-20 05:45:01 - Starting stat_type_update job
2025-01-20 05:45:01 - Environment variables loaded from /home/exx/myCode/horse-racing/FoxRiverAIRacing/config/.env
2025-01-20 05:45:01 - Running Python script: /home/exx/myCode/horse-racing/FoxRiverAIRacing/src/data_preprocessing/horse_recent_form.py
25/01/20 05:45:02 WARN Utils: Your hostname, mail.relufox.ai resolves to a loopback address: 127.0.0.1; using 192.168.4.25 instead (on interface eno2)
25/01/20 05:45:02 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
25/01/20 05:45:02 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
25/01/20 05:45:03 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).
25/01/20 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
[Stage 0:>                                                          (0 + 1) / 1]                                                                                [Stage 1:>                                                          (0 + 1) / 1]                                                                                [Stage 2:>                                                          (0 + 1) / 1][Stage 2:>                  (0 + 1) / 1][Stage 3:>                  (0 + 1) / 1][Stage 3:>                                                          (0 + 1) / 1][Stage 3:>                  (0 + 1) / 1][Stage 5:>                (0 + 28) / 28][Stage 3:>                  (0 + 1) / 1][Stage 5:=>               (3 + 25) / 28][Stage 3:>                                                          (0 + 1) / 1][Stage 9:>                                                        (0 + 66) / 66][Stage 9:=>                                                       (2 + 64) / 66][Stage 9:============================================>           (53 + 13) / 66]                                                                                [Stage 10:>                                                         (0 + 1) / 1][Stage 12:=>                                                      (1 + 30) / 31]                                                                                Spark session created successfully.
root
 |-- course_cd: string (nullable = true)
 |-- race_date: date (nullable = true)
 |-- race_number: integer (nullable = true)
 |-- saddle_cloth_number: string (nullable = true)
 |-- horse_id: integer (nullable = true)
 |-- todays_cls: long (nullable = true)
 |-- official_fin: integer (nullable = true)
 |-- speed_rating: integer (nullable = true)
 |-- running_time: double (nullable = true)
 |-- dist_bk_gate1: double (nullable = true)
 |-- dist_bk_gate2: double (nullable = true)
 |-- dist_bk_gate3: double (nullable = true)
 |-- dist_bk_gate4: double (nullable = true)
 |-- avg_speed_fullrace: double (nullable = true)
 |-- avg_stride_length: double (nullable = true)
 |-- strfreq_q1: double (nullable = true)
 |-- strfreq_q2: double (nullable = true)
 |-- strfreq_q3: double (nullable = true)
 |-- strfreq_q4: double (nullable = true)

root
 |-- course_cd: string (nullable = true)
 |-- race_date: date (nullable = true)
 |-- race_number: integer (nullable = true)
 |-- saddle_cloth_number: string (nullable = true)
 |-- horse_id: integer (nullable = true)
 |-- worknum: double (nullable = true)
 |-- days_back: double (nullable = true)
 |-- worktext: string (nullable = true)
 |-- ranking: double (nullable = true)
 |-- rank_group: double (nullable = true)

Executing: ALTER TABLE horse_recent_form ADD PRIMARY KEY (course_cd, race_date, race_number, saddle_cloth_number)
Executing: CREATE INDEX idx_horse_recent_form_horse_id ON horse_recent_form (horse_id)
DDL statements executed successfully.
Executing: ALTER TABLE horse_form_agg ADD PRIMARY KEY (horse_id, as_of_date)
Executing: CREATE INDEX idx_horse_form_agg_horse_id ON horse_form_agg (horse_id)
Executing: CREATE INDEX idx_horse_form_agg_as_of_date ON horse_form_agg (as_of_date)
DDL statements executed successfully.
2025-01-20 05:45:55 - Python script succeeded
2025-01-20 05:45:55 - Job completed
2025-01-21 05:45:01 - Starting stat_type_update job
2025-01-21 05:45:01 - Environment variables loaded from /home/exx/myCode/horse-racing/FoxRiverAIRacing/config/.env
2025-01-21 05:45:01 - Running Python script: /home/exx/myCode/horse-racing/FoxRiverAIRacing/src/data_preprocessing/horse_recent_form.py
25/01/21 05:45:02 WARN Utils: Your hostname, mail.relufox.ai resolves to a loopback address: 127.0.0.1; using 192.168.4.25 instead (on interface eno2)
25/01/21 05:45:02 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
25/01/21 05:45:02 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
25/01/21 05:45:02 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).
25/01/21 05:45:02 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
25/01/21 05:45:02 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.
[Stage 0:>                                                          (0 + 1) / 1]                                                                                [Stage 1:>                                                          (0 + 1) / 1]                                                                                [Stage 2:>                  (0 + 1) / 1][Stage 3:>                  (0 + 1) / 1][Stage 3:>                                                          (0 + 1) / 1][Stage 3:>                  (0 + 1) / 1][Stage 5:>                (0 + 28) / 28][Stage 3:>                  (0 + 1) / 1][Stage 5:>                (1 + 27) / 28][Stage 3:>                                                          (0 + 1) / 1][Stage 9:>                                                        (0 + 66) / 66][Stage 9:========>                                               (10 + 56) / 66][Stage 9:=============================>                          (35 + 31) / 66]                                                                                [Stage 10:>                                                         (0 + 1) / 1][Stage 12:>                                                       (0 + 31) / 31]                                                                                Spark session created successfully.
root
 |-- course_cd: string (nullable = true)
 |-- race_date: date (nullable = true)
 |-- race_number: integer (nullable = true)
 |-- saddle_cloth_number: string (nullable = true)
 |-- horse_id: integer (nullable = true)
 |-- todays_cls: long (nullable = true)
 |-- official_fin: integer (nullable = true)
 |-- speed_rating: integer (nullable = true)
 |-- running_time: double (nullable = true)
 |-- dist_bk_gate1: double (nullable = true)
 |-- dist_bk_gate2: double (nullable = true)
 |-- dist_bk_gate3: double (nullable = true)
 |-- dist_bk_gate4: double (nullable = true)
 |-- avg_speed_fullrace: double (nullable = true)
 |-- avg_stride_length: double (nullable = true)
 |-- strfreq_q1: double (nullable = true)
 |-- strfreq_q2: double (nullable = true)
 |-- strfreq_q3: double (nullable = true)
 |-- strfreq_q4: double (nullable = true)

root
 |-- course_cd: string (nullable = true)
 |-- race_date: date (nullable = true)
 |-- race_number: integer (nullable = true)
 |-- saddle_cloth_number: string (nullable = true)
 |-- horse_id: integer (nullable = true)
 |-- worknum: double (nullable = true)
 |-- days_back: double (nullable = true)
 |-- worktext: string (nullable = true)
 |-- ranking: double (nullable = true)
 |-- rank_group: double (nullable = true)

Executing: ALTER TABLE horse_recent_form ADD PRIMARY KEY (course_cd, race_date, race_number, saddle_cloth_number)
Executing: CREATE INDEX idx_horse_recent_form_horse_id ON horse_recent_form (horse_id)
DDL statements executed successfully.
Executing: ALTER TABLE horse_form_agg ADD PRIMARY KEY (horse_id, as_of_date)
Executing: CREATE INDEX idx_horse_form_agg_horse_id ON horse_form_agg (horse_id)
Executing: CREATE INDEX idx_horse_form_agg_as_of_date ON horse_form_agg (as_of_date)
DDL statements executed successfully.
2025-01-21 05:45:56 - Python script succeeded
2025-01-21 05:45:56 - Job completed
2025-01-22 05:45:01 - Starting stat_type_update job
2025-01-22 05:45:01 - Environment variables loaded from /home/exx/myCode/horse-racing/FoxRiverAIRacing/config/.env
2025-01-22 05:45:01 - Running Python script: /home/exx/myCode/horse-racing/FoxRiverAIRacing/src/data_preprocessing/horse_recent_form.py
25/01/22 05:45:02 WARN Utils: Your hostname, mail.relufox.ai resolves to a loopback address: 127.0.0.1; using 192.168.4.25 instead (on interface eno2)
25/01/22 05:45:02 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
25/01/22 05:45:02 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
25/01/22 05:45:03 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).
25/01/22 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
25/01/22 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.
[Stage 0:>                                                          (0 + 1) / 1]                                                                                [Stage 1:>                                                          (0 + 1) / 1]                                                                                [Stage 2:>                  (0 + 1) / 1][Stage 3:>                  (0 + 1) / 1][Stage 3:>                                                          (0 + 1) / 1][Stage 3:>                  (0 + 1) / 1][Stage 5:>                (0 + 28) / 28][Stage 3:>                  (0 + 1) / 1][Stage 5:>                (1 + 27) / 28][Stage 3:>                  (0 + 1) / 1][Stage 5:==>              (4 + 24) / 28][Stage 3:>                                                          (0 + 1) / 1][Stage 9:>                                                        (0 + 66) / 66][Stage 9:>                                                        (1 + 65) / 66][Stage 9:=>                                                       (2 + 64) / 66][Stage 9:====>                                                    (5 + 61) / 66][Stage 9:=====>                                                   (6 + 60) / 66][Stage 9:======>                                                  (7 + 59) / 66][Stage 9:========================>                               (29 + 37) / 66]                                                                                [Stage 10:>                                                         (0 + 1) / 1][Stage 12:>                                                       (0 + 31) / 31][Stage 12:==============================>                        (17 + 14) / 31]                                                                                Spark session created successfully.
root
 |-- course_cd: string (nullable = true)
 |-- race_date: date (nullable = true)
 |-- race_number: integer (nullable = true)
 |-- saddle_cloth_number: string (nullable = true)
 |-- horse_id: integer (nullable = true)
 |-- todays_cls: long (nullable = true)
 |-- official_fin: integer (nullable = true)
 |-- speed_rating: integer (nullable = true)
 |-- running_time: double (nullable = true)
 |-- dist_bk_gate1: double (nullable = true)
 |-- dist_bk_gate2: double (nullable = true)
 |-- dist_bk_gate3: double (nullable = true)
 |-- dist_bk_gate4: double (nullable = true)
 |-- avg_speed_fullrace: double (nullable = true)
 |-- avg_stride_length: double (nullable = true)
 |-- strfreq_q1: double (nullable = true)
 |-- strfreq_q2: double (nullable = true)
 |-- strfreq_q3: double (nullable = true)
 |-- strfreq_q4: double (nullable = true)

root
 |-- course_cd: string (nullable = true)
 |-- race_date: date (nullable = true)
 |-- race_number: integer (nullable = true)
 |-- saddle_cloth_number: string (nullable = true)
 |-- horse_id: integer (nullable = true)
 |-- worknum: double (nullable = true)
 |-- days_back: double (nullable = true)
 |-- worktext: string (nullable = true)
 |-- ranking: double (nullable = true)
 |-- rank_group: double (nullable = true)

Executing: ALTER TABLE horse_recent_form ADD PRIMARY KEY (course_cd, race_date, race_number, saddle_cloth_number)
Executing: CREATE INDEX idx_horse_recent_form_horse_id ON horse_recent_form (horse_id)
DDL statements executed successfully.
Executing: ALTER TABLE horse_form_agg ADD PRIMARY KEY (horse_id, as_of_date)
Executing: CREATE INDEX idx_horse_form_agg_horse_id ON horse_form_agg (horse_id)
Executing: CREATE INDEX idx_horse_form_agg_as_of_date ON horse_form_agg (as_of_date)
DDL statements executed successfully.
2025-01-22 05:45:56 - Python script succeeded
2025-01-22 05:45:56 - Job completed
2025-01-23 05:45:01 - Starting stat_type_update job
2025-01-23 05:45:01 - Environment variables loaded from /home/exx/myCode/horse-racing/FoxRiverAIRacing/config/.env
2025-01-23 05:45:01 - Running Python script: /home/exx/myCode/horse-racing/FoxRiverAIRacing/src/data_preprocessing/horse_recent_form.py
25/01/23 05:45:03 WARN Utils: Your hostname, mail.relufox.ai resolves to a loopback address: 127.0.0.1; using 192.168.4.25 instead (on interface eno2)
25/01/23 05:45:03 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
25/01/23 05:45:03 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
25/01/23 05:45:03 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).
25/01/23 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
[Stage 0:>                                                          (0 + 1) / 1]                                                                                [Stage 1:>                                                          (0 + 1) / 1]                                                                                [Stage 2:>                  (0 + 1) / 1][Stage 3:>                  (0 + 1) / 1][Stage 3:>                                                          (0 + 1) / 1][Stage 3:>                  (0 + 1) / 1][Stage 5:>                (0 + 28) / 28][Stage 3:>                  (0 + 1) / 1][Stage 5:>                (1 + 27) / 28][Stage 3:>                  (0 + 1) / 1][Stage 5:===>             (5 + 23) / 28][Stage 3:>                                                          (0 + 1) / 1][Stage 9:>                                                        (0 + 66) / 66][Stage 9:===================================================>     (60 + 6) / 66]                                                                                [Stage 10:>                                                         (0 + 1) / 1][Stage 12:>                                                       (0 + 31) / 31][Stage 12:=======>                                                (4 + 27) / 31]                                                                                Spark session created successfully.
root
 |-- course_cd: string (nullable = true)
 |-- race_date: date (nullable = true)
 |-- race_number: integer (nullable = true)
 |-- saddle_cloth_number: string (nullable = true)
 |-- horse_id: integer (nullable = true)
 |-- todays_cls: long (nullable = true)
 |-- official_fin: integer (nullable = true)
 |-- speed_rating: integer (nullable = true)
 |-- running_time: double (nullable = true)
 |-- dist_bk_gate1: double (nullable = true)
 |-- dist_bk_gate2: double (nullable = true)
 |-- dist_bk_gate3: double (nullable = true)
 |-- dist_bk_gate4: double (nullable = true)
 |-- avg_speed_fullrace: double (nullable = true)
 |-- avg_stride_length: double (nullable = true)
 |-- strfreq_q1: double (nullable = true)
 |-- strfreq_q2: double (nullable = true)
 |-- strfreq_q3: double (nullable = true)
 |-- strfreq_q4: double (nullable = true)

root
 |-- course_cd: string (nullable = true)
 |-- race_date: date (nullable = true)
 |-- race_number: integer (nullable = true)
 |-- saddle_cloth_number: string (nullable = true)
 |-- horse_id: integer (nullable = true)
 |-- worknum: double (nullable = true)
 |-- days_back: double (nullable = true)
 |-- worktext: string (nullable = true)
 |-- ranking: double (nullable = true)
 |-- rank_group: double (nullable = true)

Executing: ALTER TABLE horse_recent_form ADD PRIMARY KEY (course_cd, race_date, race_number, saddle_cloth_number)
Executing: CREATE INDEX idx_horse_recent_form_horse_id ON horse_recent_form (horse_id)
DDL statements executed successfully.
Executing: ALTER TABLE horse_form_agg ADD PRIMARY KEY (horse_id, as_of_date)
Executing: CREATE INDEX idx_horse_form_agg_horse_id ON horse_form_agg (horse_id)
Executing: CREATE INDEX idx_horse_form_agg_as_of_date ON horse_form_agg (as_of_date)
DDL statements executed successfully.
2025-01-23 05:45:57 - Python script succeeded
2025-01-23 05:45:57 - Job completed
2025-01-24 05:45:01 - Starting stat_type_update job
2025-01-24 05:45:01 - Environment variables loaded from /home/exx/myCode/horse-racing/FoxRiverAIRacing/config/.env
2025-01-24 05:45:01 - Running Python script: /home/exx/myCode/horse-racing/FoxRiverAIRacing/src/data_preprocessing/horse_recent_form.py
25/01/24 05:45:02 WARN Utils: Your hostname, mail.relufox.ai resolves to a loopback address: 127.0.0.1; using 192.168.4.25 instead (on interface eno2)
25/01/24 05:45:02 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
25/01/24 05:45:02 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
25/01/24 05:45:02 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).
25/01/24 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
[Stage 0:>                                                          (0 + 1) / 1]                                                                                [Stage 1:>                                                          (0 + 1) / 1]                                                                                [Stage 2:>                  (0 + 1) / 1][Stage 3:>                  (0 + 1) / 1][Stage 3:>                                                          (0 + 1) / 1][Stage 3:>                  (0 + 1) / 1][Stage 5:>                (0 + 28) / 28][Stage 3:>                  (0 + 1) / 1][Stage 5:=>               (2 + 26) / 28][Stage 3:>                  (0 + 1) / 1][Stage 5:=========>      (17 + 11) / 28][Stage 3:>                                                          (0 + 1) / 1][Stage 9:>                                                        (0 + 66) / 66][Stage 9:>                                                        (1 + 65) / 66][Stage 9:=================>                                      (21 + 45) / 66][Stage 9:=================================>                      (40 + 26) / 66]                                                                                [Stage 10:>                                                         (0 + 1) / 1][Stage 12:=======================>                               (13 + 18) / 31]                                                                                Spark session created successfully.
root
 |-- course_cd: string (nullable = true)
 |-- race_date: date (nullable = true)
 |-- race_number: integer (nullable = true)
 |-- saddle_cloth_number: string (nullable = true)
 |-- horse_id: integer (nullable = true)
 |-- todays_cls: long (nullable = true)
 |-- official_fin: integer (nullable = true)
 |-- speed_rating: integer (nullable = true)
 |-- running_time: double (nullable = true)
 |-- dist_bk_gate1: double (nullable = true)
 |-- dist_bk_gate2: double (nullable = true)
 |-- dist_bk_gate3: double (nullable = true)
 |-- dist_bk_gate4: double (nullable = true)
 |-- avg_speed_fullrace: double (nullable = true)
 |-- avg_stride_length: double (nullable = true)
 |-- strfreq_q1: double (nullable = true)
 |-- strfreq_q2: double (nullable = true)
 |-- strfreq_q3: double (nullable = true)
 |-- strfreq_q4: double (nullable = true)

root
 |-- course_cd: string (nullable = true)
 |-- race_date: date (nullable = true)
 |-- race_number: integer (nullable = true)
 |-- saddle_cloth_number: string (nullable = true)
 |-- horse_id: integer (nullable = true)
 |-- worknum: double (nullable = true)
 |-- days_back: double (nullable = true)
 |-- worktext: string (nullable = true)
 |-- ranking: double (nullable = true)
 |-- rank_group: double (nullable = true)

Executing: ALTER TABLE horse_recent_form ADD PRIMARY KEY (course_cd, race_date, race_number, saddle_cloth_number)
Executing: CREATE INDEX idx_horse_recent_form_horse_id ON horse_recent_form (horse_id)
DDL statements executed successfully.
Executing: ALTER TABLE horse_form_agg ADD PRIMARY KEY (horse_id, as_of_date)
Executing: CREATE INDEX idx_horse_form_agg_horse_id ON horse_form_agg (horse_id)
Executing: CREATE INDEX idx_horse_form_agg_as_of_date ON horse_form_agg (as_of_date)
DDL statements executed successfully.
2025-01-24 05:45:55 - Python script succeeded
2025-01-24 05:45:55 - Job completed
2025-01-25 05:45:01 - Starting stat_type_update job
2025-01-25 05:45:01 - Environment variables loaded from /home/exx/myCode/horse-racing/FoxRiverAIRacing/config/.env
2025-01-25 05:45:01 - Running Python script: /home/exx/myCode/horse-racing/FoxRiverAIRacing/src/data_preprocessing/horse_recent_form.py
25/01/25 05:45:03 WARN Utils: Your hostname, mail.relufox.ai resolves to a loopback address: 127.0.0.1; using 192.168.4.25 instead (on interface eno2)
25/01/25 05:45:03 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
25/01/25 05:45:03 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
25/01/25 05:45:03 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).
25/01/25 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
[Stage 0:>                                                          (0 + 1) / 1]                                                                                [Stage 1:>                                                          (0 + 1) / 1]                                                                                [Stage 2:>                  (0 + 1) / 1][Stage 3:>                  (0 + 1) / 1][Stage 3:>                                                          (0 + 1) / 1][Stage 3:>                  (0 + 1) / 1][Stage 5:>                (0 + 28) / 28][Stage 3:>                  (0 + 1) / 1][Stage 5:=>               (2 + 26) / 28][Stage 3:>                  (0 + 1) / 1][Stage 5:===>             (5 + 23) / 28][Stage 3:>                                                          (0 + 1) / 1][Stage 9:>                                                        (0 + 66) / 66][Stage 9:====>                                                    (5 + 61) / 66][Stage 9:==================>                                     (22 + 44) / 66]                                                                                [Stage 10:>                                                         (0 + 1) / 1][Stage 12:>                                                       (0 + 31) / 31][Stage 12:=>                                                      (1 + 30) / 31]                                                                                Spark session created successfully.
root
 |-- course_cd: string (nullable = true)
 |-- race_date: date (nullable = true)
 |-- race_number: integer (nullable = true)
 |-- saddle_cloth_number: string (nullable = true)
 |-- horse_id: integer (nullable = true)
 |-- todays_cls: long (nullable = true)
 |-- official_fin: integer (nullable = true)
 |-- speed_rating: integer (nullable = true)
 |-- running_time: double (nullable = true)
 |-- dist_bk_gate1: double (nullable = true)
 |-- dist_bk_gate2: double (nullable = true)
 |-- dist_bk_gate3: double (nullable = true)
 |-- dist_bk_gate4: double (nullable = true)
 |-- avg_speed_fullrace: double (nullable = true)
 |-- avg_stride_length: double (nullable = true)
 |-- strfreq_q1: double (nullable = true)
 |-- strfreq_q2: double (nullable = true)
 |-- strfreq_q3: double (nullable = true)
 |-- strfreq_q4: double (nullable = true)

root
 |-- course_cd: string (nullable = true)
 |-- race_date: date (nullable = true)
 |-- race_number: integer (nullable = true)
 |-- saddle_cloth_number: string (nullable = true)
 |-- horse_id: integer (nullable = true)
 |-- worknum: double (nullable = true)
 |-- days_back: double (nullable = true)
 |-- worktext: string (nullable = true)
 |-- ranking: double (nullable = true)
 |-- rank_group: double (nullable = true)

Executing: ALTER TABLE horse_recent_form ADD PRIMARY KEY (course_cd, race_date, race_number, saddle_cloth_number)
Executing: CREATE INDEX idx_horse_recent_form_horse_id ON horse_recent_form (horse_id)
DDL statements executed successfully.
Executing: ALTER TABLE horse_form_agg ADD PRIMARY KEY (horse_id, as_of_date)
Executing: CREATE INDEX idx_horse_form_agg_horse_id ON horse_form_agg (horse_id)
Executing: CREATE INDEX idx_horse_form_agg_as_of_date ON horse_form_agg (as_of_date)
DDL statements executed successfully.
2025-01-25 05:45:56 - Python script succeeded
2025-01-25 05:45:56 - Job completed
2025-01-26 05:45:01 - Starting stat_type_update job
2025-01-26 05:45:01 - Environment variables loaded from /home/exx/myCode/horse-racing/FoxRiverAIRacing/config/.env
2025-01-26 05:45:01 - Running Python script: /home/exx/myCode/horse-racing/FoxRiverAIRacing/src/data_preprocessing/horse_recent_form.py
25/01/26 05:45:02 WARN Utils: Your hostname, mail.relufox.ai resolves to a loopback address: 127.0.0.1; using 192.168.4.25 instead (on interface eno2)
25/01/26 05:45:02 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
25/01/26 05:45:02 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
25/01/26 05:45:02 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).
25/01/26 05:45:02 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
[Stage 0:>                                                          (0 + 1) / 1]                                                                                [Stage 1:>                                                          (0 + 1) / 1]                                                                                [Stage 2:>                  (0 + 1) / 1][Stage 3:>                  (0 + 1) / 1][Stage 3:>                                                          (0 + 1) / 1][Stage 3:>                  (0 + 1) / 1][Stage 5:>                (0 + 28) / 28][Stage 3:>                  (0 + 1) / 1][Stage 5:>                (1 + 27) / 28][Stage 3:>                  (0 + 1) / 1][Stage 5:============>    (20 + 8) / 28][Stage 3:>                                                          (0 + 1) / 1][Stage 9:>                                                        (0 + 66) / 66][Stage 9:===========>                                            (14 + 52) / 66][Stage 9:=======================================>                (46 + 20) / 66]                                                                                [Stage 10:>                                                         (0 + 1) / 1][Stage 12:>                                                       (0 + 31) / 31]                                                                                Spark session created successfully.
root
 |-- course_cd: string (nullable = true)
 |-- race_date: date (nullable = true)
 |-- race_number: integer (nullable = true)
 |-- saddle_cloth_number: string (nullable = true)
 |-- horse_id: integer (nullable = true)
 |-- todays_cls: long (nullable = true)
 |-- official_fin: integer (nullable = true)
 |-- speed_rating: integer (nullable = true)
 |-- running_time: double (nullable = true)
 |-- dist_bk_gate1: double (nullable = true)
 |-- dist_bk_gate2: double (nullable = true)
 |-- dist_bk_gate3: double (nullable = true)
 |-- dist_bk_gate4: double (nullable = true)
 |-- avg_speed_fullrace: double (nullable = true)
 |-- avg_stride_length: double (nullable = true)
 |-- strfreq_q1: double (nullable = true)
 |-- strfreq_q2: double (nullable = true)
 |-- strfreq_q3: double (nullable = true)
 |-- strfreq_q4: double (nullable = true)

root
 |-- course_cd: string (nullable = true)
 |-- race_date: date (nullable = true)
 |-- race_number: integer (nullable = true)
 |-- saddle_cloth_number: string (nullable = true)
 |-- horse_id: integer (nullable = true)
 |-- worknum: double (nullable = true)
 |-- days_back: double (nullable = true)
 |-- worktext: string (nullable = true)
 |-- ranking: double (nullable = true)
 |-- rank_group: double (nullable = true)

Executing: ALTER TABLE horse_recent_form ADD PRIMARY KEY (course_cd, race_date, race_number, saddle_cloth_number)
Executing: CREATE INDEX idx_horse_recent_form_horse_id ON horse_recent_form (horse_id)
DDL statements executed successfully.
Executing: ALTER TABLE horse_form_agg ADD PRIMARY KEY (horse_id, as_of_date)
Executing: CREATE INDEX idx_horse_form_agg_horse_id ON horse_form_agg (horse_id)
Executing: CREATE INDEX idx_horse_form_agg_as_of_date ON horse_form_agg (as_of_date)
DDL statements executed successfully.
2025-01-26 05:45:55 - Python script succeeded
2025-01-26 05:45:55 - Job completed
2025-01-27 05:45:01 - Starting stat_type_update job
2025-01-27 05:45:01 - Environment variables loaded from /home/exx/myCode/horse-racing/FoxRiverAIRacing/config/.env
2025-01-27 05:45:01 - Running Python script: /home/exx/myCode/horse-racing/FoxRiverAIRacing/src/data_preprocessing/horse_recent_form.py
25/01/27 05:45:02 WARN Utils: Your hostname, mail.relufox.ai resolves to a loopback address: 127.0.0.1; using 192.168.4.25 instead (on interface eno2)
25/01/27 05:45:02 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
25/01/27 05:45:02 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
25/01/27 05:45:03 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).
25/01/27 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
25/01/27 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.
[Stage 0:>                                                          (0 + 1) / 1]                                                                                [Stage 1:>                                                          (0 + 1) / 1]                                                                                [Stage 2:>                  (0 + 1) / 1][Stage 3:>                  (0 + 1) / 1][Stage 3:>                                                          (0 + 1) / 1][Stage 3:>                  (0 + 1) / 1][Stage 5:>                (0 + 28) / 28][Stage 3:>                  (0 + 1) / 1][Stage 5:=>               (2 + 26) / 28][Stage 3:>                                                          (0 + 1) / 1][Stage 9:>                                                        (0 + 66) / 66][Stage 9:=========================>                              (30 + 36) / 66]                                                                                [Stage 10:>                                                         (0 + 1) / 1][Stage 12:>                                                       (0 + 31) / 31][Stage 12:=>                                                      (1 + 30) / 31]                                                                                Spark session created successfully.
root
 |-- course_cd: string (nullable = true)
 |-- race_date: date (nullable = true)
 |-- race_number: integer (nullable = true)
 |-- saddle_cloth_number: string (nullable = true)
 |-- horse_id: integer (nullable = true)
 |-- todays_cls: long (nullable = true)
 |-- official_fin: integer (nullable = true)
 |-- speed_rating: integer (nullable = true)
 |-- running_time: double (nullable = true)
 |-- dist_bk_gate1: double (nullable = true)
 |-- dist_bk_gate2: double (nullable = true)
 |-- dist_bk_gate3: double (nullable = true)
 |-- dist_bk_gate4: double (nullable = true)
 |-- avg_speed_fullrace: double (nullable = true)
 |-- avg_stride_length: double (nullable = true)
 |-- strfreq_q1: double (nullable = true)
 |-- strfreq_q2: double (nullable = true)
 |-- strfreq_q3: double (nullable = true)
 |-- strfreq_q4: double (nullable = true)

root
 |-- course_cd: string (nullable = true)
 |-- race_date: date (nullable = true)
 |-- race_number: integer (nullable = true)
 |-- saddle_cloth_number: string (nullable = true)
 |-- horse_id: integer (nullable = true)
 |-- worknum: double (nullable = true)
 |-- days_back: double (nullable = true)
 |-- worktext: string (nullable = true)
 |-- ranking: double (nullable = true)
 |-- rank_group: double (nullable = true)

Executing: ALTER TABLE horse_recent_form ADD PRIMARY KEY (course_cd, race_date, race_number, saddle_cloth_number)
Executing: CREATE INDEX idx_horse_recent_form_horse_id ON horse_recent_form (horse_id)
DDL statements executed successfully.
Executing: ALTER TABLE horse_form_agg ADD PRIMARY KEY (horse_id, as_of_date)
Executing: CREATE INDEX idx_horse_form_agg_horse_id ON horse_form_agg (horse_id)
Executing: CREATE INDEX idx_horse_form_agg_as_of_date ON horse_form_agg (as_of_date)
DDL statements executed successfully.
2025-01-27 05:45:56 - Python script succeeded
2025-01-27 05:45:56 - Job completed
2025-01-28 05:45:01 - Starting stat_type_update job
2025-01-28 05:45:01 - Environment variables loaded from /home/exx/myCode/horse-racing/FoxRiverAIRacing/config/.env
2025-01-28 05:45:01 - Running Python script: /home/exx/myCode/horse-racing/FoxRiverAIRacing/src/data_preprocessing/horse_recent_form.py
25/01/28 05:45:03 WARN Utils: Your hostname, mail.relufox.ai resolves to a loopback address: 127.0.0.1; using 192.168.4.25 instead (on interface eno2)
25/01/28 05:45:03 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
25/01/28 05:45:03 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
25/01/28 05:45:03 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).
25/01/28 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
25/01/28 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.
25/01/28 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.
[Stage 0:>                                                          (0 + 1) / 1]                                                                                [Stage 1:>                                                          (0 + 1) / 1]                                                                                [Stage 2:>                  (0 + 1) / 1][Stage 3:>                  (0 + 1) / 1][Stage 3:>                                                          (0 + 1) / 1][Stage 3:>                  (0 + 1) / 1][Stage 5:>                (0 + 28) / 28][Stage 3:>                  (0 + 1) / 1][Stage 5:>                (1 + 27) / 28][Stage 3:>                                                          (0 + 1) / 1][Stage 9:>                                                        (0 + 66) / 66][Stage 9:==>                                                      (3 + 63) / 66][Stage 9:====>                                                    (5 + 61) / 66][Stage 9:=====>                                                   (6 + 60) / 66][Stage 9:==========>                                             (12 + 54) / 66][Stage 9:==============================>                         (36 + 30) / 66]                                                                                [Stage 10:>                                                         (0 + 1) / 1][Stage 12:>                                                       (0 + 31) / 31]                                                                                Spark session created successfully.
root
 |-- course_cd: string (nullable = true)
 |-- race_date: date (nullable = true)
 |-- race_number: integer (nullable = true)
 |-- saddle_cloth_number: string (nullable = true)
 |-- horse_id: integer (nullable = true)
 |-- todays_cls: long (nullable = true)
 |-- official_fin: integer (nullable = true)
 |-- speed_rating: integer (nullable = true)
 |-- running_time: double (nullable = true)
 |-- dist_bk_gate1: double (nullable = true)
 |-- dist_bk_gate2: double (nullable = true)
 |-- dist_bk_gate3: double (nullable = true)
 |-- dist_bk_gate4: double (nullable = true)
 |-- avg_speed_fullrace: double (nullable = true)
 |-- avg_stride_length: double (nullable = true)
 |-- strfreq_q1: double (nullable = true)
 |-- strfreq_q2: double (nullable = true)
 |-- strfreq_q3: double (nullable = true)
 |-- strfreq_q4: double (nullable = true)

root
 |-- course_cd: string (nullable = true)
 |-- race_date: date (nullable = true)
 |-- race_number: integer (nullable = true)
 |-- saddle_cloth_number: string (nullable = true)
 |-- horse_id: integer (nullable = true)
 |-- worknum: double (nullable = true)
 |-- days_back: double (nullable = true)
 |-- worktext: string (nullable = true)
 |-- ranking: double (nullable = true)
 |-- rank_group: double (nullable = true)

Executing: ALTER TABLE horse_recent_form ADD PRIMARY KEY (course_cd, race_date, race_number, saddle_cloth_number)
Executing: CREATE INDEX idx_horse_recent_form_horse_id ON horse_recent_form (horse_id)
DDL statements executed successfully.
Executing: ALTER TABLE horse_form_agg ADD PRIMARY KEY (horse_id, as_of_date)
Executing: CREATE INDEX idx_horse_form_agg_horse_id ON horse_form_agg (horse_id)
Executing: CREATE INDEX idx_horse_form_agg_as_of_date ON horse_form_agg (as_of_date)
DDL statements executed successfully.
2025-01-28 05:45:55 - Python script succeeded
2025-01-28 05:45:55 - Job completed
2025-01-29 05:45:02 - Starting stat_type_update job
2025-01-29 05:45:02 - Environment variables loaded from /home/exx/myCode/horse-racing/FoxRiverAIRacing/config/.env
2025-01-29 05:45:02 - Running Python script: /home/exx/myCode/horse-racing/FoxRiverAIRacing/src/data_preprocessing/horse_recent_form.py
25/01/29 05:45:03 WARN Utils: Your hostname, mail.relufox.ai resolves to a loopback address: 127.0.0.1; using 192.168.4.25 instead (on interface eno2)
25/01/29 05:45:03 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
25/01/29 05:45:03 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
25/01/29 05:45:03 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).
25/01/29 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
25/01/29 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.
25/01/29 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.
[Stage 0:>                                                          (0 + 1) / 1]                                                                                [Stage 1:>                                                          (0 + 1) / 1]                                                                                [Stage 2:>                  (0 + 1) / 1][Stage 3:>                  (0 + 1) / 1][Stage 3:>                                                          (0 + 1) / 1][Stage 3:>                  (0 + 1) / 1][Stage 5:>                (0 + 28) / 28][Stage 3:>                  (0 + 1) / 1][Stage 5:=>               (2 + 26) / 28][Stage 3:>                                                          (0 + 1) / 1][Stage 9:>                                                        (0 + 66) / 66][Stage 9:=========>                                              (11 + 55) / 66][Stage 9:=====================================>                  (44 + 22) / 66]                                                                                [Stage 10:>                                                         (0 + 1) / 1][Stage 12:===>                                                    (2 + 29) / 31]                                                                                Spark session created successfully.
root
 |-- course_cd: string (nullable = true)
 |-- race_date: date (nullable = true)
 |-- race_number: integer (nullable = true)
 |-- saddle_cloth_number: string (nullable = true)
 |-- horse_id: integer (nullable = true)
 |-- todays_cls: long (nullable = true)
 |-- official_fin: integer (nullable = true)
 |-- speed_rating: integer (nullable = true)
 |-- running_time: double (nullable = true)
 |-- dist_bk_gate1: double (nullable = true)
 |-- dist_bk_gate2: double (nullable = true)
 |-- dist_bk_gate3: double (nullable = true)
 |-- dist_bk_gate4: double (nullable = true)
 |-- avg_speed_fullrace: double (nullable = true)
 |-- avg_stride_length: double (nullable = true)
 |-- strfreq_q1: double (nullable = true)
 |-- strfreq_q2: double (nullable = true)
 |-- strfreq_q3: double (nullable = true)
 |-- strfreq_q4: double (nullable = true)

root
 |-- course_cd: string (nullable = true)
 |-- race_date: date (nullable = true)
 |-- race_number: integer (nullable = true)
 |-- saddle_cloth_number: string (nullable = true)
 |-- horse_id: integer (nullable = true)
 |-- worknum: double (nullable = true)
 |-- days_back: double (nullable = true)
 |-- worktext: string (nullable = true)
 |-- ranking: double (nullable = true)
 |-- rank_group: double (nullable = true)

Executing: ALTER TABLE horse_recent_form ADD PRIMARY KEY (course_cd, race_date, race_number, saddle_cloth_number)
Executing: CREATE INDEX idx_horse_recent_form_horse_id ON horse_recent_form (horse_id)
DDL statements executed successfully.
Executing: ALTER TABLE horse_form_agg ADD PRIMARY KEY (horse_id, as_of_date)
Executing: CREATE INDEX idx_horse_form_agg_horse_id ON horse_form_agg (horse_id)
Executing: CREATE INDEX idx_horse_form_agg_as_of_date ON horse_form_agg (as_of_date)
DDL statements executed successfully.
2025-01-29 05:45:55 - Python script succeeded
2025-01-29 05:45:55 - Job completed
2025-01-30 05:45:01 - Starting stat_type_update job
2025-01-30 05:45:01 - Environment variables loaded from /home/exx/myCode/horse-racing/FoxRiverAIRacing/config/.env
2025-01-30 05:45:01 - Running Python script: /home/exx/myCode/horse-racing/FoxRiverAIRacing/src/data_preprocessing/horse_recent_form.py
25/01/30 05:45:02 WARN Utils: Your hostname, mail.relufox.ai resolves to a loopback address: 127.0.0.1; using 192.168.4.25 instead (on interface eno2)
25/01/30 05:45:02 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
25/01/30 05:45:03 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
25/01/30 05:45:03 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).
25/01/30 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
25/01/30 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.
25/01/30 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.
[Stage 0:>                                                          (0 + 1) / 1]                                                                                [Stage 1:>                                                          (0 + 1) / 1]                                                                                [Stage 2:>                  (0 + 1) / 1][Stage 3:>                  (0 + 1) / 1][Stage 3:>                                                          (0 + 1) / 1][Stage 3:>                  (0 + 1) / 1][Stage 5:>                (0 + 28) / 28][Stage 3:>                  (0 + 1) / 1][Stage 5:>                (1 + 27) / 28][Stage 3:>                                                          (0 + 1) / 1][Stage 9:>                                                        (0 + 66) / 66]                                                                                [Stage 10:>                                                         (0 + 1) / 1][Stage 12:===>                                                    (2 + 29) / 31]                                                                                Spark session created successfully.
root
 |-- course_cd: string (nullable = true)
 |-- race_date: date (nullable = true)
 |-- race_number: integer (nullable = true)
 |-- saddle_cloth_number: string (nullable = true)
 |-- horse_id: integer (nullable = true)
 |-- todays_cls: long (nullable = true)
 |-- official_fin: integer (nullable = true)
 |-- speed_rating: integer (nullable = true)
 |-- running_time: double (nullable = true)
 |-- dist_bk_gate1: double (nullable = true)
 |-- dist_bk_gate2: double (nullable = true)
 |-- dist_bk_gate3: double (nullable = true)
 |-- dist_bk_gate4: double (nullable = true)
 |-- avg_speed_fullrace: double (nullable = true)
 |-- avg_stride_length: double (nullable = true)
 |-- strfreq_q1: double (nullable = true)
 |-- strfreq_q2: double (nullable = true)
 |-- strfreq_q3: double (nullable = true)
 |-- strfreq_q4: double (nullable = true)

root
 |-- course_cd: string (nullable = true)
 |-- race_date: date (nullable = true)
 |-- race_number: integer (nullable = true)
 |-- saddle_cloth_number: string (nullable = true)
 |-- horse_id: integer (nullable = true)
 |-- worknum: double (nullable = true)
 |-- days_back: double (nullable = true)
 |-- worktext: string (nullable = true)
 |-- ranking: double (nullable = true)
 |-- rank_group: double (nullable = true)

Executing: ALTER TABLE horse_recent_form ADD PRIMARY KEY (course_cd, race_date, race_number, saddle_cloth_number)
Executing: CREATE INDEX idx_horse_recent_form_horse_id ON horse_recent_form (horse_id)
DDL statements executed successfully.
Executing: ALTER TABLE horse_form_agg ADD PRIMARY KEY (horse_id, as_of_date)
Executing: CREATE INDEX idx_horse_form_agg_horse_id ON horse_form_agg (horse_id)
Executing: CREATE INDEX idx_horse_form_agg_as_of_date ON horse_form_agg (as_of_date)
DDL statements executed successfully.
2025-01-30 05:45:55 - Python script succeeded
2025-01-30 05:45:55 - Job completed
2025-01-31 05:45:01 - Starting stat_type_update job
2025-01-31 05:45:01 - Environment variables loaded from /home/exx/myCode/horse-racing/FoxRiverAIRacing/config/.env
2025-01-31 05:45:01 - Running Python script: /home/exx/myCode/horse-racing/FoxRiverAIRacing/src/data_preprocessing/horse_recent_form.py
25/01/31 05:45:02 WARN Utils: Your hostname, mail.relufox.ai resolves to a loopback address: 127.0.0.1; using 192.168.4.25 instead (on interface eno2)
25/01/31 05:45:02 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
25/01/31 05:45:02 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
25/01/31 05:45:02 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).
25/01/31 05:45:02 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
25/01/31 05:45:02 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.
25/01/31 05:45:02 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.
[Stage 0:>                                                          (0 + 1) / 1]                                                                                [Stage 1:>                                                          (0 + 1) / 1]                                                                                [Stage 2:>                  (0 + 1) / 1][Stage 3:>                  (0 + 1) / 1][Stage 3:>                                                          (0 + 1) / 1][Stage 3:>                  (0 + 1) / 1][Stage 5:>                (0 + 28) / 28][Stage 3:>                  (0 + 1) / 1][Stage 5:>                (1 + 27) / 28][Stage 3:>                                                          (0 + 1) / 1][Stage 9:>                                                        (0 + 66) / 66][Stage 9:==========>                                             (12 + 54) / 66][Stage 9:=======================>                                (28 + 38) / 66]                                                                                [Stage 10:>                                                         (0 + 1) / 1][Stage 12:>                                                       (0 + 31) / 31]                                                                                Spark session created successfully.
root
 |-- course_cd: string (nullable = true)
 |-- race_date: date (nullable = true)
 |-- race_number: integer (nullable = true)
 |-- saddle_cloth_number: string (nullable = true)
 |-- horse_id: integer (nullable = true)
 |-- todays_cls: long (nullable = true)
 |-- official_fin: integer (nullable = true)
 |-- speed_rating: integer (nullable = true)
 |-- running_time: double (nullable = true)
 |-- dist_bk_gate1: double (nullable = true)
 |-- dist_bk_gate2: double (nullable = true)
 |-- dist_bk_gate3: double (nullable = true)
 |-- dist_bk_gate4: double (nullable = true)
 |-- avg_speed_fullrace: double (nullable = true)
 |-- avg_stride_length: double (nullable = true)
 |-- strfreq_q1: double (nullable = true)
 |-- strfreq_q2: double (nullable = true)
 |-- strfreq_q3: double (nullable = true)
 |-- strfreq_q4: double (nullable = true)

root
 |-- course_cd: string (nullable = true)
 |-- race_date: date (nullable = true)
 |-- race_number: integer (nullable = true)
 |-- saddle_cloth_number: string (nullable = true)
 |-- horse_id: integer (nullable = true)
 |-- worknum: double (nullable = true)
 |-- days_back: double (nullable = true)
 |-- worktext: string (nullable = true)
 |-- ranking: double (nullable = true)
 |-- rank_group: double (nullable = true)

Executing: ALTER TABLE horse_recent_form ADD PRIMARY KEY (course_cd, race_date, race_number, saddle_cloth_number)
Executing: CREATE INDEX idx_horse_recent_form_horse_id ON horse_recent_form (horse_id)
DDL statements executed successfully.
Executing: ALTER TABLE horse_form_agg ADD PRIMARY KEY (horse_id, as_of_date)
Executing: CREATE INDEX idx_horse_form_agg_horse_id ON horse_form_agg (horse_id)
Executing: CREATE INDEX idx_horse_form_agg_as_of_date ON horse_form_agg (as_of_date)
DDL statements executed successfully.
2025-01-31 05:46:01 - Python script succeeded
2025-01-31 05:46:01 - Job completed
2025-02-01 05:45:01 - Starting stat_type_update job
2025-02-01 05:45:01 - Environment variables loaded from /home/exx/myCode/horse-racing/FoxRiverAIRacing/config/.env
2025-02-01 05:45:01 - Running Python script: /home/exx/myCode/horse-racing/FoxRiverAIRacing/src/data_preprocessing/horse_recent_form.py
25/02/01 05:45:03 WARN Utils: Your hostname, mail.relufox.ai resolves to a loopback address: 127.0.0.1; using 192.168.4.25 instead (on interface eno2)
25/02/01 05:45:03 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
25/02/01 05:45:03 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
25/02/01 05:45:03 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).
25/02/01 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
25/02/01 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.
25/02/01 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.
[Stage 0:>                                                          (0 + 1) / 1]                                                                                [Stage 1:>                                                          (0 + 1) / 1]                                                                                [Stage 2:>                  (0 + 1) / 1][Stage 3:>                  (0 + 1) / 1][Stage 3:>                                                          (0 + 1) / 1][Stage 3:>                  (0 + 1) / 1][Stage 5:>                (0 + 28) / 28][Stage 3:>                  (0 + 1) / 1][Stage 5:>                (1 + 27) / 28][Stage 3:>                  (0 + 1) / 1][Stage 5:=>               (2 + 26) / 28][Stage 3:>                                                          (0 + 1) / 1][Stage 9:>                                                        (0 + 66) / 66][Stage 9:>                                                        (1 + 65) / 66][Stage 9:=>                                                       (2 + 64) / 66][Stage 9:==============================================>         (55 + 11) / 66]                                                                                [Stage 10:>                                                         (0 + 1) / 1][Stage 12:>                                                       (0 + 31) / 31][Stage 12:===>                                                    (2 + 29) / 31]                                                                                Spark session created successfully.
root
 |-- course_cd: string (nullable = true)
 |-- race_date: date (nullable = true)
 |-- race_number: integer (nullable = true)
 |-- saddle_cloth_number: string (nullable = true)
 |-- horse_id: integer (nullable = true)
 |-- todays_cls: long (nullable = true)
 |-- official_fin: integer (nullable = true)
 |-- speed_rating: integer (nullable = true)
 |-- running_time: double (nullable = true)
 |-- dist_bk_gate1: double (nullable = true)
 |-- dist_bk_gate2: double (nullable = true)
 |-- dist_bk_gate3: double (nullable = true)
 |-- dist_bk_gate4: double (nullable = true)
 |-- avg_speed_fullrace: double (nullable = true)
 |-- avg_stride_length: double (nullable = true)
 |-- strfreq_q1: double (nullable = true)
 |-- strfreq_q2: double (nullable = true)
 |-- strfreq_q3: double (nullable = true)
 |-- strfreq_q4: double (nullable = true)

root
 |-- course_cd: string (nullable = true)
 |-- race_date: date (nullable = true)
 |-- race_number: integer (nullable = true)
 |-- saddle_cloth_number: string (nullable = true)
 |-- horse_id: integer (nullable = true)
 |-- worknum: double (nullable = true)
 |-- days_back: double (nullable = true)
 |-- worktext: string (nullable = true)
 |-- ranking: double (nullable = true)
 |-- rank_group: double (nullable = true)

Executing: ALTER TABLE horse_recent_form ADD PRIMARY KEY (course_cd, race_date, race_number, saddle_cloth_number)
Executing: CREATE INDEX idx_horse_recent_form_horse_id ON horse_recent_form (horse_id)
DDL statements executed successfully.
Executing: ALTER TABLE horse_form_agg ADD PRIMARY KEY (horse_id, as_of_date)
Executing: CREATE INDEX idx_horse_form_agg_horse_id ON horse_form_agg (horse_id)
Executing: CREATE INDEX idx_horse_form_agg_as_of_date ON horse_form_agg (as_of_date)
DDL statements executed successfully.
2025-02-01 05:45:58 - Python script succeeded
2025-02-01 05:45:58 - Job completed
2025-02-02 05:45:01 - Starting stat_type_update job
2025-02-02 05:45:01 - Environment variables loaded from /home/exx/myCode/horse-racing/FoxRiverAIRacing/config/.env
2025-02-02 05:45:01 - Running Python script: /home/exx/myCode/horse-racing/FoxRiverAIRacing/src/data_preprocessing/horse_recent_form.py
25/02/02 05:45:02 WARN Utils: Your hostname, mail.relufox.ai resolves to a loopback address: 127.0.0.1; using 192.168.4.25 instead (on interface eno2)
25/02/02 05:45:02 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
25/02/02 05:45:02 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
25/02/02 05:45:03 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).
25/02/02 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
25/02/02 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.
25/02/02 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.
[Stage 0:>                                                          (0 + 1) / 1]                                                                                [Stage 1:>                                                          (0 + 1) / 1]                                                                                [Stage 2:>                  (0 + 1) / 1][Stage 3:>                  (0 + 1) / 1][Stage 3:>                                                          (0 + 1) / 1][Stage 3:>                  (0 + 1) / 1][Stage 5:>                (0 + 28) / 28][Stage 3:>                  (0 + 1) / 1][Stage 5:=>               (2 + 26) / 28][Stage 3:>                  (0 + 1) / 1][Stage 5:===>             (5 + 23) / 28][Stage 3:>                                                          (0 + 1) / 1][Stage 9:>                                                        (0 + 66) / 66][Stage 9:===>                                                     (4 + 62) / 66][Stage 9:===========>                                            (14 + 52) / 66][Stage 9:========================================================>(65 + 1) / 66]                                                                                [Stage 10:>                                                         (0 + 1) / 1][Stage 12:===================>                                   (11 + 20) / 31]                                                                                Spark session created successfully.
root
 |-- course_cd: string (nullable = true)
 |-- race_date: date (nullable = true)
 |-- race_number: integer (nullable = true)
 |-- saddle_cloth_number: string (nullable = true)
 |-- horse_id: integer (nullable = true)
 |-- todays_cls: long (nullable = true)
 |-- official_fin: integer (nullable = true)
 |-- speed_rating: integer (nullable = true)
 |-- running_time: double (nullable = true)
 |-- dist_bk_gate1: double (nullable = true)
 |-- dist_bk_gate2: double (nullable = true)
 |-- dist_bk_gate3: double (nullable = true)
 |-- dist_bk_gate4: double (nullable = true)
 |-- avg_speed_fullrace: double (nullable = true)
 |-- avg_stride_length: double (nullable = true)
 |-- strfreq_q1: double (nullable = true)
 |-- strfreq_q2: double (nullable = true)
 |-- strfreq_q3: double (nullable = true)
 |-- strfreq_q4: double (nullable = true)

root
 |-- course_cd: string (nullable = true)
 |-- race_date: date (nullable = true)
 |-- race_number: integer (nullable = true)
 |-- saddle_cloth_number: string (nullable = true)
 |-- horse_id: integer (nullable = true)
 |-- worknum: double (nullable = true)
 |-- days_back: double (nullable = true)
 |-- worktext: string (nullable = true)
 |-- ranking: double (nullable = true)
 |-- rank_group: double (nullable = true)

Executing: ALTER TABLE horse_recent_form ADD PRIMARY KEY (course_cd, race_date, race_number, saddle_cloth_number)
Executing: CREATE INDEX idx_horse_recent_form_horse_id ON horse_recent_form (horse_id)
DDL statements executed successfully.
Executing: ALTER TABLE horse_form_agg ADD PRIMARY KEY (horse_id, as_of_date)
Executing: CREATE INDEX idx_horse_form_agg_horse_id ON horse_form_agg (horse_id)
Executing: CREATE INDEX idx_horse_form_agg_as_of_date ON horse_form_agg (as_of_date)
DDL statements executed successfully.
2025-02-02 05:45:56 - Python script succeeded
2025-02-02 05:45:56 - Job completed
2025-02-03 05:45:01 - Starting stat_type_update job
2025-02-03 05:45:01 - Environment variables loaded from /home/exx/myCode/horse-racing/FoxRiverAIRacing/config/.env
2025-02-03 05:45:01 - Running Python script: /home/exx/myCode/horse-racing/FoxRiverAIRacing/src/data_preprocessing/horse_recent_form.py
25/02/03 05:45:02 WARN Utils: Your hostname, mail.relufox.ai resolves to a loopback address: 127.0.0.1; using 192.168.4.25 instead (on interface eno2)
25/02/03 05:45:02 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
25/02/03 05:45:03 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
25/02/03 05:45:03 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).
25/02/03 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
25/02/03 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.
25/02/03 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.
[Stage 0:>                                                          (0 + 1) / 1]                                                                                [Stage 1:>                                                          (0 + 1) / 1]                                                                                [Stage 2:>                  (0 + 1) / 1][Stage 3:>                  (0 + 1) / 1][Stage 3:>                                                          (0 + 1) / 1][Stage 3:>                  (0 + 1) / 1][Stage 5:>                (0 + 28) / 28][Stage 3:>                  (0 + 1) / 1][Stage 5:>                (1 + 27) / 28][Stage 3:>                                                          (0 + 1) / 1][Stage 9:>                                                        (0 + 66) / 66][Stage 9:===>                                                     (4 + 62) / 66][Stage 9:====>                                                    (5 + 61) / 66][Stage 9:======>                                                  (7 + 59) / 66][Stage 9:===================================>                    (42 + 24) / 66]                                                                                [Stage 10:>                                                         (0 + 1) / 1][Stage 12:>                                                       (0 + 31) / 31][Stage 12:=>                                                      (1 + 30) / 31][Stage 12:===>                                                    (2 + 29) / 31]                                                                                Spark session created successfully.
root
 |-- course_cd: string (nullable = true)
 |-- race_date: date (nullable = true)
 |-- race_number: integer (nullable = true)
 |-- saddle_cloth_number: string (nullable = true)
 |-- horse_id: integer (nullable = true)
 |-- todays_cls: long (nullable = true)
 |-- official_fin: integer (nullable = true)
 |-- speed_rating: integer (nullable = true)
 |-- running_time: double (nullable = true)
 |-- dist_bk_gate1: double (nullable = true)
 |-- dist_bk_gate2: double (nullable = true)
 |-- dist_bk_gate3: double (nullable = true)
 |-- dist_bk_gate4: double (nullable = true)
 |-- avg_speed_fullrace: double (nullable = true)
 |-- avg_stride_length: double (nullable = true)
 |-- strfreq_q1: double (nullable = true)
 |-- strfreq_q2: double (nullable = true)
 |-- strfreq_q3: double (nullable = true)
 |-- strfreq_q4: double (nullable = true)

root
 |-- course_cd: string (nullable = true)
 |-- race_date: date (nullable = true)
 |-- race_number: integer (nullable = true)
 |-- saddle_cloth_number: string (nullable = true)
 |-- horse_id: integer (nullable = true)
 |-- worknum: double (nullable = true)
 |-- days_back: double (nullable = true)
 |-- worktext: string (nullable = true)
 |-- ranking: double (nullable = true)
 |-- rank_group: double (nullable = true)

Executing: ALTER TABLE horse_recent_form ADD PRIMARY KEY (course_cd, race_date, race_number, saddle_cloth_number)
Executing: CREATE INDEX idx_horse_recent_form_horse_id ON horse_recent_form (horse_id)
DDL statements executed successfully.
Executing: ALTER TABLE horse_form_agg ADD PRIMARY KEY (horse_id, as_of_date)
Executing: CREATE INDEX idx_horse_form_agg_horse_id ON horse_form_agg (horse_id)
Executing: CREATE INDEX idx_horse_form_agg_as_of_date ON horse_form_agg (as_of_date)
DDL statements executed successfully.
2025-02-03 05:45:57 - Python script succeeded
2025-02-03 05:45:57 - Job completed
2025-02-04 05:45:01 - Starting stat_type_update job
2025-02-04 05:45:01 - Environment variables loaded from /home/exx/myCode/horse-racing/FoxRiverAIRacing/config/.env
2025-02-04 05:45:01 - Running Python script: /home/exx/myCode/horse-racing/FoxRiverAIRacing/src/data_preprocessing/horse_recent_form.py
25/02/04 05:45:02 WARN Utils: Your hostname, mail.relufox.ai resolves to a loopback address: 127.0.0.1; using 192.168.4.25 instead (on interface eno2)
25/02/04 05:45:02 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
25/02/04 05:45:02 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
25/02/04 05:45:02 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).
25/02/04 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
25/02/04 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.
25/02/04 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.
[Stage 0:>                                                          (0 + 1) / 1]                                                                                [Stage 1:>                                                          (0 + 1) / 1]                                                                                [Stage 2:>                  (0 + 1) / 1][Stage 3:>                  (0 + 1) / 1][Stage 3:>                                                          (0 + 1) / 1][Stage 3:>                  (0 + 1) / 1][Stage 5:>                (0 + 28) / 28][Stage 3:>                  (0 + 1) / 1][Stage 5:>                (1 + 27) / 28][Stage 3:>                                                          (0 + 1) / 1][Stage 9:>                                                        (0 + 66) / 66][Stage 9:====>                                                    (5 + 61) / 66][Stage 9:=================================>                      (40 + 26) / 66]                                                                                [Stage 10:>                                                         (0 + 1) / 1][Stage 12:>                                                       (0 + 31) / 31][Stage 12:=>                                                      (1 + 30) / 31][Stage 12:=================>                                     (10 + 21) / 31]                                                                                Spark session created successfully.
root
 |-- course_cd: string (nullable = true)
 |-- race_date: date (nullable = true)
 |-- race_number: integer (nullable = true)
 |-- saddle_cloth_number: string (nullable = true)
 |-- horse_id: integer (nullable = true)
 |-- todays_cls: long (nullable = true)
 |-- official_fin: integer (nullable = true)
 |-- speed_rating: integer (nullable = true)
 |-- running_time: double (nullable = true)
 |-- dist_bk_gate1: double (nullable = true)
 |-- dist_bk_gate2: double (nullable = true)
 |-- dist_bk_gate3: double (nullable = true)
 |-- dist_bk_gate4: double (nullable = true)
 |-- avg_speed_fullrace: double (nullable = true)
 |-- avg_stride_length: double (nullable = true)
 |-- strfreq_q1: double (nullable = true)
 |-- strfreq_q2: double (nullable = true)
 |-- strfreq_q3: double (nullable = true)
 |-- strfreq_q4: double (nullable = true)

root
 |-- course_cd: string (nullable = true)
 |-- race_date: date (nullable = true)
 |-- race_number: integer (nullable = true)
 |-- saddle_cloth_number: string (nullable = true)
 |-- horse_id: integer (nullable = true)
 |-- worknum: double (nullable = true)
 |-- days_back: double (nullable = true)
 |-- worktext: string (nullable = true)
 |-- ranking: double (nullable = true)
 |-- rank_group: double (nullable = true)

Executing: ALTER TABLE horse_recent_form ADD PRIMARY KEY (course_cd, race_date, race_number, saddle_cloth_number)
Executing: CREATE INDEX idx_horse_recent_form_horse_id ON horse_recent_form (horse_id)
DDL statements executed successfully.
Executing: ALTER TABLE horse_form_agg ADD PRIMARY KEY (horse_id, as_of_date)
Executing: CREATE INDEX idx_horse_form_agg_horse_id ON horse_form_agg (horse_id)
Executing: CREATE INDEX idx_horse_form_agg_as_of_date ON horse_form_agg (as_of_date)
DDL statements executed successfully.
2025-02-04 05:46:19 - Python script succeeded
2025-02-04 05:46:19 - Job completed
2025-02-05 05:45:01 - Starting stat_type_update job
2025-02-05 05:45:01 - Environment variables loaded from /home/exx/myCode/horse-racing/FoxRiverAIRacing/config/.env
2025-02-05 05:45:01 - Running Python script: /home/exx/myCode/horse-racing/FoxRiverAIRacing/src/data_preprocessing/horse_recent_form.py
25/02/05 05:45:02 WARN Utils: Your hostname, mail.relufox.ai resolves to a loopback address: 127.0.0.1; using 192.168.4.25 instead (on interface eno2)
25/02/05 05:45:02 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
25/02/05 05:45:02 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
25/02/05 05:45:02 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).
25/02/05 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
25/02/05 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.
25/02/05 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.
25/02/05 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4043. Attempting port 4044.
[Stage 0:>                                                          (0 + 1) / 1]                                                                                [Stage 1:>                                                          (0 + 1) / 1]                                                                                [Stage 2:>                                                          (0 + 1) / 1][Stage 2:>                  (0 + 1) / 1][Stage 3:>                  (0 + 1) / 1][Stage 3:>                                                          (0 + 1) / 1][Stage 3:>                  (0 + 1) / 1][Stage 5:>                (0 + 28) / 28][Stage 3:>                  (0 + 1) / 1][Stage 5:>                (1 + 27) / 28][Stage 3:>                                                          (0 + 1) / 1][Stage 9:>                                                        (0 + 66) / 66][Stage 9:>                                                        (1 + 65) / 66][Stage 9:=====>                                                   (6 + 60) / 66][Stage 9:==========================================>             (50 + 16) / 66]                                                                                [Stage 10:>                                                         (0 + 1) / 1][Stage 12:>                                                       (0 + 32) / 32][Stage 12:=>                                                      (1 + 31) / 32]                                                                                Spark session created successfully.
root
 |-- course_cd: string (nullable = true)
 |-- race_date: date (nullable = true)
 |-- race_number: integer (nullable = true)
 |-- saddle_cloth_number: string (nullable = true)
 |-- horse_id: integer (nullable = true)
 |-- todays_cls: long (nullable = true)
 |-- official_fin: integer (nullable = true)
 |-- speed_rating: integer (nullable = true)
 |-- running_time: double (nullable = true)
 |-- dist_bk_gate1: double (nullable = true)
 |-- dist_bk_gate2: double (nullable = true)
 |-- dist_bk_gate3: double (nullable = true)
 |-- dist_bk_gate4: double (nullable = true)
 |-- avg_speed_fullrace: double (nullable = true)
 |-- avg_stride_length: double (nullable = true)
 |-- strfreq_q1: double (nullable = true)
 |-- strfreq_q2: double (nullable = true)
 |-- strfreq_q3: double (nullable = true)
 |-- strfreq_q4: double (nullable = true)

root
 |-- course_cd: string (nullable = true)
 |-- race_date: date (nullable = true)
 |-- race_number: integer (nullable = true)
 |-- saddle_cloth_number: string (nullable = true)
 |-- horse_id: integer (nullable = true)
 |-- worknum: double (nullable = true)
 |-- days_back: double (nullable = true)
 |-- worktext: string (nullable = true)
 |-- ranking: double (nullable = true)
 |-- rank_group: double (nullable = true)

Executing: ALTER TABLE horse_recent_form ADD PRIMARY KEY (course_cd, race_date, race_number, saddle_cloth_number)
Executing: CREATE INDEX idx_horse_recent_form_horse_id ON horse_recent_form (horse_id)
DDL statements executed successfully.
Executing: ALTER TABLE horse_form_agg ADD PRIMARY KEY (horse_id, as_of_date)
Executing: CREATE INDEX idx_horse_form_agg_horse_id ON horse_form_agg (horse_id)
Executing: CREATE INDEX idx_horse_form_agg_as_of_date ON horse_form_agg (as_of_date)
DDL statements executed successfully.
2025-02-05 05:46:02 - Python script succeeded
2025-02-05 05:46:02 - Job completed
2025-02-06 05:45:01 - Starting stat_type_update job
2025-02-06 05:45:01 - Environment variables loaded from /home/exx/myCode/horse-racing/FoxRiverAIRacing/config/.env
2025-02-06 05:45:01 - Running Python script: /home/exx/myCode/horse-racing/FoxRiverAIRacing/src/data_preprocessing/horse_recent_form.py
25/02/06 05:45:02 WARN Utils: Your hostname, mail.relufox.ai resolves to a loopback address: 127.0.0.1; using 192.168.4.25 instead (on interface eno2)
25/02/06 05:45:02 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
25/02/06 05:45:03 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
25/02/06 05:45:03 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).
25/02/06 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
25/02/06 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.
25/02/06 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.
[Stage 0:>                                                          (0 + 1) / 1]                                                                                [Stage 1:>                                                          (0 + 1) / 1]                                                                                [Stage 2:>                  (0 + 1) / 1][Stage 3:>                  (0 + 1) / 1][Stage 3:>                                                          (0 + 1) / 1][Stage 3:>                  (0 + 1) / 1][Stage 5:>                (0 + 28) / 28][Stage 3:>                  (0 + 1) / 1][Stage 5:=>               (3 + 25) / 28][Stage 3:>                                                          (0 + 1) / 1][Stage 9:>                                                        (0 + 66) / 66][Stage 9:>                                                        (1 + 65) / 66][Stage 9:===>                                                     (4 + 62) / 66][Stage 9:======>                                                  (8 + 58) / 66]                                                                                [Stage 10:>                                                         (0 + 1) / 1][Stage 12:>                                                       (0 + 32) / 32]                                                                                Spark session created successfully.
root
 |-- course_cd: string (nullable = true)
 |-- race_date: date (nullable = true)
 |-- race_number: integer (nullable = true)
 |-- saddle_cloth_number: string (nullable = true)
 |-- horse_id: integer (nullable = true)
 |-- todays_cls: long (nullable = true)
 |-- official_fin: integer (nullable = true)
 |-- speed_rating: integer (nullable = true)
 |-- running_time: double (nullable = true)
 |-- dist_bk_gate1: double (nullable = true)
 |-- dist_bk_gate2: double (nullable = true)
 |-- dist_bk_gate3: double (nullable = true)
 |-- dist_bk_gate4: double (nullable = true)
 |-- avg_speed_fullrace: double (nullable = true)
 |-- avg_stride_length: double (nullable = true)
 |-- strfreq_q1: double (nullable = true)
 |-- strfreq_q2: double (nullable = true)
 |-- strfreq_q3: double (nullable = true)
 |-- strfreq_q4: double (nullable = true)

root
 |-- course_cd: string (nullable = true)
 |-- race_date: date (nullable = true)
 |-- race_number: integer (nullable = true)
 |-- saddle_cloth_number: string (nullable = true)
 |-- horse_id: integer (nullable = true)
 |-- worknum: double (nullable = true)
 |-- days_back: double (nullable = true)
 |-- worktext: string (nullable = true)
 |-- ranking: double (nullable = true)
 |-- rank_group: double (nullable = true)

Executing: ALTER TABLE horse_recent_form ADD PRIMARY KEY (course_cd, race_date, race_number, saddle_cloth_number)
Executing: CREATE INDEX idx_horse_recent_form_horse_id ON horse_recent_form (horse_id)
DDL statements executed successfully.
Executing: ALTER TABLE horse_form_agg ADD PRIMARY KEY (horse_id, as_of_date)
Executing: CREATE INDEX idx_horse_form_agg_horse_id ON horse_form_agg (horse_id)
Executing: CREATE INDEX idx_horse_form_agg_as_of_date ON horse_form_agg (as_of_date)
DDL statements executed successfully.
2025-02-06 05:46:00 - Python script succeeded
2025-02-06 05:46:00 - Job completed
2025-02-07 05:45:01 - Starting stat_type_update job
2025-02-07 05:45:01 - Environment variables loaded from /home/exx/myCode/horse-racing/FoxRiverAIRacing/config/.env
2025-02-07 05:45:01 - Running Python script: /home/exx/myCode/horse-racing/FoxRiverAIRacing/src/data_preprocessing/horse_recent_form.py
25/02/07 05:45:02 WARN Utils: Your hostname, mail.relufox.ai resolves to a loopback address: 127.0.0.1; using 192.168.4.25 instead (on interface eno2)
25/02/07 05:45:02 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
25/02/07 05:45:03 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
25/02/07 05:45:03 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).
25/02/07 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
25/02/07 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.
25/02/07 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.
[Stage 0:>                                                          (0 + 1) / 1]                                                                                [Stage 1:>                                                          (0 + 1) / 1]                                                                                [Stage 2:>                  (0 + 1) / 1][Stage 3:>                  (0 + 1) / 1][Stage 3:>                                                          (0 + 1) / 1][Stage 3:>                  (0 + 1) / 1][Stage 5:>                (0 + 28) / 28][Stage 3:>                  (0 + 1) / 1][Stage 5:=>               (2 + 26) / 28][Stage 3:>                                                          (0 + 1) / 1][Stage 9:>                                                        (0 + 66) / 66][Stage 9:>                                                        (1 + 65) / 66][Stage 9:===>                                                     (4 + 62) / 66][Stage 9:========>                                               (10 + 56) / 66]                                                                                [Stage 10:>                                                         (0 + 1) / 1][Stage 12:>                                                       (0 + 32) / 32][Stage 12:=====>                                                  (3 + 29) / 32]                                                                                Spark session created successfully.
root
 |-- course_cd: string (nullable = true)
 |-- race_date: date (nullable = true)
 |-- race_number: integer (nullable = true)
 |-- saddle_cloth_number: string (nullable = true)
 |-- horse_id: integer (nullable = true)
 |-- todays_cls: long (nullable = true)
 |-- official_fin: integer (nullable = true)
 |-- speed_rating: integer (nullable = true)
 |-- running_time: double (nullable = true)
 |-- dist_bk_gate1: double (nullable = true)
 |-- dist_bk_gate2: double (nullable = true)
 |-- dist_bk_gate3: double (nullable = true)
 |-- dist_bk_gate4: double (nullable = true)
 |-- avg_speed_fullrace: double (nullable = true)
 |-- avg_stride_length: double (nullable = true)
 |-- strfreq_q1: double (nullable = true)
 |-- strfreq_q2: double (nullable = true)
 |-- strfreq_q3: double (nullable = true)
 |-- strfreq_q4: double (nullable = true)

root
 |-- course_cd: string (nullable = true)
 |-- race_date: date (nullable = true)
 |-- race_number: integer (nullable = true)
 |-- saddle_cloth_number: string (nullable = true)
 |-- horse_id: integer (nullable = true)
 |-- worknum: double (nullable = true)
 |-- days_back: double (nullable = true)
 |-- worktext: string (nullable = true)
 |-- ranking: double (nullable = true)
 |-- rank_group: double (nullable = true)

Executing: ALTER TABLE horse_recent_form ADD PRIMARY KEY (course_cd, race_date, race_number, saddle_cloth_number)
Executing: CREATE INDEX idx_horse_recent_form_horse_id ON horse_recent_form (horse_id)
DDL statements executed successfully.
Executing: ALTER TABLE horse_form_agg ADD PRIMARY KEY (horse_id, as_of_date)
Executing: CREATE INDEX idx_horse_form_agg_horse_id ON horse_form_agg (horse_id)
Executing: CREATE INDEX idx_horse_form_agg_as_of_date ON horse_form_agg (as_of_date)
DDL statements executed successfully.
2025-02-07 05:46:03 - Python script succeeded
2025-02-07 05:46:03 - Job completed
2025-02-08 05:45:01 - Starting stat_type_update job
2025-02-08 05:45:01 - Environment variables loaded from /home/exx/myCode/horse-racing/FoxRiverAIRacing/config/.env
2025-02-08 05:45:01 - Running Python script: /home/exx/myCode/horse-racing/FoxRiverAIRacing/src/data_preprocessing/horse_recent_form.py
25/02/08 05:45:02 WARN Utils: Your hostname, mail.relufox.ai resolves to a loopback address: 127.0.0.1; using 192.168.4.25 instead (on interface eno2)
25/02/08 05:45:02 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
25/02/08 05:45:02 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
25/02/08 05:45:02 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).
25/02/08 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
25/02/08 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.
25/02/08 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.
[Stage 0:>                                                          (0 + 1) / 1]                                                                                [Stage 1:>                                                          (0 + 1) / 1]                                                                                [Stage 2:>                                                          (0 + 1) / 1][Stage 2:>                  (0 + 1) / 1][Stage 3:>                  (0 + 1) / 1][Stage 3:>                                                          (0 + 1) / 1][Stage 3:>                  (0 + 1) / 1][Stage 5:>                (0 + 28) / 28][Stage 3:>                  (0 + 1) / 1][Stage 5:>                (1 + 27) / 28][Stage 3:>                                                          (0 + 1) / 1][Stage 9:>                                                        (0 + 66) / 66][Stage 9:=====>                                                   (6 + 60) / 66][Stage 9:=================>                                      (21 + 45) / 66]                                                                                [Stage 10:>                                                         (0 + 1) / 1][Stage 12:=====>                                                  (3 + 29) / 32]                                                                                Spark session created successfully.
root
 |-- course_cd: string (nullable = true)
 |-- race_date: date (nullable = true)
 |-- race_number: integer (nullable = true)
 |-- saddle_cloth_number: string (nullable = true)
 |-- horse_id: integer (nullable = true)
 |-- todays_cls: long (nullable = true)
 |-- official_fin: integer (nullable = true)
 |-- speed_rating: integer (nullable = true)
 |-- running_time: double (nullable = true)
 |-- dist_bk_gate1: double (nullable = true)
 |-- dist_bk_gate2: double (nullable = true)
 |-- dist_bk_gate3: double (nullable = true)
 |-- dist_bk_gate4: double (nullable = true)
 |-- avg_speed_fullrace: double (nullable = true)
 |-- avg_stride_length: double (nullable = true)
 |-- strfreq_q1: double (nullable = true)
 |-- strfreq_q2: double (nullable = true)
 |-- strfreq_q3: double (nullable = true)
 |-- strfreq_q4: double (nullable = true)

root
 |-- course_cd: string (nullable = true)
 |-- race_date: date (nullable = true)
 |-- race_number: integer (nullable = true)
 |-- saddle_cloth_number: string (nullable = true)
 |-- horse_id: integer (nullable = true)
 |-- worknum: double (nullable = true)
 |-- days_back: double (nullable = true)
 |-- worktext: string (nullable = true)
 |-- ranking: double (nullable = true)
 |-- rank_group: double (nullable = true)

Executing: ALTER TABLE horse_recent_form ADD PRIMARY KEY (course_cd, race_date, race_number, saddle_cloth_number)
Executing: CREATE INDEX idx_horse_recent_form_horse_id ON horse_recent_form (horse_id)
DDL statements executed successfully.
Executing: ALTER TABLE horse_form_agg ADD PRIMARY KEY (horse_id, as_of_date)
Executing: CREATE INDEX idx_horse_form_agg_horse_id ON horse_form_agg (horse_id)
Executing: CREATE INDEX idx_horse_form_agg_as_of_date ON horse_form_agg (as_of_date)
DDL statements executed successfully.
2025-02-08 05:45:59 - Python script succeeded
2025-02-08 05:45:59 - Job completed
2025-02-09 05:45:01 - Starting stat_type_update job
2025-02-09 05:45:01 - Environment variables loaded from /home/exx/myCode/horse-racing/FoxRiverAIRacing/config/.env
2025-02-09 05:45:01 - Running Python script: /home/exx/myCode/horse-racing/FoxRiverAIRacing/src/data_preprocessing/horse_recent_form.py
25/02/09 05:45:02 WARN Utils: Your hostname, mail.relufox.ai resolves to a loopback address: 127.0.0.1; using 192.168.4.25 instead (on interface eno2)
25/02/09 05:45:02 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
25/02/09 05:45:02 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
25/02/09 05:45:02 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).
25/02/09 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
25/02/09 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.
25/02/09 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.
[Stage 0:>                                                          (0 + 1) / 1]                                                                                [Stage 1:>                                                          (0 + 1) / 1]                                                                                [Stage 2:>                  (0 + 1) / 1][Stage 3:>                  (0 + 1) / 1][Stage 3:>                                                          (0 + 1) / 1][Stage 3:>                  (0 + 1) / 1][Stage 5:>                (0 + 28) / 28][Stage 3:>                  (0 + 1) / 1][Stage 5:=>               (2 + 26) / 28][Stage 3:>                                                          (0 + 1) / 1][Stage 9:>                                                        (0 + 66) / 66][Stage 9:>                                                        (1 + 65) / 66][Stage 9:=>                                                       (2 + 64) / 66][Stage 9:==>                                                      (3 + 63) / 66][Stage 9:======>                                                  (8 + 58) / 66][Stage 9:===========================>                            (32 + 34) / 66]                                                                                [Stage 10:>                                                         (0 + 1) / 1][Stage 12:>                                                       (0 + 32) / 32][Stage 12:=>                                                      (1 + 31) / 32][Stage 12:===>                                                    (2 + 30) / 32]                                                                                Spark session created successfully.
root
 |-- course_cd: string (nullable = true)
 |-- race_date: date (nullable = true)
 |-- race_number: integer (nullable = true)
 |-- saddle_cloth_number: string (nullable = true)
 |-- horse_id: integer (nullable = true)
 |-- todays_cls: long (nullable = true)
 |-- official_fin: integer (nullable = true)
 |-- speed_rating: integer (nullable = true)
 |-- running_time: double (nullable = true)
 |-- dist_bk_gate1: double (nullable = true)
 |-- dist_bk_gate2: double (nullable = true)
 |-- dist_bk_gate3: double (nullable = true)
 |-- dist_bk_gate4: double (nullable = true)
 |-- avg_speed_fullrace: double (nullable = true)
 |-- avg_stride_length: double (nullable = true)
 |-- strfreq_q1: double (nullable = true)
 |-- strfreq_q2: double (nullable = true)
 |-- strfreq_q3: double (nullable = true)
 |-- strfreq_q4: double (nullable = true)

root
 |-- course_cd: string (nullable = true)
 |-- race_date: date (nullable = true)
 |-- race_number: integer (nullable = true)
 |-- saddle_cloth_number: string (nullable = true)
 |-- horse_id: integer (nullable = true)
 |-- worknum: double (nullable = true)
 |-- days_back: double (nullable = true)
 |-- worktext: string (nullable = true)
 |-- ranking: double (nullable = true)
 |-- rank_group: double (nullable = true)

Executing: ALTER TABLE horse_recent_form ADD PRIMARY KEY (course_cd, race_date, race_number, saddle_cloth_number)
Executing: CREATE INDEX idx_horse_recent_form_horse_id ON horse_recent_form (horse_id)
DDL statements executed successfully.
Executing: ALTER TABLE horse_form_agg ADD PRIMARY KEY (horse_id, as_of_date)
Executing: CREATE INDEX idx_horse_form_agg_horse_id ON horse_form_agg (horse_id)
Executing: CREATE INDEX idx_horse_form_agg_as_of_date ON horse_form_agg (as_of_date)
DDL statements executed successfully.
2025-02-09 05:46:01 - Python script succeeded
2025-02-09 05:46:01 - Job completed
2025-02-10 05:45:01 - Starting stat_type_update job
2025-02-10 05:45:01 - Environment variables loaded from /home/exx/myCode/horse-racing/FoxRiverAIRacing/config/.env
2025-02-10 05:45:01 - Running Python script: /home/exx/myCode/horse-racing/FoxRiverAIRacing/src/data_preprocessing/horse_recent_form.py
25/02/10 05:45:03 WARN Utils: Your hostname, mail.relufox.ai resolves to a loopback address: 127.0.0.1; using 192.168.4.25 instead (on interface eno2)
25/02/10 05:45:03 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
25/02/10 05:45:03 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
25/02/10 05:45:03 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).
25/02/10 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
25/02/10 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.
25/02/10 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.
[Stage 0:>                                                          (0 + 1) / 1]                                                                                [Stage 1:>                                                          (0 + 1) / 1]                                                                                [Stage 2:>                  (0 + 1) / 1][Stage 3:>                  (0 + 1) / 1][Stage 3:>                                                          (0 + 1) / 1][Stage 3:>                  (0 + 1) / 1][Stage 5:>                (0 + 28) / 28][Stage 3:>                  (0 + 1) / 1][Stage 5:>                (1 + 27) / 28][Stage 3:>                                                          (0 + 1) / 1][Stage 9:>                                                        (0 + 66) / 66][Stage 9:>                                                        (1 + 65) / 66][Stage 9:=>                                                       (2 + 64) / 66][Stage 9:======>                                                  (7 + 59) / 66][Stage 9:==============================================>         (55 + 11) / 66]                                                                                [Stage 10:>                                                         (0 + 1) / 1][Stage 10:==========================================================(1 + 0) / 1][Stage 12:>                                                       (0 + 32) / 32][Stage 12:==============>                                         (8 + 24) / 32][Stage 12:=================>                                     (10 + 22) / 32][Stage 12:=====================================>                 (22 + 10) / 32]                                                                                Spark session created successfully.
root
 |-- course_cd: string (nullable = true)
 |-- race_date: date (nullable = true)
 |-- race_number: integer (nullable = true)
 |-- saddle_cloth_number: string (nullable = true)
 |-- horse_id: integer (nullable = true)
 |-- todays_cls: long (nullable = true)
 |-- official_fin: integer (nullable = true)
 |-- speed_rating: integer (nullable = true)
 |-- running_time: double (nullable = true)
 |-- dist_bk_gate1: double (nullable = true)
 |-- dist_bk_gate2: double (nullable = true)
 |-- dist_bk_gate3: double (nullable = true)
 |-- dist_bk_gate4: double (nullable = true)
 |-- avg_speed_fullrace: double (nullable = true)
 |-- avg_stride_length: double (nullable = true)
 |-- strfreq_q1: double (nullable = true)
 |-- strfreq_q2: double (nullable = true)
 |-- strfreq_q3: double (nullable = true)
 |-- strfreq_q4: double (nullable = true)

root
 |-- course_cd: string (nullable = true)
 |-- race_date: date (nullable = true)
 |-- race_number: integer (nullable = true)
 |-- saddle_cloth_number: string (nullable = true)
 |-- horse_id: integer (nullable = true)
 |-- worknum: double (nullable = true)
 |-- days_back: double (nullable = true)
 |-- worktext: string (nullable = true)
 |-- ranking: double (nullable = true)
 |-- rank_group: double (nullable = true)

Executing: ALTER TABLE horse_recent_form ADD PRIMARY KEY (course_cd, race_date, race_number, saddle_cloth_number)
Executing: CREATE INDEX idx_horse_recent_form_horse_id ON horse_recent_form (horse_id)
DDL statements executed successfully.
Executing: ALTER TABLE horse_form_agg ADD PRIMARY KEY (horse_id, as_of_date)
Executing: CREATE INDEX idx_horse_form_agg_horse_id ON horse_form_agg (horse_id)
Executing: CREATE INDEX idx_horse_form_agg_as_of_date ON horse_form_agg (as_of_date)
DDL statements executed successfully.
2025-02-10 05:46:02 - Python script succeeded
2025-02-10 05:46:02 - Job completed
2025-02-11 05:45:01 - Starting stat_type_update job
2025-02-11 05:45:01 - Environment variables loaded from /home/exx/myCode/horse-racing/FoxRiverAIRacing/config/.env
2025-02-11 05:45:01 - Running Python script: /home/exx/myCode/horse-racing/FoxRiverAIRacing/src/data_preprocessing/horse_recent_form.py
25/02/11 05:45:02 WARN Utils: Your hostname, mail.relufox.ai resolves to a loopback address: 127.0.0.1; using 192.168.4.25 instead (on interface eno2)
25/02/11 05:45:02 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
25/02/11 05:45:02 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
25/02/11 05:45:03 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).
25/02/11 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
25/02/11 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.
25/02/11 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.
[Stage 0:>                                                          (0 + 1) / 1]                                                                                [Stage 1:>                                                          (0 + 1) / 1]                                                                                [Stage 2:>                                                          (0 + 1) / 1]                                                                                [Stage 5:>                  (0 + 1) / 1][Stage 6:>                  (0 + 1) / 1][Stage 6:>                                                          (0 + 1) / 1][Stage 6:>                  (0 + 1) / 1][Stage 8:>                (0 + 41) / 41][Stage 6:>                  (0 + 1) / 1][Stage 8:>                (1 + 40) / 41][Stage 6:>                                                          (0 + 1) / 1][Stage 12:>                                                     (0 + 100) / 100][Stage 12:=========================>                            (47 + 53) / 100]                                                                                [Stage 13:>                                                         (0 + 1) / 1][Stage 15:>                                                       (0 + 50) / 50]                                                                                Spark session created successfully.
root
 |-- course_cd: string (nullable = true)
 |-- race_date: date (nullable = true)
 |-- race_number: integer (nullable = true)
 |-- saddle_cloth_number: string (nullable = true)
 |-- horse_id: integer (nullable = true)
 |-- todays_cls: long (nullable = true)
 |-- official_fin: integer (nullable = true)
 |-- speed_rating: integer (nullable = true)
 |-- running_time: double (nullable = true)
 |-- dist_bk_gate1: double (nullable = true)
 |-- dist_bk_gate2: double (nullable = true)
 |-- dist_bk_gate3: double (nullable = true)
 |-- dist_bk_gate4: double (nullable = true)
 |-- avg_speed_fullrace: double (nullable = true)
 |-- avg_stride_length: double (nullable = true)
 |-- strfreq_q1: double (nullable = true)
 |-- strfreq_q2: double (nullable = true)
 |-- strfreq_q3: double (nullable = true)
 |-- strfreq_q4: double (nullable = true)

root
 |-- course_cd: string (nullable = true)
 |-- race_date: date (nullable = true)
 |-- race_number: integer (nullable = true)
 |-- saddle_cloth_number: string (nullable = true)
 |-- horse_id: integer (nullable = true)
 |-- worknum: double (nullable = true)
 |-- days_back: double (nullable = true)
 |-- worktext: string (nullable = true)
 |-- ranking: double (nullable = true)
 |-- rank_group: double (nullable = true)

Executing: ALTER TABLE horse_recent_form ADD PRIMARY KEY (course_cd, race_date, race_number, saddle_cloth_number)
Executing: CREATE INDEX idx_horse_recent_form_horse_id ON horse_recent_form (horse_id)
DDL statements executed successfully.
Executing: ALTER TABLE horse_form_agg ADD PRIMARY KEY (horse_id, as_of_date)
Executing: CREATE INDEX idx_horse_form_agg_horse_id ON horse_form_agg (horse_id)
Executing: CREATE INDEX idx_horse_form_agg_as_of_date ON horse_form_agg (as_of_date)
DDL statements executed successfully.
2025-02-11 05:46:03 - Python script succeeded
2025-02-11 05:46:03 - Job completed
2025-02-12 05:45:01 - Starting stat_type_update job
2025-02-12 05:45:01 - Environment variables loaded from /home/exx/myCode/horse-racing/FoxRiverAIRacing/config/.env
2025-02-12 05:45:01 - Running Python script: /home/exx/myCode/horse-racing/FoxRiverAIRacing/src/data_preprocessing/horse_recent_form.py
25/02/12 05:45:02 WARN Utils: Your hostname, mail.relufox.ai resolves to a loopback address: 127.0.0.1; using 192.168.4.25 instead (on interface eno2)
25/02/12 05:45:02 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
25/02/12 05:45:02 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
25/02/12 05:45:02 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).
25/02/12 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
25/02/12 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.
25/02/12 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.
25/02/12 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4043. Attempting port 4044.
[Stage 0:>                                                          (0 + 1) / 1]                                                                                [Stage 1:>                                                          (0 + 1) / 1]                                                                                [Stage 2:>                                                          (0 + 1) / 1]                                                                                [Stage 5:>                  (0 + 1) / 1][Stage 6:>                  (0 + 1) / 1][Stage 6:>                                                          (0 + 1) / 1][Stage 6:>                  (0 + 1) / 1][Stage 8:>                (0 + 42) / 42][Stage 6:>                  (0 + 1) / 1][Stage 8:>                (1 + 41) / 42][Stage 6:>                                                          (0 + 1) / 1][Stage 12:>                                                     (0 + 100) / 100][Stage 12:>                                                      (1 + 99) / 100][Stage 12:=>                                                     (2 + 98) / 100][Stage 12:==>                                                    (4 + 96) / 100][Stage 12:========>                                             (16 + 84) / 100]                                                                                [Stage 13:>                                                         (0 + 1) / 1][Stage 15:>                                                       (0 + 50) / 50][Stage 15:=>                                                      (1 + 49) / 50][Stage 15:=============================>                         (27 + 23) / 50]                                                                                Spark session created successfully.
root
 |-- course_cd: string (nullable = true)
 |-- race_date: date (nullable = true)
 |-- race_number: integer (nullable = true)
 |-- saddle_cloth_number: string (nullable = true)
 |-- horse_id: integer (nullable = true)
 |-- todays_cls: long (nullable = true)
 |-- official_fin: integer (nullable = true)
 |-- speed_rating: integer (nullable = true)
 |-- running_time: double (nullable = true)
 |-- dist_bk_gate1: double (nullable = true)
 |-- dist_bk_gate2: double (nullable = true)
 |-- dist_bk_gate3: double (nullable = true)
 |-- dist_bk_gate4: double (nullable = true)
 |-- avg_speed_fullrace: double (nullable = true)
 |-- avg_stride_length: double (nullable = true)
 |-- strfreq_q1: double (nullable = true)
 |-- strfreq_q2: double (nullable = true)
 |-- strfreq_q3: double (nullable = true)
 |-- strfreq_q4: double (nullable = true)

root
 |-- course_cd: string (nullable = true)
 |-- race_date: date (nullable = true)
 |-- race_number: integer (nullable = true)
 |-- saddle_cloth_number: string (nullable = true)
 |-- horse_id: integer (nullable = true)
 |-- worknum: double (nullable = true)
 |-- days_back: double (nullable = true)
 |-- worktext: string (nullable = true)
 |-- ranking: double (nullable = true)
 |-- rank_group: double (nullable = true)

Executing: ALTER TABLE horse_recent_form ADD PRIMARY KEY (course_cd, race_date, race_number, saddle_cloth_number)
Executing: CREATE INDEX idx_horse_recent_form_horse_id ON horse_recent_form (horse_id)
DDL statements executed successfully.
Executing: ALTER TABLE horse_form_agg ADD PRIMARY KEY (horse_id, as_of_date)
Executing: CREATE INDEX idx_horse_form_agg_horse_id ON horse_form_agg (horse_id)
Executing: CREATE INDEX idx_horse_form_agg_as_of_date ON horse_form_agg (as_of_date)
DDL statements executed successfully.
2025-02-12 05:46:08 - Python script succeeded
2025-02-12 05:46:08 - Job completed
2025-02-13 05:45:01 - Starting stat_type_update job
2025-02-13 05:45:01 - Environment variables loaded from /home/exx/myCode/horse-racing/FoxRiverAIRacing/config/.env
2025-02-13 05:45:01 - Running Python script: /home/exx/myCode/horse-racing/FoxRiverAIRacing/src/data_preprocessing/horse_recent_form.py
25/02/13 05:45:02 WARN Utils: Your hostname, mail.relufox.ai resolves to a loopback address: 127.0.0.1; using 192.168.4.25 instead (on interface eno2)
25/02/13 05:45:02 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
25/02/13 05:45:02 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
25/02/13 05:45:02 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).
25/02/13 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
25/02/13 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.
25/02/13 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.
25/02/13 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4043. Attempting port 4044.
[Stage 0:>                                                          (0 + 1) / 1]                                                                                [Stage 1:>                                                          (0 + 1) / 1]                                                                                [Stage 2:>                                                          (0 + 1) / 1]                                                                                [Stage 5:>                                                          (0 + 1) / 1][Stage 5:>                  (0 + 1) / 1][Stage 6:>                  (0 + 1) / 1][Stage 5:===================(1 + 0) / 1][Stage 6:>                  (0 + 1) / 1][Stage 6:>                                                          (0 + 1) / 1][Stage 6:>                  (0 + 1) / 1][Stage 8:>                (0 + 42) / 42][Stage 6:>                  (0 + 1) / 1][Stage 8:>                (1 + 41) / 42][Stage 6:>                                                          (0 + 1) / 1][Stage 12:>                                                     (0 + 100) / 100][Stage 12:>                                                      (1 + 99) / 100][Stage 12:=>                                                     (2 + 98) / 100][Stage 12:=>                                                     (3 + 97) / 100][Stage 12:==>                                                    (4 + 96) / 100][Stage 12:===>                                                   (7 + 93) / 100][Stage 12:=======================>                              (43 + 57) / 100][Stage 12:===================================>                  (66 + 34) / 100]                                                                                [Stage 13:>                                                         (0 + 1) / 1][Stage 15:>                                                       (0 + 50) / 50][Stage 15:==>                                                     (2 + 48) / 50][Stage 15:=======>                                                (7 + 43) / 50][Stage 15:==========>                                             (9 + 41) / 50]                                                                                Spark session created successfully.
root
 |-- course_cd: string (nullable = true)
 |-- race_date: date (nullable = true)
 |-- race_number: integer (nullable = true)
 |-- saddle_cloth_number: string (nullable = true)
 |-- horse_id: integer (nullable = true)
 |-- todays_cls: long (nullable = true)
 |-- official_fin: integer (nullable = true)
 |-- speed_rating: integer (nullable = true)
 |-- running_time: double (nullable = true)
 |-- dist_bk_gate1: double (nullable = true)
 |-- dist_bk_gate2: double (nullable = true)
 |-- dist_bk_gate3: double (nullable = true)
 |-- dist_bk_gate4: double (nullable = true)
 |-- avg_speed_fullrace: double (nullable = true)
 |-- avg_stride_length: double (nullable = true)
 |-- strfreq_q1: double (nullable = true)
 |-- strfreq_q2: double (nullable = true)
 |-- strfreq_q3: double (nullable = true)
 |-- strfreq_q4: double (nullable = true)

root
 |-- course_cd: string (nullable = true)
 |-- race_date: date (nullable = true)
 |-- race_number: integer (nullable = true)
 |-- saddle_cloth_number: string (nullable = true)
 |-- horse_id: integer (nullable = true)
 |-- worknum: double (nullable = true)
 |-- days_back: double (nullable = true)
 |-- worktext: string (nullable = true)
 |-- ranking: double (nullable = true)
 |-- rank_group: double (nullable = true)

Executing: ALTER TABLE horse_recent_form ADD PRIMARY KEY (course_cd, race_date, race_number, saddle_cloth_number)
Executing: CREATE INDEX idx_horse_recent_form_horse_id ON horse_recent_form (horse_id)
DDL statements executed successfully.
Executing: ALTER TABLE horse_form_agg ADD PRIMARY KEY (horse_id, as_of_date)
Executing: CREATE INDEX idx_horse_form_agg_horse_id ON horse_form_agg (horse_id)
Executing: CREATE INDEX idx_horse_form_agg_as_of_date ON horse_form_agg (as_of_date)
DDL statements executed successfully.
2025-02-13 05:46:10 - Python script succeeded
2025-02-13 05:46:10 - Job completed
2025-02-14 05:45:01 - Starting stat_type_update job
2025-02-14 05:45:01 - Environment variables loaded from /home/exx/myCode/horse-racing/FoxRiverAIRacing/config/.env
2025-02-14 05:45:01 - Running Python script: /home/exx/myCode/horse-racing/FoxRiverAIRacing/src/data_preprocessing/horse_recent_form.py
25/02/14 05:45:02 WARN Utils: Your hostname, mail.relufox.ai resolves to a loopback address: 127.0.0.1; using 192.168.4.25 instead (on interface eno2)
25/02/14 05:45:02 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
25/02/14 05:45:02 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
25/02/14 05:45:02 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).
25/02/14 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
25/02/14 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.
25/02/14 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.
25/02/14 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4043. Attempting port 4044.
[Stage 0:>                                                          (0 + 1) / 1]                                                                                [Stage 1:>                                                          (0 + 1) / 1]                                                                                [Stage 2:>                                                          (0 + 1) / 1]                                                                                [Stage 5:>                  (0 + 1) / 1][Stage 6:>                  (0 + 1) / 1][Stage 6:>                                                          (0 + 1) / 1][Stage 6:>                  (0 + 1) / 1][Stage 8:>                (0 + 41) / 41][Stage 6:>                  (0 + 1) / 1][Stage 8:>                (1 + 40) / 41][Stage 6:>                                                          (0 + 1) / 1][Stage 12:>                                                     (0 + 100) / 100][Stage 12:=>                                                     (2 + 98) / 100]                                                                                [Stage 13:>                                                         (0 + 1) / 1][Stage 15:>                                                       (0 + 50) / 50]                                                                                Spark session created successfully.
root
 |-- course_cd: string (nullable = true)
 |-- race_date: date (nullable = true)
 |-- race_number: integer (nullable = true)
 |-- saddle_cloth_number: string (nullable = true)
 |-- horse_id: integer (nullable = true)
 |-- todays_cls: long (nullable = true)
 |-- official_fin: integer (nullable = true)
 |-- speed_rating: integer (nullable = true)
 |-- running_time: double (nullable = true)
 |-- dist_bk_gate1: double (nullable = true)
 |-- dist_bk_gate2: double (nullable = true)
 |-- dist_bk_gate3: double (nullable = true)
 |-- dist_bk_gate4: double (nullable = true)
 |-- avg_speed_fullrace: double (nullable = true)
 |-- avg_stride_length: double (nullable = true)
 |-- strfreq_q1: double (nullable = true)
 |-- strfreq_q2: double (nullable = true)
 |-- strfreq_q3: double (nullable = true)
 |-- strfreq_q4: double (nullable = true)

root
 |-- course_cd: string (nullable = true)
 |-- race_date: date (nullable = true)
 |-- race_number: integer (nullable = true)
 |-- saddle_cloth_number: string (nullable = true)
 |-- horse_id: integer (nullable = true)
 |-- worknum: double (nullable = true)
 |-- days_back: double (nullable = true)
 |-- worktext: string (nullable = true)
 |-- ranking: double (nullable = true)
 |-- rank_group: double (nullable = true)

Executing: ALTER TABLE horse_recent_form ADD PRIMARY KEY (course_cd, race_date, race_number, saddle_cloth_number)
Executing: CREATE INDEX idx_horse_recent_form_horse_id ON horse_recent_form (horse_id)
DDL statements executed successfully.
Executing: ALTER TABLE horse_form_agg ADD PRIMARY KEY (horse_id, as_of_date)
Executing: CREATE INDEX idx_horse_form_agg_horse_id ON horse_form_agg (horse_id)
Executing: CREATE INDEX idx_horse_form_agg_as_of_date ON horse_form_agg (as_of_date)
DDL statements executed successfully.
2025-02-14 05:46:03 - Python script succeeded
2025-02-14 05:46:03 - Job completed
2025-02-15 05:45:01 - Starting stat_type_update job
2025-02-15 05:45:01 - Environment variables loaded from /home/exx/myCode/horse-racing/FoxRiverAIRacing/config/.env
2025-02-15 05:45:01 - Running Python script: /home/exx/myCode/horse-racing/FoxRiverAIRacing/src/data_preprocessing/horse_recent_form.py
25/02/15 05:45:02 WARN Utils: Your hostname, mail.relufox.ai resolves to a loopback address: 127.0.0.1; using 192.168.4.25 instead (on interface eno2)
25/02/15 05:45:02 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
25/02/15 05:45:03 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
25/02/15 05:45:03 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).
25/02/15 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
25/02/15 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.
25/02/15 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.
25/02/15 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4043. Attempting port 4044.
[Stage 0:>                                                          (0 + 1) / 1]                                                                                [Stage 1:>                                                          (0 + 1) / 1]                                                                                [Stage 2:>                                                          (0 + 1) / 1]                                                                                [Stage 5:>                  (0 + 1) / 1][Stage 6:>                  (0 + 1) / 1][Stage 6:>                                                          (0 + 1) / 1][Stage 6:>                  (0 + 1) / 1][Stage 8:>                (0 + 41) / 41][Stage 6:>                  (0 + 1) / 1][Stage 8:>                (2 + 39) / 41][Stage 6:>                  (0 + 1) / 1][Stage 8:=========>      (24 + 17) / 41][Stage 6:>                                                          (0 + 1) / 1][Stage 12:>                                                     (0 + 100) / 100]                                                                                [Stage 13:>                                                         (0 + 1) / 1][Stage 15:>                                                       (0 + 50) / 50][Stage 15:====>                                                   (4 + 46) / 50]                                                                                Spark session created successfully.
root
 |-- course_cd: string (nullable = true)
 |-- race_date: date (nullable = true)
 |-- race_number: integer (nullable = true)
 |-- saddle_cloth_number: string (nullable = true)
 |-- horse_id: integer (nullable = true)
 |-- todays_cls: long (nullable = true)
 |-- official_fin: integer (nullable = true)
 |-- speed_rating: integer (nullable = true)
 |-- running_time: double (nullable = true)
 |-- dist_bk_gate1: double (nullable = true)
 |-- dist_bk_gate2: double (nullable = true)
 |-- dist_bk_gate3: double (nullable = true)
 |-- dist_bk_gate4: double (nullable = true)
 |-- avg_speed_fullrace: double (nullable = true)
 |-- avg_stride_length: double (nullable = true)
 |-- strfreq_q1: double (nullable = true)
 |-- strfreq_q2: double (nullable = true)
 |-- strfreq_q3: double (nullable = true)
 |-- strfreq_q4: double (nullable = true)

root
 |-- course_cd: string (nullable = true)
 |-- race_date: date (nullable = true)
 |-- race_number: integer (nullable = true)
 |-- saddle_cloth_number: string (nullable = true)
 |-- horse_id: integer (nullable = true)
 |-- worknum: double (nullable = true)
 |-- days_back: double (nullable = true)
 |-- worktext: string (nullable = true)
 |-- ranking: double (nullable = true)
 |-- rank_group: double (nullable = true)

Executing: ALTER TABLE horse_recent_form ADD PRIMARY KEY (course_cd, race_date, race_number, saddle_cloth_number)
Executing: CREATE INDEX idx_horse_recent_form_horse_id ON horse_recent_form (horse_id)
DDL statements executed successfully.
Executing: ALTER TABLE horse_form_agg ADD PRIMARY KEY (horse_id, as_of_date)
Executing: CREATE INDEX idx_horse_form_agg_horse_id ON horse_form_agg (horse_id)
Executing: CREATE INDEX idx_horse_form_agg_as_of_date ON horse_form_agg (as_of_date)
DDL statements executed successfully.
2025-02-15 05:46:04 - Python script succeeded
2025-02-15 05:46:04 - Job completed
2025-02-16 05:45:01 - Starting stat_type_update job
2025-02-16 05:45:01 - Environment variables loaded from /home/exx/myCode/horse-racing/FoxRiverAIRacing/config/.env
2025-02-16 05:45:01 - Running Python script: /home/exx/myCode/horse-racing/FoxRiverAIRacing/src/data_preprocessing/horse_recent_form.py
25/02/16 05:45:02 WARN Utils: Your hostname, mail.relufox.ai resolves to a loopback address: 127.0.0.1; using 192.168.4.25 instead (on interface eno2)
25/02/16 05:45:02 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
25/02/16 05:45:02 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
25/02/16 05:45:02 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).
25/02/16 05:45:02 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
25/02/16 05:45:02 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.
25/02/16 05:45:02 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.
25/02/16 05:45:02 WARN Utils: Service 'SparkUI' could not bind on port 4043. Attempting port 4044.
[Stage 0:>                                                          (0 + 1) / 1]                                                                                [Stage 1:>                                                          (0 + 1) / 1]                                                                                [Stage 2:>                                                          (0 + 1) / 1]                                                                                [Stage 5:>                  (0 + 1) / 1][Stage 6:>                  (0 + 1) / 1][Stage 6:>                                                          (0 + 1) / 1][Stage 6:>                  (0 + 1) / 1][Stage 8:>                (0 + 42) / 42][Stage 6:>                  (0 + 1) / 1][Stage 8:=>               (3 + 39) / 42][Stage 6:>                                                          (0 + 1) / 1][Stage 12:>                                                     (0 + 100) / 100][Stage 12:>                                                      (1 + 99) / 100][Stage 12:=============>                                        (25 + 75) / 100]                                                                                [Stage 13:>                                                         (0 + 1) / 1][Stage 15:>                                                       (0 + 50) / 50][Stage 15:=>                                                      (1 + 49) / 50]                                                                                Spark session created successfully.
root
 |-- course_cd: string (nullable = true)
 |-- race_date: date (nullable = true)
 |-- race_number: integer (nullable = true)
 |-- saddle_cloth_number: string (nullable = true)
 |-- horse_id: integer (nullable = true)
 |-- todays_cls: long (nullable = true)
 |-- official_fin: integer (nullable = true)
 |-- speed_rating: integer (nullable = true)
 |-- running_time: double (nullable = true)
 |-- dist_bk_gate1: double (nullable = true)
 |-- dist_bk_gate2: double (nullable = true)
 |-- dist_bk_gate3: double (nullable = true)
 |-- dist_bk_gate4: double (nullable = true)
 |-- avg_speed_fullrace: double (nullable = true)
 |-- avg_stride_length: double (nullable = true)
 |-- strfreq_q1: double (nullable = true)
 |-- strfreq_q2: double (nullable = true)
 |-- strfreq_q3: double (nullable = true)
 |-- strfreq_q4: double (nullable = true)

root
 |-- course_cd: string (nullable = true)
 |-- race_date: date (nullable = true)
 |-- race_number: integer (nullable = true)
 |-- saddle_cloth_number: string (nullable = true)
 |-- horse_id: integer (nullable = true)
 |-- worknum: double (nullable = true)
 |-- days_back: double (nullable = true)
 |-- worktext: string (nullable = true)
 |-- ranking: double (nullable = true)
 |-- rank_group: double (nullable = true)

Executing: ALTER TABLE horse_recent_form ADD PRIMARY KEY (course_cd, race_date, race_number, saddle_cloth_number)
Executing: CREATE INDEX idx_horse_recent_form_horse_id ON horse_recent_form (horse_id)
DDL statements executed successfully.
Executing: ALTER TABLE horse_form_agg ADD PRIMARY KEY (horse_id, as_of_date)
Executing: CREATE INDEX idx_horse_form_agg_horse_id ON horse_form_agg (horse_id)
Executing: CREATE INDEX idx_horse_form_agg_as_of_date ON horse_form_agg (as_of_date)
DDL statements executed successfully.
2025-02-16 05:46:04 - Python script succeeded
2025-02-16 05:46:04 - Job completed
2025-02-17 05:45:01 - Starting stat_type_update job
2025-02-17 05:45:01 - Environment variables loaded from /home/exx/myCode/horse-racing/FoxRiverAIRacing/config/.env
2025-02-17 05:45:01 - Running Python script: /home/exx/myCode/horse-racing/FoxRiverAIRacing/src/data_preprocessing/horse_recent_form.py
25/02/17 05:45:02 WARN Utils: Your hostname, mail.relufox.ai resolves to a loopback address: 127.0.0.1; using 192.168.4.25 instead (on interface eno2)
25/02/17 05:45:02 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
25/02/17 05:45:02 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
25/02/17 05:45:02 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).
25/02/17 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
25/02/17 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.
25/02/17 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.
25/02/17 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4043. Attempting port 4044.
[Stage 0:>                                                          (0 + 1) / 1]                                                                                [Stage 1:>                                                          (0 + 1) / 1]                                                                                [Stage 2:>                                                          (0 + 1) / 1]                                                                                [Stage 5:>                  (0 + 1) / 1][Stage 6:>                  (0 + 1) / 1][Stage 6:>                                                          (0 + 1) / 1][Stage 6:>                  (0 + 1) / 1][Stage 8:>                (0 + 41) / 41][Stage 6:>                  (0 + 1) / 1][Stage 8:>                (1 + 40) / 41][Stage 6:>                                                          (0 + 1) / 1][Stage 12:>                                                     (0 + 100) / 100]                                                                                [Stage 13:>                                                         (0 + 1) / 1][Stage 15:>                                                       (0 + 50) / 50]                                                                                Spark session created successfully.
root
 |-- course_cd: string (nullable = true)
 |-- race_date: date (nullable = true)
 |-- race_number: integer (nullable = true)
 |-- saddle_cloth_number: string (nullable = true)
 |-- horse_id: integer (nullable = true)
 |-- todays_cls: long (nullable = true)
 |-- official_fin: integer (nullable = true)
 |-- speed_rating: integer (nullable = true)
 |-- running_time: double (nullable = true)
 |-- dist_bk_gate1: double (nullable = true)
 |-- dist_bk_gate2: double (nullable = true)
 |-- dist_bk_gate3: double (nullable = true)
 |-- dist_bk_gate4: double (nullable = true)
 |-- avg_speed_fullrace: double (nullable = true)
 |-- avg_stride_length: double (nullable = true)
 |-- strfreq_q1: double (nullable = true)
 |-- strfreq_q2: double (nullable = true)
 |-- strfreq_q3: double (nullable = true)
 |-- strfreq_q4: double (nullable = true)

root
 |-- course_cd: string (nullable = true)
 |-- race_date: date (nullable = true)
 |-- race_number: integer (nullable = true)
 |-- saddle_cloth_number: string (nullable = true)
 |-- horse_id: integer (nullable = true)
 |-- worknum: double (nullable = true)
 |-- days_back: double (nullable = true)
 |-- worktext: string (nullable = true)
 |-- ranking: double (nullable = true)
 |-- rank_group: double (nullable = true)

Executing: ALTER TABLE horse_recent_form ADD PRIMARY KEY (course_cd, race_date, race_number, saddle_cloth_number)
Executing: CREATE INDEX idx_horse_recent_form_horse_id ON horse_recent_form (horse_id)
DDL statements executed successfully.
Executing: ALTER TABLE horse_form_agg ADD PRIMARY KEY (horse_id, as_of_date)
Executing: CREATE INDEX idx_horse_form_agg_horse_id ON horse_form_agg (horse_id)
Executing: CREATE INDEX idx_horse_form_agg_as_of_date ON horse_form_agg (as_of_date)
DDL statements executed successfully.
2025-02-17 05:46:03 - Python script succeeded
2025-02-17 05:46:03 - Job completed
2025-02-18 05:45:01 - Starting stat_type_update job
2025-02-18 05:45:01 - Environment variables loaded from /home/exx/myCode/horse-racing/FoxRiverAIRacing/config/.env
2025-02-18 05:45:01 - Running Python script: /home/exx/myCode/horse-racing/FoxRiverAIRacing/src/data_preprocessing/horse_recent_form.py
25/02/18 05:45:02 WARN Utils: Your hostname, mail.relufox.ai resolves to a loopback address: 127.0.0.1; using 192.168.4.25 instead (on interface eno2)
25/02/18 05:45:02 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
25/02/18 05:45:02 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
25/02/18 05:45:03 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).
25/02/18 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
25/02/18 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.
25/02/18 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.
25/02/18 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4043. Attempting port 4044.
[Stage 0:>                                                          (0 + 1) / 1]                                                                                [Stage 1:>                                                          (0 + 1) / 1]                                                                                [Stage 2:>                                                          (0 + 1) / 1]                                                                                [Stage 5:>                  (0 + 1) / 1][Stage 6:>                  (0 + 1) / 1][Stage 6:>                                                          (0 + 1) / 1][Stage 6:>                  (0 + 1) / 1][Stage 8:>                (0 + 41) / 41][Stage 6:>                  (0 + 1) / 1][Stage 8:>                (1 + 40) / 41][Stage 6:>                                                          (0 + 1) / 1][Stage 12:>                                                     (0 + 100) / 100][Stage 12:=================================>                    (62 + 38) / 100]                                                                                [Stage 13:>                                                         (0 + 1) / 1][Stage 15:>                                                       (0 + 50) / 50][Stage 15:=================================================>      (44 + 6) / 50]                                                                                Spark session created successfully.
root
 |-- course_cd: string (nullable = true)
 |-- race_date: date (nullable = true)
 |-- race_number: integer (nullable = true)
 |-- saddle_cloth_number: string (nullable = true)
 |-- horse_id: integer (nullable = true)
 |-- todays_cls: long (nullable = true)
 |-- official_fin: integer (nullable = true)
 |-- speed_rating: integer (nullable = true)
 |-- running_time: double (nullable = true)
 |-- dist_bk_gate1: double (nullable = true)
 |-- dist_bk_gate2: double (nullable = true)
 |-- dist_bk_gate3: double (nullable = true)
 |-- dist_bk_gate4: double (nullable = true)
 |-- avg_speed_fullrace: double (nullable = true)
 |-- avg_stride_length: double (nullable = true)
 |-- strfreq_q1: double (nullable = true)
 |-- strfreq_q2: double (nullable = true)
 |-- strfreq_q3: double (nullable = true)
 |-- strfreq_q4: double (nullable = true)

root
 |-- course_cd: string (nullable = true)
 |-- race_date: date (nullable = true)
 |-- race_number: integer (nullable = true)
 |-- saddle_cloth_number: string (nullable = true)
 |-- horse_id: integer (nullable = true)
 |-- worknum: double (nullable = true)
 |-- days_back: double (nullable = true)
 |-- worktext: string (nullable = true)
 |-- ranking: double (nullable = true)
 |-- rank_group: double (nullable = true)

Executing: ALTER TABLE horse_recent_form ADD PRIMARY KEY (course_cd, race_date, race_number, saddle_cloth_number)
Executing: CREATE INDEX idx_horse_recent_form_horse_id ON horse_recent_form (horse_id)
DDL statements executed successfully.
Executing: ALTER TABLE horse_form_agg ADD PRIMARY KEY (horse_id, as_of_date)
Executing: CREATE INDEX idx_horse_form_agg_horse_id ON horse_form_agg (horse_id)
Executing: CREATE INDEX idx_horse_form_agg_as_of_date ON horse_form_agg (as_of_date)
DDL statements executed successfully.
2025-02-18 05:46:03 - Python script succeeded
2025-02-18 05:46:03 - Job completed
2025-02-19 05:45:01 - Starting stat_type_update job
2025-02-19 05:45:01 - Environment variables loaded from /home/exx/myCode/horse-racing/FoxRiverAIRacing/config/.env
2025-02-19 05:45:01 - Running Python script: /home/exx/myCode/horse-racing/FoxRiverAIRacing/src/data_preprocessing/horse_recent_form.py
25/02/19 05:45:02 WARN Utils: Your hostname, mail.relufox.ai resolves to a loopback address: 127.0.0.1; using 192.168.4.25 instead (on interface eno2)
25/02/19 05:45:02 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
25/02/19 05:45:03 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
25/02/19 05:45:03 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).
25/02/19 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
25/02/19 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.
25/02/19 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.
25/02/19 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4043. Attempting port 4044.
[Stage 0:>                                                          (0 + 1) / 1]                                                                                [Stage 1:>                                                          (0 + 1) / 1]                                                                                [Stage 2:>                                                          (0 + 1) / 1]                                                                                [Stage 5:>                  (0 + 1) / 1][Stage 6:>                  (0 + 1) / 1][Stage 6:>                                                          (0 + 1) / 1][Stage 6:>                  (0 + 1) / 1][Stage 8:>                (0 + 40) / 40][Stage 6:>                  (0 + 1) / 1][Stage 8:>                (2 + 38) / 40][Stage 6:>                                                          (0 + 1) / 1][Stage 12:>                                                     (0 + 100) / 100][Stage 12:==>                                                    (4 + 96) / 100][Stage 12:==============>                                       (26 + 74) / 100]                                                                                [Stage 13:>                                                         (0 + 1) / 1][Stage 15:>                                                       (0 + 50) / 50][Stage 15:=>                                                      (1 + 49) / 50][Stage 15:==>                                                     (2 + 48) / 50][Stage 15:===============================>                       (29 + 21) / 50]                                                                                Spark session created successfully.
root
 |-- course_cd: string (nullable = true)
 |-- race_date: date (nullable = true)
 |-- race_number: integer (nullable = true)
 |-- saddle_cloth_number: string (nullable = true)
 |-- horse_id: integer (nullable = true)
 |-- todays_cls: long (nullable = true)
 |-- official_fin: integer (nullable = true)
 |-- speed_rating: integer (nullable = true)
 |-- running_time: double (nullable = true)
 |-- dist_bk_gate1: double (nullable = true)
 |-- dist_bk_gate2: double (nullable = true)
 |-- dist_bk_gate3: double (nullable = true)
 |-- dist_bk_gate4: double (nullable = true)
 |-- avg_speed_fullrace: double (nullable = true)
 |-- avg_stride_length: double (nullable = true)
 |-- strfreq_q1: double (nullable = true)
 |-- strfreq_q2: double (nullable = true)
 |-- strfreq_q3: double (nullable = true)
 |-- strfreq_q4: double (nullable = true)

root
 |-- course_cd: string (nullable = true)
 |-- race_date: date (nullable = true)
 |-- race_number: integer (nullable = true)
 |-- saddle_cloth_number: string (nullable = true)
 |-- horse_id: integer (nullable = true)
 |-- worknum: double (nullable = true)
 |-- days_back: double (nullable = true)
 |-- worktext: string (nullable = true)
 |-- ranking: double (nullable = true)
 |-- rank_group: double (nullable = true)

Executing: ALTER TABLE horse_recent_form ADD PRIMARY KEY (course_cd, race_date, race_number, saddle_cloth_number)
Executing: CREATE INDEX idx_horse_recent_form_horse_id ON horse_recent_form (horse_id)
DDL statements executed successfully.
Executing: ALTER TABLE horse_form_agg ADD PRIMARY KEY (horse_id, as_of_date)
Executing: CREATE INDEX idx_horse_form_agg_horse_id ON horse_form_agg (horse_id)
Executing: CREATE INDEX idx_horse_form_agg_as_of_date ON horse_form_agg (as_of_date)
DDL statements executed successfully.
2025-02-19 05:46:05 - Python script succeeded
2025-02-19 05:46:05 - Job completed
2025-02-20 05:45:01 - Starting stat_type_update job
2025-02-20 05:45:01 - Environment variables loaded from /home/exx/myCode/horse-racing/FoxRiverAIRacing/config/.env
2025-02-20 05:45:01 - Running Python script: /home/exx/myCode/horse-racing/FoxRiverAIRacing/src/data_preprocessing/horse_recent_form.py
25/02/20 05:45:02 WARN Utils: Your hostname, mail.relufox.ai resolves to a loopback address: 127.0.0.1; using 192.168.4.25 instead (on interface eno2)
25/02/20 05:45:02 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
25/02/20 05:45:02 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
25/02/20 05:45:02 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).
25/02/20 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
25/02/20 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.
25/02/20 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.
25/02/20 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4043. Attempting port 4044.
[Stage 0:>                                                          (0 + 1) / 1]                                                                                [Stage 1:>                                                          (0 + 1) / 1]                                                                                [Stage 2:>                                                          (0 + 1) / 1]                                                                                [Stage 5:>                  (0 + 1) / 1][Stage 6:>                  (0 + 1) / 1][Stage 6:>                                                          (0 + 1) / 1][Stage 6:>                  (0 + 1) / 1][Stage 8:>                (0 + 40) / 40][Stage 6:>                  (0 + 1) / 1][Stage 8:>                (1 + 39) / 40][Stage 6:>                  (0 + 1) / 1][Stage 8:=====>          (14 + 26) / 40][Stage 6:>                                                          (0 + 1) / 1][Stage 12:>                                                     (0 + 100) / 100][Stage 12:==>                                                    (5 + 95) / 100]                                                                                [Stage 13:>                                                         (0 + 1) / 1][Stage 15:>                                                       (0 + 50) / 50]                                                                                Spark session created successfully.
root
 |-- course_cd: string (nullable = true)
 |-- race_date: date (nullable = true)
 |-- race_number: integer (nullable = true)
 |-- saddle_cloth_number: string (nullable = true)
 |-- horse_id: integer (nullable = true)
 |-- todays_cls: long (nullable = true)
 |-- official_fin: integer (nullable = true)
 |-- speed_rating: integer (nullable = true)
 |-- running_time: double (nullable = true)
 |-- dist_bk_gate1: double (nullable = true)
 |-- dist_bk_gate2: double (nullable = true)
 |-- dist_bk_gate3: double (nullable = true)
 |-- dist_bk_gate4: double (nullable = true)
 |-- avg_speed_fullrace: double (nullable = true)
 |-- avg_stride_length: double (nullable = true)
 |-- strfreq_q1: double (nullable = true)
 |-- strfreq_q2: double (nullable = true)
 |-- strfreq_q3: double (nullable = true)
 |-- strfreq_q4: double (nullable = true)

root
 |-- course_cd: string (nullable = true)
 |-- race_date: date (nullable = true)
 |-- race_number: integer (nullable = true)
 |-- saddle_cloth_number: string (nullable = true)
 |-- horse_id: integer (nullable = true)
 |-- worknum: double (nullable = true)
 |-- days_back: double (nullable = true)
 |-- worktext: string (nullable = true)
 |-- ranking: double (nullable = true)
 |-- rank_group: double (nullable = true)

Executing: ALTER TABLE horse_recent_form ADD PRIMARY KEY (course_cd, race_date, race_number, saddle_cloth_number)
Executing: CREATE INDEX idx_horse_recent_form_horse_id ON horse_recent_form (horse_id)
DDL statements executed successfully.
Executing: ALTER TABLE horse_form_agg ADD PRIMARY KEY (horse_id, as_of_date)
Executing: CREATE INDEX idx_horse_form_agg_horse_id ON horse_form_agg (horse_id)
Executing: CREATE INDEX idx_horse_form_agg_as_of_date ON horse_form_agg (as_of_date)
DDL statements executed successfully.
2025-02-20 05:46:02 - Python script succeeded
2025-02-20 05:46:02 - Job completed
2025-02-21 05:45:01 - Starting stat_type_update job
2025-02-21 05:45:01 - Environment variables loaded from /home/exx/myCode/horse-racing/FoxRiverAIRacing/config/.env
2025-02-21 05:45:01 - Running Python script: /home/exx/myCode/horse-racing/FoxRiverAIRacing/src/data_preprocessing/horse_recent_form.py
25/02/21 05:45:02 WARN Utils: Your hostname, mail.relufox.ai resolves to a loopback address: 127.0.0.1; using 192.168.4.25 instead (on interface eno2)
25/02/21 05:45:02 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
25/02/21 05:45:02 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
25/02/21 05:45:03 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).
25/02/21 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
25/02/21 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.
25/02/21 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.
25/02/21 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4043. Attempting port 4044.
[Stage 0:>                                                          (0 + 1) / 1]                                                                                [Stage 1:>                                                          (0 + 1) / 1]                                                                                [Stage 2:>                                                          (0 + 1) / 1]                                                                                [Stage 5:>                  (0 + 1) / 1][Stage 6:>                  (0 + 1) / 1][Stage 6:>                                                          (0 + 1) / 1][Stage 6:>                  (0 + 1) / 1][Stage 8:>                (0 + 40) / 40][Stage 6:>                  (0 + 1) / 1][Stage 8:>                (1 + 39) / 40][Stage 6:>                                                          (0 + 1) / 1][Stage 12:>                                                     (0 + 100) / 100][Stage 12:=========>                                            (18 + 82) / 100]                                                                                [Stage 13:>                                                         (0 + 1) / 1][Stage 15:>                                                       (0 + 50) / 50]                                                                                Spark session created successfully.
root
 |-- course_cd: string (nullable = true)
 |-- race_date: date (nullable = true)
 |-- race_number: integer (nullable = true)
 |-- saddle_cloth_number: string (nullable = true)
 |-- horse_id: integer (nullable = true)
 |-- todays_cls: long (nullable = true)
 |-- official_fin: integer (nullable = true)
 |-- speed_rating: integer (nullable = true)
 |-- running_time: double (nullable = true)
 |-- dist_bk_gate1: double (nullable = true)
 |-- dist_bk_gate2: double (nullable = true)
 |-- dist_bk_gate3: double (nullable = true)
 |-- dist_bk_gate4: double (nullable = true)
 |-- avg_speed_fullrace: double (nullable = true)
 |-- avg_stride_length: double (nullable = true)
 |-- strfreq_q1: double (nullable = true)
 |-- strfreq_q2: double (nullable = true)
 |-- strfreq_q3: double (nullable = true)
 |-- strfreq_q4: double (nullable = true)

root
 |-- course_cd: string (nullable = true)
 |-- race_date: date (nullable = true)
 |-- race_number: integer (nullable = true)
 |-- saddle_cloth_number: string (nullable = true)
 |-- horse_id: integer (nullable = true)
 |-- worknum: double (nullable = true)
 |-- days_back: double (nullable = true)
 |-- worktext: string (nullable = true)
 |-- ranking: double (nullable = true)
 |-- rank_group: double (nullable = true)

Executing: ALTER TABLE horse_recent_form ADD PRIMARY KEY (course_cd, race_date, race_number, saddle_cloth_number)
Executing: CREATE INDEX idx_horse_recent_form_horse_id ON horse_recent_form (horse_id)
DDL statements executed successfully.
Executing: ALTER TABLE horse_form_agg ADD PRIMARY KEY (horse_id, as_of_date)
Executing: CREATE INDEX idx_horse_form_agg_horse_id ON horse_form_agg (horse_id)
Executing: CREATE INDEX idx_horse_form_agg_as_of_date ON horse_form_agg (as_of_date)
DDL statements executed successfully.
2025-02-21 05:46:03 - Python script succeeded
2025-02-21 05:46:03 - Job completed
2025-02-22 05:45:01 - Starting stat_type_update job
2025-02-22 05:45:01 - Environment variables loaded from /home/exx/myCode/horse-racing/FoxRiverAIRacing/config/.env
2025-02-22 05:45:01 - Running Python script: /home/exx/myCode/horse-racing/FoxRiverAIRacing/src/data_preprocessing/horse_recent_form.py
25/02/22 05:45:03 WARN Utils: Your hostname, mail.relufox.ai resolves to a loopback address: 127.0.0.1; using 192.168.4.25 instead (on interface eno2)
25/02/22 05:45:03 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
25/02/22 05:45:03 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
25/02/22 05:45:03 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).
25/02/22 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
25/02/22 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.
25/02/22 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.
25/02/22 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4043. Attempting port 4044.
25/02/22 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4044. Attempting port 4045.
[Stage 0:>                                                          (0 + 1) / 1]                                                                                [Stage 1:>                                                          (0 + 1) / 1]                                                                                [Stage 2:>                                                          (0 + 1) / 1]                                                                                [Stage 5:>                  (0 + 1) / 1][Stage 6:>                  (0 + 1) / 1][Stage 6:>                                                          (0 + 1) / 1][Stage 6:>                  (0 + 1) / 1][Stage 8:>                (0 + 40) / 40][Stage 6:>                  (0 + 1) / 1][Stage 8:>                (1 + 39) / 40][Stage 6:>                                                          (0 + 1) / 1][Stage 12:>                                                     (0 + 100) / 100][Stage 12:>                                                      (1 + 99) / 100][Stage 12:=>                                                     (2 + 98) / 100][Stage 12:===>                                                   (6 + 94) / 100][Stage 12:========>                                             (15 + 85) / 100][Stage 12:============>                                         (23 + 77) / 100][Stage 12:=======================================>              (73 + 27) / 100]                                                                                [Stage 13:>                                                         (0 + 1) / 1][Stage 15:>                                                       (0 + 50) / 50][Stage 15:=>                                                      (1 + 49) / 50]                                                                                Spark session created successfully.
root
 |-- course_cd: string (nullable = true)
 |-- race_date: date (nullable = true)
 |-- race_number: integer (nullable = true)
 |-- saddle_cloth_number: string (nullable = true)
 |-- horse_id: integer (nullable = true)
 |-- todays_cls: long (nullable = true)
 |-- official_fin: integer (nullable = true)
 |-- speed_rating: integer (nullable = true)
 |-- running_time: double (nullable = true)
 |-- dist_bk_gate1: double (nullable = true)
 |-- dist_bk_gate2: double (nullable = true)
 |-- dist_bk_gate3: double (nullable = true)
 |-- dist_bk_gate4: double (nullable = true)
 |-- avg_speed_fullrace: double (nullable = true)
 |-- avg_stride_length: double (nullable = true)
 |-- strfreq_q1: double (nullable = true)
 |-- strfreq_q2: double (nullable = true)
 |-- strfreq_q3: double (nullable = true)
 |-- strfreq_q4: double (nullable = true)

root
 |-- course_cd: string (nullable = true)
 |-- race_date: date (nullable = true)
 |-- race_number: integer (nullable = true)
 |-- saddle_cloth_number: string (nullable = true)
 |-- horse_id: integer (nullable = true)
 |-- worknum: double (nullable = true)
 |-- days_back: double (nullable = true)
 |-- worktext: string (nullable = true)
 |-- ranking: double (nullable = true)
 |-- rank_group: double (nullable = true)

Executing: ALTER TABLE horse_recent_form ADD PRIMARY KEY (course_cd, race_date, race_number, saddle_cloth_number)
Executing: CREATE INDEX idx_horse_recent_form_horse_id ON horse_recent_form (horse_id)
DDL statements executed successfully.
Executing: ALTER TABLE horse_form_agg ADD PRIMARY KEY (horse_id, as_of_date)
Executing: CREATE INDEX idx_horse_form_agg_horse_id ON horse_form_agg (horse_id)
Executing: CREATE INDEX idx_horse_form_agg_as_of_date ON horse_form_agg (as_of_date)
DDL statements executed successfully.
2025-02-22 05:46:07 - Python script succeeded
2025-02-22 05:46:07 - Job completed
2025-02-23 05:45:01 - Starting stat_type_update job
2025-02-23 05:45:01 - Environment variables loaded from /home/exx/myCode/horse-racing/FoxRiverAIRacing/config/.env
2025-02-23 05:45:01 - Running Python script: /home/exx/myCode/horse-racing/FoxRiverAIRacing/src/data_preprocessing/horse_recent_form.py
25/02/23 05:45:03 WARN Utils: Your hostname, mail.relufox.ai resolves to a loopback address: 127.0.0.1; using 192.168.4.25 instead (on interface eno2)
25/02/23 05:45:03 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
25/02/23 05:45:03 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
25/02/23 05:45:03 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).
25/02/23 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
25/02/23 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.
25/02/23 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.
25/02/23 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4043. Attempting port 4044.
[Stage 0:>                                                          (0 + 1) / 1]                                                                                [Stage 1:>                                                          (0 + 1) / 1]                                                                                [Stage 2:>                                                          (0 + 1) / 1]                                                                                [Stage 5:>                  (0 + 1) / 1][Stage 6:>                  (0 + 1) / 1][Stage 6:>                                                          (0 + 1) / 1][Stage 6:>                  (0 + 1) / 1][Stage 8:>                (0 + 40) / 40][Stage 6:>                  (0 + 1) / 1][Stage 8:>                (1 + 39) / 40][Stage 6:>                                                          (0 + 1) / 1][Stage 12:>                                                     (0 + 100) / 100][Stage 12:=>                                                     (3 + 97) / 100][Stage 12:==>                                                    (4 + 96) / 100][Stage 12:===============>                                      (29 + 71) / 100][Stage 12:=============================>                        (54 + 46) / 100]                                                                                [Stage 13:>                                                         (0 + 1) / 1][Stage 15:>                                                       (0 + 50) / 50][Stage 15:====>                                                   (4 + 46) / 50][Stage 15:===============>                                       (14 + 36) / 50][Stage 15:===================================>                   (32 + 18) / 50]                                                                                Spark session created successfully.
root
 |-- course_cd: string (nullable = true)
 |-- race_date: date (nullable = true)
 |-- race_number: integer (nullable = true)
 |-- saddle_cloth_number: string (nullable = true)
 |-- horse_id: integer (nullable = true)
 |-- todays_cls: long (nullable = true)
 |-- official_fin: integer (nullable = true)
 |-- speed_rating: integer (nullable = true)
 |-- running_time: double (nullable = true)
 |-- dist_bk_gate1: double (nullable = true)
 |-- dist_bk_gate2: double (nullable = true)
 |-- dist_bk_gate3: double (nullable = true)
 |-- dist_bk_gate4: double (nullable = true)
 |-- avg_speed_fullrace: double (nullable = true)
 |-- avg_stride_length: double (nullable = true)
 |-- strfreq_q1: double (nullable = true)
 |-- strfreq_q2: double (nullable = true)
 |-- strfreq_q3: double (nullable = true)
 |-- strfreq_q4: double (nullable = true)

root
 |-- course_cd: string (nullable = true)
 |-- race_date: date (nullable = true)
 |-- race_number: integer (nullable = true)
 |-- saddle_cloth_number: string (nullable = true)
 |-- horse_id: integer (nullable = true)
 |-- worknum: double (nullable = true)
 |-- days_back: double (nullable = true)
 |-- worktext: string (nullable = true)
 |-- ranking: double (nullable = true)
 |-- rank_group: double (nullable = true)

Executing: ALTER TABLE horse_recent_form ADD PRIMARY KEY (course_cd, race_date, race_number, saddle_cloth_number)
Executing: CREATE INDEX idx_horse_recent_form_horse_id ON horse_recent_form (horse_id)
DDL statements executed successfully.
Executing: ALTER TABLE horse_form_agg ADD PRIMARY KEY (horse_id, as_of_date)
Executing: CREATE INDEX idx_horse_form_agg_horse_id ON horse_form_agg (horse_id)
Executing: CREATE INDEX idx_horse_form_agg_as_of_date ON horse_form_agg (as_of_date)
DDL statements executed successfully.
2025-02-23 05:46:08 - Python script succeeded
2025-02-23 05:46:08 - Job completed
2025-02-24 05:45:01 - Starting stat_type_update job
2025-02-24 05:45:01 - Environment variables loaded from /home/exx/myCode/horse-racing/FoxRiverAIRacing/config/.env
2025-02-24 05:45:01 - Running Python script: /home/exx/myCode/horse-racing/FoxRiverAIRacing/src/data_preprocessing/horse_recent_form.py
25/02/24 05:45:02 WARN Utils: Your hostname, mail.relufox.ai resolves to a loopback address: 127.0.0.1; using 192.168.4.25 instead (on interface eno2)
25/02/24 05:45:02 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
25/02/24 05:45:02 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
25/02/24 05:45:03 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).
25/02/24 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
25/02/24 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.
25/02/24 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.
25/02/24 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4043. Attempting port 4044.
25/02/24 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4044. Attempting port 4045.
25/02/24 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4045. Attempting port 4046.
[Stage 0:>                                                          (0 + 1) / 1]                                                                                [Stage 1:>                                                          (0 + 1) / 1]                                                                                [Stage 2:>                                                          (0 + 1) / 1]                                                                                [Stage 5:>                  (0 + 1) / 1][Stage 6:>                  (0 + 1) / 1][Stage 6:>                                                          (0 + 1) / 1][Stage 6:>                  (0 + 1) / 1][Stage 8:>                (0 + 40) / 40][Stage 6:>                  (0 + 1) / 1][Stage 8:>                (2 + 38) / 40][Stage 6:>                  (0 + 1) / 1][Stage 8:===>             (8 + 32) / 40][Stage 6:>                                                          (0 + 1) / 1][Stage 12:>                                                     (0 + 100) / 100][Stage 12:==>                                                    (5 + 95) / 100]                                                                                [Stage 13:>                                                         (0 + 1) / 1][Stage 15:>                                                       (0 + 50) / 50]                                                                                Spark session created successfully.
root
 |-- course_cd: string (nullable = true)
 |-- race_date: date (nullable = true)
 |-- race_number: integer (nullable = true)
 |-- saddle_cloth_number: string (nullable = true)
 |-- horse_id: integer (nullable = true)
 |-- todays_cls: long (nullable = true)
 |-- official_fin: integer (nullable = true)
 |-- speed_rating: integer (nullable = true)
 |-- running_time: double (nullable = true)
 |-- dist_bk_gate1: double (nullable = true)
 |-- dist_bk_gate2: double (nullable = true)
 |-- dist_bk_gate3: double (nullable = true)
 |-- dist_bk_gate4: double (nullable = true)
 |-- avg_speed_fullrace: double (nullable = true)
 |-- avg_stride_length: double (nullable = true)
 |-- strfreq_q1: double (nullable = true)
 |-- strfreq_q2: double (nullable = true)
 |-- strfreq_q3: double (nullable = true)
 |-- strfreq_q4: double (nullable = true)

root
 |-- course_cd: string (nullable = true)
 |-- race_date: date (nullable = true)
 |-- race_number: integer (nullable = true)
 |-- saddle_cloth_number: string (nullable = true)
 |-- horse_id: integer (nullable = true)
 |-- worknum: double (nullable = true)
 |-- days_back: double (nullable = true)
 |-- worktext: string (nullable = true)
 |-- ranking: double (nullable = true)
 |-- rank_group: double (nullable = true)

Executing: ALTER TABLE horse_recent_form ADD PRIMARY KEY (course_cd, race_date, race_number, saddle_cloth_number)
Executing: CREATE INDEX idx_horse_recent_form_horse_id ON horse_recent_form (horse_id)
DDL statements executed successfully.
Executing: ALTER TABLE horse_form_agg ADD PRIMARY KEY (horse_id, as_of_date)
Executing: CREATE INDEX idx_horse_form_agg_horse_id ON horse_form_agg (horse_id)
Executing: CREATE INDEX idx_horse_form_agg_as_of_date ON horse_form_agg (as_of_date)
DDL statements executed successfully.
2025-02-24 05:46:07 - Python script succeeded
2025-02-24 05:46:07 - Job completed
2025-02-25 05:45:01 - Starting stat_type_update job
2025-02-25 05:45:01 - Environment variables loaded from /home/exx/myCode/horse-racing/FoxRiverAIRacing/config/.env
2025-02-25 05:45:01 - Running Python script: /home/exx/myCode/horse-racing/FoxRiverAIRacing/src/data_preprocessing/horse_recent_form.py
25/02/25 05:45:02 WARN Utils: Your hostname, mail.relufox.ai resolves to a loopback address: 127.0.0.1; using 192.168.4.25 instead (on interface eno2)
25/02/25 05:45:02 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
25/02/25 05:45:03 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
25/02/25 05:45:03 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).
25/02/25 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
25/02/25 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.
25/02/25 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.
25/02/25 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4043. Attempting port 4044.
25/02/25 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4044. Attempting port 4045.
25/02/25 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4045. Attempting port 4046.
[Stage 0:>                                                          (0 + 1) / 1]                                                                                [Stage 1:>                                                          (0 + 1) / 1]                                                                                [Stage 2:>                                                          (0 + 1) / 1]                                                                                [Stage 5:>                  (0 + 1) / 1][Stage 6:>                  (0 + 1) / 1][Stage 6:>                                                          (0 + 1) / 1][Stage 6:>                  (0 + 1) / 1][Stage 8:>                (0 + 40) / 40][Stage 6:>                  (0 + 1) / 1][Stage 8:>                (1 + 39) / 40][Stage 6:>                  (0 + 1) / 1][Stage 8:=>               (3 + 37) / 40][Stage 6:>                                                          (0 + 1) / 1][Stage 12:>                                                     (0 + 100) / 100][Stage 12:>                                                      (1 + 99) / 100][Stage 12:=====>                                                (11 + 89) / 100]                                                                                [Stage 13:>                                                         (0 + 1) / 1][Stage 15:>                                                       (0 + 50) / 50][Stage 15:======================>                                (20 + 30) / 50]                                                                                Spark session created successfully.
root
 |-- course_cd: string (nullable = true)
 |-- race_date: date (nullable = true)
 |-- race_number: integer (nullable = true)
 |-- saddle_cloth_number: string (nullable = true)
 |-- horse_id: integer (nullable = true)
 |-- todays_cls: long (nullable = true)
 |-- official_fin: integer (nullable = true)
 |-- speed_rating: integer (nullable = true)
 |-- running_time: double (nullable = true)
 |-- dist_bk_gate1: double (nullable = true)
 |-- dist_bk_gate2: double (nullable = true)
 |-- dist_bk_gate3: double (nullable = true)
 |-- dist_bk_gate4: double (nullable = true)
 |-- avg_speed_fullrace: double (nullable = true)
 |-- avg_stride_length: double (nullable = true)
 |-- strfreq_q1: double (nullable = true)
 |-- strfreq_q2: double (nullable = true)
 |-- strfreq_q3: double (nullable = true)
 |-- strfreq_q4: double (nullable = true)

root
 |-- course_cd: string (nullable = true)
 |-- race_date: date (nullable = true)
 |-- race_number: integer (nullable = true)
 |-- saddle_cloth_number: string (nullable = true)
 |-- horse_id: integer (nullable = true)
 |-- worknum: double (nullable = true)
 |-- days_back: double (nullable = true)
 |-- worktext: string (nullable = true)
 |-- ranking: double (nullable = true)
 |-- rank_group: double (nullable = true)

Executing: ALTER TABLE horse_recent_form ADD PRIMARY KEY (course_cd, race_date, race_number, saddle_cloth_number)
Executing: CREATE INDEX idx_horse_recent_form_horse_id ON horse_recent_form (horse_id)
DDL statements executed successfully.
Executing: ALTER TABLE horse_form_agg ADD PRIMARY KEY (horse_id, as_of_date)
Executing: CREATE INDEX idx_horse_form_agg_horse_id ON horse_form_agg (horse_id)
Executing: CREATE INDEX idx_horse_form_agg_as_of_date ON horse_form_agg (as_of_date)
DDL statements executed successfully.
2025-02-25 05:45:58 - Python script succeeded
2025-02-25 05:45:58 - Job completed
2025-02-26 05:45:01 - Starting stat_type_update job
2025-02-26 05:45:01 - Environment variables loaded from /home/exx/myCode/horse-racing/FoxRiverAIRacing/config/.env
2025-02-26 05:45:01 - Running Python script: /home/exx/myCode/horse-racing/FoxRiverAIRacing/src/data_preprocessing/horse_recent_form.py
25/02/26 05:45:03 WARN Utils: Your hostname, mail.relufox.ai resolves to a loopback address: 127.0.0.1; using 192.168.4.25 instead (on interface eno2)
25/02/26 05:45:03 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
25/02/26 05:45:03 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
25/02/26 05:45:03 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).
25/02/26 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
25/02/26 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.
25/02/26 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.
25/02/26 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4043. Attempting port 4044.
25/02/26 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4044. Attempting port 4045.
[Stage 0:>                                                          (0 + 1) / 1]                                                                                [Stage 1:>                                                          (0 + 1) / 1]                                                                                [Stage 2:>                                                          (0 + 1) / 1]                                                                                [Stage 5:>                  (0 + 1) / 1][Stage 6:>                  (0 + 1) / 1][Stage 6:>                                                          (0 + 1) / 1][Stage 6:>                  (0 + 1) / 1][Stage 8:>                (0 + 40) / 40][Stage 6:>                  (0 + 1) / 1][Stage 8:>                (1 + 39) / 40][Stage 6:>                                                          (0 + 1) / 1][Stage 12:>                                                     (0 + 100) / 100]                                                                                [Stage 13:>                                                         (0 + 1) / 1][Stage 15:>                                                       (0 + 50) / 50][Stage 15:==>                                                     (2 + 48) / 50]                                                                                Spark session created successfully.
root
 |-- course_cd: string (nullable = true)
 |-- race_date: date (nullable = true)
 |-- race_number: integer (nullable = true)
 |-- saddle_cloth_number: string (nullable = true)
 |-- horse_id: integer (nullable = true)
 |-- todays_cls: long (nullable = true)
 |-- official_fin: integer (nullable = true)
 |-- speed_rating: integer (nullable = true)
 |-- running_time: double (nullable = true)
 |-- dist_bk_gate1: double (nullable = true)
 |-- dist_bk_gate2: double (nullable = true)
 |-- dist_bk_gate3: double (nullable = true)
 |-- dist_bk_gate4: double (nullable = true)
 |-- avg_speed_fullrace: double (nullable = true)
 |-- avg_stride_length: double (nullable = true)
 |-- strfreq_q1: double (nullable = true)
 |-- strfreq_q2: double (nullable = true)
 |-- strfreq_q3: double (nullable = true)
 |-- strfreq_q4: double (nullable = true)

root
 |-- course_cd: string (nullable = true)
 |-- race_date: date (nullable = true)
 |-- race_number: integer (nullable = true)
 |-- saddle_cloth_number: string (nullable = true)
 |-- horse_id: integer (nullable = true)
 |-- worknum: double (nullable = true)
 |-- days_back: double (nullable = true)
 |-- worktext: string (nullable = true)
 |-- ranking: double (nullable = true)
 |-- rank_group: double (nullable = true)

Executing: ALTER TABLE horse_recent_form ADD PRIMARY KEY (course_cd, race_date, race_number, saddle_cloth_number)
Executing: CREATE INDEX idx_horse_recent_form_horse_id ON horse_recent_form (horse_id)
DDL statements executed successfully.
Executing: ALTER TABLE horse_form_agg ADD PRIMARY KEY (horse_id, as_of_date)
Executing: CREATE INDEX idx_horse_form_agg_horse_id ON horse_form_agg (horse_id)
Executing: CREATE INDEX idx_horse_form_agg_as_of_date ON horse_form_agg (as_of_date)
DDL statements executed successfully.
2025-02-26 05:45:52 - Python script succeeded
2025-02-26 05:45:52 - Job completed
2025-02-27 05:45:01 - Starting stat_type_update job
2025-02-27 05:45:01 - Environment variables loaded from /home/exx/myCode/horse-racing/FoxRiverAIRacing/config/.env
2025-02-27 05:45:01 - Running Python script: /home/exx/myCode/horse-racing/FoxRiverAIRacing/src/data_preprocessing/horse_recent_form.py
25/02/27 05:45:02 WARN Utils: Your hostname, mail.relufox.ai resolves to a loopback address: 127.0.0.1; using 192.168.4.25 instead (on interface eno2)
25/02/27 05:45:02 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
25/02/27 05:45:02 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
25/02/27 05:45:03 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).
25/02/27 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
25/02/27 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.
25/02/27 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.
25/02/27 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4043. Attempting port 4044.
25/02/27 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4044. Attempting port 4045.
25/02/27 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4045. Attempting port 4046.
[Stage 0:>                                                          (0 + 1) / 1]                                                                                [Stage 1:>                                                          (0 + 1) / 1]                                                                                [Stage 2:>                                                          (0 + 1) / 1]                                                                                [Stage 5:>                  (0 + 1) / 1][Stage 6:>                  (0 + 1) / 1][Stage 6:>                                                          (0 + 1) / 1][Stage 6:>                  (0 + 1) / 1][Stage 8:>                (2 + 38) / 40][Stage 6:>                                                          (0 + 1) / 1][Stage 12:>                                                     (0 + 100) / 100][Stage 12:====>                                                  (9 + 91) / 100][Stage 12:=================================>                    (62 + 38) / 100]                                                                                [Stage 13:>                                                         (0 + 1) / 1][Stage 15:>                                                       (0 + 50) / 50][Stage 15:=====>                                                  (5 + 45) / 50][Stage 15:===============================>                       (29 + 21) / 50]                                                                                Spark session created successfully.
root
 |-- course_cd: string (nullable = true)
 |-- race_date: date (nullable = true)
 |-- race_number: integer (nullable = true)
 |-- saddle_cloth_number: string (nullable = true)
 |-- horse_id: integer (nullable = true)
 |-- todays_cls: long (nullable = true)
 |-- official_fin: integer (nullable = true)
 |-- speed_rating: integer (nullable = true)
 |-- running_time: double (nullable = true)
 |-- dist_bk_gate1: double (nullable = true)
 |-- dist_bk_gate2: double (nullable = true)
 |-- dist_bk_gate3: double (nullable = true)
 |-- dist_bk_gate4: double (nullable = true)
 |-- avg_speed_fullrace: double (nullable = true)
 |-- avg_stride_length: double (nullable = true)
 |-- strfreq_q1: double (nullable = true)
 |-- strfreq_q2: double (nullable = true)
 |-- strfreq_q3: double (nullable = true)
 |-- strfreq_q4: double (nullable = true)

root
 |-- course_cd: string (nullable = true)
 |-- race_date: date (nullable = true)
 |-- race_number: integer (nullable = true)
 |-- saddle_cloth_number: string (nullable = true)
 |-- horse_id: integer (nullable = true)
 |-- worknum: double (nullable = true)
 |-- days_back: double (nullable = true)
 |-- worktext: string (nullable = true)
 |-- ranking: double (nullable = true)
 |-- rank_group: double (nullable = true)

Executing: ALTER TABLE horse_recent_form ADD PRIMARY KEY (course_cd, race_date, race_number, saddle_cloth_number)
Executing: CREATE INDEX idx_horse_recent_form_horse_id ON horse_recent_form (horse_id)
DDL statements executed successfully.
Executing: ALTER TABLE horse_form_agg ADD PRIMARY KEY (horse_id, as_of_date)
Executing: CREATE INDEX idx_horse_form_agg_horse_id ON horse_form_agg (horse_id)
Executing: CREATE INDEX idx_horse_form_agg_as_of_date ON horse_form_agg (as_of_date)
DDL statements executed successfully.
2025-02-27 05:45:58 - Python script succeeded
2025-02-27 05:45:58 - Job completed
2025-02-28 05:45:01 - Starting stat_type_update job
2025-02-28 05:45:01 - Environment variables loaded from /home/exx/myCode/horse-racing/FoxRiverAIRacing/config/.env
2025-02-28 05:45:01 - Running Python script: /home/exx/myCode/horse-racing/FoxRiverAIRacing/src/data_preprocessing/horse_recent_form.py
25/02/28 05:45:02 WARN Utils: Your hostname, mail.relufox.ai resolves to a loopback address: 127.0.0.1; using 192.168.4.25 instead (on interface eno2)
25/02/28 05:45:02 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
25/02/28 05:45:02 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
25/02/28 05:45:02 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).
25/02/28 05:45:02 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
25/02/28 05:45:02 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.
25/02/28 05:45:02 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.
25/02/28 05:45:02 WARN Utils: Service 'SparkUI' could not bind on port 4043. Attempting port 4044.
25/02/28 05:45:02 WARN Utils: Service 'SparkUI' could not bind on port 4044. Attempting port 4045.
[Stage 0:>                                                          (0 + 1) / 1]                                                                                [Stage 1:>                                                          (0 + 1) / 1]                                                                                [Stage 2:>                                                          (0 + 1) / 1]                                                                                [Stage 5:>                                                          (0 + 1) / 1][Stage 5:>                  (0 + 1) / 1][Stage 6:>                  (0 + 1) / 1][Stage 6:>                                                          (0 + 1) / 1][Stage 6:>                  (0 + 1) / 1][Stage 8:>                (0 + 40) / 40][Stage 6:>                  (0 + 1) / 1][Stage 8:>                (1 + 39) / 40][Stage 6:>                  (0 + 1) / 1][Stage 8:>                (2 + 38) / 40][Stage 6:>                                                          (0 + 1) / 1][Stage 12:>                                                     (0 + 100) / 100][Stage 12:>                                                      (1 + 99) / 100][Stage 12:===>                                                   (6 + 94) / 100][Stage 12:==========================================>           (78 + 22) / 100]                                                                                [Stage 13:>                                                         (0 + 1) / 1][Stage 15:>                                                       (0 + 50) / 50][Stage 15:====>                                                   (4 + 46) / 50]                                                                                Spark session created successfully.
root
 |-- course_cd: string (nullable = true)
 |-- race_date: date (nullable = true)
 |-- race_number: integer (nullable = true)
 |-- saddle_cloth_number: string (nullable = true)
 |-- horse_id: integer (nullable = true)
 |-- todays_cls: long (nullable = true)
 |-- official_fin: integer (nullable = true)
 |-- speed_rating: integer (nullable = true)
 |-- running_time: double (nullable = true)
 |-- dist_bk_gate1: double (nullable = true)
 |-- dist_bk_gate2: double (nullable = true)
 |-- dist_bk_gate3: double (nullable = true)
 |-- dist_bk_gate4: double (nullable = true)
 |-- avg_speed_fullrace: double (nullable = true)
 |-- avg_stride_length: double (nullable = true)
 |-- strfreq_q1: double (nullable = true)
 |-- strfreq_q2: double (nullable = true)
 |-- strfreq_q3: double (nullable = true)
 |-- strfreq_q4: double (nullable = true)

root
 |-- course_cd: string (nullable = true)
 |-- race_date: date (nullable = true)
 |-- race_number: integer (nullable = true)
 |-- saddle_cloth_number: string (nullable = true)
 |-- horse_id: integer (nullable = true)
 |-- worknum: double (nullable = true)
 |-- days_back: double (nullable = true)
 |-- worktext: string (nullable = true)
 |-- ranking: double (nullable = true)
 |-- rank_group: double (nullable = true)

Executing: ALTER TABLE horse_recent_form ADD PRIMARY KEY (course_cd, race_date, race_number, saddle_cloth_number)
Executing: CREATE INDEX idx_horse_recent_form_horse_id ON horse_recent_form (horse_id)
DDL statements executed successfully.
Executing: ALTER TABLE horse_form_agg ADD PRIMARY KEY (horse_id, as_of_date)
Executing: CREATE INDEX idx_horse_form_agg_horse_id ON horse_form_agg (horse_id)
Executing: CREATE INDEX idx_horse_form_agg_as_of_date ON horse_form_agg (as_of_date)
DDL statements executed successfully.
2025-02-28 05:45:57 - Python script succeeded
2025-02-28 05:45:57 - Job completed
2025-03-01 05:45:01 - Starting stat_type_update job
2025-03-01 05:45:01 - Environment variables loaded from /home/exx/myCode/horse-racing/FoxRiverAIRacing/config/.env
2025-03-01 05:45:01 - Running Python script: /home/exx/myCode/horse-racing/FoxRiverAIRacing/src/data_preprocessing/horse_recent_form.py
25/03/01 05:45:02 WARN Utils: Your hostname, mail.relufox.ai resolves to a loopback address: 127.0.0.1; using 192.168.4.25 instead (on interface eno2)
25/03/01 05:45:02 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
25/03/01 05:45:03 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
25/03/01 05:45:03 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).
25/03/01 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
25/03/01 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.
25/03/01 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.
25/03/01 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4043. Attempting port 4044.
25/03/01 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4044. Attempting port 4045.
[Stage 0:>                                                          (0 + 1) / 1]                                                                                [Stage 1:>                                                          (0 + 1) / 1]                                                                                [Stage 2:>                                                          (0 + 1) / 1]                                                                                [Stage 5:>                  (0 + 1) / 1][Stage 6:>                  (0 + 1) / 1][Stage 6:>                                                          (0 + 1) / 1][Stage 6:>                  (0 + 1) / 1][Stage 8:>                (0 + 40) / 40][Stage 6:>                  (0 + 1) / 1][Stage 8:>                (1 + 39) / 40][Stage 6:>                  (0 + 1) / 1][Stage 8:====>           (10 + 30) / 40][Stage 6:>                                                          (0 + 1) / 1][Stage 12:>                                                     (0 + 100) / 100]                                                                                [Stage 13:>                                                         (0 + 1) / 1][Stage 15:>                                                       (0 + 50) / 50]                                                                                Spark session created successfully.
root
 |-- course_cd: string (nullable = true)
 |-- race_date: date (nullable = true)
 |-- race_number: integer (nullable = true)
 |-- saddle_cloth_number: string (nullable = true)
 |-- horse_id: integer (nullable = true)
 |-- todays_cls: long (nullable = true)
 |-- official_fin: integer (nullable = true)
 |-- speed_rating: integer (nullable = true)
 |-- running_time: double (nullable = true)
 |-- dist_bk_gate1: double (nullable = true)
 |-- dist_bk_gate2: double (nullable = true)
 |-- dist_bk_gate3: double (nullable = true)
 |-- dist_bk_gate4: double (nullable = true)
 |-- avg_speed_fullrace: double (nullable = true)
 |-- avg_stride_length: double (nullable = true)
 |-- strfreq_q1: double (nullable = true)
 |-- strfreq_q2: double (nullable = true)
 |-- strfreq_q3: double (nullable = true)
 |-- strfreq_q4: double (nullable = true)

root
 |-- course_cd: string (nullable = true)
 |-- race_date: date (nullable = true)
 |-- race_number: integer (nullable = true)
 |-- saddle_cloth_number: string (nullable = true)
 |-- horse_id: integer (nullable = true)
 |-- worknum: double (nullable = true)
 |-- days_back: double (nullable = true)
 |-- worktext: string (nullable = true)
 |-- ranking: double (nullable = true)
 |-- rank_group: double (nullable = true)

Executing: ALTER TABLE horse_recent_form ADD PRIMARY KEY (course_cd, race_date, race_number, saddle_cloth_number)
Executing: CREATE INDEX idx_horse_recent_form_horse_id ON horse_recent_form (horse_id)
DDL statements executed successfully.
Executing: ALTER TABLE horse_form_agg ADD PRIMARY KEY (horse_id, as_of_date)
Executing: CREATE INDEX idx_horse_form_agg_horse_id ON horse_form_agg (horse_id)
Executing: CREATE INDEX idx_horse_form_agg_as_of_date ON horse_form_agg (as_of_date)
DDL statements executed successfully.
2025-03-01 05:45:54 - Python script succeeded
2025-03-01 05:45:54 - Job completed
2025-03-02 05:45:01 - Starting stat_type_update job
2025-03-02 05:45:01 - Environment variables loaded from /home/exx/myCode/horse-racing/FoxRiverAIRacing/config/.env
2025-03-02 05:45:01 - Running Python script: /home/exx/myCode/horse-racing/FoxRiverAIRacing/src/data_preprocessing/horse_recent_form.py
25/03/02 05:45:02 WARN Utils: Your hostname, mail.relufox.ai resolves to a loopback address: 127.0.0.1; using 192.168.4.25 instead (on interface eno2)
25/03/02 05:45:02 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
25/03/02 05:45:02 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
25/03/02 05:45:03 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).
25/03/02 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
25/03/02 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.
25/03/02 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.
25/03/02 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4043. Attempting port 4044.
25/03/02 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4044. Attempting port 4045.
25/03/02 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4045. Attempting port 4046.
[Stage 0:>                                                          (0 + 1) / 1]                                                                                [Stage 1:>                                                          (0 + 1) / 1]                                                                                [Stage 2:>                                                          (0 + 1) / 1]                                                                                [Stage 5:>                                                          (0 + 1) / 1][Stage 5:>                  (0 + 1) / 1][Stage 6:>                  (0 + 1) / 1][Stage 6:>                                                          (0 + 1) / 1][Stage 6:>                  (0 + 1) / 1][Stage 8:>                (0 + 40) / 40][Stage 6:>                  (0 + 1) / 1][Stage 8:>                (1 + 39) / 40][Stage 6:>                  (0 + 1) / 1][Stage 8:=====>          (14 + 26) / 40][Stage 6:>                                                          (0 + 1) / 1][Stage 12:>                                                     (0 + 100) / 100][Stage 12:=====>                                                (11 + 89) / 100][Stage 12:===========================>                          (51 + 49) / 100]                                                                                [Stage 13:>                                                         (0 + 1) / 1][Stage 15:>                                                       (0 + 50) / 50][Stage 15:=>                                                      (1 + 49) / 50][Stage 15:==>                                                     (2 + 48) / 50]                                                                                Spark session created successfully.
root
 |-- course_cd: string (nullable = true)
 |-- race_date: date (nullable = true)
 |-- race_number: integer (nullable = true)
 |-- saddle_cloth_number: string (nullable = true)
 |-- horse_id: integer (nullable = true)
 |-- todays_cls: long (nullable = true)
 |-- official_fin: integer (nullable = true)
 |-- speed_rating: integer (nullable = true)
 |-- running_time: double (nullable = true)
 |-- dist_bk_gate1: double (nullable = true)
 |-- dist_bk_gate2: double (nullable = true)
 |-- dist_bk_gate3: double (nullable = true)
 |-- dist_bk_gate4: double (nullable = true)
 |-- avg_speed_fullrace: double (nullable = true)
 |-- avg_stride_length: double (nullable = true)
 |-- strfreq_q1: double (nullable = true)
 |-- strfreq_q2: double (nullable = true)
 |-- strfreq_q3: double (nullable = true)
 |-- strfreq_q4: double (nullable = true)

root
 |-- course_cd: string (nullable = true)
 |-- race_date: date (nullable = true)
 |-- race_number: integer (nullable = true)
 |-- saddle_cloth_number: string (nullable = true)
 |-- horse_id: integer (nullable = true)
 |-- worknum: double (nullable = true)
 |-- days_back: double (nullable = true)
 |-- worktext: string (nullable = true)
 |-- ranking: double (nullable = true)
 |-- rank_group: double (nullable = true)

Executing: ALTER TABLE horse_recent_form ADD PRIMARY KEY (course_cd, race_date, race_number, saddle_cloth_number)
Executing: CREATE INDEX idx_horse_recent_form_horse_id ON horse_recent_form (horse_id)
DDL statements executed successfully.
Executing: ALTER TABLE horse_form_agg ADD PRIMARY KEY (horse_id, as_of_date)
Executing: CREATE INDEX idx_horse_form_agg_horse_id ON horse_form_agg (horse_id)
Executing: CREATE INDEX idx_horse_form_agg_as_of_date ON horse_form_agg (as_of_date)
DDL statements executed successfully.
2025-03-02 05:46:03 - Python script succeeded
2025-03-02 05:46:03 - Job completed
2025-03-03 05:45:01 - Starting stat_type_update job
2025-03-03 05:45:01 - Environment variables loaded from /home/exx/myCode/horse-racing/FoxRiverAIRacing/config/.env
2025-03-03 05:45:01 - Running Python script: /home/exx/myCode/horse-racing/FoxRiverAIRacing/src/data_preprocessing/horse_recent_form.py
25/03/03 05:45:02 WARN Utils: Your hostname, mail.relufox.ai resolves to a loopback address: 127.0.0.1; using 192.168.4.25 instead (on interface eno2)
25/03/03 05:45:02 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
25/03/03 05:45:03 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
25/03/03 05:45:03 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).
25/03/03 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
25/03/03 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.
25/03/03 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.
25/03/03 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4043. Attempting port 4044.
25/03/03 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4044. Attempting port 4045.
[Stage 0:>                                                          (0 + 1) / 1]                                                                                [Stage 1:>                                                          (0 + 1) / 1]                                                                                [Stage 2:>                                                          (0 + 1) / 1]                                                                                [Stage 5:>                  (0 + 1) / 1][Stage 6:>                  (0 + 1) / 1][Stage 6:>                                                          (0 + 1) / 1][Stage 6:>                  (0 + 1) / 1][Stage 8:>                (0 + 40) / 40][Stage 6:>                  (0 + 1) / 1][Stage 8:>                (1 + 39) / 40][Stage 6:>                                                          (0 + 1) / 1][Stage 12:>                                                     (0 + 100) / 100][Stage 12:>                                                      (1 + 99) / 100][Stage 12:=====>                                                (10 + 90) / 100][Stage 12:==============================>                       (57 + 43) / 100]                                                                                [Stage 13:>                                                         (0 + 1) / 1][Stage 15:>                                                       (0 + 50) / 50][Stage 15:=>                                                      (1 + 49) / 50][Stage 15:==>                                                     (2 + 48) / 50]                                                                                Spark session created successfully.
root
 |-- course_cd: string (nullable = true)
 |-- race_date: date (nullable = true)
 |-- race_number: integer (nullable = true)
 |-- saddle_cloth_number: string (nullable = true)
 |-- horse_id: integer (nullable = true)
 |-- todays_cls: long (nullable = true)
 |-- official_fin: integer (nullable = true)
 |-- speed_rating: integer (nullable = true)
 |-- running_time: double (nullable = true)
 |-- dist_bk_gate1: double (nullable = true)
 |-- dist_bk_gate2: double (nullable = true)
 |-- dist_bk_gate3: double (nullable = true)
 |-- dist_bk_gate4: double (nullable = true)
 |-- avg_speed_fullrace: double (nullable = true)
 |-- avg_stride_length: double (nullable = true)
 |-- strfreq_q1: double (nullable = true)
 |-- strfreq_q2: double (nullable = true)
 |-- strfreq_q3: double (nullable = true)
 |-- strfreq_q4: double (nullable = true)

root
 |-- course_cd: string (nullable = true)
 |-- race_date: date (nullable = true)
 |-- race_number: integer (nullable = true)
 |-- saddle_cloth_number: string (nullable = true)
 |-- horse_id: integer (nullable = true)
 |-- worknum: double (nullable = true)
 |-- days_back: double (nullable = true)
 |-- worktext: string (nullable = true)
 |-- ranking: double (nullable = true)
 |-- rank_group: double (nullable = true)

Executing: ALTER TABLE horse_recent_form ADD PRIMARY KEY (course_cd, race_date, race_number, saddle_cloth_number)
Executing: CREATE INDEX idx_horse_recent_form_horse_id ON horse_recent_form (horse_id)
DDL statements executed successfully.
Executing: ALTER TABLE horse_form_agg ADD PRIMARY KEY (horse_id, as_of_date)
Executing: CREATE INDEX idx_horse_form_agg_horse_id ON horse_form_agg (horse_id)
Executing: CREATE INDEX idx_horse_form_agg_as_of_date ON horse_form_agg (as_of_date)
DDL statements executed successfully.
2025-03-03 05:45:59 - Python script succeeded
2025-03-03 05:45:59 - Job completed
2025-03-04 05:45:01 - Starting stat_type_update job
2025-03-04 05:45:01 - Environment variables loaded from /home/exx/myCode/horse-racing/FoxRiverAIRacing/config/.env
2025-03-04 05:45:01 - Running Python script: /home/exx/myCode/horse-racing/FoxRiverAIRacing/src/data_preprocessing/horse_recent_form.py
25/03/04 05:45:02 WARN Utils: Your hostname, mail.relufox.ai resolves to a loopback address: 127.0.0.1; using 192.168.4.25 instead (on interface eno2)
25/03/04 05:45:02 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
25/03/04 05:45:03 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
25/03/04 05:45:03 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).
25/03/04 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
25/03/04 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.
25/03/04 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.
25/03/04 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4043. Attempting port 4044.
25/03/04 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4044. Attempting port 4045.
[Stage 0:>                                                          (0 + 1) / 1]                                                                                [Stage 1:>                                                          (0 + 1) / 1]                                                                                [Stage 2:>                                                          (0 + 1) / 1]                                                                                [Stage 5:>                  (0 + 1) / 1][Stage 6:>                  (0 + 1) / 1][Stage 6:>                                                          (0 + 1) / 1][Stage 6:>                  (0 + 1) / 1][Stage 8:>                (0 + 40) / 40][Stage 6:>                  (0 + 1) / 1][Stage 8:>                (1 + 39) / 40][Stage 6:>                  (0 + 1) / 1][Stage 8:===>             (9 + 31) / 40][Stage 6:>                                                          (0 + 1) / 1][Stage 12:>                                                     (0 + 100) / 100][Stage 12:===>                                                   (7 + 93) / 100][Stage 12:========================>                             (46 + 54) / 100][Stage 12:=========================>                            (47 + 53) / 100]                                                                                [Stage 13:>                                                         (0 + 1) / 1][Stage 15:>                                                       (0 + 50) / 50][Stage 15:=>                                                      (1 + 49) / 50]                                                                                Spark session created successfully.
root
 |-- course_cd: string (nullable = true)
 |-- race_date: date (nullable = true)
 |-- race_number: integer (nullable = true)
 |-- saddle_cloth_number: string (nullable = true)
 |-- horse_id: integer (nullable = true)
 |-- todays_cls: long (nullable = true)
 |-- official_fin: integer (nullable = true)
 |-- speed_rating: integer (nullable = true)
 |-- running_time: double (nullable = true)
 |-- dist_bk_gate1: double (nullable = true)
 |-- dist_bk_gate2: double (nullable = true)
 |-- dist_bk_gate3: double (nullable = true)
 |-- dist_bk_gate4: double (nullable = true)
 |-- avg_speed_fullrace: double (nullable = true)
 |-- avg_stride_length: double (nullable = true)
 |-- strfreq_q1: double (nullable = true)
 |-- strfreq_q2: double (nullable = true)
 |-- strfreq_q3: double (nullable = true)
 |-- strfreq_q4: double (nullable = true)

root
 |-- course_cd: string (nullable = true)
 |-- race_date: date (nullable = true)
 |-- race_number: integer (nullable = true)
 |-- saddle_cloth_number: string (nullable = true)
 |-- horse_id: integer (nullable = true)
 |-- worknum: double (nullable = true)
 |-- days_back: double (nullable = true)
 |-- worktext: string (nullable = true)
 |-- ranking: double (nullable = true)
 |-- rank_group: double (nullable = true)

Executing: ALTER TABLE horse_recent_form ADD PRIMARY KEY (course_cd, race_date, race_number, saddle_cloth_number)
Executing: CREATE INDEX idx_horse_recent_form_horse_id ON horse_recent_form (horse_id)
DDL statements executed successfully.
Executing: ALTER TABLE horse_form_agg ADD PRIMARY KEY (horse_id, as_of_date)
Executing: CREATE INDEX idx_horse_form_agg_horse_id ON horse_form_agg (horse_id)
Executing: CREATE INDEX idx_horse_form_agg_as_of_date ON horse_form_agg (as_of_date)
DDL statements executed successfully.
2025-03-04 05:46:01 - Python script succeeded
2025-03-04 05:46:01 - Job completed
2025-03-05 05:45:02 - Starting stat_type_update job
2025-03-05 05:45:02 - Environment variables loaded from /home/exx/myCode/horse-racing/FoxRiverAIRacing/config/.env
2025-03-05 05:45:02 - Running Python script: /home/exx/myCode/horse-racing/FoxRiverAIRacing/src/data_preprocessing/horse_recent_form.py
25/03/05 05:45:03 WARN Utils: Your hostname, mail.relufox.ai resolves to a loopback address: 127.0.0.1; using 192.168.4.25 instead (on interface eno2)
25/03/05 05:45:03 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
25/03/05 05:45:03 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
25/03/05 05:45:03 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).
25/03/05 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
25/03/05 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.
25/03/05 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.
25/03/05 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4043. Attempting port 4044.
25/03/05 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4044. Attempting port 4045.
[Stage 0:>                                                          (0 + 1) / 1]                                                                                [Stage 1:>                                                          (0 + 1) / 1]                                                                                [Stage 2:>                                                          (0 + 1) / 1]                                                                                [Stage 5:>                  (0 + 1) / 1][Stage 6:>                  (0 + 1) / 1][Stage 6:>                                                          (0 + 1) / 1][Stage 6:>                  (0 + 1) / 1][Stage 8:>                (0 + 40) / 40][Stage 6:>                  (0 + 1) / 1][Stage 8:>                (1 + 39) / 40][Stage 6:>                                                          (0 + 1) / 1][Stage 12:>                                                     (0 + 100) / 100]                                                                                [Stage 13:>                                                         (0 + 1) / 1][Stage 15:>                                                       (0 + 50) / 50]                                                                                Spark session created successfully.
root
 |-- course_cd: string (nullable = true)
 |-- race_date: date (nullable = true)
 |-- race_number: integer (nullable = true)
 |-- saddle_cloth_number: string (nullable = true)
 |-- horse_id: integer (nullable = true)
 |-- todays_cls: long (nullable = true)
 |-- official_fin: integer (nullable = true)
 |-- speed_rating: integer (nullable = true)
 |-- running_time: double (nullable = true)
 |-- dist_bk_gate1: double (nullable = true)
 |-- dist_bk_gate2: double (nullable = true)
 |-- dist_bk_gate3: double (nullable = true)
 |-- dist_bk_gate4: double (nullable = true)
 |-- avg_speed_fullrace: double (nullable = true)
 |-- avg_stride_length: double (nullable = true)
 |-- strfreq_q1: double (nullable = true)
 |-- strfreq_q2: double (nullable = true)
 |-- strfreq_q3: double (nullable = true)
 |-- strfreq_q4: double (nullable = true)

root
 |-- course_cd: string (nullable = true)
 |-- race_date: date (nullable = true)
 |-- race_number: integer (nullable = true)
 |-- saddle_cloth_number: string (nullable = true)
 |-- horse_id: integer (nullable = true)
 |-- worknum: double (nullable = true)
 |-- days_back: double (nullable = true)
 |-- worktext: string (nullable = true)
 |-- ranking: double (nullable = true)
 |-- rank_group: double (nullable = true)

Executing: ALTER TABLE horse_recent_form ADD PRIMARY KEY (course_cd, race_date, race_number, saddle_cloth_number)
Executing: CREATE INDEX idx_horse_recent_form_horse_id ON horse_recent_form (horse_id)
DDL statements executed successfully.
Executing: ALTER TABLE horse_form_agg ADD PRIMARY KEY (horse_id, as_of_date)
Executing: CREATE INDEX idx_horse_form_agg_horse_id ON horse_form_agg (horse_id)
Executing: CREATE INDEX idx_horse_form_agg_as_of_date ON horse_form_agg (as_of_date)
DDL statements executed successfully.
2025-03-05 05:45:55 - Python script succeeded
2025-03-05 05:45:55 - Job completed
2025-03-06 05:45:01 - Starting stat_type_update job
2025-03-06 05:45:01 - Environment variables loaded from /home/exx/myCode/horse-racing/FoxRiverAIRacing/config/.env
2025-03-06 05:45:01 - Running Python script: /home/exx/myCode/horse-racing/FoxRiverAIRacing/src/data_preprocessing/horse_recent_form.py
25/03/06 05:45:02 WARN Utils: Your hostname, mail.relufox.ai resolves to a loopback address: 127.0.0.1; using 192.168.4.25 instead (on interface eno2)
25/03/06 05:45:02 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
25/03/06 05:45:02 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
25/03/06 05:45:02 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).
25/03/06 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
25/03/06 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.
25/03/06 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.
25/03/06 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4043. Attempting port 4044.
25/03/06 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4044. Attempting port 4045.
25/03/06 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4045. Attempting port 4046.
[Stage 0:>                                                          (0 + 1) / 1]                                                                                [Stage 1:>                                                          (0 + 1) / 1]                                                                                [Stage 2:>                                                          (0 + 1) / 1]                                                                                [Stage 5:>                  (0 + 1) / 1][Stage 6:>                  (0 + 1) / 1][Stage 6:>                                                          (0 + 1) / 1][Stage 6:>                  (0 + 1) / 1][Stage 8:>                (0 + 40) / 40][Stage 6:>                  (0 + 1) / 1][Stage 8:>                (1 + 39) / 40][Stage 6:>                                                          (0 + 1) / 1][Stage 12:>                                                     (0 + 100) / 100][Stage 12:======>                                               (12 + 88) / 100][Stage 12:====================>                                 (38 + 62) / 100]                                                                                [Stage 13:>                                                         (0 + 1) / 1][Stage 15:>                                                       (0 + 50) / 50][Stage 15:=>                                                      (1 + 49) / 50][Stage 15:==>                                                     (2 + 48) / 50][Stage 15:==============================>                        (28 + 22) / 50]                                                                                Spark session created successfully.
root
 |-- course_cd: string (nullable = true)
 |-- race_date: date (nullable = true)
 |-- race_number: integer (nullable = true)
 |-- saddle_cloth_number: string (nullable = true)
 |-- horse_id: integer (nullable = true)
 |-- todays_cls: long (nullable = true)
 |-- official_fin: integer (nullable = true)
 |-- speed_rating: integer (nullable = true)
 |-- running_time: double (nullable = true)
 |-- dist_bk_gate1: double (nullable = true)
 |-- dist_bk_gate2: double (nullable = true)
 |-- dist_bk_gate3: double (nullable = true)
 |-- dist_bk_gate4: double (nullable = true)
 |-- avg_speed_fullrace: double (nullable = true)
 |-- avg_stride_length: double (nullable = true)
 |-- strfreq_q1: double (nullable = true)
 |-- strfreq_q2: double (nullable = true)
 |-- strfreq_q3: double (nullable = true)
 |-- strfreq_q4: double (nullable = true)

root
 |-- course_cd: string (nullable = true)
 |-- race_date: date (nullable = true)
 |-- race_number: integer (nullable = true)
 |-- saddle_cloth_number: string (nullable = true)
 |-- horse_id: integer (nullable = true)
 |-- worknum: double (nullable = true)
 |-- days_back: double (nullable = true)
 |-- worktext: string (nullable = true)
 |-- ranking: double (nullable = true)
 |-- rank_group: double (nullable = true)

Executing: ALTER TABLE horse_recent_form ADD PRIMARY KEY (course_cd, race_date, race_number, saddle_cloth_number)
Executing: CREATE INDEX idx_horse_recent_form_horse_id ON horse_recent_form (horse_id)
DDL statements executed successfully.
Executing: ALTER TABLE horse_form_agg ADD PRIMARY KEY (horse_id, as_of_date)
Executing: CREATE INDEX idx_horse_form_agg_horse_id ON horse_form_agg (horse_id)
Executing: CREATE INDEX idx_horse_form_agg_as_of_date ON horse_form_agg (as_of_date)
DDL statements executed successfully.
2025-03-06 05:45:59 - Python script succeeded
2025-03-06 05:45:59 - Job completed
2025-03-07 05:45:01 - Starting stat_type_update job
2025-03-07 05:45:01 - Environment variables loaded from /home/exx/myCode/horse-racing/FoxRiverAIRacing/config/.env
2025-03-07 05:45:01 - Running Python script: /home/exx/myCode/horse-racing/FoxRiverAIRacing/src/data_preprocessing/horse_recent_form.py
25/03/07 05:45:02 WARN Utils: Your hostname, mail.relufox.ai resolves to a loopback address: 127.0.0.1; using 192.168.4.25 instead (on interface eno2)
25/03/07 05:45:02 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
25/03/07 05:45:02 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
25/03/07 05:45:03 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).
25/03/07 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
25/03/07 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.
25/03/07 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.
25/03/07 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4043. Attempting port 4044.
25/03/07 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4044. Attempting port 4045.
[Stage 0:>                                                          (0 + 1) / 1]                                                                                [Stage 1:>                                                          (0 + 1) / 1]                                                                                [Stage 2:>                                                          (0 + 1) / 1]                                                                                [Stage 5:>                  (0 + 1) / 1][Stage 6:>                  (0 + 1) / 1][Stage 6:>                                                          (0 + 1) / 1][Stage 6:>                  (0 + 1) / 1][Stage 8:>                (0 + 40) / 40][Stage 6:>                  (0 + 1) / 1][Stage 8:>                (2 + 38) / 40][Stage 6:>                                                          (0 + 1) / 1][Stage 12:>                                                     (0 + 100) / 100]                                                                                [Stage 13:>                                                         (0 + 1) / 1][Stage 15:>                                                       (0 + 50) / 50][Stage 15:=>                                                      (1 + 49) / 50][Stage 15:==>                                                     (2 + 48) / 50][Stage 15:=================>                                     (16 + 34) / 50]                                                                                Spark session created successfully.
root
 |-- course_cd: string (nullable = true)
 |-- race_date: date (nullable = true)
 |-- race_number: integer (nullable = true)
 |-- saddle_cloth_number: string (nullable = true)
 |-- horse_id: integer (nullable = true)
 |-- todays_cls: long (nullable = true)
 |-- official_fin: integer (nullable = true)
 |-- speed_rating: integer (nullable = true)
 |-- running_time: double (nullable = true)
 |-- dist_bk_gate1: double (nullable = true)
 |-- dist_bk_gate2: double (nullable = true)
 |-- dist_bk_gate3: double (nullable = true)
 |-- dist_bk_gate4: double (nullable = true)
 |-- avg_speed_fullrace: double (nullable = true)
 |-- avg_stride_length: double (nullable = true)
 |-- strfreq_q1: double (nullable = true)
 |-- strfreq_q2: double (nullable = true)
 |-- strfreq_q3: double (nullable = true)
 |-- strfreq_q4: double (nullable = true)

root
 |-- course_cd: string (nullable = true)
 |-- race_date: date (nullable = true)
 |-- race_number: integer (nullable = true)
 |-- saddle_cloth_number: string (nullable = true)
 |-- horse_id: integer (nullable = true)
 |-- worknum: double (nullable = true)
 |-- days_back: double (nullable = true)
 |-- worktext: string (nullable = true)
 |-- ranking: double (nullable = true)
 |-- rank_group: double (nullable = true)

Executing: ALTER TABLE horse_recent_form ADD PRIMARY KEY (course_cd, race_date, race_number, saddle_cloth_number)
Executing: CREATE INDEX idx_horse_recent_form_horse_id ON horse_recent_form (horse_id)
DDL statements executed successfully.
Executing: ALTER TABLE horse_form_agg ADD PRIMARY KEY (horse_id, as_of_date)
Executing: CREATE INDEX idx_horse_form_agg_horse_id ON horse_form_agg (horse_id)
Executing: CREATE INDEX idx_horse_form_agg_as_of_date ON horse_form_agg (as_of_date)
DDL statements executed successfully.
2025-03-07 05:45:56 - Python script succeeded
2025-03-07 05:45:56 - Job completed
2025-03-08 05:45:01 - Starting stat_type_update job
2025-03-08 05:45:01 - Environment variables loaded from /home/exx/myCode/horse-racing/FoxRiverAIRacing/config/.env
2025-03-08 05:45:01 - Running Python script: /home/exx/myCode/horse-racing/FoxRiverAIRacing/src/data_preprocessing/horse_recent_form.py
25/03/08 05:45:02 WARN Utils: Your hostname, mail.relufox.ai resolves to a loopback address: 127.0.0.1; using 192.168.4.25 instead (on interface eno2)
25/03/08 05:45:02 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
25/03/08 05:45:02 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
25/03/08 05:45:02 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).
25/03/08 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
25/03/08 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.
25/03/08 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.
25/03/08 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4043. Attempting port 4044.
25/03/08 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4044. Attempting port 4045.
[Stage 0:>                                                          (0 + 1) / 1]                                                                                [Stage 1:>                                                          (0 + 1) / 1]                                                                                [Stage 2:>                                                          (0 + 1) / 1]                                                                                [Stage 5:>                  (0 + 1) / 1][Stage 6:>                  (0 + 1) / 1][Stage 6:>                                                          (0 + 1) / 1][Stage 6:>                  (0 + 1) / 1][Stage 8:>                (0 + 40) / 40][Stage 6:>                  (0 + 1) / 1][Stage 8:>                (1 + 39) / 40][Stage 6:>                  (0 + 1) / 1][Stage 8:>                (2 + 38) / 40][Stage 6:>                                                          (0 + 1) / 1][Stage 12:>                                                     (0 + 100) / 100][Stage 12:>                                                      (1 + 99) / 100]                                                                                [Stage 13:>                                                         (0 + 1) / 1][Stage 15:>                                                       (0 + 50) / 50][Stage 15:======================================================> (49 + 1) / 50]                                                                                Spark session created successfully.
root
 |-- course_cd: string (nullable = true)
 |-- race_date: date (nullable = true)
 |-- race_number: integer (nullable = true)
 |-- saddle_cloth_number: string (nullable = true)
 |-- horse_id: integer (nullable = true)
 |-- todays_cls: long (nullable = true)
 |-- official_fin: integer (nullable = true)
 |-- speed_rating: integer (nullable = true)
 |-- running_time: double (nullable = true)
 |-- dist_bk_gate1: double (nullable = true)
 |-- dist_bk_gate2: double (nullable = true)
 |-- dist_bk_gate3: double (nullable = true)
 |-- dist_bk_gate4: double (nullable = true)
 |-- avg_speed_fullrace: double (nullable = true)
 |-- avg_stride_length: double (nullable = true)
 |-- strfreq_q1: double (nullable = true)
 |-- strfreq_q2: double (nullable = true)
 |-- strfreq_q3: double (nullable = true)
 |-- strfreq_q4: double (nullable = true)

root
 |-- course_cd: string (nullable = true)
 |-- race_date: date (nullable = true)
 |-- race_number: integer (nullable = true)
 |-- saddle_cloth_number: string (nullable = true)
 |-- horse_id: integer (nullable = true)
 |-- worknum: double (nullable = true)
 |-- days_back: double (nullable = true)
 |-- worktext: string (nullable = true)
 |-- ranking: double (nullable = true)
 |-- rank_group: double (nullable = true)

Executing: ALTER TABLE horse_recent_form ADD PRIMARY KEY (course_cd, race_date, race_number, saddle_cloth_number)
Executing: CREATE INDEX idx_horse_recent_form_horse_id ON horse_recent_form (horse_id)
DDL statements executed successfully.
Executing: ALTER TABLE horse_form_agg ADD PRIMARY KEY (horse_id, as_of_date)
Executing: CREATE INDEX idx_horse_form_agg_horse_id ON horse_form_agg (horse_id)
Executing: CREATE INDEX idx_horse_form_agg_as_of_date ON horse_form_agg (as_of_date)
DDL statements executed successfully.
2025-03-08 05:45:53 - Python script succeeded
2025-03-08 05:45:53 - Job completed
2025-03-09 05:45:01 - Starting stat_type_update job
2025-03-09 05:45:01 - Environment variables loaded from /home/exx/myCode/horse-racing/FoxRiverAIRacing/config/.env
2025-03-09 05:45:01 - Running Python script: /home/exx/myCode/horse-racing/FoxRiverAIRacing/src/data_preprocessing/horse_recent_form.py
25/03/09 05:45:02 WARN Utils: Your hostname, mail.relufox.ai resolves to a loopback address: 127.0.0.1; using 192.168.4.25 instead (on interface eno2)
25/03/09 05:45:02 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
25/03/09 05:45:02 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
25/03/09 05:45:03 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).
25/03/09 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
25/03/09 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.
25/03/09 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.
25/03/09 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4043. Attempting port 4044.
25/03/09 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4044. Attempting port 4045.
[Stage 0:>                                                          (0 + 1) / 1]                                                                                [Stage 1:>                                                          (0 + 1) / 1]                                                                                [Stage 2:>                                                          (0 + 1) / 1]                                                                                [Stage 5:>                  (0 + 1) / 1][Stage 6:>                  (0 + 1) / 1][Stage 6:>                                                          (0 + 1) / 1][Stage 6:>                  (0 + 1) / 1][Stage 8:>                (0 + 40) / 40][Stage 6:>                  (0 + 1) / 1][Stage 8:>                (1 + 39) / 40][Stage 6:>                  (0 + 1) / 1][Stage 8:=>               (3 + 37) / 40][Stage 6:>                                                          (0 + 1) / 1][Stage 12:>                                                     (0 + 100) / 100]                                                                                [Stage 13:>                                                         (0 + 1) / 1][Stage 15:>                                                       (0 + 50) / 50][Stage 15:==>                                                     (2 + 48) / 50]                                                                                Spark session created successfully.
root
 |-- course_cd: string (nullable = true)
 |-- race_date: date (nullable = true)
 |-- race_number: integer (nullable = true)
 |-- saddle_cloth_number: string (nullable = true)
 |-- horse_id: integer (nullable = true)
 |-- todays_cls: long (nullable = true)
 |-- official_fin: integer (nullable = true)
 |-- speed_rating: integer (nullable = true)
 |-- running_time: double (nullable = true)
 |-- dist_bk_gate1: double (nullable = true)
 |-- dist_bk_gate2: double (nullable = true)
 |-- dist_bk_gate3: double (nullable = true)
 |-- dist_bk_gate4: double (nullable = true)
 |-- avg_speed_fullrace: double (nullable = true)
 |-- avg_stride_length: double (nullable = true)
 |-- strfreq_q1: double (nullable = true)
 |-- strfreq_q2: double (nullable = true)
 |-- strfreq_q3: double (nullable = true)
 |-- strfreq_q4: double (nullable = true)

root
 |-- course_cd: string (nullable = true)
 |-- race_date: date (nullable = true)
 |-- race_number: integer (nullable = true)
 |-- saddle_cloth_number: string (nullable = true)
 |-- horse_id: integer (nullable = true)
 |-- worknum: double (nullable = true)
 |-- days_back: double (nullable = true)
 |-- worktext: string (nullable = true)
 |-- ranking: double (nullable = true)
 |-- rank_group: double (nullable = true)

Executing: ALTER TABLE horse_recent_form ADD PRIMARY KEY (course_cd, race_date, race_number, saddle_cloth_number)
Executing: CREATE INDEX idx_horse_recent_form_horse_id ON horse_recent_form (horse_id)
DDL statements executed successfully.
Executing: ALTER TABLE horse_form_agg ADD PRIMARY KEY (horse_id, as_of_date)
Executing: CREATE INDEX idx_horse_form_agg_horse_id ON horse_form_agg (horse_id)
Executing: CREATE INDEX idx_horse_form_agg_as_of_date ON horse_form_agg (as_of_date)
DDL statements executed successfully.
2025-03-09 05:45:54 - Python script succeeded
2025-03-09 05:45:54 - Job completed
2025-03-10 05:45:01 - Starting stat_type_update job
2025-03-10 05:45:01 - Environment variables loaded from /home/exx/myCode/horse-racing/FoxRiverAIRacing/config/.env
2025-03-10 05:45:01 - Running Python script: /home/exx/myCode/horse-racing/FoxRiverAIRacing/src/data_preprocessing/horse_recent_form.py
25/03/10 05:45:02 WARN Utils: Your hostname, mail.relufox.ai resolves to a loopback address: 127.0.0.1; using 192.168.4.25 instead (on interface eno2)
25/03/10 05:45:02 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
25/03/10 05:45:02 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
25/03/10 05:45:03 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).
25/03/10 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
25/03/10 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.
25/03/10 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.
25/03/10 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4043. Attempting port 4044.
25/03/10 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4044. Attempting port 4045.
[Stage 0:>                                                          (0 + 1) / 1]                                                                                [Stage 1:>                                                          (0 + 1) / 1]                                                                                [Stage 2:>                                                          (0 + 1) / 1]                                                                                [Stage 5:>                  (0 + 1) / 1][Stage 6:>                  (0 + 1) / 1][Stage 6:>                                                          (0 + 1) / 1][Stage 6:>                  (0 + 1) / 1][Stage 8:>                (0 + 40) / 40][Stage 6:>                  (0 + 1) / 1][Stage 8:>                (1 + 39) / 40][Stage 6:>                                                          (0 + 1) / 1][Stage 12:>                                                     (0 + 100) / 100][Stage 12:>                                                      (1 + 99) / 100][Stage 12:=>                                                     (2 + 98) / 100][Stage 12:=====>                                                (10 + 90) / 100][Stage 12:=========================>                            (48 + 52) / 100]                                                                                [Stage 13:>                                                         (0 + 1) / 1][Stage 15:>                                                       (0 + 50) / 50][Stage 15:=>                                                      (1 + 49) / 50][Stage 15:==>                                                     (2 + 48) / 50][Stage 15:======================================>                (35 + 15) / 50]                                                                                Spark session created successfully.
root
 |-- course_cd: string (nullable = true)
 |-- race_date: date (nullable = true)
 |-- race_number: integer (nullable = true)
 |-- saddle_cloth_number: string (nullable = true)
 |-- horse_id: integer (nullable = true)
 |-- todays_cls: long (nullable = true)
 |-- official_fin: integer (nullable = true)
 |-- speed_rating: integer (nullable = true)
 |-- running_time: double (nullable = true)
 |-- dist_bk_gate1: double (nullable = true)
 |-- dist_bk_gate2: double (nullable = true)
 |-- dist_bk_gate3: double (nullable = true)
 |-- dist_bk_gate4: double (nullable = true)
 |-- avg_speed_fullrace: double (nullable = true)
 |-- avg_stride_length: double (nullable = true)
 |-- strfreq_q1: double (nullable = true)
 |-- strfreq_q2: double (nullable = true)
 |-- strfreq_q3: double (nullable = true)
 |-- strfreq_q4: double (nullable = true)

root
 |-- course_cd: string (nullable = true)
 |-- race_date: date (nullable = true)
 |-- race_number: integer (nullable = true)
 |-- saddle_cloth_number: string (nullable = true)
 |-- horse_id: integer (nullable = true)
 |-- worknum: double (nullable = true)
 |-- days_back: double (nullable = true)
 |-- worktext: string (nullable = true)
 |-- ranking: double (nullable = true)
 |-- rank_group: double (nullable = true)

Executing: ALTER TABLE horse_recent_form ADD PRIMARY KEY (course_cd, race_date, race_number, saddle_cloth_number)
Executing: CREATE INDEX idx_horse_recent_form_horse_id ON horse_recent_form (horse_id)
DDL statements executed successfully.
Executing: ALTER TABLE horse_form_agg ADD PRIMARY KEY (horse_id, as_of_date)
Executing: CREATE INDEX idx_horse_form_agg_horse_id ON horse_form_agg (horse_id)
Executing: CREATE INDEX idx_horse_form_agg_as_of_date ON horse_form_agg (as_of_date)
DDL statements executed successfully.
2025-03-10 05:46:00 - Python script succeeded
2025-03-10 05:46:00 - Job completed
2025-03-11 05:45:01 - Starting stat_type_update job
2025-03-11 05:45:01 - Environment variables loaded from /home/exx/myCode/horse-racing/FoxRiverAIRacing/config/.env
2025-03-11 05:45:01 - Running Python script: /home/exx/myCode/horse-racing/FoxRiverAIRacing/src/data_preprocessing/horse_recent_form.py
25/03/11 05:45:03 WARN Utils: Your hostname, mail.relufox.ai resolves to a loopback address: 127.0.0.1; using 192.168.4.25 instead (on interface eno2)
25/03/11 05:45:03 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
25/03/11 05:45:03 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
25/03/11 05:45:03 WARN SparkConf: Note that spark.local.dir will be overridden by the value set by the cluster manager (via SPARK_LOCAL_DIRS in mesos/standalone/kubernetes and LOCAL_DIRS in YARN).
25/03/11 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
25/03/11 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.
25/03/11 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.
25/03/11 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4043. Attempting port 4044.
25/03/11 05:45:03 WARN Utils: Service 'SparkUI' could not bind on port 4044. Attempting port 4045.
[Stage 0:>                                                          (0 + 1) / 1]                                                                                [Stage 1:>                                                          (0 + 1) / 1]                                                                                [Stage 2:>                                                          (0 + 1) / 1]                                                                                [Stage 5:>                  (0 + 1) / 1][Stage 6:>                  (0 + 1) / 1][Stage 6:>                                                          (0 + 1) / 1][Stage 6:>                  (0 + 1) / 1][Stage 8:>                (0 + 41) / 41][Stage 6:>                  (0 + 1) / 1][Stage 8:>                (1 + 40) / 41][Stage 6:>                                                          (0 + 1) / 1][Stage 12:>                                                     (0 + 100) / 100][Stage 12:==>                                                    (4 + 96) / 100][Stage 12:=======>                                              (14 + 86) / 100]                                                                                [Stage 13:>                                                         (0 + 1) / 1][Stage 15:>                                                       (0 + 50) / 50][Stage 15:===>                                                    (3 + 47) / 50][Stage 15:============================================>          (40 + 10) / 50][Stage 15:==================================================>     (45 + 5) / 50]                                                                                Spark session created successfully.
root
 |-- course_cd: string (nullable = true)
 |-- race_date: date (nullable = true)
 |-- race_number: integer (nullable = true)
 |-- saddle_cloth_number: string (nullable = true)
 |-- horse_id: integer (nullable = true)
 |-- todays_cls: long (nullable = true)
 |-- official_fin: integer (nullable = true)
 |-- speed_rating: integer (nullable = true)
 |-- running_time: double (nullable = true)
 |-- dist_bk_gate1: double (nullable = true)
 |-- dist_bk_gate2: double (nullable = true)
 |-- dist_bk_gate3: double (nullable = true)
 |-- dist_bk_gate4: double (nullable = true)
 |-- avg_speed_fullrace: double (nullable = true)
 |-- avg_stride_length: double (nullable = true)
 |-- strfreq_q1: double (nullable = true)
 |-- strfreq_q2: double (nullable = true)
 |-- strfreq_q3: double (nullable = true)
 |-- strfreq_q4: double (nullable = true)

root
 |-- course_cd: string (nullable = true)
 |-- race_date: date (nullable = true)
 |-- race_number: integer (nullable = true)
 |-- saddle_cloth_number: string (nullable = true)
 |-- horse_id: integer (nullable = true)
 |-- worknum: double (nullable = true)
 |-- days_back: double (nullable = true)
 |-- worktext: string (nullable = true)
 |-- ranking: double (nullable = true)
 |-- rank_group: double (nullable = true)

Executing: ALTER TABLE horse_recent_form ADD PRIMARY KEY (course_cd, race_date, race_number, saddle_cloth_number)
Executing: CREATE INDEX idx_horse_recent_form_horse_id ON horse_recent_form (horse_id)
DDL statements executed successfully.
Executing: ALTER TABLE horse_form_agg ADD PRIMARY KEY (horse_id, as_of_date)
Executing: CREATE INDEX idx_horse_form_agg_horse_id ON horse_form_agg (horse_id)
Executing: CREATE INDEX idx_horse_form_agg_as_of_date ON horse_form_agg (as_of_date)
DDL statements executed successfully.
2025-03-11 05:46:00 - Python script succeeded
2025-03-11 05:46:00 - Job completed
