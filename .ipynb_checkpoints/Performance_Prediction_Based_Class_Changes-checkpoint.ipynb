{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "499bc123-daf3-4f61-8e2c-bb7f964f2544",
   "metadata": {},
   "source": [
    "# Performance Prediction Based on Class Changes\n",
    "\n",
    "## Model Recommendations: \n",
    "\n",
    "1. Logistic Regression: Good for binary outcomes (win/place vs. loss).\n",
    "2. Random Forest or Gradient Boosting: Capture non-linear relationships, which are useful for interactions between class changes and other variables.\n",
    "3. XGBoost: Often performs well with tabular data, especially for binary or multi-class classification.\n",
    "\n",
    "## Key Data Attributes:\n",
    "\n",
    "1. class rating: Measure of the race’s competitive level.\n",
    "2. todays_cls: Indicates the current class level.\n",
    "3. historical class changes: For each horse, this is a record of up/down movements over time.\n",
    "4. trainer and jockey win rates: Historical data on trainer and jockey success rates for class transitions.\n",
    "5. horse performance metrics: Past results, such as speed, average speed, and distance performance.\n",
    "\n",
    "## Custom Metrics:\n",
    "\n",
    "1. Class Change Rate: Ratio of class changes (up or down) for a specific horse.\n",
    "2. Success Rate by Class: Percentage of positive outcomes (e.g., win/place) for each class change type for a specific horse.\n",
    "3. Trainer-Jockey Class Shift Success: Win/place rate when trainer-jockey combinations have adjusted a horse’s class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97816f3-878d-41b6-a4f9-8f7cb20d822a",
   "metadata": {},
   "source": [
    "# Notes -- delete later:\n",
    "\n",
    "To test your system, especially with GPUs, I recommend starting with a model that balances computational demand and efficiency while taking advantage of parallel processing on GPUs. Here are three models to consider, listed in order of increasing complexity and computational intensity:\n",
    "\n",
    "1. Random Forest with Scikit-Learn\n",
    "\n",
    "\t•\tWhy: Random Forest is easy to set up and provides a good performance baseline. It’s also highly parallelizable, which can utilize multiple CPU cores efficiently.\n",
    "\t•\tGPU Compatibility: While Scikit-Learn itself doesn’t natively support GPU acceleration, RAPIDS (from NVIDIA) has a library called cuML that includes a GPU-accelerated version of Random Forest.\n",
    "\t•\tImplementation:\n",
    "\t•\tStart with Scikit-Learn’s RandomForestClassifier to verify data pipelines and performance on CPU.\n",
    "\t•\tOptionally, try cuML’s RandomForestClassifier to utilize GPU(s) on your RTX A6000 cards.\n",
    "\n",
    "2. XGBoost with GPU Support\n",
    "\n",
    "\t•\tWhy: XGBoost is widely used for structured/tabular data and has excellent GPU support built in. It handles complex, non-linear data well and is optimized for performance, especially with large datasets.\n",
    "\t•\tGPU Compatibility: XGBoost can leverage your GPUs for faster training.\n",
    "\t•\tImplementation:\n",
    "\t•\tSet tree_method='gpu_hist' in XGBClassifier to enable GPU acceleration.\n",
    "\t•\tThis is a good choice for benchmarking GPU performance and testing your system’s stability under heavy loads.\n",
    "\n",
    "3. LightGBM with GPU Support\n",
    "\n",
    "\t•\tWhy: LightGBM is similar to XGBoost but typically faster and more memory-efficient, especially on large datasets with high-dimensional data. It’s well-suited for imbalanced datasets and allows for efficient handling of categorical data.\n",
    "\t•\tGPU Compatibility: LightGBM can use your GPUs for accelerated training.\n",
    "\t•\tImplementation:\n",
    "\t•\tUse device='gpu' in LGBMClassifier to leverage GPU acceleration.\n",
    "\t•\tLightGBM’s memory efficiency can help gauge your system’s ability to handle large, complex datasets.\n",
    "\n",
    "Suggested Approach to Testing\n",
    "\n",
    "\t1.\tData Preparation: Use a subset of your data initially to ensure models are set up correctly and refine your feature engineering process.\n",
    "\t2.\tHyperparameter Tuning: Keep parameters minimal for initial tests, then gradually increase complexity, exploring tuning options.\n",
    "\t3.\tBenchmark: Start with CPU tests for Random Forest, then move to GPU-accelerated XGBoost or LightGBM.\n",
    "\t4.\tSystem Monitoring: Track GPU and CPU usage, memory consumption, and training times.\n",
    "\n",
    "Given your goal of performance testing, starting with XGBoost using GPU acceleration would likely provide the best balance of computational load and insight into your system’s capabilities.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2572b87-7b2d-422f-96f2-7569ee86028f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'ingestion_utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 12\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mconfigparser\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_ingestion\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mingestion_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     10\u001b[0m     get_db_connection, update_tracking, load_processed_files\n\u001b[1;32m     11\u001b[0m )\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_ingestion\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01meqb_ppData\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m process_pluspro_data\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_ingestion\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01meqb_resultsCharts\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m process_resultscharts_data\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_ingestion\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtpd_datasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     15\u001b[0m     process_tpd_sectionals_data,\n\u001b[1;32m     16\u001b[0m     process_tpd_gpsdata_data\n\u001b[1;32m     17\u001b[0m )\n",
      "File \u001b[0;32m~/myCode/horse-racing/FoxRiverAIRacing/src/data_ingestion/eqb_ppData.py:7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_ingestion\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mingestion_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m validate_xml\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_ingestion\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mracedata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m process_racedata_file\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_ingestion\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhorse_data\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m process_horsedata_file \n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_ingestion\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdam\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m process_dam_file\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_ingestion\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msire\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m process_sire_file\n",
      "File \u001b[0;32m~/myCode/horse-racing/FoxRiverAIRacing/src/data_ingestion/horse_data.py:4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatetime\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m datetime\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlogging\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mingestion_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m validate_xml, get_text, log_rejected_record, update_ingestion_status\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# from mapping_dictionaries import eqb_to_course_cd  # Not used in this function\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprocess_horsedata_file\u001b[39m(xml_file, xsd_file_path, conn, cursor):\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'ingestion_utils'"
     ]
    }
   ],
   "source": [
    "# Environment setup\n",
    "import logging\n",
    "import os\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import geopandas as gpd\n",
    "from datetime import datetime\n",
    "import configparser\n",
    "from src.data_ingestion.ingestion_utils import (\n",
    "    get_db_connection, update_tracking, load_processed_files\n",
    ")\n",
    "from src.data_ingestion.eqb_ppData import process_pluspro_data\n",
    "from src.data_ingestion.eqb_resultsCharts import process_resultscharts_data\n",
    "from src.data_ingestion.tpd_datasets import (\n",
    "    process_tpd_sectionals_data,\n",
    "    process_tpd_gpsdata_data\n",
    ")\n",
    "\n",
    "# Load the configuration file\n",
    "config = configparser.ConfigParser()\n",
    "config.read('/home/exx/myCode/horse-racing/FoxRiverAIRacing/config.ini')\n",
    "\n",
    "# Set up logging for consistent logging behavior in Notebook\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# Retrieve database credentials from config file\n",
    "# Retrieve database credentials from config file\n",
    "db_host = config['database']['host']\n",
    "db_port = config['database']['port']\n",
    "db_name = config['database']['dbname']  # Corrected from 'name' to 'dbname'\n",
    "db_user = config['database']['user']\n",
    "\n",
    "# Establish connection using get_db_connection\n",
    "conn = get_db_connection(config)\n",
    "\n",
    "# Create the SQLAlchemy engine\n",
    "engine = create_engine(f'postgresql+psycopg2://{db_user}@{db_host}:{db_port}/{db_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5100dc15-2ec3-4bc2-9d8f-7b482b45654e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
