{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a43fc8b",
   "metadata": {},
   "source": [
    "# XGBoost Model Preparation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1463424",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Environment\n",
    "\n",
    "import os\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn import set_config\n",
    "from src.data_preprocessing.data_prep1.data_loader import load_data_from_postgresql\n",
    "from src.data_preprocessing.data_prep1.sql_queries import sql_queries\n",
    "import pyspark.sql.functions as F\n",
    "import xgboost as xgb\n",
    "from sklearn import set_config\n",
    "from pyspark.sql.functions import (col, count, row_number, abs, unix_timestamp, mean, \n",
    "                                   when, lit, min as F_min, max as F_max , upper, trim,\n",
    "                                   row_number, mean as F_mean, countDistinct, last, first, when)\n",
    "import configparser\n",
    "from pyspark.sql import SparkSession\n",
    "from src.data_preprocessing.data_prep1.sql_queries import sql_queries\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql import DataFrame, Window\n",
    "from src.data_preprocessing.data_prep1.data_utils import (save_parquet, gather_statistics, \n",
    "                initialize_environment, load_config, initialize_spark, \n",
    "                identify_and_impute_outliers, \n",
    "                identify_and_remove_outliers, identify_missing_and_outliers)\n",
    "from pyspark.ml.functions import vector_to_array\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Set global references to None\n",
    "spark = None\n",
    "master_results_df = None\n",
    "race_df = None\n",
    "df = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73671a61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-01 10:33:49,648 - INFO - Environment setup initialized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark session created successfully.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "spark, jdbc_url, jdbc_properties, parquet_dir, log_file = initialize_environment()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c57a596",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This dataset has already been cleaned up in the LGB notebook and saved as a starting point\n",
    "# It now just need to be converted to Panadas and run in the GBDT variant model (LGB, XGB, CatBoost)\n",
    "race_df = spark.read.parquet(os.path.join(parquet_dir, \"race_df_p2.parquet\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ccd5955",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "777100"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "race_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce2ed82",
   "metadata": {},
   "source": [
    "# Switching to Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e3b985b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "race_df = race_df.toPandas()\n",
    "# Quick info about the DataFrame\n",
    "#print(df.info())\n",
    "#print(df.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df8b562-bdbd-4ac0-8f58-38984594b4bd",
   "metadata": {},
   "source": [
    "## Set the race_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412c7f9a-7b84-4b22-bc58-6b21556363c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "race_df[\"race_id\"] = (\n",
    "    race_df[\"course_cd\"].astype(str) + \"_\" +\n",
    "    race_df[\"race_date\"].astype(str) + \"_\" +\n",
    "    race_df[\"race_number\"].astype(str)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6cc11f6-457e-47a5-acde-168d99c9cabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_array = race_df.groupby(\"race_id\").size().values  # array of group sizes\n",
    "print(group_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32bb9d4c-ea48-4388-8f93-1014ab908724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the largest official_fin is 20 (some races can have 20 horses),\n",
    "# then label = (21 - official_fin).\n",
    "# So official_fin=1 => label=20, official_fin=2 =>19, etc.\n",
    "# If your max is 14, you can do (15 - official_fin).  Just ensure \"best\" horse has largest label.\n",
    "race_df[\"rank\"] = 21 - race_df[\"official_fin\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484e5647-2ac5-4b15-94aa-e4db454bc5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"official_fin\" in race_df.columns:\n",
    "    race_df.drop(columns=[\"official_fin\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4586abd9-0d51-46b5-a2f4-2d9644011f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "cat_cols = [\"course_cd\", \"sex\", \"equip\", \"surface\", \"trk_cond\", \"weather\", \"med\", \n",
    "            \"race_type\", \"stk_clm_md\", \"turf_mud_mark\", \"layoff_cat\"]\n",
    "for c in cat_cols:\n",
    "    lbl = LabelEncoder()\n",
    "    race_df[c] = lbl.fit_transform(race_df[c].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1346135c-4374-4e3e-9c15-11809c23838a",
   "metadata": {},
   "outputs": [],
   "source": [
    "race_df = race_df.sort_values(\"race_id\", ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a5726e-5135-42e0-8142-236bf380f56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    # Basic numeric columns\n",
    "    \"purse\",\n",
    "    \"wps_pool\",\n",
    "    \"weight\",\n",
    "    \"claimprice\",\n",
    "    \"power\",\n",
    "    \"morn_odds\",\n",
    "    \"distance_meters\",\n",
    "    \"avgspd\",\n",
    "    \"class_rating\",\n",
    "    \"todays_cls\",\n",
    "    \"net_sentiment\",\n",
    "    \"avg_spd_sd\",\n",
    "    \"ave_cl_sd\",\n",
    "    \"hi_spd_sd\",\n",
    "    \"pstyerl\",\n",
    "\n",
    "    # Cumulative performance stats\n",
    "    \"all_starts\",\n",
    "    \"all_win\",\n",
    "    \"all_place\",\n",
    "    \"all_show\",\n",
    "    \"all_fourth\",\n",
    "    \"all_earnings\",\n",
    "    \"cond_starts\",\n",
    "    \"cond_win\",\n",
    "    \"cond_place\",\n",
    "    \"cond_show\",\n",
    "    \"cond_fourth\",\n",
    "    \"cond_earnings\",\n",
    "\n",
    "    # Recent form metrics\n",
    "    \"avg_fin_3\",\n",
    "    \"avg_beaten_3\",\n",
    "    \"avg_speed_3\",\n",
    "    \"avg_fin_5\",\n",
    "    \"avg_beaten_5\",\n",
    "    \"avg_speed_5\",\n",
    "    \"speed_improvement\",\n",
    "    \"days_off\",\n",
    "\n",
    "    # Sectionals / GPS\n",
    "    \"avgtime_gate1\",\n",
    "    \"avgtime_gate2\",\n",
    "    \"avgtime_gate3\",\n",
    "    \"avgtime_gate4\",\n",
    "    \"total_distance_ran\",\n",
    "    \"running_time\",\n",
    "    \"speed_q1\",\n",
    "    \"speed_q2\",\n",
    "    \"speed_q3\",\n",
    "    \"speed_q4\",\n",
    "    \"total_dist_covered\",\n",
    "    \"avg_acceleration\",\n",
    "    \"net_progress_gain\",\n",
    "    \"gps_avg_stride_length\",\n",
    "\n",
    "    # Jockey/Trainer stats\n",
    "    \"jock_win_percent\",\n",
    "    \"jock_itm_percent\",\n",
    "    \"trainer_win_percent\",\n",
    "    \"trainer_itm_percent\",\n",
    "    \"jt_win_percent\",\n",
    "    \"jt_itm_percent\",\n",
    "    \"jock_win_track\",\n",
    "    \"jock_itm_track\",\n",
    "    \"trainer_win_track\",\n",
    "    \"trainer_itm_track\",\n",
    "    \"jt_win_track\",\n",
    "    \"jt_itm_track\",\n",
    "\n",
    "    # Other\n",
    "    \"age_at_race_day\",\n",
    "    \"is_first_race\",\n",
    "]\n",
    "\n",
    "\n",
    "X_all = race_df[features].values\n",
    "y_all = race_df['rank'].values\n",
    "race_ids = race_df['race_id'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d78c10-ccaf-4b39-bf2c-24567137c5cb",
   "metadata": {},
   "source": [
    "### Split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e288757-5fb0-477b-bcb1-e8649af4ef52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "unique_races = race_df['race_id'].unique()\n",
    "unique_races = shuffle(unique_races, random_state=42)\n",
    "\n",
    "train_ratio = 0.8\n",
    "cut = int(len(unique_races) * train_ratio)\n",
    "train_races = set(unique_races[:cut])\n",
    "valid_races = set(unique_races[cut:])\n",
    "\n",
    "# Create a boolean mask\n",
    "train_mask = race_df['race_id'].isin(train_races)\n",
    "valid_mask  = race_df['race_id'].isin(valid_races)\n",
    "\n",
    "# Now slice\n",
    "X_train = X_all[train_mask]\n",
    "y_train = y_all[train_mask]\n",
    "race_id_train = race_ids[train_mask]\n",
    "\n",
    "X_valid = X_all[valid_mask]\n",
    "y_valid = y_all[valid_mask]\n",
    "race_id_valid = race_ids[valid_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e1f523-3912-4825-b082-db9efbecf519",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def make_group_array(race_id_array):\n",
    "    \"\"\"\n",
    "    Returns an array of group sizes in the order of race_id_array’s actual row order.\n",
    "    Expects that race_id_array is sorted or lumps each race contiguously.\n",
    "    \"\"\"\n",
    "    # Approach 1: Rely on the data already being grouped in contiguous rows\n",
    "    # If your data is not guaranteed to be sorted by race_id, you can sort it first.\n",
    "    # But let's assume from the train_mask/valid_mask approach that the relative order\n",
    "    # is consistent. We can just accumulate counts.\n",
    "\n",
    "    # A simpler approach: group the data by unique race_id in the order they appear\n",
    "    # and store the size for each chunk.\n",
    "    # We'll do a loop approach:\n",
    "\n",
    "    groups = []\n",
    "    current_race = None\n",
    "    current_count = 0\n",
    "\n",
    "    group_sequence = []\n",
    "\n",
    "    for rid in race_id_array:\n",
    "        if rid != current_race:\n",
    "            # if we have an existing group, push it\n",
    "            if current_race is not None:\n",
    "                groups.append(current_count)\n",
    "            current_race = rid\n",
    "            current_count = 1\n",
    "        else:\n",
    "            current_count += 1\n",
    "    # push the last group\n",
    "    if current_race is not None and current_count > 0:\n",
    "        groups.append(current_count)\n",
    "\n",
    "    return np.array(groups, dtype=np.int32)\n",
    "\n",
    "group_train = make_group_array(race_id_train)\n",
    "group_valid  = make_group_array(race_id_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2842de6d",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0aced663",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_config(display=\"text\")  # Switch to text-based display\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(\n",
    "    objective=\"multi:softmax\",  # Multi-class classification\n",
    "    predictor='gpu_predictor', # GPU acceleration\n",
    "    num_class=8,               # Number of classes (0 to 7)\n",
    "    max_depth=6,               # Tree depth\n",
    "    learning_rate=0.1,         # Learning rate\n",
    "    n_estimators=100,          # Number of trees\n",
    "    eval_metric=\"mlogloss\",    # Log loss for multi-class\n",
    "    early_stopping_rounds=10   # Specify early stopping rounds here\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "12ba670f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-mlogloss:2.06199\tvalidation_1-mlogloss:2.06233\n",
      "[1]\tvalidation_0-mlogloss:2.04695\tvalidation_1-mlogloss:2.04759\n",
      "[2]\tvalidation_0-mlogloss:2.03382\tvalidation_1-mlogloss:2.03479\n",
      "[3]\tvalidation_0-mlogloss:2.02233\tvalidation_1-mlogloss:2.02360\n",
      "[4]\tvalidation_0-mlogloss:2.01206\tvalidation_1-mlogloss:2.01363\n",
      "[5]\tvalidation_0-mlogloss:2.00295\tvalidation_1-mlogloss:2.00482\n",
      "[6]\tvalidation_0-mlogloss:1.99479\tvalidation_1-mlogloss:1.99699\n",
      "[7]\tvalidation_0-mlogloss:1.98747\tvalidation_1-mlogloss:1.98996\n",
      "[8]\tvalidation_0-mlogloss:1.98084\tvalidation_1-mlogloss:1.98360\n",
      "[9]\tvalidation_0-mlogloss:1.97486\tvalidation_1-mlogloss:1.97792\n",
      "[10]\tvalidation_0-mlogloss:1.96942\tvalidation_1-mlogloss:1.97277\n",
      "[11]\tvalidation_0-mlogloss:1.96444\tvalidation_1-mlogloss:1.96807\n",
      "[12]\tvalidation_0-mlogloss:1.95992\tvalidation_1-mlogloss:1.96384\n",
      "[13]\tvalidation_0-mlogloss:1.95579\tvalidation_1-mlogloss:1.95998\n",
      "[14]\tvalidation_0-mlogloss:1.95200\tvalidation_1-mlogloss:1.95647\n",
      "[15]\tvalidation_0-mlogloss:1.94855\tvalidation_1-mlogloss:1.95329\n",
      "[16]\tvalidation_0-mlogloss:1.94536\tvalidation_1-mlogloss:1.95038\n",
      "[17]\tvalidation_0-mlogloss:1.94242\tvalidation_1-mlogloss:1.94775\n",
      "[18]\tvalidation_0-mlogloss:1.93973\tvalidation_1-mlogloss:1.94534\n",
      "[19]\tvalidation_0-mlogloss:1.93722\tvalidation_1-mlogloss:1.94312\n",
      "[20]\tvalidation_0-mlogloss:1.93489\tvalidation_1-mlogloss:1.94108\n",
      "[21]\tvalidation_0-mlogloss:1.93273\tvalidation_1-mlogloss:1.93921\n",
      "[22]\tvalidation_0-mlogloss:1.93072\tvalidation_1-mlogloss:1.93749\n",
      "[23]\tvalidation_0-mlogloss:1.92884\tvalidation_1-mlogloss:1.93588\n",
      "[24]\tvalidation_0-mlogloss:1.92709\tvalidation_1-mlogloss:1.93439\n",
      "[25]\tvalidation_0-mlogloss:1.92545\tvalidation_1-mlogloss:1.93302\n",
      "[26]\tvalidation_0-mlogloss:1.92388\tvalidation_1-mlogloss:1.93174\n",
      "[27]\tvalidation_0-mlogloss:1.92240\tvalidation_1-mlogloss:1.93052\n",
      "[28]\tvalidation_0-mlogloss:1.92105\tvalidation_1-mlogloss:1.92943\n",
      "[29]\tvalidation_0-mlogloss:1.91972\tvalidation_1-mlogloss:1.92839\n",
      "[30]\tvalidation_0-mlogloss:1.91847\tvalidation_1-mlogloss:1.92742\n",
      "[31]\tvalidation_0-mlogloss:1.91732\tvalidation_1-mlogloss:1.92655\n",
      "[32]\tvalidation_0-mlogloss:1.91620\tvalidation_1-mlogloss:1.92570\n",
      "[33]\tvalidation_0-mlogloss:1.91511\tvalidation_1-mlogloss:1.92490\n",
      "[34]\tvalidation_0-mlogloss:1.91411\tvalidation_1-mlogloss:1.92417\n",
      "[35]\tvalidation_0-mlogloss:1.91315\tvalidation_1-mlogloss:1.92348\n",
      "[36]\tvalidation_0-mlogloss:1.91224\tvalidation_1-mlogloss:1.92283\n",
      "[37]\tvalidation_0-mlogloss:1.91137\tvalidation_1-mlogloss:1.92224\n",
      "[38]\tvalidation_0-mlogloss:1.91053\tvalidation_1-mlogloss:1.92168\n",
      "[39]\tvalidation_0-mlogloss:1.90971\tvalidation_1-mlogloss:1.92115\n",
      "[40]\tvalidation_0-mlogloss:1.90892\tvalidation_1-mlogloss:1.92062\n",
      "[41]\tvalidation_0-mlogloss:1.90817\tvalidation_1-mlogloss:1.92013\n",
      "[42]\tvalidation_0-mlogloss:1.90744\tvalidation_1-mlogloss:1.91971\n",
      "[43]\tvalidation_0-mlogloss:1.90671\tvalidation_1-mlogloss:1.91928\n",
      "[44]\tvalidation_0-mlogloss:1.90602\tvalidation_1-mlogloss:1.91886\n",
      "[45]\tvalidation_0-mlogloss:1.90537\tvalidation_1-mlogloss:1.91850\n",
      "[46]\tvalidation_0-mlogloss:1.90469\tvalidation_1-mlogloss:1.91812\n",
      "[47]\tvalidation_0-mlogloss:1.90404\tvalidation_1-mlogloss:1.91775\n",
      "[48]\tvalidation_0-mlogloss:1.90341\tvalidation_1-mlogloss:1.91740\n",
      "[49]\tvalidation_0-mlogloss:1.90282\tvalidation_1-mlogloss:1.91708\n",
      "[50]\tvalidation_0-mlogloss:1.90222\tvalidation_1-mlogloss:1.91678\n",
      "[51]\tvalidation_0-mlogloss:1.90162\tvalidation_1-mlogloss:1.91648\n",
      "[52]\tvalidation_0-mlogloss:1.90107\tvalidation_1-mlogloss:1.91622\n",
      "[53]\tvalidation_0-mlogloss:1.90051\tvalidation_1-mlogloss:1.91594\n",
      "[54]\tvalidation_0-mlogloss:1.89995\tvalidation_1-mlogloss:1.91569\n",
      "[55]\tvalidation_0-mlogloss:1.89943\tvalidation_1-mlogloss:1.91546\n",
      "[56]\tvalidation_0-mlogloss:1.89892\tvalidation_1-mlogloss:1.91523\n",
      "[57]\tvalidation_0-mlogloss:1.89842\tvalidation_1-mlogloss:1.91501\n",
      "[58]\tvalidation_0-mlogloss:1.89792\tvalidation_1-mlogloss:1.91478\n",
      "[59]\tvalidation_0-mlogloss:1.89742\tvalidation_1-mlogloss:1.91457\n",
      "[60]\tvalidation_0-mlogloss:1.89691\tvalidation_1-mlogloss:1.91435\n",
      "[61]\tvalidation_0-mlogloss:1.89644\tvalidation_1-mlogloss:1.91414\n",
      "[62]\tvalidation_0-mlogloss:1.89596\tvalidation_1-mlogloss:1.91396\n",
      "[63]\tvalidation_0-mlogloss:1.89551\tvalidation_1-mlogloss:1.91378\n",
      "[64]\tvalidation_0-mlogloss:1.89505\tvalidation_1-mlogloss:1.91360\n",
      "[65]\tvalidation_0-mlogloss:1.89458\tvalidation_1-mlogloss:1.91341\n",
      "[66]\tvalidation_0-mlogloss:1.89415\tvalidation_1-mlogloss:1.91321\n",
      "[67]\tvalidation_0-mlogloss:1.89369\tvalidation_1-mlogloss:1.91302\n",
      "[68]\tvalidation_0-mlogloss:1.89325\tvalidation_1-mlogloss:1.91288\n",
      "[69]\tvalidation_0-mlogloss:1.89286\tvalidation_1-mlogloss:1.91274\n",
      "[70]\tvalidation_0-mlogloss:1.89241\tvalidation_1-mlogloss:1.91256\n",
      "[71]\tvalidation_0-mlogloss:1.89199\tvalidation_1-mlogloss:1.91243\n",
      "[72]\tvalidation_0-mlogloss:1.89155\tvalidation_1-mlogloss:1.91227\n",
      "[73]\tvalidation_0-mlogloss:1.89107\tvalidation_1-mlogloss:1.91206\n",
      "[74]\tvalidation_0-mlogloss:1.89070\tvalidation_1-mlogloss:1.91194\n",
      "[75]\tvalidation_0-mlogloss:1.89030\tvalidation_1-mlogloss:1.91179\n",
      "[76]\tvalidation_0-mlogloss:1.88990\tvalidation_1-mlogloss:1.91165\n",
      "[77]\tvalidation_0-mlogloss:1.88949\tvalidation_1-mlogloss:1.91152\n",
      "[78]\tvalidation_0-mlogloss:1.88913\tvalidation_1-mlogloss:1.91140\n",
      "[79]\tvalidation_0-mlogloss:1.88875\tvalidation_1-mlogloss:1.91129\n",
      "[80]\tvalidation_0-mlogloss:1.88835\tvalidation_1-mlogloss:1.91115\n",
      "[81]\tvalidation_0-mlogloss:1.88800\tvalidation_1-mlogloss:1.91105\n",
      "[82]\tvalidation_0-mlogloss:1.88764\tvalidation_1-mlogloss:1.91096\n",
      "[83]\tvalidation_0-mlogloss:1.88728\tvalidation_1-mlogloss:1.91087\n",
      "[84]\tvalidation_0-mlogloss:1.88692\tvalidation_1-mlogloss:1.91074\n",
      "[85]\tvalidation_0-mlogloss:1.88656\tvalidation_1-mlogloss:1.91065\n",
      "[86]\tvalidation_0-mlogloss:1.88624\tvalidation_1-mlogloss:1.91052\n",
      "[87]\tvalidation_0-mlogloss:1.88591\tvalidation_1-mlogloss:1.91045\n",
      "[88]\tvalidation_0-mlogloss:1.88556\tvalidation_1-mlogloss:1.91034\n",
      "[89]\tvalidation_0-mlogloss:1.88521\tvalidation_1-mlogloss:1.91025\n",
      "[90]\tvalidation_0-mlogloss:1.88488\tvalidation_1-mlogloss:1.91016\n",
      "[91]\tvalidation_0-mlogloss:1.88458\tvalidation_1-mlogloss:1.91008\n",
      "[92]\tvalidation_0-mlogloss:1.88428\tvalidation_1-mlogloss:1.91000\n",
      "[93]\tvalidation_0-mlogloss:1.88394\tvalidation_1-mlogloss:1.90992\n",
      "[94]\tvalidation_0-mlogloss:1.88358\tvalidation_1-mlogloss:1.90983\n",
      "[95]\tvalidation_0-mlogloss:1.88324\tvalidation_1-mlogloss:1.90975\n",
      "[96]\tvalidation_0-mlogloss:1.88291\tvalidation_1-mlogloss:1.90969\n",
      "[97]\tvalidation_0-mlogloss:1.88262\tvalidation_1-mlogloss:1.90959\n",
      "[98]\tvalidation_0-mlogloss:1.88234\tvalidation_1-mlogloss:1.90956\n",
      "[99]\tvalidation_0-mlogloss:1.88203\tvalidation_1-mlogloss:1.90951\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=10,\n",
       "              enable_categorical=False, eval_metric='mlogloss',\n",
       "              feature_types=None, gamma=None, gpu_id=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=0.1, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=6,\n",
       "              max_leaves=None, min_child_weight=None, missing=nan,\n",
       "              monotone_constraints=None, n_estimators=100, n_jobs=None,\n",
       "              num_class=8, num_parallel_tree=None, objective='multi:softmax', ...)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "xgb_model.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_train, y_train), (X_test, y_test)],\n",
    "    verbose=True  # Use verbose for training progress\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9a326fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# # Assuming y_train contains the labels\n",
    "# class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_train), y=y_train)\n",
    "# class_weights_dict = {i: class_weights[i] for i in range(len(class_weights))}\n",
    "\n",
    "# Use 'balanced' which automatically computes the class weights based on training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7aeff08a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[10995  3068  2111  1205  1207   547     8  2014]\n",
      " [ 8152  3238  2674  1656  1836   836    16  2720]\n",
      " [ 6184  2977  2877  2054  2455  1184    21  3353]\n",
      " [ 4604  2544  2670  2280  3121  1688    28  4086]\n",
      " [ 3433  2061  2374  2265  3347  1966    44  4933]\n",
      " [ 2353  1499  1779  1730  2906  2162    45  5525]\n",
      " [ 1422   897  1034   975  1745  1621    50  5669]\n",
      " [ 1345   831   972   780  1409  1474    29 12336]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.52      0.37     21155\n",
      "           1       0.19      0.15      0.17     21128\n",
      "           2       0.17      0.14      0.15     21105\n",
      "           3       0.18      0.11      0.13     21021\n",
      "           4       0.19      0.16      0.17     20423\n",
      "           5       0.19      0.12      0.15     17999\n",
      "           6       0.21      0.00      0.01     13413\n",
      "           7       0.30      0.64      0.41     19176\n",
      "\n",
      "    accuracy                           0.24    155420\n",
      "   macro avg       0.21      0.23      0.20    155420\n",
      "weighted avg       0.21      0.24      0.20    155420\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predict on test set\n",
    "y_pred = xgb_model.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4b66f9ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "morn_odds: 0.4517\n",
      "net_sentiment: 0.0453\n",
      "power: 0.0157\n",
      "avg_spd_sd: 0.0172\n",
      "hi_spd_sd: 0.0184\n",
      "avgspd: 0.0175\n",
      "ave_cl_sd: 0.0118\n",
      "cond_win: 0.0154\n",
      "cond_place: 0.0095\n",
      "all_win: 0.0197\n",
      "all_place: 0.0129\n",
      "cond_earnings: 0.0124\n",
      "all_earnings: 0.0170\n",
      "weight: 0.0101\n",
      "cond_show: 0.0100\n",
      "all_show: 0.0153\n",
      "cond_starts: 0.0121\n",
      "all_starts: 0.0161\n",
      "class_rating: 0.0171\n",
      "age_at_race_day: 0.0117\n",
      "distance: 0.0117\n",
      "horse_id: 0.0104\n",
      "claimprice: 0.0133\n",
      "wps_pool: 0.0274\n",
      "cond_fourth: 0.0115\n",
      "all_fourth: 0.0141\n",
      "purse: 0.0180\n",
      "pstyerl: 0.0195\n",
      "race_number: 0.0447\n",
      "start_position: 0.0726\n"
     ]
    }
   ],
   "source": [
    "importances = xgb_model.feature_importances_\n",
    "for col, imp in zip(feature_cols, importances):\n",
    "    print(f\"{col}: {imp:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2939f420",
   "metadata": {},
   "source": [
    "# Predicting Probabilities for Ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b9ee05e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/exx/anaconda3/envs/mamba_env/envs/tf_310/lib/python3.10/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Predict Probabilities\n",
    "predicted_probs = rf_model.predict_proba(X_test_scaled)[:, 1]  # Probability for winning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8963293a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         race_date  race_number  horse_id  predicted_probability  rank\n",
      "443968  2022-01-01            1    257862                  0.190   1.0\n",
      "403657  2022-01-01            1     96356                  0.189   2.0\n",
      "557148  2022-01-01            1     14941                  0.188   3.0\n",
      "143143  2022-01-01            1    294126                  0.187   4.0\n",
      "732523  2022-01-01            1    113458                  0.148   5.0\n",
      "241696  2022-01-01            1      9903                  0.143   6.0\n",
      "732524  2022-01-01            1     35560                  0.085   7.0\n",
      "732528  2022-01-01            1    181319                  0.084   8.0\n",
      "403659  2022-01-01            1     96358                  0.084   9.0\n",
      "200286  2022-01-01            1    269764                  0.084  10.0\n",
      "443966  2022-01-01            1     10298                  0.078  11.0\n",
      "200285  2022-01-01            1     62596                  0.078  12.0\n",
      "424227  2022-01-01            1    163465                  0.077  13.0\n",
      "443969  2022-01-01            1    257859                  0.075  14.0\n",
      "409177  2022-01-01            1      4068                  0.071  15.0\n",
      "200284  2022-01-01            1      6236                  0.071  16.0\n",
      "403661  2022-01-01            1      9405                  0.062  17.0\n",
      "443965  2022-01-01            1     15154                  0.062  18.0\n",
      "598473  2022-01-01            2     14951                  0.310   1.0\n",
      "598474  2022-01-01            2     12667                  0.309   2.0\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Combine Metadata with Predictions\n",
    "ranked_df = metadata_test.copy()\n",
    "ranked_df[\"predicted_probability\"] = predicted_probs\n",
    "\n",
    "# Step 3: Rank Horses\n",
    "ranked_df[\"rank\"] = (\n",
    "    ranked_df.groupby([\"race_date\", \"race_number\"])[\"predicted_probability\"]\n",
    "    .rank(method=\"first\", ascending=False)\n",
    ")\n",
    "\n",
    "# Step 4: Sort Ranked DataFrame\n",
    "ranked_df = ranked_df.sort_values(by=[\"race_date\", \"race_number\", \"rank\"])\n",
    "\n",
    "# Step 5: Save or Display Results\n",
    "print(ranked_df.head(20))  # Display top 20 ranked horses\n",
    "ranked_df.to_csv(\"ranked_horses.csv\", index=False)  # Save to CSV if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "270b85ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/exx/anaconda3/envs/mamba_env/envs/tf_310/lib/python3.10/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'race_date' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 14\u001b[0m\n\u001b[1;32m      9\u001b[0m predicted_probs \u001b[38;5;241m=\u001b[39m proba[:, \u001b[38;5;241m1\u001b[39m]  \u001b[38;5;66;03m# Probability for class 1 (winning)\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Step 2: Create a DataFrame for `X_test` with metadata\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Replace with actual metadata (e.g., from original test data before splitting)\u001b[39;00m\n\u001b[1;32m     13\u001b[0m metadata \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\n\u001b[0;32m---> 14\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrace_date\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[43mrace_date\u001b[49m,  \u001b[38;5;66;03m# Replace with actual race dates\u001b[39;00m\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrace_number\u001b[39m\u001b[38;5;124m\"\u001b[39m: race_number,  \u001b[38;5;66;03m# Replace with actual race numbers\u001b[39;00m\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhorse_id\u001b[39m\u001b[38;5;124m\"\u001b[39m: horse_id,  \u001b[38;5;66;03m# Replace with actual horse IDs\u001b[39;00m\n\u001b[1;32m     17\u001b[0m })\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Combine predicted probabilities with metadata\u001b[39;00m\n\u001b[1;32m     20\u001b[0m ranked_df \u001b[38;5;241m=\u001b[39m metadata\u001b[38;5;241m.\u001b[39mcopy()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'race_date' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Assuming X_test corresponds to the feature matrix for your test set\n",
    "# And you have additional columns `race_date`, `race_number`, `horse_id` in the original data.\n",
    "\n",
    "# Step 1: Predict Probabilities\n",
    "proba = rf_model.predict_proba(X_test_scaled)  # Shape: (n_samples, 2)\n",
    "predicted_probs = proba[:, 1]  # Probability for class 1 (winning)\n",
    "\n",
    "# Step 2: Create a DataFrame for `X_test` with metadata\n",
    "# Replace with actual metadata (e.g., from original test data before splitting)\n",
    "metadata = pd.DataFrame({\n",
    "    \"race_date\": race_date,  # Replace with actual race dates\n",
    "    \"race_number\": race_number,  # Replace with actual race numbers\n",
    "    \"horse_id\": horse_id,  # Replace with actual horse IDs\n",
    "})\n",
    "\n",
    "# Combine predicted probabilities with metadata\n",
    "ranked_df = metadata.copy()\n",
    "ranked_df[\"predicted_probability\"] = predicted_probs\n",
    "\n",
    "# Step 3: Rank Horses\n",
    "# Group by race_date and race_number, then rank by predicted_probability\n",
    "ranked_df[\"rank\"] = (\n",
    "    ranked_df.groupby([\"race_date\", \"race_number\"])[\"predicted_probability\"]\n",
    "    .rank(method=\"first\", ascending=False)\n",
    ")\n",
    "\n",
    "# Step 4: Sort Ranked DataFrame\n",
    "ranked_df = ranked_df.sort_values(by=[\"race_date\", \"race_number\", \"rank\"])\n",
    "\n",
    "# Step 5: Save or Display Results\n",
    "print(ranked_df.head(20))  # Display top 20 ranked horses\n",
    "ranked_df.to_csv(\"ranked_horses.csv\", index=False)  # Save to CSV if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca5f385",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranked_df = metadata_test.copy()  # Metadata includes race_date, race_number, horse_id\n",
    "ranked_df[\"predicted_probability\"] = predicted_probs\n",
    "ranked_df[\"actual_label\"] = y_test  # Optional: for evaluation purposes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b920b06",
   "metadata": {},
   "source": [
    "## Predict via Ranking using Test Race from Dataset\n",
    "\n",
    "You can test the model on a race in your dataset by excluding the target variable (official_fin) and making predictions as if it were a new race. Here’s how you can proceed:\n",
    "\n",
    "Step 1: Select a Race for Testing\n",
    "\n",
    "Extract a specific race from your dataset based on race_date and race_number.\n",
    "\n",
    "race_to_test = df[\n",
    "    (df[\"race_date\"] == \"2023-05-15\") & (df[\"race_number\"] == 5)\n",
    "].drop(columns=[\"official_fin\"])  # Drop the target variable\n",
    "\n",
    "Step 2: Prepare the Features\n",
    "\n",
    "Ensure that the extracted race has the same feature processing (scaling, encoding) as was done during training.\n",
    "\n",
    "# Extract features\n",
    "X_race = race_to_test[feature_cols]  # Ensure `feature_cols` matches the training feature set\n",
    "\n",
    "# Scale features\n",
    "X_race_scaled = scaler.transform(X_race)  # Use the scaler fitted during training\n",
    "\n",
    "Step 3: Predict Probabilities\n",
    "\n",
    "Use the model to predict probabilities for this specific race.\n",
    "\n",
    "# Predict probabilities\n",
    "race_probs = rf_model.predict_proba(X_race_scaled)\n",
    "\n",
    "# Attach probabilities back to the metadata\n",
    "race_to_test[\"predicted_probability\"] = race_probs[:, 1]  # Assuming class 1 is 'winning'\n",
    "\n",
    "# Rank horses by predicted probability\n",
    "race_to_test[\"rank\"] = race_to_test[\"predicted_probability\"].rank(ascending=False)\n",
    "race_to_test = race_to_test.sort_values(by=\"rank\")\n",
    "\n",
    "Step 4: Compare to Actual Results\n",
    "\n",
    "If you still have the actual official_fin values in a backup, compare the model’s ranking against the real results.\n",
    "\n",
    "# Add actual finish positions for comparison (if available)\n",
    "actual_results = df[\n",
    "    (df[\"race_date\"] == \"2023-05-15\") & (df[\"race_number\"] == 5)\n",
    "][[\"horse_id\", \"official_fin\"]]\n",
    "\n",
    "race_to_test = race_to_test.merge(actual_results, on=\"horse_id\", how=\"left\")\n",
    "\n",
    "# Display results\n",
    "print(race_to_test[[\"horse_id\", \"predicted_probability\", \"rank\", \"official_fin\"]])\n",
    "\n",
    "Testing Without horse_id, race_date, or race_number\n",
    "\n",
    "If you remove horse_id, race_date, or race_number, the model should still be able to make predictions if those columns are not part of the feature set. However, you won’t be able to group or rank the predictions by race because race_date and race_number are critical for distinguishing horses in the same race.\n",
    "\n",
    "To simulate a future race:\n",
    "\t1.\tSelect a race that the model hasn’t seen during training (e.g., from a holdout set).\n",
    "\t2.\tRemove any identifying metadata (e.g., horse_id, race_date, race_number).\n",
    "\t3.\tProcess the features the same way as during training.\n",
    "\t4.\tUse the model to predict probabilities for the horses in that race.\n",
    "\t5.\tRank the predictions by probability.\n",
    "\n",
    "Testing with a Future Race\n",
    "\n",
    "For a future race:\n",
    "\t1.\tCollect horse features for that race (e.g., from Equibase).\n",
    "\t2.\tProcess the data the same way as the training data.\n",
    "\t3.\tUse the model to make predictions.\n",
    "\t4.\tRank horses by predicted probabilities.\n",
    "\t5.\tWait for the race results and compare the model’s rankings to the actual outcomes.\n",
    "\n",
    "This approach ensures the model is evaluated on unseen data, simulating a real-world scenario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccea8560",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c9d5cf9c",
   "metadata": {},
   "source": [
    "## Hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f69c255",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f05de29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    \"n_estimators\": [50, 100, 200],\n",
    "    \"max_depth\": [None, 10, 20],\n",
    "    \"max_features\": [\"auto\", \"sqrt\", 0.5],\n",
    "    \"class_weight\": [None, \"balanced\"]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=RandomForestClassifier(random_state=42),\n",
    "    param_grid=param_grid,\n",
    "    scoring=\"accuracy\",    # or \"f1\", \"balanced_accuracy\", etc.\n",
    "    cv=3,                  # 3-fold cross-validation\n",
    "    n_jobs=-1             # use all CPU cores\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(\"Best Params:\", grid_search.best_params_)\n",
    "print(\"Best Score:\", grid_search.best_score_)\n",
    "\n",
    "# Then evaluate on the test set:\n",
    "best_rf = grid_search.best_estimator_\n",
    "y_pred_best = best_rf.predict(X_test)\n",
    "print(\"Final Test Accuracy:\", (y_pred_best == y_test).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a0649f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3486d1c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb16452a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
