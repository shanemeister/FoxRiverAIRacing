{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a43fc8b",
   "metadata": {},
   "source": [
    "# LGBoost Model Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cad7392",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#%pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912f5950-5221-4430-ac4d-01a4f528be41",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1463424",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Environment\n",
    "\n",
    "import os\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import KFold\n",
    "import matplotlib.pyplot as plt\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMRanker\n",
    "import optuna\n",
    "import itertools\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.functions import (col, count, row_number, abs, unix_timestamp, mean, \n",
    "                                   when, lit, min as F_min, max as F_max , upper, trim,\n",
    "                                   row_number, mean as F_mean, countDistinct, last, first, when)\n",
    "from src.data_preprocessing.data_prep1.data_utils import initialize_environment \n",
    "# Set global references to None\n",
    "spark = None\n",
    "master_results_df = None\n",
    "df = None\n",
    "upcoming_races = None\n",
    "train_df = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73671a61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark session created successfully.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "spark, jdbc_url, jdbc_properties, parquet_dir, log_file = initialize_environment()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2dc25f3-b696-4012-ba01-0d89d4776580",
   "metadata": {},
   "outputs": [],
   "source": [
    "upcoming_races = spark.read.parquet(\"/home/exx/myCode/horse-racing/FoxRiverAIRacing/data/parquet/upcoming_races.parquet\")\n",
    "training_data = spark.read.parquet(\"/home/exx/myCode/horse-racing/FoxRiverAIRacing/data/parquet/train_df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b95383bf-b81c-47ce-bccf-020cc2762bb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1078"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upcoming_races.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ccd5955",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "394322"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.count() # Bringing in training data to do embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce2ed82",
   "metadata": {},
   "source": [
    "# Switching to Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e3b985b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "# Convert Spark DataFrame -> Pandas DataFrame\n",
    "\n",
    "upcoming_races = upcoming_races.toPandas()\n",
    "\n",
    "training_data = training_data.toPandas()\n",
    "\n",
    "# Quick info about the DataFrame\n",
    "#print(df.info())\n",
    "#print(df.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d1f824-4334-49f5-8660-62f3cb4a54bb",
   "metadata": {},
   "source": [
    "# Set race_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92eb1d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "upcoming_races[\"race_id\"] = (\n",
    "    upcoming_races[\"course_cd\"].astype(str) + \"_\" +\n",
    "    upcoming_races[\"race_date\"].astype(str) + \"_\" +\n",
    "    upcoming_races[\"race_number\"].astype(str)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5bf69f5-0652-45e0-9fa0-a2aeea6f89c5",
   "metadata": {},
   "source": [
    "# Group and sort data by race_id and group_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f3dade4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate unique numeric group_id from race_id\n",
    "upcoming_races[\"group_id\"] = upcoming_races[\"race_id\"].astype(\"category\").cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "004194b1-d13d-4395-b9a1-f2f6b28d4250",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by race_id for consistency\n",
    "upcoming_races = upcoming_races.sort_values(\"group_id\", ascending=True)\n",
    "upcoming_races.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f46e2237-bd4d-46fb-a33d-0150230e59bc",
   "metadata": {},
   "source": [
    "# Drop Non-numeric Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "984acd83-988f-4f6d-99e1-9aab30198b74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After dropping unused cols, shape: (1078, 77)\n"
     ]
    }
   ],
   "source": [
    "unused_columns = [\n",
    "    # columns you do NOT use in features or group_id\n",
    "    \"race_date\", \"date_of_birth\"\n",
    "]\n",
    "cols_to_drop = [col for col in unused_columns if col in upcoming_races.columns]\n",
    "\n",
    "upcoming_races.drop(columns=cols_to_drop, inplace=True)\n",
    "print(\"After dropping unused cols, shape:\", upcoming_races.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36345682-6fdd-42e3-af00-e9da9c4ba4c4",
   "metadata": {},
   "source": [
    "# Convert DataTime columns to Numerical Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "79f6fc05-d4c6-4ecb-87eb-aafa2b73ba20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert datetime columns to numerical\n",
    "upcoming_races[\"first_race_date_5\"] = pd.to_datetime(upcoming_races[\"first_race_date_5\"])\n",
    "upcoming_races[\"most_recent_race_5\"] = pd.to_datetime(upcoming_races[\"most_recent_race_5\"])\n",
    "upcoming_races[\"prev_race_date\"] = pd.to_datetime(upcoming_races[\"prev_race_date\"])\n",
    "\n",
    "# Calculate numeric date features\n",
    "upcoming_races[\"first_race_date_5_numeric\"] = (upcoming_races[\"first_race_date_5\"] - pd.Timestamp(\"1970-01-01\")).dt.days\n",
    "upcoming_races[\"most_recent_race_5_numeric\"] = (upcoming_races[\"most_recent_race_5\"] - pd.Timestamp(\"1970-01-01\")).dt.days\n",
    "upcoming_races[\"prev_race_date_numeric\"] = (upcoming_races[\"prev_race_date\"] - pd.Timestamp(\"1970-01-01\")).dt.days\n",
    "\n",
    "# Drop original datetime columns\n",
    "upcoming_races.drop(columns=[\"first_race_date_5\", \"most_recent_race_5\", \"prev_race_date\"], inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d1f3dc7-8571-47c4-93d8-0c52048663fe",
   "metadata": {},
   "source": [
    "# Set Rank/Label -- Used for Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c0d9caaf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# If the largest official_fin is 20 (some races can have 20 horses),\n",
    "# then label = (21 - official_fin).\n",
    "# So official_fin=1 => label=20, official_fin=2 =>19, etc.\n",
    "# If your max is 14, you can do (15 - official_fin).  Just ensure \"best\" horse has largest label.\n",
    "if \"official_fin\" in training_data.columns:\n",
    "    # Calculate 'rank' and add it to the DataFrame\n",
    "    training_data[\"rank\"] = 21 - training_data[\"official_fin\"]\n",
    "    # Drop the 'official_fin' column\n",
    "    training_data.drop(columns=[\"official_fin\"], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814c4120-34dd-48b9-ab46-93c197e118e4",
   "metadata": {},
   "source": [
    "# Simple Target Encoding for (XGBoost/LightGBM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dfbd2f1a-4b43-4894-9b88-b07bda82934e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure original horse_id is kept\n",
    "upcoming_races[\"horse_id_original\"] = upcoming_races[\"horse_id\"]\n",
    "\n",
    "def encode_horse_id_with_training_mean(upcoming_df, training_df, horse_col, target_col):\n",
    "    \"\"\"\n",
    "    Encode horse_id in the upcoming data using the historical mean target\n",
    "    from the training data.\n",
    "\n",
    "    Parameters:\n",
    "    - upcoming_df: DataFrame for races to predict\n",
    "    - training_df: DataFrame with historical data\n",
    "    - horse_col: Column containing horse IDs\n",
    "    - target_col: Target column (e.g., rank, performance metric)\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame with encoded horse_id\n",
    "    \"\"\"\n",
    "    # Compute historical mean for each horse_id from the training data\n",
    "    horse_means = training_df.groupby(horse_col)[target_col].mean()\n",
    "\n",
    "    # Map the historical means to the upcoming races\n",
    "    upcoming_df[\"horse_id_encoded\"] = upcoming_df[horse_col].map(horse_means)\n",
    "\n",
    "    # If a horse_id in upcoming races doesn't exist in training data, fill with the global mean\n",
    "    global_mean = training_df[target_col].mean()\n",
    "    upcoming_df[\"horse_id_encoded\"] = upcoming_df[\"horse_id_encoded\"].fillna(global_mean)\n",
    "\n",
    "    return upcoming_df\n",
    "\n",
    "# Example usage\n",
    "upcoming_races = encode_horse_id_with_training_mean(\n",
    "    upcoming_df=upcoming_races,\n",
    "    training_df=training_data,  # Historical data\n",
    "    horse_col=\"horse_id\",\n",
    "    target_col=\"rank\"  # Column used for encoding (from historical data)\n",
    ")\n",
    "\n",
    "# Drop the original horse_id if it's not needed\n",
    "upcoming_races.drop(columns=[\"horse_id\"], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba32ee9b-ee14-4c64-8891-bbc26759d840",
   "metadata": {},
   "source": [
    "# Assigned Numerical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "63102b51-4944-48c8-a1b5-7d291a4f4aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['race_number','horse_id_encoded','purse','weight','claimprice','power','morn_odds','avgspd','class_rating',\n",
    "    'net_sentiment','avg_spd_sd','ave_cl_sd','hi_spd_sd','pstyerl','all_starts','all_win','all_place',\n",
    "    'all_show','all_fourth','all_earnings','cond_starts','cond_win','cond_place','cond_show','cond_fourth',\n",
    "    'cond_earnings','avg_speed_5','best_speed','avg_beaten_len_5','avg_dist_bk_gate1_5','avg_dist_bk_gate2_5',\n",
    "    'avg_dist_bk_gate3_5','avg_dist_bk_gate4_5','avg_speed_fullrace_5','avg_stride_length_5','avg_strfreq_q1_5',\n",
    "    'avg_strfreq_q2_5','avg_strfreq_q3_5','avg_strfreq_q4_5','prev_speed','speed_improvement','days_off',\n",
    "    'avg_workout_rank_3','jock_win_percent','jock_itm_percent','trainer_win_percent','trainer_itm_percent',\n",
    "    'jt_win_percent','jt_itm_percent','jock_win_track','jock_itm_track','trainer_win_track','trainer_itm_track',\n",
    "    'jt_win_track','jt_itm_track','age_at_race_day','distance_meters', 'count_workouts_3']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b9913a-ca63-4b7d-815f-630aa2c9a1f4",
   "metadata": {},
   "source": [
    "# Set the Category Columns with Label Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ca12b72c-3f3f-4fc4-9f52-f109880cb5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cat_cols = [ \"course_cd\", \"sex\", \"equip\", \"surface\", \"med\",  \n",
    "            \"race_type\", \"stk_clm_md\", \"turf_mud_mark\", \"layoff_cat\"]\n",
    "for c in cat_cols:\n",
    "    lbl = LabelEncoder()\n",
    "    upcoming_races[c] = lbl.fit_transform(upcoming_races[c].astype(str))\n",
    "\n",
    "# Specify categorical feature indices\n",
    "cat_cols_indices = [upcoming_races.columns.get_loc(col) for col in cat_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc4d751-7a89-49ed-93ff-51c2f56e1638",
   "metadata": {},
   "source": [
    "# Load the LGB Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dbdfb695-67b8-40a8-b236-6de0e96d0678",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_model = lgb.Booster(model_file=\"/home/exx/myCode/horse-racing/FoxRiverAIRacing/src/models/LGB_962065_2025-01-12.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9fa41011-6223-4c42-8719-0863613dd021",
   "metadata": {},
   "outputs": [],
   "source": [
    "#upcoming_races.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d0304950-6f84-4abe-9fbb-a8deeddcb01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retain horse_name and saddle_cloth_number\n",
    "extra_cols = [\"race_id\", \"saddle_cloth_number\", \"horse_name\"]  # Columns to retain for output\n",
    "\n",
    "# Create a DataFrame with only the necessary columns\n",
    "X_predict = upcoming_races[features].copy()\n",
    "\n",
    "# Convert categorical columns if needed\n",
    "cat_cols = [\"course_cd\", \"sex\", \"equip\", \"surface\", \"med\", \"race_type\", \"stk_clm_md\", \"turf_mud_mark\", \"layoff_cat\"]\n",
    "for col in cat_cols:\n",
    "    if col in X_predict.columns:\n",
    "        X_predict[col] = X_predict[col].astype(\"category\")\n",
    "\n",
    "# Handle missing values (adjust fill strategy as needed)\n",
    "X_predict.fillna(0, inplace=True)\n",
    "\n",
    "# Step 3: Predict scores\n",
    "X_predict_values = X_predict.values\n",
    "predicted_scores = lgbm_model.predict(X_predict_values)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fd73adc3-8de3-4849-942f-c2ff3c187bfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 race_id saddle_cloth_number         horse_name  \\\n",
      "0     AQU_2025-01-12_1.0                   2           Toned Up   \n",
      "1     AQU_2025-01-12_1.0                   6      dh-Proud Foot   \n",
      "2     AQU_2025-01-12_1.0                   3    Romantic Dancer   \n",
      "3     AQU_2025-01-12_1.0                   4   Echo in Eternity   \n",
      "4     AQU_2025-01-12_1.0                   5          Moonboots   \n",
      "...                  ...                 ...                ...   \n",
      "1073  TTP_2025-01-16_9.0                   6           Tonalite   \n",
      "1074  TTP_2025-01-16_9.0                   7   Rosario's Prayer   \n",
      "1075  TTP_2025-01-16_9.0                   8  Katie's Checkride   \n",
      "1076  TTP_2025-01-16_9.0                  10          Right Now   \n",
      "1077  TTP_2025-01-16_9.0                   3            El Kown   \n",
      "\n",
      "      predicted_rank  predicted_score  \n",
      "0                1.0         1.941737  \n",
      "1                2.0         1.889484  \n",
      "2                3.0         1.513722  \n",
      "3                4.0        -2.412867  \n",
      "4                5.0        -2.809916  \n",
      "...              ...              ...  \n",
      "1073            10.0        -2.276961  \n",
      "1074            11.0        -2.885741  \n",
      "1075            12.0        -3.280773  \n",
      "1076            13.0        -3.514030  \n",
      "1077            14.0        -5.778836  \n",
      "\n",
      "[1078 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Add predictions to the DataFrame\n",
    "upcoming_races[\"predicted_score\"] = predicted_scores\n",
    "\n",
    "# Step 5: Rank horses within each race_id based on predicted_score\n",
    "upcoming_races[\"predicted_rank\"] = upcoming_races.groupby(\"race_id\")[\"predicted_score\"].rank(\n",
    "    method=\"dense\", ascending=False\n",
    ")\n",
    "\n",
    "# Step 6: Create the final DataFrame\n",
    "output = upcoming_races[[\"race_id\", \"saddle_cloth_number\", \"horse_name\", \"predicted_rank\", \"predicted_score\"]]\n",
    "\n",
    "# Optional: Sort by race_id and predicted_rank for better readability\n",
    "output = output.sort_values(by=[\"race_id\", \"predicted_rank\"]).reset_index(drop=True)\n",
    "\n",
    "# Display the output\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab58aa0-4803-4f27-9944-de7356745c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the race_id you want to filter\n",
    "selected_race_id = \"TAM_2025-01-12_9.0\"  # Replace with your desired race_id\n",
    "\n",
    "# Filter the DataFrame for the selected race_id\n",
    "selected_race = output[output[\"race_id\"] == selected_race_id].copy()\n",
    "\n",
    "# Optional: Sort by predicted rank for readability\n",
    "selected_race = selected_race.sort_values(by=\"predicted_rank\").reset_index(drop=True)\n",
    "\n",
    "# Display the filtered DataFrame\n",
    "print(selected_race)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2100ce64-e38e-4bd6-8e95-9efc54b9fd47",
   "metadata": {},
   "outputs": [],
   "source": [
    "importance = lgbm_model.feature_importance(importance_type='gain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b7b941-578a-4441-b3af-0402bb69a52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance_df = pd.DataFrame({\n",
    "    'feature': features,\n",
    "    'importance': importance\n",
    "}).sort_values(by='importance', ascending=False)\n",
    "# Filter features with importance > 50\n",
    "important_features = feature_importance_df[feature_importance_df['importance'] > 50]\n",
    "print(important_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e14d10-4e87-4090-bb56-392a1712b86c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
