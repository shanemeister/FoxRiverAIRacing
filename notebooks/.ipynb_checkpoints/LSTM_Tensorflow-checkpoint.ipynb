{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f96c21c8",
   "metadata": {},
   "source": [
    "# Proposed Ensemble Models\n",
    "\n",
    "Given the constraints and objectives, I will consider the following models for the ensemble:\n",
    "\t\n",
    "    1.\tModel 1: LSTM Network on Raw GPS Data\n",
    "    \n",
    ">•\tInput Data: Sequences of raw GPS data (speed, progress, stride_frequency, etc.).\n",
    "\n",
    ">•\tArchitecture: An LSTM network designed to capture temporal dependencies and patterns in the sequential data.\n",
    "\n",
    ">•\tAdvantage: LSTMs are well-suited for time-series data and can learn complex temporal dynamics without the need for hand-engineered features like acceleration.\n",
    "\n",
    "    2.\tModel 2: 1D Convolutional Neural Network (1D-CNN)\n",
    "\t\n",
    ">•\tInput Data: The same raw GPS sequences as in Model 1.\n",
    "\n",
    ">•\tArchitecture: A 1D-CNN that applies convolutional filters across the time dimension to detect local patterns.\n",
    "\n",
    ">•\tAdvantage: CNNs can capture spatial hierarchies and are effective in recognizing patterns in sequences, potentially identifying features like sudden changes in speed or stride frequency.\n",
    "\n",
    "    3.\tModel 3: Transformer-based Model\n",
    "\t\n",
    ">•\tInput Data: Raw GPS sequences and possibly sectionals data.\n",
    "\n",
    ">•\tArchitecture: A Transformer model that uses self-attention mechanisms to weigh the importance of different parts of the sequence.\n",
    "\n",
    ">•\tAdvantage: Transformers can model long-range dependencies and focus on the most relevant parts of the sequence for prediction.\n",
    "\n",
    "## Additional Models (Optional):\n",
    "\n",
    "    4.\tModel 4: Gated Recurrent Unit (GRU) Network\n",
    "\n",
    ">•\tSimilar to LSTMs but with a simpler architecture, GRUs can be more efficient and may perform better on certain datasets.\n",
    "\n",
    ">•\tModel 5: Temporal Convolutional Network (TCN)\n",
    "\n",
    ">•\tTCNs are designed for sequential data and can capture long-term dependencies using causal convolutions and residual connections.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f703df",
   "metadata": {},
   "source": [
    "## Load Parquet Train, Test, and Validaion (VAL) Data:\n",
    "\n",
    "/home/exx/myCode/horse-racing/FoxRiverAIRacing/data/parquet/train_sequences.parquet\n",
    "\n",
    "/home/exx/myCode/horse-racing/FoxRiverAIRacing/data/parquet/test_sequences.parquet\n",
    "\n",
    "/home/exx/myCode/horse-racing/FoxRiverAIRacing/data/parquet/val_sequences.parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a60982",
   "metadata": {},
   "outputs": [],
   "source": [
    "#spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1cf56395",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-30 15:06:03,543 - INFO - Environment setup initialized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark session created successfully.\n"
     ]
    }
   ],
   "source": [
    "# Set Environment\n",
    "import os\n",
    "import pyspark.sql.functions as F\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pyspark.sql import DataFrame\n",
    "from pyspark.sql.functions import col, size, when, count\n",
    "from src.data_preprocessing.data_prep1.data_utils import (\n",
    "    save_parquet, gather_statistics, initialize_environment,\n",
    "    load_config, initialize_logging, initialize_spark, \n",
    "    identify_and_impute_outliers, identify_and_remove_outliers, process_merged_results_sectionals,\n",
    "    identify_missing_and_outliers\n",
    ")\n",
    "\n",
    "try:\n",
    "    spark, jdbc_url, jdbc_properties, queries, parquet_dir, log_file = initialize_environment()\n",
    "    # input(\"Press Enter to continue...\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during initialization: {e}\")\n",
    "    logging.error(f\"An error occurred during initialization: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96ddf3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sequences = os.path.join(parquet_dir, \"train_sequences.parquet\")\n",
    "train_sequences = spark.read.parquet(train_sequences)\n",
    "test_sequences = os.path.join(parquet_dir, \"test_sequences.parquet\")\n",
    "test_sequences = spark.read.parquet(test_sequences)\n",
    "val_sequences = os.path.join(parquet_dir, \"val_sequences.parquet\")\n",
    "val_sequences = spark.read.parquet(val_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1eb72401",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- horse_id: integer (nullable = true)\n",
      " |-- label: integer (nullable = true)\n",
      " |-- gate_index: integer (nullable = true)\n",
      " |-- course_cd_ohe: array (nullable = true)\n",
      " |    |-- element: double (containsNull = true)\n",
      " |-- equip_ohe: array (nullable = true)\n",
      " |    |-- element: double (containsNull = true)\n",
      " |-- surface_ohe: array (nullable = true)\n",
      " |    |-- element: double (containsNull = true)\n",
      " |-- trk_cond_ohe: array (nullable = true)\n",
      " |    |-- element: double (containsNull = true)\n",
      " |-- weather_ohe: array (nullable = true)\n",
      " |    |-- element: double (containsNull = true)\n",
      " |-- med_ohe: array (nullable = true)\n",
      " |    |-- element: double (containsNull = true)\n",
      " |-- stk_clm_md_ohe: array (nullable = true)\n",
      " |    |-- element: double (containsNull = true)\n",
      " |-- turf_mud_mark_ohe: array (nullable = true)\n",
      " |    |-- element: double (containsNull = true)\n",
      " |-- race_type_ohe: array (nullable = true)\n",
      " |    |-- element: double (containsNull = true)\n",
      " |-- scaled_features: vector (nullable = true)\n",
      " |-- aggregated_struct: struct (nullable = true)\n",
      " |    |-- ohe_flat: array (nullable = true)\n",
      " |    |    |-- element: double (containsNull = true)\n",
      " |    |-- avg_speed_agg: double (nullable = true)\n",
      " |    |-- max_speed_agg: double (nullable = true)\n",
      " |    |-- final_speed_agg: double (nullable = true)\n",
      " |    |-- avg_accel_agg: double (nullable = true)\n",
      " |    |-- fatigue_agg: double (nullable = true)\n",
      " |    |-- sectional_time_agg: double (nullable = true)\n",
      " |    |-- running_time_agg: double (nullable = true)\n",
      " |    |-- distance_back_agg: double (nullable = true)\n",
      " |    |-- distance_ran_agg: double (nullable = true)\n",
      " |    |-- strides_agg: double (nullable = true)\n",
      " |    |-- max_speed_overall: double (nullable = true)\n",
      " |    |-- min_speed_overall: double (nullable = true)\n",
      " |-- past_races_sequence: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- ohe_flat: array (nullable = true)\n",
      " |    |    |    |-- element: double (containsNull = true)\n",
      " |    |    |-- avg_speed_agg: double (nullable = true)\n",
      " |    |    |-- max_speed_agg: double (nullable = true)\n",
      " |    |    |-- final_speed_agg: double (nullable = true)\n",
      " |    |    |-- avg_accel_agg: double (nullable = true)\n",
      " |    |    |-- fatigue_agg: double (nullable = true)\n",
      " |    |    |-- sectional_time_agg: double (nullable = true)\n",
      " |    |    |-- running_time_agg: double (nullable = true)\n",
      " |    |    |-- distance_back_agg: double (nullable = true)\n",
      " |    |    |-- distance_ran_agg: double (nullable = true)\n",
      " |    |    |-- strides_agg: double (nullable = true)\n",
      " |    |    |-- max_speed_overall: double (nullable = true)\n",
      " |    |    |-- min_speed_overall: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_sequences.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84e0d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_sequences.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1e22727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_sequences.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd513365",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|label|count|\n",
      "+-----+-----+\n",
      "|    2| 5984|\n",
      "|    3| 5955|\n",
      "|    1| 5840|\n",
      "|    4| 5738|\n",
      "|    0| 5662|\n",
      "|    7| 5065|\n",
      "|    5| 4928|\n",
      "|    6| 3640|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# If your label column is named \"label\":\n",
    "train_sequences.groupBy(\"label\").count().orderBy(\"count\", ascending=False).show()\n",
    "\n",
    "# This shows how many examples you have in each label category.\n",
    "# If it's a multi-class problem (e.g., finishing position 0,1,2,...),\n",
    "# you'll see how many rows for each class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8163ebaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+------------------+\n",
      "|label|count|        percentage|\n",
      "+-----+-----+------------------+\n",
      "|    2| 5984| 13.97738951695786|\n",
      "|    3| 5955|13.909651499579557|\n",
      "|    1| 5840|13.641035223769038|\n",
      "|    4| 5738|13.402784266093617|\n",
      "|    0| 5662|13.225263944688406|\n",
      "|    7| 5065|  11.8307951041764|\n",
      "|    5| 4928|11.510791366906476|\n",
      "|    6| 3640| 8.502289077828646|\n",
      "+-----+-----+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyspark.sql.functions as F\n",
    "\n",
    "label_counts = (\n",
    "    train_sequences.groupBy(\"label\")\n",
    "      .agg(F.count(\"*\").alias(\"count\"))\n",
    ")\n",
    "\n",
    "total_count = train_sequences.count()\n",
    "\n",
    "label_distribution = (\n",
    "    label_counts\n",
    "    .withColumn(\"percentage\", (F.col(\"count\") / total_count) * 100)\n",
    "    .orderBy(F.desc(\"count\"))\n",
    ")\n",
    "\n",
    "label_distribution.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5e41fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of course codes\n",
    "# train_sequences.groupBy(\"course_cd_ohe\").count().orderBy(F.desc(\"count\")).show(50, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "81d6108a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_sequences.groupBy(\"race_type_ohe\").count().orderBy(F.desc(\"count\")).show(50, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "72cb1dea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-------------------+\n",
      "|distinct_tracks|distinct_race_types|\n",
      "+---------------+-------------------+\n",
      "|             26|                 13|\n",
      "+---------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_sequences.agg(\n",
    "    F.countDistinct(\"course_cd_ohe\").alias(\"distinct_tracks\"),\n",
    "    F.countDistinct(\"race_type_ohe\").alias(\"distinct_race_types\")\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "10a44d62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+-----+\n",
      "|year|month|count|\n",
      "+----+-----+-----+\n",
      "|2022|3    |80   |\n",
      "|2022|4    |576  |\n",
      "|2022|5    |1051 |\n",
      "|2022|6    |1266 |\n",
      "|2022|7    |1606 |\n",
      "|2022|8    |1942 |\n",
      "|2022|9    |2469 |\n",
      "|2022|10   |2683 |\n",
      "|2022|11   |3096 |\n",
      "|2022|12   |3261 |\n",
      "|2023|1    |2945 |\n",
      "|2023|2    |3289 |\n",
      "|2023|3    |3976 |\n",
      "|2023|4    |4335 |\n",
      "|2023|5    |5090 |\n",
      "|2023|6    |5147 |\n",
      "+----+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_sequences.groupBy(F.year(\"race_date\").alias(\"year\"), F.month(\"race_date\").alias(\"month\"))\\\n",
    "  .count()\\\n",
    "  .orderBy(\"year\", \"month\")\\\n",
    "  .show(48, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "728c1701",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Convert to Pandas DataFrame\n",
    "train_sequences_pd = train_sequences.toPandas()\n",
    "val_sequences_pd = val_sequences.toPandas()\n",
    "test_sequences_pd = test_sequences.toPandas()\n",
    "\n",
    "horse_ids_train = train_sequences_pd[\"horse_id\"].values  # Extract horse_id for training\n",
    "horse_ids_val = val_sequences_pd[\"horse_id\"].values  # Extract horse_id for validation\n",
    "horse_ids_test = test_sequences_pd[\"horse_id\"].values  # Extract horse_id for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0fca647b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------+\n",
      "|size(past_races_sequence)|\n",
      "+-------------------------+\n",
      "|                       10|\n",
      "+-------------------------+\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(train_sequences.select(F.size(\"past_races_sequence\")).distinct().show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e78edfb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Row(label=1, count=5840), Row(label=6, count=3640), Row(label=3, count=5955), Row(label=5, count=4928), Row(label=4, count=5738), Row(label=7, count=5065), Row(label=2, count=5984), Row(label=0, count=5662)]\n"
     ]
    }
   ],
   "source": [
    "label_distribution = train_sequences.groupBy(\"label\").count().collect()\n",
    "print(label_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "779dec92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...\n",
       "1    [([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...\n",
       "2    [([0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...\n",
       "3    [([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0...\n",
       "4    [([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0...\n",
       "Name: past_races_sequence, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sequences_pd[\"past_races_sequence\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "04b82223",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def flatten_sequence(sequence):\n",
    "    \"\"\"\n",
    "    Flattens a sequence of race data into a single NumPy array.\n",
    "    Ensures uniform array shapes for each time step in the sequence.\n",
    "    \"\"\"\n",
    "    ohe_length = 43 + 26 + 10 + 2 + 8 + 7 + 5 + 4 + 4 + 14  # Total OHE length\n",
    "    aggregator_length = len(aggregator_cols)  # Length of aggregator columns\n",
    "\n",
    "    flattened_sequence = []\n",
    "    for step in sequence:\n",
    "        # Extract `ohe_flat` or default to zero array\n",
    "        ohe_flat = step[\"ohe_flat\"] if \"ohe_flat\" in step else [0.0] * ohe_length\n",
    "\n",
    "        # Ensure `ohe_flat` has the correct length\n",
    "        if len(ohe_flat) != ohe_length:\n",
    "            ohe_flat = [0.0] * ohe_length\n",
    "\n",
    "        # Extract aggregator values or default to -999.0\n",
    "        aggregator_values = [step[agg] if agg in step else -999.0 for agg in aggregator_cols]\n",
    "\n",
    "        # Concatenate `ohe_flat` and aggregator values\n",
    "        flattened_step = np.array(ohe_flat + aggregator_values)\n",
    "\n",
    "        # Verify the length of the flattened step\n",
    "        if len(flattened_step) != (ohe_length + aggregator_length):\n",
    "            raise ValueError(f\"Flattened step has inconsistent length: {len(flattened_step)}\")\n",
    "\n",
    "        flattened_sequence.append(flattened_step)\n",
    "\n",
    "    return np.array(flattened_sequence)\n",
    "\n",
    "aggregator_cols = [\n",
    "    \"avg_speed_agg\", \"max_speed_agg\", \"final_speed_agg\", \"avg_accel_agg\", \n",
    "    \"fatigue_agg\", \"sectional_time_agg\", \"running_time_agg\", \"distance_back_agg\", \n",
    "    \"distance_ran_agg\", \"strides_agg\", \"max_speed_overall\", \"min_speed_overall\"\n",
    "]\n",
    "\n",
    "X_train = np.array([flatten_sequence(seq) for seq in train_sequences_pd[\"past_races_sequence\"]])\n",
    "y_train = train_sequences_pd[\"label\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c0ee064c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array([flatten_sequence(seq) for seq in train_sequences_pd[\"past_races_sequence\"]])\n",
    "y_train = train_sequences_pd[\"label\"].values\n",
    "\n",
    "X_val = np.array([flatten_sequence(seq) for seq in val_sequences_pd[\"past_races_sequence\"]])\n",
    "y_val = val_sequences_pd[\"label\"].values\n",
    "\n",
    "X_test = np.array([flatten_sequence(seq) for seq in test_sequences_pd[\"past_races_sequence\"]])\n",
    "y_test = test_sequences_pd[\"label\"].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "09a71c0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (42812, 10, 135)\n",
      "y_train shape: (42812,)\n"
     ]
    }
   ],
   "source": [
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9fc17a27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6 7]\n"
     ]
    }
   ],
   "source": [
    " # Label targets\n",
    "print(np.unique(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "10c190a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|label|count|\n",
      "+-----+-----+\n",
      "|    0| 5662|\n",
      "|    1| 5840|\n",
      "|    2| 5984|\n",
      "|    3| 5955|\n",
      "|    4| 5738|\n",
      "|    5| 4928|\n",
      "|    6| 3640|\n",
      "|    7| 5065|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "label_dist = train_sequences.groupBy(\"label\").count().orderBy(\"label\")\n",
    "label_dist.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a21ba9a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|label|count|\n",
      "+-----+-----+\n",
      "|    0| 1473|\n",
      "|    1| 1591|\n",
      "|    2| 1528|\n",
      "|    3| 1536|\n",
      "|    4| 1437|\n",
      "|    5| 1261|\n",
      "|    6|  940|\n",
      "|    7| 1487|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "label_dist = val_sequences.groupBy(\"label\").count().orderBy(\"label\")\n",
    "label_dist.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "382e23df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|label|count|\n",
      "+-----+-----+\n",
      "|    0| 1055|\n",
      "|    1| 1115|\n",
      "|    2| 1130|\n",
      "|    3| 1107|\n",
      "|    4| 1073|\n",
      "|    5|  943|\n",
      "|    6|  821|\n",
      "|    7| 1224|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "label_dist = test_sequences.groupBy(\"label\").count().orderBy(\"label\")\n",
    "label_dist.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "42173d97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (42812, 10, 135), y_train shape: (42812,), horse_ids_train shape: (42812,)\n",
      "X_val shape: (11253, 10, 135), y_val shape: (11253,), horse_ids_val shape: (11253,)\n",
      "X_test shape: (8468, 10, 135), y_test shape: (8468,), horse_ids_test shape: (8468,)\n"
     ]
    }
   ],
   "source": [
    "print(f\"X_train shape: {X_train.shape}, y_train shape: {y_train.shape}, horse_ids_train shape: {horse_ids_train.shape}\")\n",
    "print(f\"X_val shape: {X_val.shape}, y_val shape: {y_val.shape}, horse_ids_val shape: {horse_ids_val.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}, y_test shape: {y_test.shape}, horse_ids_test shape: {horse_ids_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "88a2ee2d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (42812, 10, 135), horse_ids_train: (42812,), y_train: (42812,)\n",
      "X_val: (11253, 10, 135), horse_ids_val: (11253,), y_val: (11253,)\n"
     ]
    }
   ],
   "source": [
    "print(f\"X_train: {X_train.shape}, horse_ids_train: {horse_ids_train.shape}, y_train: {y_train.shape}\")\n",
    "print(f\"X_val: {X_val.shape}, horse_ids_val: {horse_ids_val.shape}, y_val: {y_val.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb17aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Embedding, Concatenate, Dropout, Flatten\n",
    "\n",
    "# Define the input shapes\n",
    "time_steps = X_train.shape[1]  # Number of time steps in sequences\n",
    "features = X_train.shape[2]    # Number of features per time step\n",
    "num_horses = len(np.unique(horse_ids_train))  # Number of unique horse IDs\n",
    "\n",
    "# 1. Input layers\n",
    "input_features = Input(shape=(time_steps, features), name='input_features')\n",
    "input_horse_id = Input(shape=(1,), name='input_horse_id')\n",
    "\n",
    "# 2. Embedding layer for horse_id\n",
    "embedding = Embedding(input_dim=num_horses, output_dim=32)(input_horse_id)\n",
    "embedding = Flatten()(embedding)  # Flatten embedding\n",
    "\n",
    "# 3. LSTM layers for sequential data\n",
    "x = LSTM(256, return_sequences=True)(input_features)\n",
    "x = Dropout(0.2)(x)\n",
    "x = LSTM(128, return_sequences=True)(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = LSTM(64, return_sequences=True)(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = LSTM(32, return_sequences=False)(x)\n",
    "x = Dropout(0.2)(x)\n",
    "\n",
    "# 4. Concatenate the final LSTM output with the horse embedding\n",
    "concat = Concatenate()([x, embedding])\n",
    "\n",
    "# 5. Dense layers\n",
    "dense_out = Dense(64, activation='relu')(concat)\n",
    "dense_out = Dropout(0.2)(dense_out)\n",
    "\n",
    "# 6. Final output layer for 8-class classification\n",
    "num_classes = 8\n",
    "output = Dense(num_classes, activation='softmax')(dense_out)\n",
    "\n",
    "# Compile with sparse_categorical_crossentropy for integer labels\n",
    "# Define the model\n",
    "model_lstm = Model(inputs=[input_features, input_horse_id], outputs=output)\n",
    "\n",
    "# Compile the model with binary_crossentropy\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "# Compile with sparse_categorical_crossentropy for integer labels\n",
    "model_lstm = Model(inputs=[input_features, input_horse_id], outputs=output)\n",
    "model_lstm.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',  # works with integer labels\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "model_lstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787fa0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_scheduler = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6\n",
    ")\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', patience=10, restore_best_weights=True\n",
    ")\n",
    "\n",
    "model_checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath='best_model.keras',\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30426d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique, counts = np.unique(y_train, return_counts=True)\n",
    "train_counts = dict(zip(unique, counts))\n",
    "\n",
    "print(train_counts)\n",
    "print(unique)\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d22444e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Label distribution\n",
    "unique, counts = np.unique(y_train, return_counts=True)\n",
    "train_counts = dict(zip(unique, counts))\n",
    "\n",
    "print(\"Label Counts:\", train_counts)\n",
    "\n",
    "# Total samples and number of unique classes\n",
    "total_samples = np.sum(counts)\n",
    "num_classes = len(unique)\n",
    "\n",
    "# Calculate class weights\n",
    "class_weight = {label: (total_samples / (num_classes * count)) for label, count in train_counts.items()}\n",
    "\n",
    "print(\"Class Weights:\", class_weight)\n",
    "# # Train label counts from your distribution\n",
    "# train_counts = np.array([580, 621, 604, 594, 1889])\n",
    "# total = train_counts.sum()  # 18164\n",
    "# n_classes = len(train_counts)  # 5\n",
    "\n",
    "# class_weight = {}\n",
    "# for i, count_i in enumerate(train_counts):\n",
    "#     class_weight[i] = float(total) / (n_classes * count_i)\n",
    "\n",
    "print(class_weight)\n",
    "# Example output:\n",
    "# {0: 1.463870..., 1: 1.416..., 2: 1.426..., 3: 1.446..., 4: 0.45...}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f748f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee588f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "\n",
    "history = model_lstm.fit(\n",
    "    [X_train, horse_ids_train],\n",
    "    y_train,\n",
    "    epochs=50,  \n",
    "    batch_size=64,  # 64,\n",
    "    validation_data=([X_val, horse_ids_val], y_val),\n",
    "    callbacks=[\n",
    "        lr_scheduler, \n",
    "        early_stopping,\n",
    "        model_checkpoint\n",
    "    ],\n",
    "    #class_weight=class_weight,\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c647b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss, val_accuracy = model_lstm.evaluate([X_val, horse_ids_val], y_val)\n",
    "print(f'Validation Loss: {val_loss}, Validation Accuracy: {val_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d24823de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Predict on validation data\n",
    "val_preds = (model_lstm.predict([X_val, horse_ids_val]) > 0.5).astype(int)\n",
    "\n",
    "# Generate a classification report\n",
    "print(classification_report(y_val, val_preds, target_names=[\"Not 1st\", \"1st\"]))\n",
    "\n",
    "# Display a confusion matrix\n",
    "print(confusion_matrix(y_val, val_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d936d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "#model.save('/path/to/save/model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686865bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lstm.get_layer(\"embedding_6\").get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284c5de2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
