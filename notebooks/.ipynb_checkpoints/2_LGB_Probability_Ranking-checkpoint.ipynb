{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a43fc8b",
   "metadata": {},
   "source": [
    "# LGBoost Model Preparation\n",
    "\n",
    "Previously I did a lot of work compiling a dataset that joined the Equibase and TPD data in Spark here before training. The data loaded now, results_df, is a query to the database where all of the data has been combined using PySpark scripts and SQL. The resulting dataset should perform much better than previously and will be run with a ranking objective. The same problem exists. I have approximately 327K rows with just the TPD data but a considerable amount more, 780K if I use just Equibase. I will test both datasets eventually. \n",
    "## Get Started\n",
    "\n",
    "1. Going to load the parquet DataFrame from disk and do some imputation, one-hot encoding, string indexing, and scaling. The run it through XBBoost to see how it's looking. At this point I will do the integration of route data, and add the GPS aggregations. I just want to see what I can minimally do and how its working before I go down the wrong path. If the XGBoost doesn't do any better than the LSTM, at least I won't have wasted any more time on it. \n",
    "\n",
    "### Model Additional Requirements\n",
    "\n",
    "#### Logistic Regression:\n",
    "> Ensure features are scaled (e.g., StandardScaler) and that categorical variables are one-hot encoded.\n",
    "\n",
    "#### Random Forest\t\n",
    "> Scaling is unnecessary, and categorical variables should be one-hot encoded.\n",
    "\n",
    "#### XGBoost/LightGBM\t\n",
    "> **Scaling is unnecessary, and categorical variables should be one-hot encoded.**\n",
    "\n",
    "#### Support Vector Machines (SVM)\t\n",
    ">Requires scaling and one-hot encoding.\n",
    "\n",
    "#### k-Nearest Neighbors\t\n",
    ">Requires scaling and one-hot encoding.\n",
    "\n",
    "#### Multi-Layer Perceptron (MLP)\n",
    "> Requires scaling and one-hot encoding.\n",
    "\n",
    "#### CatBoost\t\n",
    "> No need for one-hot encoding; you can specify categorical columns directly using CatBoost’s cat_features parameter.\n",
    "\n",
    "\n",
    "### Load master_results_df.parquet file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0cad7392",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#%pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1463424",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Environment\n",
    "\n",
    "import os\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn import set_config\n",
    "from src.data_preprocessing.data_prep1.data_loader import load_data_from_postgresql\n",
    "from src.data_preprocessing.data_prep1.sql_queries import sql_queries\n",
    "import pyspark.sql.functions as F\n",
    "import xgboost as xgb\n",
    "from sklearn import set_config\n",
    "from pyspark.sql.functions import (col, count, row_number, abs, unix_timestamp, mean, \n",
    "                                   when, lit, min as F_min, max as F_max , upper, trim,\n",
    "                                   row_number, mean as F_mean, countDistinct, last, first, when)\n",
    "import configparser\n",
    "from pyspark.sql import SparkSession\n",
    "from src.data_preprocessing.data_prep1.sql_queries import sql_queries\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql import DataFrame, Window\n",
    "from src.data_preprocessing.data_prep1.data_utils import (save_parquet, gather_statistics, \n",
    "                initialize_environment, load_config, initialize_spark, \n",
    "                identify_and_impute_outliers, \n",
    "                identify_and_remove_outliers, identify_missing_and_outliers)\n",
    "from pyspark.ml.functions import vector_to_array\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Set global references to None\n",
    "spark = None\n",
    "master_results_df = None\n",
    "race_df = None\n",
    "df = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73671a61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark session created successfully.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "spark, jdbc_url, jdbc_properties, parquet_dir, log_file = initialize_environment()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2dc25f3-b696-4012-ba01-0d89d4776580",
   "metadata": {},
   "outputs": [],
   "source": [
    "race_df = spark.read.parquet(os.path.join(parquet_dir, \"race_df_p1.parquet\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ce0c4ce-8cbb-402f-839a-f86ab2d2cc54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------------+---------------+\n",
      "|distance|dist_unit         |distance_meters|\n",
      "+--------+------------------+---------------+\n",
      "|850.0   |F                 |1709.928       |\n",
      "|800.0   |F                 |1609.344       |\n",
      "|850.0   |F                 |1709.928       |\n",
      "|800.0   |F                 |1609.344       |\n",
      "|850.0   |F                 |1709.928       |\n",
      "|818.0   |F                 |1645.55424     |\n",
      "|850.0   |F                 |1709.928       |\n",
      "|600.0   |F                 |1207.008       |\n",
      "|650.0   |F                 |1307.592       |\n",
      "|800.0   |F                 |1609.344       |\n",
      "+--------+------------------+---------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 11a.) Convert distance from Furlongs (F) to meters if dist_unit is F\n",
    "    #    1 Furlong ≈ 201.168 meters.\n",
    "    #    Then change dist_unit to 'm'.\n",
    "\n",
    "race_df = race_df.withColumn(\n",
    "    \"distance_meters\",\n",
    "    when(upper(trim(col(\"dist_unit\"))) == \"F\", ((col(\"distance\") / 100)) * lit(201.168))\n",
    "    .otherwise(lit(None))\n",
    ")\n",
    "# Now final_df has \"distance_meters\" instead of \"distance\" / \"dist_unit\"\n",
    "\n",
    "race_df.select(\"distance\", \"dist_unit\", \"distance_meters\").show(10, truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de8d9653-f6d8-425b-a768-0e59b53acb56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: drop the old columns\n",
    "race_df = race_df.drop(\"distance\", \"dist_unit\")\n",
    "race_df = race_df.drop(\"sa_dist_bk_gate4\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ca544b6-8fd0-42c1-b8d8-967aa357c488",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- horse_id: integer (nullable = true)\n",
      " |-- horse_name: string (nullable = true)\n",
      " |-- official_fin: integer (nullable = true)\n",
      " |-- purse: integer (nullable = true)\n",
      " |-- wps_pool: double (nullable = true)\n",
      " |-- weight: double (nullable = true)\n",
      " |-- sex: string (nullable = true)\n",
      " |-- equip: string (nullable = true)\n",
      " |-- claimprice: double (nullable = true)\n",
      " |-- surface: string (nullable = true)\n",
      " |-- trk_cond: string (nullable = true)\n",
      " |-- weather: string (nullable = true)\n",
      " |-- power: double (nullable = true)\n",
      " |-- med: string (nullable = true)\n",
      " |-- morn_odds: double (nullable = true)\n",
      " |-- avgspd: double (nullable = true)\n",
      " |-- race_type: string (nullable = true)\n",
      " |-- class_rating: integer (nullable = true)\n",
      " |-- todays_cls: double (nullable = true)\n",
      " |-- net_sentiment: integer (nullable = true)\n",
      " |-- stk_clm_md: string (nullable = true)\n",
      " |-- turf_mud_mark: string (nullable = true)\n",
      " |-- avg_spd_sd: double (nullable = true)\n",
      " |-- ave_cl_sd: double (nullable = true)\n",
      " |-- hi_spd_sd: double (nullable = true)\n",
      " |-- pstyerl: double (nullable = true)\n",
      " |-- all_starts: integer (nullable = true)\n",
      " |-- all_win: integer (nullable = true)\n",
      " |-- all_place: integer (nullable = true)\n",
      " |-- all_show: integer (nullable = true)\n",
      " |-- all_fourth: integer (nullable = true)\n",
      " |-- all_earnings: double (nullable = true)\n",
      " |-- cond_starts: integer (nullable = true)\n",
      " |-- cond_win: integer (nullable = true)\n",
      " |-- cond_place: integer (nullable = true)\n",
      " |-- cond_show: integer (nullable = true)\n",
      " |-- cond_fourth: integer (nullable = true)\n",
      " |-- cond_earnings: double (nullable = true)\n",
      " |-- avg_fin_3: double (nullable = true)\n",
      " |-- avg_beaten_3: double (nullable = true)\n",
      " |-- avg_speed_3: double (nullable = true)\n",
      " |-- avg_fin_5: double (nullable = true)\n",
      " |-- avg_beaten_5: double (nullable = true)\n",
      " |-- avg_speed_5: double (nullable = true)\n",
      " |-- speed_improvement: double (nullable = true)\n",
      " |-- days_off: integer (nullable = true)\n",
      " |-- layoff_cat: string (nullable = true)\n",
      " |-- avgtime_gate1: double (nullable = true)\n",
      " |-- avgtime_gate2: double (nullable = true)\n",
      " |-- avgtime_gate3: double (nullable = true)\n",
      " |-- avgtime_gate4: double (nullable = true)\n",
      " |-- total_distance_ran: double (nullable = true)\n",
      " |-- running_time: double (nullable = true)\n",
      " |-- speed_q1: double (nullable = true)\n",
      " |-- speed_q2: double (nullable = true)\n",
      " |-- speed_q3: double (nullable = true)\n",
      " |-- speed_q4: double (nullable = true)\n",
      " |-- total_dist_covered: double (nullable = true)\n",
      " |-- avg_acceleration: double (nullable = true)\n",
      " |-- net_progress_gain: double (nullable = true)\n",
      " |-- gps_avg_stride_length: double (nullable = true)\n",
      " |-- jock_win_percent: integer (nullable = true)\n",
      " |-- jock_itm_percent: integer (nullable = true)\n",
      " |-- trainer_win_percent: integer (nullable = true)\n",
      " |-- trainer_itm_percent: integer (nullable = true)\n",
      " |-- jt_win_percent: integer (nullable = true)\n",
      " |-- jt_itm_percent: integer (nullable = true)\n",
      " |-- jock_win_track: integer (nullable = true)\n",
      " |-- jock_itm_track: integer (nullable = true)\n",
      " |-- trainer_win_track: integer (nullable = true)\n",
      " |-- trainer_itm_track: integer (nullable = true)\n",
      " |-- jt_win_track: integer (nullable = true)\n",
      " |-- jt_itm_track: integer (nullable = true)\n",
      " |-- age_at_race_day: double (nullable = true)\n",
      " |-- is_first_race: integer (nullable = true)\n",
      " |-- distance_meters: double (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "save_parquet(spark, race_df, \"race_df_p2\", parquet_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ccd5955",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "324041"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "race_df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce2ed82",
   "metadata": {},
   "source": [
    "# Switching to Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e3b985b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "# Convert Spark DataFrame -> Pandas DataFrame\n",
    "\n",
    "race_df = race_df.toPandas()\n",
    "# Quick info about the DataFrame\n",
    "#print(df.info())\n",
    "#print(df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3ffd5518-dc86-47dc-98d7-54ec7214ebfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 324041 entries, 0 to 324040\n",
      "Data columns (total 80 columns):\n",
      " #   Column                 Non-Null Count   Dtype  \n",
      "---  ------                 --------------   -----  \n",
      " 0   course_cd              324041 non-null  object \n",
      " 1   race_date              324041 non-null  object \n",
      " 2   race_number            324041 non-null  int32  \n",
      " 3   saddle_cloth_number    324041 non-null  object \n",
      " 4   horse_id               324041 non-null  int32  \n",
      " 5   horse_name             324041 non-null  object \n",
      " 6   official_fin           324041 non-null  int32  \n",
      " 7   purse                  324041 non-null  int32  \n",
      " 8   wps_pool               324041 non-null  float64\n",
      " 9   weight                 324041 non-null  float64\n",
      " 10  sex                    324041 non-null  object \n",
      " 11  equip                  324041 non-null  object \n",
      " 12  claimprice             324041 non-null  float64\n",
      " 13  surface                324041 non-null  object \n",
      " 14  trk_cond               324041 non-null  object \n",
      " 15  weather                324041 non-null  object \n",
      " 16  power                  324041 non-null  float64\n",
      " 17  med                    324041 non-null  object \n",
      " 18  morn_odds              324041 non-null  float64\n",
      " 19  avgspd                 324041 non-null  float64\n",
      " 20  race_type              324041 non-null  object \n",
      " 21  class_rating           324041 non-null  int32  \n",
      " 22  todays_cls             324041 non-null  float64\n",
      " 23  net_sentiment          324041 non-null  int32  \n",
      " 24  stk_clm_md             324041 non-null  object \n",
      " 25  turf_mud_mark          324041 non-null  object \n",
      " 26  avg_spd_sd             324041 non-null  float64\n",
      " 27  ave_cl_sd              324041 non-null  float64\n",
      " 28  hi_spd_sd              324041 non-null  float64\n",
      " 29  pstyerl                324041 non-null  float64\n",
      " 30  all_starts             324041 non-null  int32  \n",
      " 31  all_win                324041 non-null  int32  \n",
      " 32  all_place              324041 non-null  int32  \n",
      " 33  all_show               324041 non-null  int32  \n",
      " 34  all_fourth             324041 non-null  int32  \n",
      " 35  all_earnings           324041 non-null  float64\n",
      " 36  cond_starts            324041 non-null  int32  \n",
      " 37  cond_win               324041 non-null  int32  \n",
      " 38  cond_place             324041 non-null  int32  \n",
      " 39  cond_show              324041 non-null  int32  \n",
      " 40  cond_fourth            324041 non-null  int32  \n",
      " 41  cond_earnings          324041 non-null  float64\n",
      " 42  avg_fin_3              324041 non-null  float64\n",
      " 43  avg_beaten_3           324041 non-null  float64\n",
      " 44  avg_speed_3            324041 non-null  float64\n",
      " 45  avg_fin_5              324041 non-null  float64\n",
      " 46  avg_beaten_5           324041 non-null  float64\n",
      " 47  avg_speed_5            324041 non-null  float64\n",
      " 48  speed_improvement      324041 non-null  float64\n",
      " 49  days_off               324041 non-null  int32  \n",
      " 50  layoff_cat             324041 non-null  object \n",
      " 51  avgtime_gate1          324041 non-null  float64\n",
      " 52  avgtime_gate2          324041 non-null  float64\n",
      " 53  avgtime_gate3          324041 non-null  float64\n",
      " 54  avgtime_gate4          324041 non-null  float64\n",
      " 55  total_distance_ran     324041 non-null  float64\n",
      " 56  running_time           324041 non-null  float64\n",
      " 57  speed_q1               324041 non-null  float64\n",
      " 58  speed_q2               324041 non-null  float64\n",
      " 59  speed_q3               324041 non-null  float64\n",
      " 60  speed_q4               324041 non-null  float64\n",
      " 61  total_dist_covered     324041 non-null  float64\n",
      " 62  avg_acceleration       324041 non-null  float64\n",
      " 63  net_progress_gain      324041 non-null  float64\n",
      " 64  gps_avg_stride_length  324041 non-null  float64\n",
      " 65  jock_win_percent       324041 non-null  int32  \n",
      " 66  jock_itm_percent       324041 non-null  int32  \n",
      " 67  trainer_win_percent    324041 non-null  int32  \n",
      " 68  trainer_itm_percent    324041 non-null  int32  \n",
      " 69  jt_win_percent         324041 non-null  int32  \n",
      " 70  jt_itm_percent         324041 non-null  int32  \n",
      " 71  jock_win_track         324041 non-null  int32  \n",
      " 72  jock_itm_track         324041 non-null  int32  \n",
      " 73  trainer_win_track      324041 non-null  int32  \n",
      " 74  trainer_itm_track      324041 non-null  int32  \n",
      " 75  jt_win_track           324041 non-null  int32  \n",
      " 76  jt_itm_track           324041 non-null  int32  \n",
      " 77  age_at_race_day        324041 non-null  float64\n",
      " 78  is_first_race          324041 non-null  int32  \n",
      " 79  distance_meters        324041 non-null  float64\n",
      "dtypes: float64(36), int32(30), object(14)\n",
      "memory usage: 160.7+ MB\n",
      "None\n",
      "  course_cd   race_date  race_number saddle_cloth_number  horse_id  \\\n",
      "0       TOP  2022-04-03            5                   6      4879   \n",
      "1       TOP  2024-01-27            9                   1      1380   \n",
      "2       TOP  2022-02-12           10                   8      1383   \n",
      "3       ASD  2024-08-05            6                   6      1400   \n",
      "4       TOP  2023-12-08            4                   7      1402   \n",
      "\n",
      "          horse_name  official_fin   purse  wps_pool  weight  ...  \\\n",
      "0  Mr. Thunderstruck             3   36000  237578.0   119.0  ...   \n",
      "1     Promise Keeper             1  150000  213855.0   115.0  ...   \n",
      "2          Plainsman             1  600000  539960.0   120.0  ...   \n",
      "3     Brody's Streak             9   51000   68088.0   119.0  ...   \n",
      "4           Shamayim             6   35000  196166.0   120.0  ...   \n",
      "\n",
      "  jt_itm_percent jock_win_track  jock_itm_track trainer_win_track  \\\n",
      "0              0              0               0                 0   \n",
      "1              0              0               0                 0   \n",
      "2              0              0               0                 0   \n",
      "3              0              0               0                 0   \n",
      "4              0              0               0                 0   \n",
      "\n",
      "  trainer_itm_track jt_win_track  jt_itm_track age_at_race_day  is_first_race  \\\n",
      "0                 0            0             0        4.065708              0   \n",
      "1                 0            0             0        5.796030              0   \n",
      "2                 0            0             0        6.828200              1   \n",
      "3                 0            0             0        5.289528              0   \n",
      "4                 0            0             0        4.736482              0   \n",
      "\n",
      "   distance_meters  \n",
      "0         1709.928  \n",
      "1         1609.344  \n",
      "2         1709.928  \n",
      "3         1609.344  \n",
      "4         1709.928  \n",
      "\n",
      "[5 rows x 80 columns]\n"
     ]
    }
   ],
   "source": [
    "print(race_df.info())\n",
    "print(race_df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7eb90e50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Value Summary:\n",
      " gps_avg_stride_length    0\n",
      "jock_win_percent         0\n",
      "jock_itm_percent         0\n",
      "trainer_win_percent      0\n",
      "trainer_itm_percent      0\n",
      "                        ..\n",
      "saddle_cloth_number      0\n",
      "horse_id                 0\n",
      "horse_name               0\n",
      "official_fin             0\n",
      "purse                    0\n",
      "Length: 80, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 4a) Identify columns with high missingness\n",
    "missing_summary = race_df.isna().sum().sort_values(ascending=False)\n",
    "print(\"Missing Value Summary:\\n\", missing_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "92eb1d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "race_df[\"race_id\"] = (\n",
    "    race_df[\"course_cd\"].astype(str) + \"_\" +\n",
    "    race_df[\"race_date\"].astype(str) + \"_\" +\n",
    "    race_df[\"race_number\"].astype(str)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0f3dade4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9 8 9 ... 9 9 6]\n"
     ]
    }
   ],
   "source": [
    "group_array = race_df.groupby(\"race_id\").size().values  # array of group sizes\n",
    "print(group_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c0d9caaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the largest official_fin is 20 (some races can have 20 horses),\n",
    "# then label = (21 - official_fin).\n",
    "# So official_fin=1 => label=20, official_fin=2 =>19, etc.\n",
    "# If your max is 14, you can do (15 - official_fin).  Just ensure \"best\" horse has largest label.\n",
    "race_df[\"rank\"] = 21 - race_df[\"official_fin\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7ec86ede-42a6-4f0a-a099-d21a6e24b8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"official_fin\" in race_df.columns:\n",
    "    race_df.drop(columns=[\"official_fin\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ca12b72c-3f3f-4fc4-9f52-f109880cb5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "cat_cols = [\"course_cd\", \"sex\", \"equip\", \"surface\", \"trk_cond\", \"weather\", \"med\", \n",
    "            \"race_type\", \"stk_clm_md\", \"turf_mud_mark\", \"layoff_cat\"]\n",
    "for c in cat_cols:\n",
    "    lbl = LabelEncoder()\n",
    "    race_df[c] = lbl.fit_transform(race_df[c].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "84383e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "race_df = race_df.sort_values(\"race_id\", ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e2a0649f",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    # Basic numeric columns\n",
    "    \"purse\",\n",
    "    \"wps_pool\",\n",
    "    \"weight\",\n",
    "    \"claimprice\",\n",
    "    \"power\",\n",
    "    \"morn_odds\",\n",
    "    \"distance_meters\",\n",
    "    \"avgspd\",\n",
    "    \"class_rating\",\n",
    "    \"todays_cls\",\n",
    "    \"net_sentiment\",\n",
    "    \"avg_spd_sd\",\n",
    "    \"ave_cl_sd\",\n",
    "    \"hi_spd_sd\",\n",
    "    \"pstyerl\",\n",
    "\n",
    "    # Cumulative performance stats\n",
    "    \"all_starts\",\n",
    "    \"all_win\",\n",
    "    \"all_place\",\n",
    "    \"all_show\",\n",
    "    \"all_fourth\",\n",
    "    \"all_earnings\",\n",
    "    \"cond_starts\",\n",
    "    \"cond_win\",\n",
    "    \"cond_place\",\n",
    "    \"cond_show\",\n",
    "    \"cond_fourth\",\n",
    "    \"cond_earnings\",\n",
    "\n",
    "    # Recent form metrics\n",
    "    \"avg_fin_3\",\n",
    "    \"avg_beaten_3\",\n",
    "    \"avg_speed_3\",\n",
    "    \"avg_fin_5\",\n",
    "    \"avg_beaten_5\",\n",
    "    \"avg_speed_5\",\n",
    "    \"speed_improvement\",\n",
    "    \"days_off\",\n",
    "\n",
    "    # Sectionals / GPS\n",
    "    \"avgtime_gate1\",\n",
    "    \"avgtime_gate2\",\n",
    "    \"avgtime_gate3\",\n",
    "    \"avgtime_gate4\",\n",
    "    \"total_distance_ran\",\n",
    "    \"running_time\",\n",
    "    \"speed_q1\",\n",
    "    \"speed_q2\",\n",
    "    \"speed_q3\",\n",
    "    \"speed_q4\",\n",
    "    \"total_dist_covered\",\n",
    "    \"avg_acceleration\",\n",
    "    \"net_progress_gain\",\n",
    "    \"gps_avg_stride_length\",\n",
    "\n",
    "    # Jockey/Trainer stats\n",
    "    \"jock_win_percent\",\n",
    "    \"jock_itm_percent\",\n",
    "    \"trainer_win_percent\",\n",
    "    \"trainer_itm_percent\",\n",
    "    \"jt_win_percent\",\n",
    "    \"jt_itm_percent\",\n",
    "    \"jock_win_track\",\n",
    "    \"jock_itm_track\",\n",
    "    \"trainer_win_track\",\n",
    "    \"trainer_itm_track\",\n",
    "    \"jt_win_track\",\n",
    "    \"jt_itm_track\",\n",
    "\n",
    "    # Other\n",
    "    \"age_at_race_day\",\n",
    "    \"is_first_race\",\n",
    "]\n",
    "\n",
    "\n",
    "X_all = race_df[features].values\n",
    "y_all = race_df['rank'].values\n",
    "race_ids = race_df['race_id'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3486d1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "unique_races = race_df['race_id'].unique()\n",
    "unique_races = shuffle(unique_races, random_state=42)\n",
    "\n",
    "train_ratio = 0.8\n",
    "cut = int(len(unique_races) * train_ratio)\n",
    "train_races = set(unique_races[:cut])\n",
    "valid_races = set(unique_races[cut:])\n",
    "\n",
    "# Create a boolean mask\n",
    "train_mask = race_df['race_id'].isin(train_races)\n",
    "valid_mask  = race_df['race_id'].isin(valid_races)\n",
    "\n",
    "# Now slice\n",
    "X_train = X_all[train_mask]\n",
    "y_train = y_all[train_mask]\n",
    "race_id_train = race_ids[train_mask]\n",
    "\n",
    "X_valid = X_all[valid_mask]\n",
    "y_valid = y_all[valid_mask]\n",
    "race_id_valid = race_ids[valid_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cb16452a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def make_group_array(race_id_array):\n",
    "    \"\"\"\n",
    "    Returns an array of group sizes in the order of race_id_array’s actual row order.\n",
    "    Expects that race_id_array is sorted or lumps each race contiguously.\n",
    "    \"\"\"\n",
    "    # Approach 1: Rely on the data already being grouped in contiguous rows\n",
    "    # If your data is not guaranteed to be sorted by race_id, you can sort it first.\n",
    "    # But let's assume from the train_mask/valid_mask approach that the relative order\n",
    "    # is consistent. We can just accumulate counts.\n",
    "\n",
    "    # A simpler approach: group the data by unique race_id in the order they appear\n",
    "    # and store the size for each chunk.\n",
    "    # We'll do a loop approach:\n",
    "\n",
    "    groups = []\n",
    "    current_race = None\n",
    "    current_count = 0\n",
    "\n",
    "    group_sequence = []\n",
    "\n",
    "    for rid in race_id_array:\n",
    "        if rid != current_race:\n",
    "            # if we have an existing group, push it\n",
    "            if current_race is not None:\n",
    "                groups.append(current_count)\n",
    "            current_race = rid\n",
    "            current_count = 1\n",
    "        else:\n",
    "            current_count += 1\n",
    "    # push the last group\n",
    "    if current_race is not None and current_count > 0:\n",
    "        groups.append(current_count)\n",
    "\n",
    "    return np.array(groups, dtype=np.int32)\n",
    "\n",
    "group_train = make_group_array(race_id_train)\n",
    "group_valid  = make_group_array(race_id_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "49c8435a-1659-4622-9a7f-0705b7c6ac56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "train_dataset = lgb.Dataset(\n",
    "    X_train,\n",
    "    label=y_train,\n",
    "    group=group_train\n",
    ")\n",
    "\n",
    "valid_dataset = lgb.Dataset(\n",
    "    X_valid,\n",
    "    label=y_valid,\n",
    "    group=group_valid,\n",
    "    reference=train_dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0f4f96f3-e5cf-45ce-a4b1-80cf225b15cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "698b9e54-f6e0-49db-a800-3ff87cd4d027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 10 rounds\n",
      "[50]\ttrain's ndcg@1: 0.696998\ttrain's ndcg@2: 0.750842\ttrain's ndcg@3: 0.795771\ttrain's ndcg@4: 0.82891\ttrain's ndcg@5: 0.851468\tvalid's ndcg@1: 0.697354\tvalid's ndcg@2: 0.749028\tvalid's ndcg@3: 0.796698\tvalid's ndcg@4: 0.829194\tvalid's ndcg@5: 0.85084\n",
      "[100]\ttrain's ndcg@1: 0.711597\ttrain's ndcg@2: 0.765218\ttrain's ndcg@3: 0.80829\ttrain's ndcg@4: 0.839809\ttrain's ndcg@5: 0.860858\tvalid's ndcg@1: 0.709453\tvalid's ndcg@2: 0.762388\tvalid's ndcg@3: 0.807557\tvalid's ndcg@4: 0.838902\tvalid's ndcg@5: 0.859324\n",
      "[150]\ttrain's ndcg@1: 0.731692\ttrain's ndcg@2: 0.782398\ttrain's ndcg@3: 0.82332\ttrain's ndcg@4: 0.852915\ttrain's ndcg@5: 0.872411\tvalid's ndcg@1: 0.728505\tvalid's ndcg@2: 0.779201\tvalid's ndcg@3: 0.82207\tvalid's ndcg@4: 0.85178\tvalid's ndcg@5: 0.870245\n",
      "[200]\ttrain's ndcg@1: 0.748669\ttrain's ndcg@2: 0.796928\ttrain's ndcg@3: 0.836213\ttrain's ndcg@4: 0.863959\ttrain's ndcg@5: 0.88217\tvalid's ndcg@1: 0.744247\tvalid's ndcg@2: 0.792958\tvalid's ndcg@3: 0.834426\tvalid's ndcg@4: 0.862238\tvalid's ndcg@5: 0.879497\n",
      "[250]\ttrain's ndcg@1: 0.763916\ttrain's ndcg@2: 0.8098\ttrain's ndcg@3: 0.847663\ttrain's ndcg@4: 0.873436\ttrain's ndcg@5: 0.890346\tvalid's ndcg@1: 0.757323\tvalid's ndcg@2: 0.805005\tvalid's ndcg@3: 0.844583\tvalid's ndcg@4: 0.870822\tvalid's ndcg@5: 0.887146\n",
      "[300]\ttrain's ndcg@1: 0.775062\ttrain's ndcg@2: 0.819738\ttrain's ndcg@3: 0.85595\ttrain's ndcg@4: 0.880481\ttrain's ndcg@5: 0.896528\tvalid's ndcg@1: 0.767851\tvalid's ndcg@2: 0.814613\tvalid's ndcg@3: 0.852381\tvalid's ndcg@4: 0.877547\tvalid's ndcg@5: 0.89317\n",
      "[350]\ttrain's ndcg@1: 0.785273\ttrain's ndcg@2: 0.828575\ttrain's ndcg@3: 0.863431\ttrain's ndcg@4: 0.886968\ttrain's ndcg@5: 0.901971\tvalid's ndcg@1: 0.77573\tvalid's ndcg@2: 0.822778\tvalid's ndcg@3: 0.859637\tvalid's ndcg@4: 0.883357\tvalid's ndcg@5: 0.898366\n",
      "[400]\ttrain's ndcg@1: 0.792895\ttrain's ndcg@2: 0.835696\ttrain's ndcg@3: 0.869293\ttrain's ndcg@4: 0.892091\ttrain's ndcg@5: 0.906349\tvalid's ndcg@1: 0.785644\tvalid's ndcg@2: 0.830727\tvalid's ndcg@3: 0.865179\tvalid's ndcg@4: 0.888659\tvalid's ndcg@5: 0.903013\n",
      "[450]\ttrain's ndcg@1: 0.800601\ttrain's ndcg@2: 0.842053\ttrain's ndcg@3: 0.874772\ttrain's ndcg@4: 0.896683\ttrain's ndcg@5: 0.910224\tvalid's ndcg@1: 0.789652\tvalid's ndcg@2: 0.834987\tvalid's ndcg@3: 0.869234\tvalid's ndcg@4: 0.892086\tvalid's ndcg@5: 0.905756\n",
      "[500]\ttrain's ndcg@1: 0.806758\ttrain's ndcg@2: 0.847585\ttrain's ndcg@3: 0.879275\ttrain's ndcg@4: 0.900339\ttrain's ndcg@5: 0.913508\tvalid's ndcg@1: 0.794644\tvalid's ndcg@2: 0.840437\tvalid's ndcg@3: 0.873223\tvalid's ndcg@4: 0.895536\tvalid's ndcg@5: 0.908817\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttrain's ndcg@1: 0.806758\ttrain's ndcg@2: 0.847585\ttrain's ndcg@3: 0.879275\ttrain's ndcg@4: 0.900339\ttrain's ndcg@5: 0.913508\tvalid's ndcg@1: 0.794644\tvalid's ndcg@2: 0.840437\tvalid's ndcg@3: 0.873223\tvalid's ndcg@4: 0.895536\tvalid's ndcg@5: 0.908817\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[22]\ttrain's ndcg@1: 0.679859\ttrain's ndcg@2: 0.736294\ttrain's ndcg@3: 0.782673\ttrain's ndcg@4: 0.817604\ttrain's ndcg@5: 0.841526\tvalid's ndcg@1: 0.678224\tvalid's ndcg@2: 0.734255\tvalid's ndcg@3: 0.782888\tvalid's ndcg@4: 0.81719\tvalid's ndcg@5: 0.840023\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[50]\ttrain's ndcg@1: 0.679932\ttrain's ndcg@2: 0.736183\ttrain's ndcg@3: 0.782895\ttrain's ndcg@4: 0.817479\ttrain's ndcg@5: 0.841404\tvalid's ndcg@1: 0.678411\tvalid's ndcg@2: 0.735412\tvalid's ndcg@3: 0.782619\tvalid's ndcg@4: 0.817772\tvalid's ndcg@5: 0.840263\n",
      "[100]\ttrain's ndcg@1: 0.705151\ttrain's ndcg@2: 0.759309\ttrain's ndcg@3: 0.802993\ttrain's ndcg@4: 0.835698\ttrain's ndcg@5: 0.857382\tvalid's ndcg@1: 0.700909\tvalid's ndcg@2: 0.757336\tvalid's ndcg@3: 0.802738\tvalid's ndcg@4: 0.8346\tvalid's ndcg@5: 0.85511\n",
      "[150]\ttrain's ndcg@1: 0.728963\ttrain's ndcg@2: 0.780531\ttrain's ndcg@3: 0.821547\ttrain's ndcg@4: 0.851544\ttrain's ndcg@5: 0.871289\tvalid's ndcg@1: 0.72475\tvalid's ndcg@2: 0.777364\tvalid's ndcg@3: 0.820096\tvalid's ndcg@4: 0.849996\tvalid's ndcg@5: 0.869021\n",
      "[200]\ttrain's ndcg@1: 0.749186\ttrain's ndcg@2: 0.796744\ttrain's ndcg@3: 0.836212\ttrain's ndcg@4: 0.864016\ttrain's ndcg@5: 0.882178\tvalid's ndcg@1: 0.743511\tvalid's ndcg@2: 0.793595\tvalid's ndcg@3: 0.83406\tvalid's ndcg@4: 0.862238\tvalid's ndcg@5: 0.879482\n",
      "[250]\ttrain's ndcg@1: 0.764261\ttrain's ndcg@2: 0.80999\ttrain's ndcg@3: 0.847821\ttrain's ndcg@4: 0.8738\ttrain's ndcg@5: 0.890595\tvalid's ndcg@1: 0.756779\tvalid's ndcg@2: 0.80567\tvalid's ndcg@3: 0.844235\tvalid's ndcg@4: 0.871027\tvalid's ndcg@5: 0.887241\n",
      "[300]\ttrain's ndcg@1: 0.776784\ttrain's ndcg@2: 0.820521\ttrain's ndcg@3: 0.856856\ttrain's ndcg@4: 0.881618\ttrain's ndcg@5: 0.897244\tvalid's ndcg@1: 0.76857\tvalid's ndcg@2: 0.815564\tvalid's ndcg@3: 0.852958\tvalid's ndcg@4: 0.878158\tvalid's ndcg@5: 0.89342\n",
      "[350]\ttrain's ndcg@1: 0.786893\ttrain's ndcg@2: 0.829657\ttrain's ndcg@3: 0.86424\ttrain's ndcg@4: 0.88807\ttrain's ndcg@5: 0.902766\tvalid's ndcg@1: 0.779184\tvalid's ndcg@2: 0.824178\tvalid's ndcg@3: 0.860541\tvalid's ndcg@4: 0.884417\tvalid's ndcg@5: 0.899129\n",
      "[400]\ttrain's ndcg@1: 0.795172\ttrain's ndcg@2: 0.837058\ttrain's ndcg@3: 0.870336\ttrain's ndcg@4: 0.892995\ttrain's ndcg@5: 0.907143\tvalid's ndcg@1: 0.78513\tvalid's ndcg@2: 0.830567\tvalid's ndcg@3: 0.865812\tvalid's ndcg@4: 0.888962\tvalid's ndcg@5: 0.90312\n",
      "[450]\ttrain's ndcg@1: 0.801688\ttrain's ndcg@2: 0.842974\ttrain's ndcg@3: 0.87541\ttrain's ndcg@4: 0.897201\ttrain's ndcg@5: 0.910663\tvalid's ndcg@1: 0.790277\tvalid's ndcg@2: 0.836312\tvalid's ndcg@3: 0.870351\tvalid's ndcg@4: 0.89281\tvalid's ndcg@5: 0.906428\n",
      "[500]\ttrain's ndcg@1: 0.807848\ttrain's ndcg@2: 0.848517\ttrain's ndcg@3: 0.87971\ttrain's ndcg@4: 0.900937\ttrain's ndcg@5: 0.913882\tvalid's ndcg@1: 0.795731\tvalid's ndcg@2: 0.841604\tvalid's ndcg@3: 0.874681\tvalid's ndcg@4: 0.896266\tvalid's ndcg@5: 0.909454\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[499]\ttrain's ndcg@1: 0.807828\ttrain's ndcg@2: 0.848472\ttrain's ndcg@3: 0.879658\ttrain's ndcg@4: 0.900888\ttrain's ndcg@5: 0.91385\tvalid's ndcg@1: 0.795738\tvalid's ndcg@2: 0.841625\tvalid's ndcg@3: 0.874681\tvalid's ndcg@4: 0.89626\tvalid's ndcg@5: 0.909434\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[50]\ttrain's ndcg@1: 0.761254\ttrain's ndcg@2: 0.808211\ttrain's ndcg@3: 0.846128\ttrain's ndcg@4: 0.872166\ttrain's ndcg@5: 0.88947\tvalid's ndcg@1: 0.75469\tvalid's ndcg@2: 0.804967\tvalid's ndcg@3: 0.843697\tvalid's ndcg@4: 0.870077\tvalid's ndcg@5: 0.886676\n",
      "[100]\ttrain's ndcg@1: 0.804185\ttrain's ndcg@2: 0.845636\ttrain's ndcg@3: 0.87778\ttrain's ndcg@4: 0.899253\ttrain's ndcg@5: 0.912437\tvalid's ndcg@1: 0.795468\tvalid's ndcg@2: 0.840726\tvalid's ndcg@3: 0.873484\tvalid's ndcg@4: 0.895943\tvalid's ndcg@5: 0.909033\n",
      "[150]\ttrain's ndcg@1: 0.828354\ttrain's ndcg@2: 0.866588\ttrain's ndcg@3: 0.895324\ttrain's ndcg@4: 0.913469\ttrain's ndcg@5: 0.924773\tvalid's ndcg@1: 0.815392\tvalid's ndcg@2: 0.859547\tvalid's ndcg@3: 0.889297\tvalid's ndcg@4: 0.909018\tvalid's ndcg@5: 0.920049\n",
      "[200]\ttrain's ndcg@1: 0.845907\ttrain's ndcg@2: 0.881029\ttrain's ndcg@3: 0.906888\ttrain's ndcg@4: 0.923358\ttrain's ndcg@5: 0.933099\tvalid's ndcg@1: 0.830366\tvalid's ndcg@2: 0.872191\tvalid's ndcg@3: 0.899581\tvalid's ndcg@4: 0.917663\tvalid's ndcg@5: 0.927606\n",
      "[250]\ttrain's ndcg@1: 0.858904\ttrain's ndcg@2: 0.891451\ttrain's ndcg@3: 0.915588\ttrain's ndcg@4: 0.930299\ttrain's ndcg@5: 0.939203\tvalid's ndcg@1: 0.839952\tvalid's ndcg@2: 0.881036\tvalid's ndcg@3: 0.907239\tvalid's ndcg@4: 0.923476\tvalid's ndcg@5: 0.932767\n",
      "[300]\ttrain's ndcg@1: 0.869166\ttrain's ndcg@2: 0.899532\ttrain's ndcg@3: 0.922123\ttrain's ndcg@4: 0.935804\ttrain's ndcg@5: 0.943973\tvalid's ndcg@1: 0.848911\tvalid's ndcg@2: 0.888101\tvalid's ndcg@3: 0.913275\tvalid's ndcg@4: 0.928642\tvalid's ndcg@5: 0.937078\n",
      "[350]\ttrain's ndcg@1: 0.877878\ttrain's ndcg@2: 0.906534\ttrain's ndcg@3: 0.92754\ttrain's ndcg@4: 0.940382\ttrain's ndcg@5: 0.947958\tvalid's ndcg@1: 0.855057\tvalid's ndcg@2: 0.893949\tvalid's ndcg@3: 0.917772\tvalid's ndcg@4: 0.932419\tvalid's ndcg@5: 0.940265\n",
      "[400]\ttrain's ndcg@1: 0.885641\ttrain's ndcg@2: 0.912986\ttrain's ndcg@3: 0.932415\ttrain's ndcg@4: 0.944586\ttrain's ndcg@5: 0.951528\tvalid's ndcg@1: 0.860409\tvalid's ndcg@2: 0.899154\tvalid's ndcg@3: 0.922222\tvalid's ndcg@4: 0.936171\tvalid's ndcg@5: 0.943299\n",
      "[450]\ttrain's ndcg@1: 0.892818\ttrain's ndcg@2: 0.918311\ttrain's ndcg@3: 0.936563\ttrain's ndcg@4: 0.948102\ttrain's ndcg@5: 0.954495\tvalid's ndcg@1: 0.865648\tvalid's ndcg@2: 0.903614\tvalid's ndcg@3: 0.925696\tvalid's ndcg@4: 0.9391\tvalid's ndcg@5: 0.945745\n",
      "[500]\ttrain's ndcg@1: 0.899693\ttrain's ndcg@2: 0.923336\ttrain's ndcg@3: 0.940471\ttrain's ndcg@4: 0.951358\ttrain's ndcg@5: 0.957322\tvalid's ndcg@1: 0.870149\tvalid's ndcg@2: 0.907804\tvalid's ndcg@3: 0.928691\tvalid's ndcg@4: 0.941511\tvalid's ndcg@5: 0.947891\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttrain's ndcg@1: 0.899693\ttrain's ndcg@2: 0.923336\ttrain's ndcg@3: 0.940471\ttrain's ndcg@4: 0.951358\ttrain's ndcg@5: 0.957322\tvalid's ndcg@1: 0.870149\tvalid's ndcg@2: 0.907804\tvalid's ndcg@3: 0.928691\tvalid's ndcg@4: 0.941511\tvalid's ndcg@5: 0.947891\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[50]\ttrain's ndcg@1: 0.76308\ttrain's ndcg@2: 0.809056\ttrain's ndcg@3: 0.847345\ttrain's ndcg@4: 0.873135\ttrain's ndcg@5: 0.890019\tvalid's ndcg@1: 0.755265\tvalid's ndcg@2: 0.805237\tvalid's ndcg@3: 0.843645\tvalid's ndcg@4: 0.870548\tvalid's ndcg@5: 0.88672\n",
      "[100]\ttrain's ndcg@1: 0.805332\ttrain's ndcg@2: 0.847034\ttrain's ndcg@3: 0.878548\ttrain's ndcg@4: 0.899791\ttrain's ndcg@5: 0.912937\tvalid's ndcg@1: 0.794505\tvalid's ndcg@2: 0.841293\tvalid's ndcg@3: 0.873922\tvalid's ndcg@4: 0.895568\tvalid's ndcg@5: 0.908874\n",
      "[150]\ttrain's ndcg@1: 0.830158\ttrain's ndcg@2: 0.867925\ttrain's ndcg@3: 0.89625\ttrain's ndcg@4: 0.914302\ttrain's ndcg@5: 0.925409\tvalid's ndcg@1: 0.815593\tvalid's ndcg@2: 0.859547\tvalid's ndcg@3: 0.889653\tvalid's ndcg@4: 0.909211\tvalid's ndcg@5: 0.920213\n",
      "[200]\ttrain's ndcg@1: 0.847033\ttrain's ndcg@2: 0.88219\ttrain's ndcg@3: 0.907788\ttrain's ndcg@4: 0.923855\ttrain's ndcg@5: 0.933629\tvalid's ndcg@1: 0.827607\tvalid's ndcg@2: 0.871423\tvalid's ndcg@3: 0.899453\tvalid's ndcg@4: 0.916924\tvalid's ndcg@5: 0.926854\n",
      "[250]\ttrain's ndcg@1: 0.859375\ttrain's ndcg@2: 0.892349\ttrain's ndcg@3: 0.916039\ttrain's ndcg@4: 0.930505\ttrain's ndcg@5: 0.939444\tvalid's ndcg@1: 0.83965\tvalid's ndcg@2: 0.880888\tvalid's ndcg@3: 0.907396\tvalid's ndcg@4: 0.923483\tvalid's ndcg@5: 0.93282\n",
      "[300]\ttrain's ndcg@1: 0.868937\ttrain's ndcg@2: 0.90024\ttrain's ndcg@3: 0.922247\ttrain's ndcg@4: 0.935821\ttrain's ndcg@5: 0.944099\tvalid's ndcg@1: 0.848246\tvalid's ndcg@2: 0.888526\tvalid's ndcg@3: 0.913261\tvalid's ndcg@4: 0.928496\tvalid's ndcg@5: 0.937117\n",
      "[350]\ttrain's ndcg@1: 0.878128\ttrain's ndcg@2: 0.907383\ttrain's ndcg@3: 0.927749\ttrain's ndcg@4: 0.94048\ttrain's ndcg@5: 0.948151\tvalid's ndcg@1: 0.854883\tvalid's ndcg@2: 0.894622\tvalid's ndcg@3: 0.917802\tvalid's ndcg@4: 0.932681\tvalid's ndcg@5: 0.940563\n",
      "[400]\ttrain's ndcg@1: 0.885646\ttrain's ndcg@2: 0.913193\ttrain's ndcg@3: 0.932561\ttrain's ndcg@4: 0.944577\ttrain's ndcg@5: 0.951573\tvalid's ndcg@1: 0.860134\tvalid's ndcg@2: 0.899457\tvalid's ndcg@3: 0.922105\tvalid's ndcg@4: 0.936013\tvalid's ndcg@5: 0.9433\n",
      "[450]\ttrain's ndcg@1: 0.893104\ttrain's ndcg@2: 0.918418\ttrain's ndcg@3: 0.936556\ttrain's ndcg@4: 0.948114\ttrain's ndcg@5: 0.954551\tvalid's ndcg@1: 0.864403\tvalid's ndcg@2: 0.903691\tvalid's ndcg@3: 0.925684\tvalid's ndcg@4: 0.938808\tvalid's ndcg@5: 0.945577\n",
      "[500]\ttrain's ndcg@1: 0.900149\ttrain's ndcg@2: 0.92367\ttrain's ndcg@3: 0.940511\ttrain's ndcg@4: 0.951423\ttrain's ndcg@5: 0.957432\tvalid's ndcg@1: 0.870332\tvalid's ndcg@2: 0.90864\tvalid's ndcg@3: 0.92947\tvalid's ndcg@4: 0.941804\tvalid's ndcg@5: 0.948218\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttrain's ndcg@1: 0.900149\ttrain's ndcg@2: 0.92367\ttrain's ndcg@3: 0.940511\ttrain's ndcg@4: 0.951423\ttrain's ndcg@5: 0.957432\tvalid's ndcg@1: 0.870332\tvalid's ndcg@2: 0.90864\tvalid's ndcg@3: 0.92947\tvalid's ndcg@4: 0.941804\tvalid's ndcg@5: 0.948218\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[50]\ttrain's ndcg@1: 0.761295\ttrain's ndcg@2: 0.807558\ttrain's ndcg@3: 0.845671\ttrain's ndcg@4: 0.872311\ttrain's ndcg@5: 0.889309\tvalid's ndcg@1: 0.75282\tvalid's ndcg@2: 0.804137\tvalid's ndcg@3: 0.842804\tvalid's ndcg@4: 0.869853\tvalid's ndcg@5: 0.885956\n",
      "[100]\ttrain's ndcg@1: 0.80579\ttrain's ndcg@2: 0.847406\ttrain's ndcg@3: 0.878576\ttrain's ndcg@4: 0.899922\ttrain's ndcg@5: 0.913041\tvalid's ndcg@1: 0.796499\tvalid's ndcg@2: 0.8408\tvalid's ndcg@3: 0.873667\tvalid's ndcg@4: 0.896302\tvalid's ndcg@5: 0.909247\n",
      "[150]\ttrain's ndcg@1: 0.830421\ttrain's ndcg@2: 0.868077\ttrain's ndcg@3: 0.895936\ttrain's ndcg@4: 0.914242\ttrain's ndcg@5: 0.925308\tvalid's ndcg@1: 0.816671\tvalid's ndcg@2: 0.859477\tvalid's ndcg@3: 0.889737\tvalid's ndcg@4: 0.909313\tvalid's ndcg@5: 0.920374\n",
      "[200]\ttrain's ndcg@1: 0.84667\ttrain's ndcg@2: 0.882178\ttrain's ndcg@3: 0.907471\ttrain's ndcg@4: 0.923728\ttrain's ndcg@5: 0.93347\tvalid's ndcg@1: 0.830024\tvalid's ndcg@2: 0.870917\tvalid's ndcg@3: 0.899562\tvalid's ndcg@4: 0.917531\tvalid's ndcg@5: 0.927474\n",
      "[250]\ttrain's ndcg@1: 0.85892\ttrain's ndcg@2: 0.892179\ttrain's ndcg@3: 0.915783\ttrain's ndcg@4: 0.930464\ttrain's ndcg@5: 0.939358\tvalid's ndcg@1: 0.840863\tvalid's ndcg@2: 0.879839\tvalid's ndcg@3: 0.907083\tvalid's ndcg@4: 0.923438\tvalid's ndcg@5: 0.932802\n",
      "[300]\ttrain's ndcg@1: 0.869151\ttrain's ndcg@2: 0.900016\ttrain's ndcg@3: 0.922058\ttrain's ndcg@4: 0.935695\ttrain's ndcg@5: 0.943996\tvalid's ndcg@1: 0.849207\tvalid's ndcg@2: 0.887167\tvalid's ndcg@3: 0.913101\tvalid's ndcg@4: 0.928373\tvalid's ndcg@5: 0.937069\n",
      "[350]\ttrain's ndcg@1: 0.878187\ttrain's ndcg@2: 0.907117\ttrain's ndcg@3: 0.927759\ttrain's ndcg@4: 0.940631\ttrain's ndcg@5: 0.948051\tvalid's ndcg@1: 0.855632\tvalid's ndcg@2: 0.89397\tvalid's ndcg@3: 0.917966\tvalid's ndcg@4: 0.932509\tvalid's ndcg@5: 0.940581\n",
      "[400]\ttrain's ndcg@1: 0.885911\ttrain's ndcg@2: 0.913179\ttrain's ndcg@3: 0.932389\ttrain's ndcg@4: 0.944598\ttrain's ndcg@5: 0.951424\tvalid's ndcg@1: 0.861085\tvalid's ndcg@2: 0.899148\tvalid's ndcg@3: 0.921957\tvalid's ndcg@4: 0.935858\tvalid's ndcg@5: 0.943289\n",
      "[450]\ttrain's ndcg@1: 0.893693\ttrain's ndcg@2: 0.918925\ttrain's ndcg@3: 0.936753\ttrain's ndcg@4: 0.948329\ttrain's ndcg@5: 0.954692\tvalid's ndcg@1: 0.86729\tvalid's ndcg@2: 0.904674\tvalid's ndcg@3: 0.926063\tvalid's ndcg@4: 0.939454\tvalid's ndcg@5: 0.946276\n",
      "[500]\ttrain's ndcg@1: 0.900323\ttrain's ndcg@2: 0.923616\ttrain's ndcg@3: 0.940604\ttrain's ndcg@4: 0.951494\ttrain's ndcg@5: 0.957445\tvalid's ndcg@1: 0.871596\tvalid's ndcg@2: 0.90899\tvalid's ndcg@3: 0.929549\tvalid's ndcg@4: 0.942444\tvalid's ndcg@5: 0.948556\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttrain's ndcg@1: 0.900323\ttrain's ndcg@2: 0.923616\ttrain's ndcg@3: 0.940604\ttrain's ndcg@4: 0.951494\ttrain's ndcg@5: 0.957445\tvalid's ndcg@1: 0.871596\tvalid's ndcg@2: 0.90899\tvalid's ndcg@3: 0.929549\tvalid's ndcg@4: 0.942444\tvalid's ndcg@5: 0.948556\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[50]\ttrain's ndcg@1: 0.802008\ttrain's ndcg@2: 0.844474\ttrain's ndcg@3: 0.876493\ttrain's ndcg@4: 0.898064\ttrain's ndcg@5: 0.91148\tvalid's ndcg@1: 0.79071\tvalid's ndcg@2: 0.838948\tvalid's ndcg@3: 0.872194\tvalid's ndcg@4: 0.894223\tvalid's ndcg@5: 0.907523\n",
      "[100]\ttrain's ndcg@1: 0.84099\ttrain's ndcg@2: 0.878937\ttrain's ndcg@3: 0.905025\ttrain's ndcg@4: 0.921542\ttrain's ndcg@5: 0.931515\tvalid's ndcg@1: 0.825099\tvalid's ndcg@2: 0.868374\tvalid's ndcg@3: 0.897679\tvalid's ndcg@4: 0.915544\tvalid's ndcg@5: 0.92562\n",
      "[150]\ttrain's ndcg@1: 0.866573\ttrain's ndcg@2: 0.898385\ttrain's ndcg@3: 0.921131\ttrain's ndcg@4: 0.934764\ttrain's ndcg@5: 0.943075\tvalid's ndcg@1: 0.845433\tvalid's ndcg@2: 0.887047\tvalid's ndcg@3: 0.912465\tvalid's ndcg@4: 0.92774\tvalid's ndcg@5: 0.93608\n",
      "[200]\ttrain's ndcg@1: 0.883659\ttrain's ndcg@2: 0.911828\ttrain's ndcg@3: 0.931528\ttrain's ndcg@4: 0.943699\ttrain's ndcg@5: 0.950677\tvalid's ndcg@1: 0.859985\tvalid's ndcg@2: 0.898807\tvalid's ndcg@3: 0.9217\tvalid's ndcg@4: 0.935727\tvalid's ndcg@5: 0.943106\n",
      "[250]\ttrain's ndcg@1: 0.897126\ttrain's ndcg@2: 0.92197\ttrain's ndcg@3: 0.939328\ttrain's ndcg@4: 0.95018\ttrain's ndcg@5: 0.956371\tvalid's ndcg@1: 0.86936\tvalid's ndcg@2: 0.906671\tvalid's ndcg@3: 0.928241\tvalid's ndcg@4: 0.941042\tvalid's ndcg@5: 0.947602\n",
      "[300]\ttrain's ndcg@1: 0.908878\ttrain's ndcg@2: 0.930089\ttrain's ndcg@3: 0.945804\ttrain's ndcg@4: 0.955623\ttrain's ndcg@5: 0.961107\tvalid's ndcg@1: 0.878271\tvalid's ndcg@2: 0.913777\tvalid's ndcg@3: 0.93396\tvalid's ndcg@4: 0.945771\tvalid's ndcg@5: 0.951647\n",
      "Early stopping, best iteration is:\n",
      "[301]\ttrain's ndcg@1: 0.909209\ttrain's ndcg@2: 0.930262\ttrain's ndcg@3: 0.945925\ttrain's ndcg@4: 0.955724\ttrain's ndcg@5: 0.961207\tvalid's ndcg@1: 0.878905\tvalid's ndcg@2: 0.914071\tvalid's ndcg@3: 0.934097\tvalid's ndcg@4: 0.945912\tvalid's ndcg@5: 0.951847\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[50]\ttrain's ndcg@1: 0.802723\ttrain's ndcg@2: 0.845026\ttrain's ndcg@3: 0.87731\ttrain's ndcg@4: 0.898852\ttrain's ndcg@5: 0.911932\tvalid's ndcg@1: 0.791715\tvalid's ndcg@2: 0.838668\tvalid's ndcg@3: 0.872865\tvalid's ndcg@4: 0.894823\tvalid's ndcg@5: 0.907918\n",
      "[100]\ttrain's ndcg@1: 0.843218\ttrain's ndcg@2: 0.880093\ttrain's ndcg@3: 0.90617\ttrain's ndcg@4: 0.922472\ttrain's ndcg@5: 0.932451\tvalid's ndcg@1: 0.827111\tvalid's ndcg@2: 0.870041\tvalid's ndcg@3: 0.898748\tvalid's ndcg@4: 0.916389\tvalid's ndcg@5: 0.926609\n",
      "[150]\ttrain's ndcg@1: 0.866962\ttrain's ndcg@2: 0.89919\ttrain's ndcg@3: 0.921474\ttrain's ndcg@4: 0.935421\ttrain's ndcg@5: 0.943445\tvalid's ndcg@1: 0.84569\tvalid's ndcg@2: 0.887188\tvalid's ndcg@3: 0.912737\tvalid's ndcg@4: 0.927746\tvalid's ndcg@5: 0.936354\n",
      "[200]\ttrain's ndcg@1: 0.883489\ttrain's ndcg@2: 0.911448\ttrain's ndcg@3: 0.931279\ttrain's ndcg@4: 0.94376\ttrain's ndcg@5: 0.950575\tvalid's ndcg@1: 0.858837\tvalid's ndcg@2: 0.897965\tvalid's ndcg@3: 0.921132\tvalid's ndcg@4: 0.935451\tvalid's ndcg@5: 0.94277\n",
      "[250]\ttrain's ndcg@1: 0.897609\ttrain's ndcg@2: 0.922373\ttrain's ndcg@3: 0.939616\ttrain's ndcg@4: 0.95066\ttrain's ndcg@5: 0.95664\tvalid's ndcg@1: 0.870998\tvalid's ndcg@2: 0.90804\tvalid's ndcg@3: 0.929156\tvalid's ndcg@4: 0.941783\tvalid's ndcg@5: 0.948412\n",
      "[300]\ttrain's ndcg@1: 0.910331\ttrain's ndcg@2: 0.930981\ttrain's ndcg@3: 0.946433\ttrain's ndcg@4: 0.956278\ttrain's ndcg@5: 0.961696\tvalid's ndcg@1: 0.879677\tvalid's ndcg@2: 0.915681\tvalid's ndcg@3: 0.934956\tvalid's ndcg@4: 0.946395\tvalid's ndcg@5: 0.952358\n",
      "[350]\ttrain's ndcg@1: 0.920206\ttrain's ndcg@2: 0.938001\ttrain's ndcg@3: 0.951732\ttrain's ndcg@4: 0.960696\ttrain's ndcg@5: 0.965598\tvalid's ndcg@1: 0.887541\tvalid's ndcg@2: 0.921856\tvalid's ndcg@3: 0.939645\tvalid's ndcg@4: 0.95039\tvalid's ndcg@5: 0.955779\n",
      "[400]\ttrain's ndcg@1: 0.928028\ttrain's ndcg@2: 0.943336\ttrain's ndcg@3: 0.955956\ttrain's ndcg@4: 0.964242\ttrain's ndcg@5: 0.968688\tvalid's ndcg@1: 0.89213\tvalid's ndcg@2: 0.926391\tvalid's ndcg@3: 0.942859\tvalid's ndcg@4: 0.952975\tvalid's ndcg@5: 0.958037\n",
      "[450]\ttrain's ndcg@1: 0.935363\ttrain's ndcg@2: 0.948855\ttrain's ndcg@3: 0.960051\ttrain's ndcg@4: 0.967547\ttrain's ndcg@5: 0.971616\tvalid's ndcg@1: 0.896653\tvalid's ndcg@2: 0.931143\tvalid's ndcg@3: 0.945787\tvalid's ndcg@4: 0.955496\tvalid's ndcg@5: 0.960185\n",
      "Early stopping, best iteration is:\n",
      "[453]\ttrain's ndcg@1: 0.935788\ttrain's ndcg@2: 0.94917\ttrain's ndcg@3: 0.960303\ttrain's ndcg@4: 0.967728\ttrain's ndcg@5: 0.971791\tvalid's ndcg@1: 0.897235\tvalid's ndcg@2: 0.931306\tvalid's ndcg@3: 0.945977\tvalid's ndcg@4: 0.955712\tvalid's ndcg@5: 0.960347\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[50]\ttrain's ndcg@1: 0.801959\ttrain's ndcg@2: 0.84476\ttrain's ndcg@3: 0.876481\ttrain's ndcg@4: 0.898197\ttrain's ndcg@5: 0.911388\tvalid's ndcg@1: 0.792236\tvalid's ndcg@2: 0.837077\tvalid's ndcg@3: 0.871485\tvalid's ndcg@4: 0.894696\tvalid's ndcg@5: 0.907307\n",
      "[100]\ttrain's ndcg@1: 0.843524\ttrain's ndcg@2: 0.879268\ttrain's ndcg@3: 0.905473\ttrain's ndcg@4: 0.922056\ttrain's ndcg@5: 0.932016\tvalid's ndcg@1: 0.826233\tvalid's ndcg@2: 0.869467\tvalid's ndcg@3: 0.898063\tvalid's ndcg@4: 0.916201\tvalid's ndcg@5: 0.92632\n",
      "[150]\ttrain's ndcg@1: 0.866546\ttrain's ndcg@2: 0.89795\ttrain's ndcg@3: 0.920573\ttrain's ndcg@4: 0.934542\ttrain's ndcg@5: 0.94291\tvalid's ndcg@1: 0.843919\tvalid's ndcg@2: 0.885634\tvalid's ndcg@3: 0.910813\tvalid's ndcg@4: 0.926866\tvalid's ndcg@5: 0.935598\n",
      "[200]\ttrain's ndcg@1: 0.883839\ttrain's ndcg@2: 0.911064\ttrain's ndcg@3: 0.931122\ttrain's ndcg@4: 0.943539\ttrain's ndcg@5: 0.950531\tvalid's ndcg@1: 0.859349\tvalid's ndcg@2: 0.897592\tvalid's ndcg@3: 0.921217\tvalid's ndcg@4: 0.935303\tvalid's ndcg@5: 0.942646\n",
      "[250]\ttrain's ndcg@1: 0.897971\ttrain's ndcg@2: 0.922105\ttrain's ndcg@3: 0.939463\ttrain's ndcg@4: 0.950555\ttrain's ndcg@5: 0.956637\tvalid's ndcg@1: 0.868759\tvalid's ndcg@2: 0.906639\tvalid's ndcg@3: 0.928336\tvalid's ndcg@4: 0.940895\tvalid's ndcg@5: 0.9476\n",
      "[300]\ttrain's ndcg@1: 0.90925\ttrain's ndcg@2: 0.930577\ttrain's ndcg@3: 0.945869\ttrain's ndcg@4: 0.955899\ttrain's ndcg@5: 0.961329\tvalid's ndcg@1: 0.877856\tvalid's ndcg@2: 0.914006\tvalid's ndcg@3: 0.933939\tvalid's ndcg@4: 0.945525\tvalid's ndcg@5: 0.95166\n",
      "[350]\ttrain's ndcg@1: 0.920037\ttrain's ndcg@2: 0.938053\ttrain's ndcg@3: 0.951669\ttrain's ndcg@4: 0.960799\ttrain's ndcg@5: 0.965576\tvalid's ndcg@1: 0.884074\tvalid's ndcg@2: 0.91983\tvalid's ndcg@3: 0.937978\tvalid's ndcg@4: 0.949078\tvalid's ndcg@5: 0.954613\n",
      "[400]\ttrain's ndcg@1: 0.927926\ttrain's ndcg@2: 0.943668\ttrain's ndcg@3: 0.956159\ttrain's ndcg@4: 0.964355\ttrain's ndcg@5: 0.968672\tvalid's ndcg@1: 0.890433\tvalid's ndcg@2: 0.924441\tvalid's ndcg@3: 0.942072\tvalid's ndcg@4: 0.952196\tvalid's ndcg@5: 0.957316\n",
      "[450]\ttrain's ndcg@1: 0.935412\ttrain's ndcg@2: 0.948899\ttrain's ndcg@3: 0.960092\ttrain's ndcg@4: 0.967628\ttrain's ndcg@5: 0.971617\tvalid's ndcg@1: 0.895437\tvalid's ndcg@2: 0.929056\tvalid's ndcg@3: 0.94512\tvalid's ndcg@4: 0.954791\tvalid's ndcg@5: 0.959619\n",
      "[500]\ttrain's ndcg@1: 0.941113\ttrain's ndcg@2: 0.952911\ttrain's ndcg@3: 0.963172\ttrain's ndcg@4: 0.970076\ttrain's ndcg@5: 0.973862\tvalid's ndcg@1: 0.899809\tvalid's ndcg@2: 0.931654\tvalid's ndcg@3: 0.94764\tvalid's ndcg@4: 0.956817\tvalid's ndcg@5: 0.961326\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[496]\ttrain's ndcg@1: 0.940768\ttrain's ndcg@2: 0.952656\ttrain's ndcg@3: 0.963011\ttrain's ndcg@4: 0.969929\ttrain's ndcg@5: 0.973722\tvalid's ndcg@1: 0.899958\tvalid's ndcg@2: 0.931755\tvalid's ndcg@3: 0.947661\tvalid's ndcg@4: 0.956845\tvalid's ndcg@5: 0.961357\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[50]\ttrain's ndcg@1: 0.709752\ttrain's ndcg@2: 0.762444\ttrain's ndcg@3: 0.806057\ttrain's ndcg@4: 0.837809\ttrain's ndcg@5: 0.859018\tvalid's ndcg@1: 0.704982\tvalid's ndcg@2: 0.759528\tvalid's ndcg@3: 0.805059\tvalid's ndcg@4: 0.836282\tvalid's ndcg@5: 0.856597\n",
      "[100]\ttrain's ndcg@1: 0.726974\ttrain's ndcg@2: 0.776915\ttrain's ndcg@3: 0.818117\ttrain's ndcg@4: 0.848137\ttrain's ndcg@5: 0.867957\tvalid's ndcg@1: 0.718621\tvalid's ndcg@2: 0.771857\tvalid's ndcg@3: 0.814858\tvalid's ndcg@4: 0.845181\tvalid's ndcg@5: 0.864308\n",
      "[150]\ttrain's ndcg@1: 0.745933\ttrain's ndcg@2: 0.792992\ttrain's ndcg@3: 0.832073\ttrain's ndcg@4: 0.859865\ttrain's ndcg@5: 0.878537\tvalid's ndcg@1: 0.732046\tvalid's ndcg@2: 0.785564\tvalid's ndcg@3: 0.826523\tvalid's ndcg@4: 0.85502\tvalid's ndcg@5: 0.873203\n",
      "[200]\ttrain's ndcg@1: 0.764926\ttrain's ndcg@2: 0.808836\ttrain's ndcg@3: 0.846159\ttrain's ndcg@4: 0.871758\ttrain's ndcg@5: 0.888856\tvalid's ndcg@1: 0.751791\tvalid's ndcg@2: 0.801576\tvalid's ndcg@3: 0.841034\tvalid's ndcg@4: 0.866611\tvalid's ndcg@5: 0.88384\n",
      "[250]\ttrain's ndcg@1: 0.780388\ttrain's ndcg@2: 0.821834\ttrain's ndcg@3: 0.857099\ttrain's ndcg@4: 0.881381\ttrain's ndcg@5: 0.897148\tvalid's ndcg@1: 0.764544\tvalid's ndcg@2: 0.813781\tvalid's ndcg@3: 0.850351\tvalid's ndcg@4: 0.875476\tvalid's ndcg@5: 0.891229\n",
      "[300]\ttrain's ndcg@1: 0.793097\ttrain's ndcg@2: 0.832674\ttrain's ndcg@3: 0.866103\ttrain's ndcg@4: 0.889065\ttrain's ndcg@5: 0.903831\tvalid's ndcg@1: 0.775303\tvalid's ndcg@2: 0.822933\tvalid's ndcg@3: 0.858279\tvalid's ndcg@4: 0.882546\tvalid's ndcg@5: 0.89726\n",
      "[350]\ttrain's ndcg@1: 0.803009\ttrain's ndcg@2: 0.841615\ttrain's ndcg@3: 0.873313\ttrain's ndcg@4: 0.895154\ttrain's ndcg@5: 0.909252\tvalid's ndcg@1: 0.783784\tvalid's ndcg@2: 0.831223\tvalid's ndcg@3: 0.865343\tvalid's ndcg@4: 0.888154\tvalid's ndcg@5: 0.902419\n",
      "[400]\ttrain's ndcg@1: 0.811544\ttrain's ndcg@2: 0.849169\ttrain's ndcg@3: 0.879669\ttrain's ndcg@4: 0.900464\ttrain's ndcg@5: 0.913797\tvalid's ndcg@1: 0.790215\tvalid's ndcg@2: 0.837292\tvalid's ndcg@3: 0.870284\tvalid's ndcg@4: 0.892634\tvalid's ndcg@5: 0.906247\n",
      "[450]\ttrain's ndcg@1: 0.818505\ttrain's ndcg@2: 0.855774\ttrain's ndcg@3: 0.885076\ttrain's ndcg@4: 0.904927\ttrain's ndcg@5: 0.917679\tvalid's ndcg@1: 0.797047\tvalid's ndcg@2: 0.843456\tvalid's ndcg@3: 0.875118\tvalid's ndcg@4: 0.897188\tvalid's ndcg@5: 0.909851\n",
      "[500]\ttrain's ndcg@1: 0.82516\ttrain's ndcg@2: 0.861553\ttrain's ndcg@3: 0.889739\ttrain's ndcg@4: 0.908962\ttrain's ndcg@5: 0.921179\tvalid's ndcg@1: 0.803705\tvalid's ndcg@2: 0.848335\tvalid's ndcg@3: 0.879957\tvalid's ndcg@4: 0.900865\tvalid's ndcg@5: 0.913107\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttrain's ndcg@1: 0.82516\ttrain's ndcg@2: 0.861553\ttrain's ndcg@3: 0.889739\ttrain's ndcg@4: 0.908962\ttrain's ndcg@5: 0.921179\tvalid's ndcg@1: 0.803705\tvalid's ndcg@2: 0.848335\tvalid's ndcg@3: 0.879957\tvalid's ndcg@4: 0.900865\tvalid's ndcg@5: 0.913107\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[15]\ttrain's ndcg@1: 0.688842\ttrain's ndcg@2: 0.746219\ttrain's ndcg@3: 0.792446\ttrain's ndcg@4: 0.826148\ttrain's ndcg@5: 0.84862\tvalid's ndcg@1: 0.689928\tvalid's ndcg@2: 0.744969\tvalid's ndcg@3: 0.791957\tvalid's ndcg@4: 0.825734\tvalid's ndcg@5: 0.847206\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[50]\ttrain's ndcg@1: 0.691236\ttrain's ndcg@2: 0.746068\ttrain's ndcg@3: 0.791363\ttrain's ndcg@4: 0.824799\ttrain's ndcg@5: 0.847521\tvalid's ndcg@1: 0.68621\tvalid's ndcg@2: 0.743357\tvalid's ndcg@3: 0.78963\tvalid's ndcg@4: 0.823236\tvalid's ndcg@5: 0.845353\n",
      "[100]\ttrain's ndcg@1: 0.717473\ttrain's ndcg@2: 0.769056\ttrain's ndcg@3: 0.811693\ttrain's ndcg@4: 0.842669\ttrain's ndcg@5: 0.863079\tvalid's ndcg@1: 0.709879\tvalid's ndcg@2: 0.76443\tvalid's ndcg@3: 0.808391\tvalid's ndcg@4: 0.839625\tvalid's ndcg@5: 0.859592\n",
      "[150]\ttrain's ndcg@1: 0.74383\ttrain's ndcg@2: 0.790958\ttrain's ndcg@3: 0.830575\ttrain's ndcg@4: 0.858696\ttrain's ndcg@5: 0.877633\tvalid's ndcg@1: 0.73021\tvalid's ndcg@2: 0.783508\tvalid's ndcg@3: 0.824973\tvalid's ndcg@4: 0.854032\tvalid's ndcg@5: 0.87233\n",
      "[200]\ttrain's ndcg@1: 0.763801\ttrain's ndcg@2: 0.807999\ttrain's ndcg@3: 0.845379\ttrain's ndcg@4: 0.871598\ttrain's ndcg@5: 0.88869\tvalid's ndcg@1: 0.748407\tvalid's ndcg@2: 0.799162\tvalid's ndcg@3: 0.839098\tvalid's ndcg@4: 0.865939\tvalid's ndcg@5: 0.882583\n",
      "[250]\ttrain's ndcg@1: 0.77949\ttrain's ndcg@2: 0.821494\ttrain's ndcg@3: 0.856712\ttrain's ndcg@4: 0.881334\ttrain's ndcg@5: 0.897168\tvalid's ndcg@1: 0.763711\tvalid's ndcg@2: 0.812955\tvalid's ndcg@3: 0.850025\tvalid's ndcg@4: 0.875427\tvalid's ndcg@5: 0.891098\n",
      "[300]\ttrain's ndcg@1: 0.792267\ttrain's ndcg@2: 0.832548\ttrain's ndcg@3: 0.865907\ttrain's ndcg@4: 0.889086\ttrain's ndcg@5: 0.903896\tvalid's ndcg@1: 0.776187\tvalid's ndcg@2: 0.823282\tvalid's ndcg@3: 0.858832\tvalid's ndcg@4: 0.883269\tvalid's ndcg@5: 0.897667\n",
      "[350]\ttrain's ndcg@1: 0.802752\ttrain's ndcg@2: 0.841812\ttrain's ndcg@3: 0.873694\ttrain's ndcg@4: 0.895735\ttrain's ndcg@5: 0.909458\tvalid's ndcg@1: 0.785238\tvalid's ndcg@2: 0.831999\tvalid's ndcg@3: 0.865595\tvalid's ndcg@4: 0.889134\tvalid's ndcg@5: 0.903046\n",
      "[400]\ttrain's ndcg@1: 0.811757\ttrain's ndcg@2: 0.849442\ttrain's ndcg@3: 0.880159\ttrain's ndcg@4: 0.901086\ttrain's ndcg@5: 0.913968\tvalid's ndcg@1: 0.792131\tvalid's ndcg@2: 0.838082\tvalid's ndcg@3: 0.871461\tvalid's ndcg@4: 0.893775\tvalid's ndcg@5: 0.907248\n",
      "[450]\ttrain's ndcg@1: 0.819156\ttrain's ndcg@2: 0.856102\ttrain's ndcg@3: 0.885548\ttrain's ndcg@4: 0.905459\ttrain's ndcg@5: 0.917806\tvalid's ndcg@1: 0.798061\tvalid's ndcg@2: 0.842804\tvalid's ndcg@3: 0.876303\tvalid's ndcg@4: 0.897709\tvalid's ndcg@5: 0.910367\n",
      "[500]\ttrain's ndcg@1: 0.826002\ttrain's ndcg@2: 0.861884\ttrain's ndcg@3: 0.890182\ttrain's ndcg@4: 0.909352\ttrain's ndcg@5: 0.921373\tvalid's ndcg@1: 0.803122\tvalid's ndcg@2: 0.848849\tvalid's ndcg@3: 0.880927\tvalid's ndcg@4: 0.901542\tvalid's ndcg@5: 0.9136\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttrain's ndcg@1: 0.826002\ttrain's ndcg@2: 0.861884\ttrain's ndcg@3: 0.890182\ttrain's ndcg@4: 0.909352\ttrain's ndcg@5: 0.921373\tvalid's ndcg@1: 0.803122\tvalid's ndcg@2: 0.848849\tvalid's ndcg@3: 0.880927\tvalid's ndcg@4: 0.901542\tvalid's ndcg@5: 0.9136\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[50]\ttrain's ndcg@1: 0.778718\ttrain's ndcg@2: 0.821872\ttrain's ndcg@3: 0.856945\ttrain's ndcg@4: 0.88152\ttrain's ndcg@5: 0.897149\tvalid's ndcg@1: 0.765004\tvalid's ndcg@2: 0.814519\tvalid's ndcg@3: 0.851373\tvalid's ndcg@4: 0.876297\tvalid's ndcg@5: 0.891738\n",
      "[100]\ttrain's ndcg@1: 0.823709\ttrain's ndcg@2: 0.860495\ttrain's ndcg@3: 0.88909\ttrain's ndcg@4: 0.90835\ttrain's ndcg@5: 0.92059\tvalid's ndcg@1: 0.801041\tvalid's ndcg@2: 0.847465\tvalid's ndcg@3: 0.879556\tvalid's ndcg@4: 0.900379\tvalid's ndcg@5: 0.912695\n",
      "[150]\ttrain's ndcg@1: 0.849201\ttrain's ndcg@2: 0.882078\ttrain's ndcg@3: 0.906717\ttrain's ndcg@4: 0.92294\ttrain's ndcg@5: 0.933095\tvalid's ndcg@1: 0.821799\tvalid's ndcg@2: 0.866855\tvalid's ndcg@3: 0.894404\tvalid's ndcg@4: 0.913421\tvalid's ndcg@5: 0.923946\n",
      "[200]\ttrain's ndcg@1: 0.867957\ttrain's ndcg@2: 0.896442\ttrain's ndcg@3: 0.918632\ttrain's ndcg@4: 0.932864\ttrain's ndcg@5: 0.941645\tvalid's ndcg@1: 0.835541\tvalid's ndcg@2: 0.87849\tvalid's ndcg@3: 0.904292\tvalid's ndcg@4: 0.921551\tvalid's ndcg@5: 0.930794\n",
      "[250]\ttrain's ndcg@1: 0.882769\ttrain's ndcg@2: 0.908203\ttrain's ndcg@3: 0.927669\ttrain's ndcg@4: 0.940422\ttrain's ndcg@5: 0.948255\tvalid's ndcg@1: 0.845953\tvalid's ndcg@2: 0.886839\tvalid's ndcg@3: 0.912158\tvalid's ndcg@4: 0.92752\tvalid's ndcg@5: 0.936099\n",
      "[300]\ttrain's ndcg@1: 0.895122\ttrain's ndcg@2: 0.917687\ttrain's ndcg@3: 0.935101\ttrain's ndcg@4: 0.946621\ttrain's ndcg@5: 0.953697\tvalid's ndcg@1: 0.85343\tvalid's ndcg@2: 0.894748\tvalid's ndcg@3: 0.918144\tvalid's ndcg@4: 0.932519\tvalid's ndcg@5: 0.940166\n",
      "[350]\ttrain's ndcg@1: 0.906531\ttrain's ndcg@2: 0.925743\ttrain's ndcg@3: 0.941271\ttrain's ndcg@4: 0.951885\ttrain's ndcg@5: 0.958241\tvalid's ndcg@1: 0.860665\tvalid's ndcg@2: 0.900415\tvalid's ndcg@3: 0.922881\tvalid's ndcg@4: 0.936344\tvalid's ndcg@5: 0.943587\n",
      "[400]\ttrain's ndcg@1: 0.915722\ttrain's ndcg@2: 0.932399\ttrain's ndcg@3: 0.946495\ttrain's ndcg@4: 0.956185\ttrain's ndcg@5: 0.962023\tvalid's ndcg@1: 0.867381\tvalid's ndcg@2: 0.905783\tvalid's ndcg@3: 0.927303\tvalid's ndcg@4: 0.939925\tvalid's ndcg@5: 0.946636\n",
      "[450]\ttrain's ndcg@1: 0.923927\ttrain's ndcg@2: 0.938105\ttrain's ndcg@3: 0.950841\ttrain's ndcg@4: 0.959876\ttrain's ndcg@5: 0.965306\tvalid's ndcg@1: 0.871389\tvalid's ndcg@2: 0.909676\tvalid's ndcg@3: 0.930187\tvalid's ndcg@4: 0.942089\tvalid's ndcg@5: 0.948732\n",
      "[500]\ttrain's ndcg@1: 0.930488\ttrain's ndcg@2: 0.942695\ttrain's ndcg@3: 0.954357\ttrain's ndcg@4: 0.962882\ttrain's ndcg@5: 0.967937\tvalid's ndcg@1: 0.87579\tvalid's ndcg@2: 0.913444\tvalid's ndcg@3: 0.933058\tvalid's ndcg@4: 0.944433\tvalid's ndcg@5: 0.950818\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[493]\ttrain's ndcg@1: 0.929716\ttrain's ndcg@2: 0.942096\ttrain's ndcg@3: 0.953849\ttrain's ndcg@4: 0.962506\ttrain's ndcg@5: 0.967612\tvalid's ndcg@1: 0.876111\tvalid's ndcg@2: 0.913037\tvalid's ndcg@3: 0.932861\tvalid's ndcg@4: 0.94427\tvalid's ndcg@5: 0.950742\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[50]\ttrain's ndcg@1: 0.777514\ttrain's ndcg@2: 0.820705\ttrain's ndcg@3: 0.856322\ttrain's ndcg@4: 0.880996\ttrain's ndcg@5: 0.896653\tvalid's ndcg@1: 0.766632\tvalid's ndcg@2: 0.81363\tvalid's ndcg@3: 0.851235\tvalid's ndcg@4: 0.876568\tvalid's ndcg@5: 0.891937\n",
      "[100]\ttrain's ndcg@1: 0.823666\ttrain's ndcg@2: 0.860884\ttrain's ndcg@3: 0.889601\ttrain's ndcg@4: 0.908783\ttrain's ndcg@5: 0.920798\tvalid's ndcg@1: 0.801015\tvalid's ndcg@2: 0.848839\tvalid's ndcg@3: 0.879718\tvalid's ndcg@4: 0.901042\tvalid's ndcg@5: 0.912699\n",
      "[150]\ttrain's ndcg@1: 0.849425\ttrain's ndcg@2: 0.882411\ttrain's ndcg@3: 0.906994\ttrain's ndcg@4: 0.92325\ttrain's ndcg@5: 0.933363\tvalid's ndcg@1: 0.822218\tvalid's ndcg@2: 0.866176\tvalid's ndcg@3: 0.894598\tvalid's ndcg@4: 0.913588\tvalid's ndcg@5: 0.923619\n",
      "[200]\ttrain's ndcg@1: 0.868996\ttrain's ndcg@2: 0.897574\ttrain's ndcg@3: 0.919254\ttrain's ndcg@4: 0.933345\ttrain's ndcg@5: 0.942112\tvalid's ndcg@1: 0.834322\tvalid's ndcg@2: 0.877192\tvalid's ndcg@3: 0.903886\tvalid's ndcg@4: 0.92132\tvalid's ndcg@5: 0.930438\n",
      "[250]\ttrain's ndcg@1: 0.883034\ttrain's ndcg@2: 0.908394\ttrain's ndcg@3: 0.927998\ttrain's ndcg@4: 0.94061\ttrain's ndcg@5: 0.948373\tvalid's ndcg@1: 0.845397\tvalid's ndcg@2: 0.886663\tvalid's ndcg@3: 0.912455\tvalid's ndcg@4: 0.92788\tvalid's ndcg@5: 0.936032\n",
      "[300]\ttrain's ndcg@1: 0.895435\ttrain's ndcg@2: 0.9176\ttrain's ndcg@3: 0.935116\ttrain's ndcg@4: 0.946847\ttrain's ndcg@5: 0.953702\tvalid's ndcg@1: 0.855684\tvalid's ndcg@2: 0.894622\tvalid's ndcg@3: 0.9187\tvalid's ndcg@4: 0.933098\tvalid's ndcg@5: 0.940621\n",
      "[350]\ttrain's ndcg@1: 0.905698\ttrain's ndcg@2: 0.925261\ttrain's ndcg@3: 0.940993\ttrain's ndcg@4: 0.951803\ttrain's ndcg@5: 0.957977\tvalid's ndcg@1: 0.862559\tvalid's ndcg@2: 0.901019\tvalid's ndcg@3: 0.923503\tvalid's ndcg@4: 0.937014\tvalid's ndcg@5: 0.944134\n",
      "Early stopping, best iteration is:\n",
      "[377]\ttrain's ndcg@1: 0.911386\ttrain's ndcg@2: 0.929174\ttrain's ndcg@3: 0.943985\ttrain's ndcg@4: 0.954297\ttrain's ndcg@5: 0.960236\tvalid's ndcg@1: 0.866319\tvalid's ndcg@2: 0.90397\tvalid's ndcg@3: 0.925847\tvalid's ndcg@4: 0.938731\tvalid's ndcg@5: 0.945805\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[50]\ttrain's ndcg@1: 0.777748\ttrain's ndcg@2: 0.820221\ttrain's ndcg@3: 0.855722\ttrain's ndcg@4: 0.880463\ttrain's ndcg@5: 0.896389\tvalid's ndcg@1: 0.763242\tvalid's ndcg@2: 0.812385\tvalid's ndcg@3: 0.849371\tvalid's ndcg@4: 0.875254\tvalid's ndcg@5: 0.890975\n",
      "[100]\ttrain's ndcg@1: 0.824273\ttrain's ndcg@2: 0.860933\ttrain's ndcg@3: 0.889452\ttrain's ndcg@4: 0.908571\ttrain's ndcg@5: 0.920696\tvalid's ndcg@1: 0.802691\tvalid's ndcg@2: 0.848734\tvalid's ndcg@3: 0.879638\tvalid's ndcg@4: 0.900769\tvalid's ndcg@5: 0.913173\n",
      "[150]\ttrain's ndcg@1: 0.850351\ttrain's ndcg@2: 0.882102\ttrain's ndcg@3: 0.906661\ttrain's ndcg@4: 0.923154\ttrain's ndcg@5: 0.933286\tvalid's ndcg@1: 0.822058\tvalid's ndcg@2: 0.865108\tvalid's ndcg@3: 0.894152\tvalid's ndcg@4: 0.913043\tvalid's ndcg@5: 0.923727\n",
      "[200]\ttrain's ndcg@1: 0.868438\ttrain's ndcg@2: 0.896949\ttrain's ndcg@3: 0.918595\ttrain's ndcg@4: 0.932992\ttrain's ndcg@5: 0.941839\tvalid's ndcg@1: 0.836371\tvalid's ndcg@2: 0.877453\tvalid's ndcg@3: 0.904196\tvalid's ndcg@4: 0.921392\tvalid's ndcg@5: 0.930805\n",
      "[250]\ttrain's ndcg@1: 0.882977\ttrain's ndcg@2: 0.908177\ttrain's ndcg@3: 0.927503\ttrain's ndcg@4: 0.940395\ttrain's ndcg@5: 0.948298\tvalid's ndcg@1: 0.847423\tvalid's ndcg@2: 0.886553\tvalid's ndcg@3: 0.911918\tvalid's ndcg@4: 0.927619\tvalid's ndcg@5: 0.936196\n",
      "[300]\ttrain's ndcg@1: 0.8947\ttrain's ndcg@2: 0.917151\ttrain's ndcg@3: 0.934651\ttrain's ndcg@4: 0.946253\ttrain's ndcg@5: 0.953475\tvalid's ndcg@1: 0.855901\tvalid's ndcg@2: 0.894062\tvalid's ndcg@3: 0.918246\tvalid's ndcg@4: 0.932892\tvalid's ndcg@5: 0.940482\n",
      "[350]\ttrain's ndcg@1: 0.905412\ttrain's ndcg@2: 0.925061\ttrain's ndcg@3: 0.940725\ttrain's ndcg@4: 0.951461\ttrain's ndcg@5: 0.957916\tvalid's ndcg@1: 0.861681\tvalid's ndcg@2: 0.900292\tvalid's ndcg@3: 0.922879\tvalid's ndcg@4: 0.936695\tvalid's ndcg@5: 0.943657\n",
      "[400]\ttrain's ndcg@1: 0.914283\ttrain's ndcg@2: 0.93161\ttrain's ndcg@3: 0.945741\ttrain's ndcg@4: 0.95571\ttrain's ndcg@5: 0.961585\tvalid's ndcg@1: 0.866969\tvalid's ndcg@2: 0.904065\tvalid's ndcg@3: 0.926846\tvalid's ndcg@4: 0.939533\tvalid's ndcg@5: 0.946165\n",
      "[450]\ttrain's ndcg@1: 0.92273\ttrain's ndcg@2: 0.937518\ttrain's ndcg@3: 0.950196\ttrain's ndcg@4: 0.959567\ttrain's ndcg@5: 0.964928\tvalid's ndcg@1: 0.872811\tvalid's ndcg@2: 0.908216\tvalid's ndcg@3: 0.930273\tvalid's ndcg@4: 0.942592\tvalid's ndcg@5: 0.948695\n",
      "Early stopping, best iteration is:\n",
      "[446]\ttrain's ndcg@1: 0.922067\ttrain's ndcg@2: 0.937131\ttrain's ndcg@3: 0.949871\ttrain's ndcg@4: 0.959259\ttrain's ndcg@5: 0.96468\tvalid's ndcg@1: 0.873012\tvalid's ndcg@2: 0.908072\tvalid's ndcg@3: 0.930065\tvalid's ndcg@4: 0.942553\tvalid's ndcg@5: 0.948645\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[50]\ttrain's ndcg@1: 0.818536\ttrain's ndcg@2: 0.857692\ttrain's ndcg@3: 0.88679\ttrain's ndcg@4: 0.906731\ttrain's ndcg@5: 0.918816\tvalid's ndcg@1: 0.798473\tvalid's ndcg@2: 0.845681\tvalid's ndcg@3: 0.877519\tvalid's ndcg@4: 0.899404\tvalid's ndcg@5: 0.911648\n",
      "[100]\ttrain's ndcg@1: 0.863504\ttrain's ndcg@2: 0.893868\ttrain's ndcg@3: 0.916675\ttrain's ndcg@4: 0.931208\ttrain's ndcg@5: 0.940092\tvalid's ndcg@1: 0.833808\tvalid's ndcg@2: 0.876479\tvalid's ndcg@3: 0.903566\tvalid's ndcg@4: 0.921114\tvalid's ndcg@5: 0.930276\n",
      "[150]\ttrain's ndcg@1: 0.892493\ttrain's ndcg@2: 0.915479\ttrain's ndcg@3: 0.933638\ttrain's ndcg@4: 0.945419\ttrain's ndcg@5: 0.952559\tvalid's ndcg@1: 0.851954\tvalid's ndcg@2: 0.893248\tvalid's ndcg@3: 0.917499\tvalid's ndcg@4: 0.932128\tvalid's ndcg@5: 0.939616\n",
      "[200]\ttrain's ndcg@1: 0.912124\ttrain's ndcg@2: 0.929908\ttrain's ndcg@3: 0.944481\ttrain's ndcg@4: 0.954694\ttrain's ndcg@5: 0.960647\tvalid's ndcg@1: 0.865719\tvalid's ndcg@2: 0.9039\tvalid's ndcg@3: 0.925987\tvalid's ndcg@4: 0.939137\tvalid's ndcg@5: 0.945956\n",
      "Early stopping, best iteration is:\n",
      "[234]\ttrain's ndcg@1: 0.923335\ttrain's ndcg@2: 0.937981\ttrain's ndcg@3: 0.950552\ttrain's ndcg@4: 0.959829\ttrain's ndcg@5: 0.965179\tvalid's ndcg@1: 0.873864\tvalid's ndcg@2: 0.90987\tvalid's ndcg@3: 0.931102\tvalid's ndcg@4: 0.942963\tvalid's ndcg@5: 0.949336\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[50]\ttrain's ndcg@1: 0.820248\ttrain's ndcg@2: 0.858081\ttrain's ndcg@3: 0.886919\ttrain's ndcg@4: 0.906907\ttrain's ndcg@5: 0.919184\tvalid's ndcg@1: 0.80037\tvalid's ndcg@2: 0.846261\tvalid's ndcg@3: 0.877624\tvalid's ndcg@4: 0.899726\tvalid's ndcg@5: 0.911958\n",
      "[100]\ttrain's ndcg@1: 0.865372\ttrain's ndcg@2: 0.894479\ttrain's ndcg@3: 0.917238\ttrain's ndcg@4: 0.931668\ttrain's ndcg@5: 0.940609\tvalid's ndcg@1: 0.835352\tvalid's ndcg@2: 0.876057\tvalid's ndcg@3: 0.903634\tvalid's ndcg@4: 0.920944\tvalid's ndcg@5: 0.930311\n",
      "[150]\ttrain's ndcg@1: 0.893349\ttrain's ndcg@2: 0.91538\ttrain's ndcg@3: 0.933719\ttrain's ndcg@4: 0.945574\ttrain's ndcg@5: 0.952685\tvalid's ndcg@1: 0.853366\tvalid's ndcg@2: 0.892894\tvalid's ndcg@3: 0.917098\tvalid's ndcg@4: 0.93182\tvalid's ndcg@5: 0.939659\n",
      "[200]\ttrain's ndcg@1: 0.912967\ttrain's ndcg@2: 0.929996\ttrain's ndcg@3: 0.944836\ttrain's ndcg@4: 0.955009\ttrain's ndcg@5: 0.960828\tvalid's ndcg@1: 0.866303\tvalid's ndcg@2: 0.904432\tvalid's ndcg@3: 0.926263\tvalid's ndcg@4: 0.939235\tvalid's ndcg@5: 0.945937\n",
      "[250]\ttrain's ndcg@1: 0.927984\ttrain's ndcg@2: 0.941025\ttrain's ndcg@3: 0.952988\ttrain's ndcg@4: 0.961909\ttrain's ndcg@5: 0.966983\tvalid's ndcg@1: 0.877159\tvalid's ndcg@2: 0.912634\tvalid's ndcg@3: 0.93297\tvalid's ndcg@4: 0.944651\tvalid's ndcg@5: 0.950818\n",
      "[300]\ttrain's ndcg@1: 0.940212\ttrain's ndcg@2: 0.949535\ttrain's ndcg@3: 0.959606\ttrain's ndcg@4: 0.967222\ttrain's ndcg@5: 0.971802\tvalid's ndcg@1: 0.885561\tvalid's ndcg@2: 0.9193\tvalid's ndcg@3: 0.937946\tvalid's ndcg@4: 0.948821\tvalid's ndcg@5: 0.954504\n",
      "Early stopping, best iteration is:\n",
      "[332]\ttrain's ndcg@1: 0.946712\ttrain's ndcg@2: 0.953817\ttrain's ndcg@3: 0.962934\ttrain's ndcg@4: 0.969942\ttrain's ndcg@5: 0.974245\tvalid's ndcg@1: 0.889676\tvalid's ndcg@2: 0.922338\tvalid's ndcg@3: 0.94053\tvalid's ndcg@4: 0.950655\tvalid's ndcg@5: 0.956247\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[50]\ttrain's ndcg@1: 0.819341\ttrain's ndcg@2: 0.856454\ttrain's ndcg@3: 0.88621\ttrain's ndcg@4: 0.906012\ttrain's ndcg@5: 0.918455\tvalid's ndcg@1: 0.801277\tvalid's ndcg@2: 0.844965\tvalid's ndcg@3: 0.877431\tvalid's ndcg@4: 0.899293\tvalid's ndcg@5: 0.911999\n",
      "[100]\ttrain's ndcg@1: 0.864066\ttrain's ndcg@2: 0.894182\ttrain's ndcg@3: 0.916416\ttrain's ndcg@4: 0.931035\ttrain's ndcg@5: 0.940271\tvalid's ndcg@1: 0.83361\tvalid's ndcg@2: 0.876346\tvalid's ndcg@3: 0.903429\tvalid's ndcg@4: 0.920285\tvalid's ndcg@5: 0.930047\n",
      "[150]\ttrain's ndcg@1: 0.892765\ttrain's ndcg@2: 0.91551\ttrain's ndcg@3: 0.933265\ttrain's ndcg@4: 0.94548\ttrain's ndcg@5: 0.952538\tvalid's ndcg@1: 0.853051\tvalid's ndcg@2: 0.893876\tvalid's ndcg@3: 0.917639\tvalid's ndcg@4: 0.931877\tvalid's ndcg@5: 0.939914\n",
      "[200]\ttrain's ndcg@1: 0.911921\ttrain's ndcg@2: 0.929628\ttrain's ndcg@3: 0.944151\ttrain's ndcg@4: 0.954529\ttrain's ndcg@5: 0.960525\tvalid's ndcg@1: 0.867901\tvalid's ndcg@2: 0.904493\tvalid's ndcg@3: 0.926538\tvalid's ndcg@4: 0.939473\tvalid's ndcg@5: 0.946427\n",
      "[250]\ttrain's ndcg@1: 0.927943\ttrain's ndcg@2: 0.940698\ttrain's ndcg@3: 0.952829\ttrain's ndcg@4: 0.96179\ttrain's ndcg@5: 0.966884\tvalid's ndcg@1: 0.878391\tvalid's ndcg@2: 0.912511\tvalid's ndcg@3: 0.932673\tvalid's ndcg@4: 0.9447\tvalid's ndcg@5: 0.950971\n",
      "[300]\ttrain's ndcg@1: 0.940403\ttrain's ndcg@2: 0.949347\ttrain's ndcg@3: 0.959376\ttrain's ndcg@4: 0.967298\ttrain's ndcg@5: 0.971781\tvalid's ndcg@1: 0.884645\tvalid's ndcg@2: 0.918694\tvalid's ndcg@3: 0.93708\tvalid's ndcg@4: 0.948422\tvalid's ndcg@5: 0.954158\n",
      "[350]\ttrain's ndcg@1: 0.949455\ttrain's ndcg@2: 0.95586\ttrain's ndcg@3: 0.964393\ttrain's ndcg@4: 0.971383\ttrain's ndcg@5: 0.975413\tvalid's ndcg@1: 0.889942\tvalid's ndcg@2: 0.923013\tvalid's ndcg@3: 0.94044\tvalid's ndcg@4: 0.951115\tvalid's ndcg@5: 0.956552\n",
      "[400]\ttrain's ndcg@1: 0.957041\ttrain's ndcg@2: 0.961557\ttrain's ndcg@3: 0.968723\ttrain's ndcg@4: 0.974762\ttrain's ndcg@5: 0.978447\tvalid's ndcg@1: 0.894604\tvalid's ndcg@2: 0.927013\tvalid's ndcg@3: 0.943299\tvalid's ndcg@4: 0.953648\tvalid's ndcg@5: 0.958719\n",
      "Early stopping, best iteration is:\n",
      "[399]\ttrain's ndcg@1: 0.956959\ttrain's ndcg@2: 0.961489\ttrain's ndcg@3: 0.968661\ttrain's ndcg@4: 0.974742\ttrain's ndcg@5: 0.978416\tvalid's ndcg@1: 0.894712\tvalid's ndcg@2: 0.927051\tvalid's ndcg@3: 0.943369\tvalid's ndcg@4: 0.95365\tvalid's ndcg@5: 0.958749\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[50]\ttrain's ndcg@1: 0.726683\ttrain's ndcg@2: 0.776766\ttrain's ndcg@3: 0.817893\ttrain's ndcg@4: 0.84757\ttrain's ndcg@5: 0.867455\tvalid's ndcg@1: 0.714287\tvalid's ndcg@2: 0.767666\tvalid's ndcg@3: 0.812258\tvalid's ndcg@4: 0.84245\tvalid's ndcg@5: 0.862021\n",
      "[100]\ttrain's ndcg@1: 0.74672\ttrain's ndcg@2: 0.792184\ttrain's ndcg@3: 0.830826\ttrain's ndcg@4: 0.858594\ttrain's ndcg@5: 0.87713\tvalid's ndcg@1: 0.725637\tvalid's ndcg@2: 0.780227\tvalid's ndcg@3: 0.822261\tvalid's ndcg@4: 0.850515\tvalid's ndcg@5: 0.869188\n",
      "[150]\ttrain's ndcg@1: 0.766457\ttrain's ndcg@2: 0.808311\ttrain's ndcg@3: 0.844432\ttrain's ndcg@4: 0.870265\ttrain's ndcg@5: 0.887482\tvalid's ndcg@1: 0.740849\tvalid's ndcg@2: 0.79366\tvalid's ndcg@3: 0.833255\tvalid's ndcg@4: 0.860692\tvalid's ndcg@5: 0.878095\n",
      "[200]\ttrain's ndcg@1: 0.784859\ttrain's ndcg@2: 0.824109\ttrain's ndcg@3: 0.8579\ttrain's ndcg@4: 0.881839\ttrain's ndcg@5: 0.897313\tvalid's ndcg@1: 0.757034\tvalid's ndcg@2: 0.808807\tvalid's ndcg@3: 0.846168\tvalid's ndcg@4: 0.871662\tvalid's ndcg@5: 0.887607\n",
      "[250]\ttrain's ndcg@1: 0.800918\ttrain's ndcg@2: 0.837497\ttrain's ndcg@3: 0.869188\ttrain's ndcg@4: 0.891278\ttrain's ndcg@5: 0.90588\tvalid's ndcg@1: 0.769894\tvalid's ndcg@2: 0.819701\tvalid's ndcg@3: 0.855428\tvalid's ndcg@4: 0.879382\tvalid's ndcg@5: 0.894636\n",
      "[300]\ttrain's ndcg@1: 0.814128\ttrain's ndcg@2: 0.848288\ttrain's ndcg@3: 0.878165\ttrain's ndcg@4: 0.898874\ttrain's ndcg@5: 0.912497\tvalid's ndcg@1: 0.780594\tvalid's ndcg@2: 0.828722\tvalid's ndcg@3: 0.863446\tvalid's ndcg@4: 0.886287\tvalid's ndcg@5: 0.900612\n",
      "[350]\ttrain's ndcg@1: 0.825079\ttrain's ndcg@2: 0.857705\ttrain's ndcg@3: 0.885834\ttrain's ndcg@4: 0.905218\ttrain's ndcg@5: 0.918081\tvalid's ndcg@1: 0.790716\tvalid's ndcg@2: 0.837086\tvalid's ndcg@3: 0.870413\tvalid's ndcg@4: 0.892312\tvalid's ndcg@5: 0.90588\n",
      "[400]\ttrain's ndcg@1: 0.834494\ttrain's ndcg@2: 0.86543\ttrain's ndcg@3: 0.892236\ttrain's ndcg@4: 0.910633\ttrain's ndcg@5: 0.922791\tvalid's ndcg@1: 0.798212\tvalid's ndcg@2: 0.842225\tvalid's ndcg@3: 0.875321\tvalid's ndcg@4: 0.896898\tvalid's ndcg@5: 0.909818\n",
      "[450]\ttrain's ndcg@1: 0.842803\ttrain's ndcg@2: 0.872379\ttrain's ndcg@3: 0.897837\ttrain's ndcg@4: 0.915397\ttrain's ndcg@5: 0.927005\tvalid's ndcg@1: 0.803394\tvalid's ndcg@2: 0.847947\tvalid's ndcg@3: 0.880094\tvalid's ndcg@4: 0.90089\tvalid's ndcg@5: 0.913063\n",
      "[500]\ttrain's ndcg@1: 0.8501\ttrain's ndcg@2: 0.878459\ttrain's ndcg@3: 0.902495\ttrain's ndcg@4: 0.919473\ttrain's ndcg@5: 0.930588\tvalid's ndcg@1: 0.808613\tvalid's ndcg@2: 0.852606\tvalid's ndcg@3: 0.884055\tvalid's ndcg@4: 0.90441\tvalid's ndcg@5: 0.916047\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttrain's ndcg@1: 0.8501\ttrain's ndcg@2: 0.878459\ttrain's ndcg@3: 0.902495\ttrain's ndcg@4: 0.919473\ttrain's ndcg@5: 0.930588\tvalid's ndcg@1: 0.808613\tvalid's ndcg@2: 0.852606\tvalid's ndcg@3: 0.884055\tvalid's ndcg@4: 0.90441\tvalid's ndcg@5: 0.916047\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "Early stopping, best iteration is:\n",
      "[15]\ttrain's ndcg@1: 0.703716\ttrain's ndcg@2: 0.758975\ttrain's ndcg@3: 0.803782\ttrain's ndcg@4: 0.835797\ttrain's ndcg@5: 0.856896\tvalid's ndcg@1: 0.697506\tvalid's ndcg@2: 0.754734\tvalid's ndcg@3: 0.800836\tvalid's ndcg@4: 0.832995\tvalid's ndcg@5: 0.853677\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[50]\ttrain's ndcg@1: 0.707604\ttrain's ndcg@2: 0.760094\ttrain's ndcg@3: 0.802306\ttrain's ndcg@4: 0.834449\ttrain's ndcg@5: 0.856014\tvalid's ndcg@1: 0.696909\tvalid's ndcg@2: 0.753118\tvalid's ndcg@3: 0.798505\tvalid's ndcg@4: 0.830414\tvalid's ndcg@5: 0.851436\n",
      "[100]\ttrain's ndcg@1: 0.734918\ttrain's ndcg@2: 0.782084\ttrain's ndcg@3: 0.821972\ttrain's ndcg@4: 0.851189\ttrain's ndcg@5: 0.87073\tvalid's ndcg@1: 0.715648\tvalid's ndcg@2: 0.771365\tvalid's ndcg@3: 0.813978\tvalid's ndcg@4: 0.843958\tvalid's ndcg@5: 0.863535\n",
      "[150]\ttrain's ndcg@1: 0.760138\ttrain's ndcg@2: 0.803469\ttrain's ndcg@3: 0.840472\ttrain's ndcg@4: 0.867054\ttrain's ndcg@5: 0.884684\tvalid's ndcg@1: 0.73604\tvalid's ndcg@2: 0.78919\tvalid's ndcg@3: 0.829905\tvalid's ndcg@4: 0.857966\tvalid's ndcg@5: 0.875692\n",
      "[200]\ttrain's ndcg@1: 0.78095\ttrain's ndcg@2: 0.820821\ttrain's ndcg@3: 0.855562\ttrain's ndcg@4: 0.879769\ttrain's ndcg@5: 0.895829\tvalid's ndcg@1: 0.753397\tvalid's ndcg@2: 0.805295\tvalid's ndcg@3: 0.844023\tvalid's ndcg@4: 0.86997\tvalid's ndcg@5: 0.886021\n",
      "[250]\ttrain's ndcg@1: 0.798024\ttrain's ndcg@2: 0.835688\ttrain's ndcg@3: 0.867696\ttrain's ndcg@4: 0.890057\ttrain's ndcg@5: 0.90491\tvalid's ndcg@1: 0.767466\tvalid's ndcg@2: 0.817468\tvalid's ndcg@3: 0.854058\tvalid's ndcg@4: 0.878693\tvalid's ndcg@5: 0.893828\n",
      "[300]\ttrain's ndcg@1: 0.812011\ttrain's ndcg@2: 0.847399\ttrain's ndcg@3: 0.87737\ttrain's ndcg@4: 0.898311\ttrain's ndcg@5: 0.912057\tvalid's ndcg@1: 0.77882\tvalid's ndcg@2: 0.829051\tvalid's ndcg@3: 0.863019\tvalid's ndcg@4: 0.886065\tvalid's ndcg@5: 0.900448\n",
      "[350]\ttrain's ndcg@1: 0.823149\ttrain's ndcg@2: 0.856878\ttrain's ndcg@3: 0.885134\ttrain's ndcg@4: 0.904918\ttrain's ndcg@5: 0.917703\tvalid's ndcg@1: 0.788867\tvalid's ndcg@2: 0.836399\tvalid's ndcg@3: 0.870222\tvalid's ndcg@4: 0.89232\tvalid's ndcg@5: 0.905767\n",
      "[400]\ttrain's ndcg@1: 0.832994\ttrain's ndcg@2: 0.864553\ttrain's ndcg@3: 0.891335\ttrain's ndcg@4: 0.91031\ttrain's ndcg@5: 0.922446\tvalid's ndcg@1: 0.795705\tvalid's ndcg@2: 0.841892\tvalid's ndcg@3: 0.875078\tvalid's ndcg@4: 0.896788\tvalid's ndcg@5: 0.909546\n",
      "Early stopping, best iteration is:\n",
      "[402]\ttrain's ndcg@1: 0.833067\ttrain's ndcg@2: 0.864807\ttrain's ndcg@3: 0.891475\ttrain's ndcg@4: 0.910465\ttrain's ndcg@5: 0.922583\tvalid's ndcg@1: 0.795877\tvalid's ndcg@2: 0.84212\tvalid's ndcg@3: 0.87531\tvalid's ndcg@4: 0.896924\tvalid's ndcg@5: 0.909678\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[50]\ttrain's ndcg@1: 0.797555\ttrain's ndcg@2: 0.835946\ttrain's ndcg@3: 0.868106\ttrain's ndcg@4: 0.89051\ttrain's ndcg@5: 0.904989\tvalid's ndcg@1: 0.768923\tvalid's ndcg@2: 0.820322\tvalid's ndcg@3: 0.855472\tvalid's ndcg@4: 0.879554\tvalid's ndcg@5: 0.894783\n",
      "[100]\ttrain's ndcg@1: 0.847981\ttrain's ndcg@2: 0.876974\ttrain's ndcg@3: 0.901683\ttrain's ndcg@4: 0.918915\ttrain's ndcg@5: 0.929973\tvalid's ndcg@1: 0.80417\tvalid's ndcg@2: 0.851015\tvalid's ndcg@3: 0.882409\tvalid's ndcg@4: 0.903151\tvalid's ndcg@5: 0.914817\n",
      "[150]\ttrain's ndcg@1: 0.876429\ttrain's ndcg@2: 0.900001\ttrain's ndcg@3: 0.91995\ttrain's ndcg@4: 0.934327\ttrain's ndcg@5: 0.943202\tvalid's ndcg@1: 0.826061\tvalid's ndcg@2: 0.870028\tvalid's ndcg@3: 0.897612\tvalid's ndcg@4: 0.916096\tvalid's ndcg@5: 0.9258\n",
      "[200]\ttrain's ndcg@1: 0.897855\ttrain's ndcg@2: 0.916217\ttrain's ndcg@3: 0.93285\ttrain's ndcg@4: 0.94483\ttrain's ndcg@5: 0.952489\tvalid's ndcg@1: 0.839655\tvalid's ndcg@2: 0.882321\tvalid's ndcg@3: 0.90788\tvalid's ndcg@4: 0.924088\tvalid's ndcg@5: 0.93291\n",
      "[250]\ttrain's ndcg@1: 0.914323\ttrain's ndcg@2: 0.928515\ttrain's ndcg@3: 0.94231\ttrain's ndcg@4: 0.952738\ttrain's ndcg@5: 0.959486\tvalid's ndcg@1: 0.848589\tvalid's ndcg@2: 0.890622\tvalid's ndcg@3: 0.914664\tvalid's ndcg@4: 0.929536\tvalid's ndcg@5: 0.937822\n",
      "[300]\ttrain's ndcg@1: 0.927041\ttrain's ndcg@2: 0.938355\ttrain's ndcg@3: 0.949856\ttrain's ndcg@4: 0.95908\ttrain's ndcg@5: 0.964896\tvalid's ndcg@1: 0.858202\tvalid's ndcg@2: 0.897312\tvalid's ndcg@3: 0.920655\tvalid's ndcg@4: 0.934413\tvalid's ndcg@5: 0.941986\n",
      "[350]\ttrain's ndcg@1: 0.936906\ttrain's ndcg@2: 0.945617\ttrain's ndcg@3: 0.955478\ttrain's ndcg@4: 0.963763\ttrain's ndcg@5: 0.969027\tvalid's ndcg@1: 0.86406\tvalid's ndcg@2: 0.902019\tvalid's ndcg@3: 0.924502\tvalid's ndcg@4: 0.937709\tvalid's ndcg@5: 0.944764\n",
      "Early stopping, best iteration is:\n",
      "[388]\ttrain's ndcg@1: 0.944025\ttrain's ndcg@2: 0.950824\ttrain's ndcg@3: 0.959667\ttrain's ndcg@4: 0.9671\ttrain's ndcg@5: 0.971974\tvalid's ndcg@1: 0.86991\tvalid's ndcg@2: 0.906192\tvalid's ndcg@3: 0.928116\tvalid's ndcg@4: 0.940529\tvalid's ndcg@5: 0.947192\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[50]\ttrain's ndcg@1: 0.797703\ttrain's ndcg@2: 0.835814\ttrain's ndcg@3: 0.867801\ttrain's ndcg@4: 0.890261\ttrain's ndcg@5: 0.904766\tvalid's ndcg@1: 0.769106\tvalid's ndcg@2: 0.817925\tvalid's ndcg@3: 0.854169\tvalid's ndcg@4: 0.879207\tvalid's ndcg@5: 0.894322\n",
      "[100]\ttrain's ndcg@1: 0.847037\ttrain's ndcg@2: 0.876664\ttrain's ndcg@3: 0.901375\ttrain's ndcg@4: 0.918525\ttrain's ndcg@5: 0.929677\tvalid's ndcg@1: 0.808403\tvalid's ndcg@2: 0.852701\tvalid's ndcg@3: 0.883212\tvalid's ndcg@4: 0.904249\tvalid's ndcg@5: 0.915887\n",
      "[150]\ttrain's ndcg@1: 0.876586\ttrain's ndcg@2: 0.900037\ttrain's ndcg@3: 0.920427\ttrain's ndcg@4: 0.934305\ttrain's ndcg@5: 0.943189\tvalid's ndcg@1: 0.827863\tvalid's ndcg@2: 0.870383\tvalid's ndcg@3: 0.898166\tvalid's ndcg@4: 0.916695\tvalid's ndcg@5: 0.926386\n",
      "[200]\ttrain's ndcg@1: 0.898418\ttrain's ndcg@2: 0.917098\ttrain's ndcg@3: 0.933133\ttrain's ndcg@4: 0.945073\ttrain's ndcg@5: 0.952795\tvalid's ndcg@1: 0.841168\tvalid's ndcg@2: 0.882007\tvalid's ndcg@3: 0.908167\tvalid's ndcg@4: 0.924405\tvalid's ndcg@5: 0.933172\n",
      "[250]\ttrain's ndcg@1: 0.915581\ttrain's ndcg@2: 0.929259\ttrain's ndcg@3: 0.942767\ttrain's ndcg@4: 0.953237\ttrain's ndcg@5: 0.959856\tvalid's ndcg@1: 0.852177\tvalid's ndcg@2: 0.890422\tvalid's ndcg@3: 0.915208\tvalid's ndcg@4: 0.930374\tvalid's ndcg@5: 0.938362\n",
      "[300]\ttrain's ndcg@1: 0.928198\ttrain's ndcg@2: 0.938674\ttrain's ndcg@3: 0.949974\ttrain's ndcg@4: 0.959319\ttrain's ndcg@5: 0.965158\tvalid's ndcg@1: 0.861049\tvalid's ndcg@2: 0.897942\tvalid's ndcg@3: 0.921\tvalid's ndcg@4: 0.935002\tvalid's ndcg@5: 0.942559\n",
      "[350]\ttrain's ndcg@1: 0.938139\ttrain's ndcg@2: 0.946329\ttrain's ndcg@3: 0.955761\ttrain's ndcg@4: 0.964182\ttrain's ndcg@5: 0.969345\tvalid's ndcg@1: 0.866551\tvalid's ndcg@2: 0.902418\tvalid's ndcg@3: 0.924559\tvalid's ndcg@4: 0.938153\tvalid's ndcg@5: 0.945323\n",
      "[400]\ttrain's ndcg@1: 0.946503\ttrain's ndcg@2: 0.952615\ttrain's ndcg@3: 0.960739\ttrain's ndcg@4: 0.968244\ttrain's ndcg@5: 0.972883\tvalid's ndcg@1: 0.868942\tvalid's ndcg@2: 0.906424\tvalid's ndcg@3: 0.927575\tvalid's ndcg@4: 0.940518\tvalid's ndcg@5: 0.947207\n",
      "Early stopping, best iteration is:\n",
      "[390]\ttrain's ndcg@1: 0.944763\ttrain's ndcg@2: 0.951447\ttrain's ndcg@3: 0.959762\ttrain's ndcg@4: 0.967497\ttrain's ndcg@5: 0.972199\tvalid's ndcg@1: 0.869671\tvalid's ndcg@2: 0.90611\tvalid's ndcg@3: 0.927036\tvalid's ndcg@4: 0.940352\tvalid's ndcg@5: 0.94716\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[50]\ttrain's ndcg@1: 0.795479\ttrain's ndcg@2: 0.834053\ttrain's ndcg@3: 0.865918\ttrain's ndcg@4: 0.888945\ttrain's ndcg@5: 0.903728\tvalid's ndcg@1: 0.766517\tvalid's ndcg@2: 0.816506\tvalid's ndcg@3: 0.853219\tvalid's ndcg@4: 0.877867\tvalid's ndcg@5: 0.892924\n",
      "[100]\ttrain's ndcg@1: 0.84651\ttrain's ndcg@2: 0.876166\ttrain's ndcg@3: 0.900814\ttrain's ndcg@4: 0.91811\ttrain's ndcg@5: 0.929133\tvalid's ndcg@1: 0.80666\tvalid's ndcg@2: 0.851942\tvalid's ndcg@3: 0.882887\tvalid's ndcg@4: 0.903333\tvalid's ndcg@5: 0.915328\n",
      "[150]\ttrain's ndcg@1: 0.87704\ttrain's ndcg@2: 0.899624\ttrain's ndcg@3: 0.919697\ttrain's ndcg@4: 0.933905\ttrain's ndcg@5: 0.942905\tvalid's ndcg@1: 0.828317\tvalid's ndcg@2: 0.869678\tvalid's ndcg@3: 0.897774\tvalid's ndcg@4: 0.916294\tvalid's ndcg@5: 0.926235\n",
      "[200]\ttrain's ndcg@1: 0.898175\ttrain's ndcg@2: 0.915722\ttrain's ndcg@3: 0.932597\ttrain's ndcg@4: 0.944499\ttrain's ndcg@5: 0.952321\tvalid's ndcg@1: 0.839252\tvalid's ndcg@2: 0.881131\tvalid's ndcg@3: 0.906721\tvalid's ndcg@4: 0.923503\tvalid's ndcg@5: 0.932562\n",
      "[250]\ttrain's ndcg@1: 0.914125\ttrain's ndcg@2: 0.92771\ttrain's ndcg@3: 0.941956\ttrain's ndcg@4: 0.952538\ttrain's ndcg@5: 0.959158\tvalid's ndcg@1: 0.849371\tvalid's ndcg@2: 0.890217\tvalid's ndcg@3: 0.914235\tvalid's ndcg@4: 0.929216\tvalid's ndcg@5: 0.937636\n",
      "[300]\ttrain's ndcg@1: 0.927473\ttrain's ndcg@2: 0.937691\ttrain's ndcg@3: 0.949592\ttrain's ndcg@4: 0.958946\ttrain's ndcg@5: 0.964751\tvalid's ndcg@1: 0.856942\tvalid's ndcg@2: 0.896771\tvalid's ndcg@3: 0.919755\tvalid's ndcg@4: 0.933924\tvalid's ndcg@5: 0.941491\n",
      "[350]\ttrain's ndcg@1: 0.937978\ttrain's ndcg@2: 0.945509\ttrain's ndcg@3: 0.955703\ttrain's ndcg@4: 0.963951\ttrain's ndcg@5: 0.969218\tvalid's ndcg@1: 0.862036\tvalid's ndcg@2: 0.901475\tvalid's ndcg@3: 0.924177\tvalid's ndcg@4: 0.937246\tvalid's ndcg@5: 0.944307\n",
      "[400]\ttrain's ndcg@1: 0.946405\ttrain's ndcg@2: 0.951991\ttrain's ndcg@3: 0.960578\ttrain's ndcg@4: 0.967954\ttrain's ndcg@5: 0.972743\tvalid's ndcg@1: 0.868741\tvalid's ndcg@2: 0.90646\tvalid's ndcg@3: 0.928088\tvalid's ndcg@4: 0.940728\tvalid's ndcg@5: 0.947176\n",
      "[450]\ttrain's ndcg@1: 0.953706\ttrain's ndcg@2: 0.957531\ttrain's ndcg@3: 0.964868\ttrain's ndcg@4: 0.971438\ttrain's ndcg@5: 0.975797\tvalid's ndcg@1: 0.873264\tvalid's ndcg@2: 0.910825\tvalid's ndcg@3: 0.931081\tvalid's ndcg@4: 0.943127\tvalid's ndcg@5: 0.949461\n",
      "Early stopping, best iteration is:\n",
      "[476]\ttrain's ndcg@1: 0.956855\ttrain's ndcg@2: 0.960196\ttrain's ndcg@3: 0.966912\ttrain's ndcg@4: 0.973111\ttrain's ndcg@5: 0.977202\tvalid's ndcg@1: 0.877292\tvalid's ndcg@2: 0.912844\tvalid's ndcg@3: 0.932809\tvalid's ndcg@4: 0.94469\tvalid's ndcg@5: 0.950747\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[50]\ttrain's ndcg@1: 0.842298\ttrain's ndcg@2: 0.873852\ttrain's ndcg@3: 0.899149\ttrain's ndcg@4: 0.916802\ttrain's ndcg@5: 0.927967\tvalid's ndcg@1: 0.801993\tvalid's ndcg@2: 0.849954\tvalid's ndcg@3: 0.881777\tvalid's ndcg@4: 0.902459\tvalid's ndcg@5: 0.914093\n",
      "[100]\ttrain's ndcg@1: 0.893101\ttrain's ndcg@2: 0.913404\ttrain's ndcg@3: 0.930664\ttrain's ndcg@4: 0.942885\ttrain's ndcg@5: 0.950728\tvalid's ndcg@1: 0.83821\tvalid's ndcg@2: 0.879488\tvalid's ndcg@3: 0.906602\tvalid's ndcg@4: 0.923079\tvalid's ndcg@5: 0.931936\n",
      "[150]\ttrain's ndcg@1: 0.924233\ttrain's ndcg@2: 0.935841\ttrain's ndcg@3: 0.948317\ttrain's ndcg@4: 0.95761\ttrain's ndcg@5: 0.96365\tvalid's ndcg@1: 0.856924\tvalid's ndcg@2: 0.895094\tvalid's ndcg@3: 0.918662\tvalid's ndcg@4: 0.933547\tvalid's ndcg@5: 0.940944\n",
      "[200]\ttrain's ndcg@1: 0.944012\ttrain's ndcg@2: 0.95032\ttrain's ndcg@3: 0.959273\ttrain's ndcg@4: 0.966738\ttrain's ndcg@5: 0.971643\tvalid's ndcg@1: 0.867131\tvalid's ndcg@2: 0.904701\tvalid's ndcg@3: 0.926766\tvalid's ndcg@4: 0.939591\tvalid's ndcg@5: 0.946182\n",
      "[250]\ttrain's ndcg@1: 0.956847\ttrain's ndcg@2: 0.960307\ttrain's ndcg@3: 0.966834\ttrain's ndcg@4: 0.972964\ttrain's ndcg@5: 0.977104\tvalid's ndcg@1: 0.873808\tvalid's ndcg@2: 0.910576\tvalid's ndcg@3: 0.930975\tvalid's ndcg@4: 0.943351\tvalid's ndcg@5: 0.949628\n",
      "[300]\ttrain's ndcg@1: 0.966252\ttrain's ndcg@2: 0.967526\ttrain's ndcg@3: 0.97241\ttrain's ndcg@4: 0.977428\ttrain's ndcg@5: 0.981054\tvalid's ndcg@1: 0.880486\tvalid's ndcg@2: 0.916422\tvalid's ndcg@3: 0.935595\tvalid's ndcg@4: 0.946925\tvalid's ndcg@5: 0.952812\n",
      "Early stopping, best iteration is:\n",
      "[331]\ttrain's ndcg@1: 0.971048\ttrain's ndcg@2: 0.971061\ttrain's ndcg@3: 0.975184\ttrain's ndcg@4: 0.97969\ttrain's ndcg@5: 0.983051\tvalid's ndcg@1: 0.88475\tvalid's ndcg@2: 0.919761\tvalid's ndcg@3: 0.937928\tvalid's ndcg@4: 0.949031\tvalid's ndcg@5: 0.954534\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[50]\ttrain's ndcg@1: 0.842963\ttrain's ndcg@2: 0.873542\ttrain's ndcg@3: 0.898716\ttrain's ndcg@4: 0.916564\ttrain's ndcg@5: 0.927723\tvalid's ndcg@1: 0.803653\tvalid's ndcg@2: 0.848458\tvalid's ndcg@3: 0.88176\tvalid's ndcg@4: 0.901947\tvalid's ndcg@5: 0.914136\n",
      "[100]\ttrain's ndcg@1: 0.893944\ttrain's ndcg@2: 0.913573\ttrain's ndcg@3: 0.931117\ttrain's ndcg@4: 0.943234\ttrain's ndcg@5: 0.95104\tvalid's ndcg@1: 0.838261\tvalid's ndcg@2: 0.878793\tvalid's ndcg@3: 0.905939\tvalid's ndcg@4: 0.922851\tvalid's ndcg@5: 0.931883\n",
      "[150]\ttrain's ndcg@1: 0.924748\ttrain's ndcg@2: 0.936352\ttrain's ndcg@3: 0.948562\ttrain's ndcg@4: 0.957915\ttrain's ndcg@5: 0.963824\tvalid's ndcg@1: 0.855761\tvalid's ndcg@2: 0.893785\tvalid's ndcg@3: 0.918561\tvalid's ndcg@4: 0.932607\tvalid's ndcg@5: 0.940705\n",
      "[200]\ttrain's ndcg@1: 0.944917\ttrain's ndcg@2: 0.950801\ttrain's ndcg@3: 0.959509\ttrain's ndcg@4: 0.967233\ttrain's ndcg@5: 0.972009\tvalid's ndcg@1: 0.867633\tvalid's ndcg@2: 0.905006\tvalid's ndcg@3: 0.926667\tvalid's ndcg@4: 0.939498\tvalid's ndcg@5: 0.94651\n",
      "[250]\ttrain's ndcg@1: 0.957738\ttrain's ndcg@2: 0.961098\ttrain's ndcg@3: 0.967386\ttrain's ndcg@4: 0.973515\ttrain's ndcg@5: 0.977542\tvalid's ndcg@1: 0.876851\tvalid's ndcg@2: 0.912207\tvalid's ndcg@3: 0.932487\tvalid's ndcg@4: 0.944256\tvalid's ndcg@5: 0.950592\n",
      "Early stopping, best iteration is:\n",
      "[274]\ttrain's ndcg@1: 0.963044\ttrain's ndcg@2: 0.964768\ttrain's ndcg@3: 0.97037\ttrain's ndcg@4: 0.97594\ttrain's ndcg@5: 0.979668\tvalid's ndcg@1: 0.88011\tvalid's ndcg@2: 0.914171\tvalid's ndcg@3: 0.934352\tvalid's ndcg@4: 0.945848\tvalid's ndcg@5: 0.951896\n",
      "Training until validation scores don't improve for 10 rounds\n",
      "[50]\ttrain's ndcg@1: 0.840882\ttrain's ndcg@2: 0.871912\ttrain's ndcg@3: 0.897715\ttrain's ndcg@4: 0.915545\ttrain's ndcg@5: 0.926837\tvalid's ndcg@1: 0.803761\tvalid's ndcg@2: 0.849961\tvalid's ndcg@3: 0.880942\tvalid's ndcg@4: 0.901466\tvalid's ndcg@5: 0.913962\n",
      "[100]\ttrain's ndcg@1: 0.894115\ttrain's ndcg@2: 0.913125\ttrain's ndcg@3: 0.9304\ttrain's ndcg@4: 0.94277\ttrain's ndcg@5: 0.950689\tvalid's ndcg@1: 0.840589\tvalid's ndcg@2: 0.88067\tvalid's ndcg@3: 0.90668\tvalid's ndcg@4: 0.923342\tvalid's ndcg@5: 0.932468\n",
      "[150]\ttrain's ndcg@1: 0.923614\ttrain's ndcg@2: 0.935145\ttrain's ndcg@3: 0.947529\ttrain's ndcg@4: 0.957107\ttrain's ndcg@5: 0.963181\tvalid's ndcg@1: 0.857433\tvalid's ndcg@2: 0.895646\tvalid's ndcg@3: 0.919621\tvalid's ndcg@4: 0.933613\tvalid's ndcg@5: 0.941226\n",
      "[200]\ttrain's ndcg@1: 0.944077\ttrain's ndcg@2: 0.950116\ttrain's ndcg@3: 0.959019\ttrain's ndcg@4: 0.966685\ttrain's ndcg@5: 0.971595\tvalid's ndcg@1: 0.868668\tvalid's ndcg@2: 0.905348\tvalid's ndcg@3: 0.927387\tvalid's ndcg@4: 0.939775\tvalid's ndcg@5: 0.946619\n",
      "[250]\ttrain's ndcg@1: 0.957369\ttrain's ndcg@2: 0.960555\ttrain's ndcg@3: 0.966729\ttrain's ndcg@4: 0.97303\ttrain's ndcg@5: 0.977183\tvalid's ndcg@1: 0.87668\tvalid's ndcg@2: 0.912706\tvalid's ndcg@3: 0.932387\tvalid's ndcg@4: 0.94414\tvalid's ndcg@5: 0.950697\n",
      "Early stopping, best iteration is:\n",
      "[256]\ttrain's ndcg@1: 0.958889\ttrain's ndcg@2: 0.961548\ttrain's ndcg@3: 0.96756\ttrain's ndcg@4: 0.973716\ttrain's ndcg@5: 0.977765\tvalid's ndcg@1: 0.879097\tvalid's ndcg@2: 0.913543\tvalid's ndcg@3: 0.933446\tvalid's ndcg@4: 0.944964\tvalid's ndcg@5: 0.95136\n",
      "Best params: {'objective': 'lambdarank', 'metric': 'ndcg', 'boosting_type': 'gbdt', 'num_leaves': 15, 'learning_rate': 0.1, 'feature_fraction': 1.0, 'verbosity': -1} Best score: 0.9613571245358653\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import lightgbm as lgb\n",
    "\n",
    "param_grid = {\n",
    "    \"num_leaves\": [15, 31, 63],\n",
    "    \"learning_rate\": [0.01, 0.05, 0.1],\n",
    "    \"feature_fraction\": [0.8, 0.9, 1.0]\n",
    "}\n",
    "\n",
    "best_score = float(\"-inf\")\n",
    "best_params = None\n",
    "\n",
    "for num_leaves, lr, feat_frac in itertools.product(\n",
    "    param_grid[\"num_leaves\"],\n",
    "    param_grid[\"learning_rate\"],\n",
    "    param_grid[\"feature_fraction\"]\n",
    "):\n",
    "    params = {\n",
    "        \"objective\": \"lambdarank\",\n",
    "        \"metric\": \"ndcg\",             # LightGBM may produce ndcg@1, ndcg@2, etc.\n",
    "        \"boosting_type\": \"gbdt\",\n",
    "        \"num_leaves\": num_leaves,\n",
    "        \"learning_rate\": lr,\n",
    "        \"feature_fraction\": feat_frac,\n",
    "        \"verbosity\": -1\n",
    "    }\n",
    "    \n",
    "    # Provide names for data sets so best_score keys become [\"train\", \"valid\"]\n",
    "    gbm = lgb.train(\n",
    "        params,\n",
    "        train_dataset,\n",
    "        num_boost_round=500,\n",
    "        valid_sets=[train_dataset, valid_dataset],\n",
    "        valid_names=[\"train\", \"valid\"],\n",
    "        callbacks=[\n",
    "            lgb.early_stopping(stopping_rounds=10),\n",
    "            lgb.log_evaluation(period=50)\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # Depending on your metric, LightGBM might store something like \"ndcg@1\", \"ndcg@5\", etc.\n",
    "    # If you only specified \"ndcg\", typically it logs multiple sub-metrics like ndcg@1..5.\n",
    "    # You can pick whichever sub-metric you want. For example, \"ndcg@5\" might be:\n",
    "    #   gbm.best_score[\"valid\"][\"ndcg@5\"]\n",
    "    # If you prefer \"ndcg@1\", use that key. Below is an example with ndcg@5:\n",
    "    if \"ndcg@5\" in gbm.best_score[\"valid\"]:\n",
    "        score = gbm.best_score[\"valid\"][\"ndcg@5\"]\n",
    "    else:\n",
    "        # fallback: if only \"ndcg@1\" or plain \"ndcg\" is stored\n",
    "        # you can check what's available in gbm.best_score[\"valid\"].keys()\n",
    "        # For example, if \"ndcg\" is directly there:\n",
    "        score = gbm.best_score[\"valid\"].get(\"ndcg\", float(\"-inf\"))\n",
    "\n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_params = params\n",
    "\n",
    "print(\"Best params:\", best_params, \"Best score:\", best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a3d0fc-4415-46cc-865b-8fb8612a5b3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "33c3507f-0bfd-46de-b4d0-fdb9b97e6d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"objective\": \"lambdarank\",\n",
    "    \"metric\": \"ndcg\",          # or \"map\"\n",
    "    \"boosting_type\": \"gbdt\",\n",
    "    \"num_leaves\": 15,\n",
    "    \"learning_rate\": 0.1,\n",
    "    \"feature_fraction\": 1.0,\n",
    "    \"verbosity\": -1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4458b83b-2d04-4329-8e31-dea33b1f638b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 10 rounds\n",
      "[50]\ttrain's ndcg@1: 0.801959\ttrain's ndcg@2: 0.84476\ttrain's ndcg@3: 0.876481\ttrain's ndcg@4: 0.898197\ttrain's ndcg@5: 0.911388\tvalid's ndcg@1: 0.792236\tvalid's ndcg@2: 0.837077\tvalid's ndcg@3: 0.871485\tvalid's ndcg@4: 0.894696\tvalid's ndcg@5: 0.907307\n",
      "[100]\ttrain's ndcg@1: 0.843524\ttrain's ndcg@2: 0.879268\ttrain's ndcg@3: 0.905473\ttrain's ndcg@4: 0.922056\ttrain's ndcg@5: 0.932016\tvalid's ndcg@1: 0.826233\tvalid's ndcg@2: 0.869467\tvalid's ndcg@3: 0.898063\tvalid's ndcg@4: 0.916201\tvalid's ndcg@5: 0.92632\n",
      "[150]\ttrain's ndcg@1: 0.866546\ttrain's ndcg@2: 0.89795\ttrain's ndcg@3: 0.920573\ttrain's ndcg@4: 0.934542\ttrain's ndcg@5: 0.94291\tvalid's ndcg@1: 0.843919\tvalid's ndcg@2: 0.885634\tvalid's ndcg@3: 0.910813\tvalid's ndcg@4: 0.926866\tvalid's ndcg@5: 0.935598\n",
      "[200]\ttrain's ndcg@1: 0.883839\ttrain's ndcg@2: 0.911064\ttrain's ndcg@3: 0.931122\ttrain's ndcg@4: 0.943539\ttrain's ndcg@5: 0.950531\tvalid's ndcg@1: 0.859349\tvalid's ndcg@2: 0.897592\tvalid's ndcg@3: 0.921217\tvalid's ndcg@4: 0.935303\tvalid's ndcg@5: 0.942646\n",
      "[250]\ttrain's ndcg@1: 0.897971\ttrain's ndcg@2: 0.922105\ttrain's ndcg@3: 0.939463\ttrain's ndcg@4: 0.950555\ttrain's ndcg@5: 0.956637\tvalid's ndcg@1: 0.868759\tvalid's ndcg@2: 0.906639\tvalid's ndcg@3: 0.928336\tvalid's ndcg@4: 0.940895\tvalid's ndcg@5: 0.9476\n",
      "[300]\ttrain's ndcg@1: 0.90925\ttrain's ndcg@2: 0.930577\ttrain's ndcg@3: 0.945869\ttrain's ndcg@4: 0.955899\ttrain's ndcg@5: 0.961329\tvalid's ndcg@1: 0.877856\tvalid's ndcg@2: 0.914006\tvalid's ndcg@3: 0.933939\tvalid's ndcg@4: 0.945525\tvalid's ndcg@5: 0.95166\n",
      "[350]\ttrain's ndcg@1: 0.920037\ttrain's ndcg@2: 0.938053\ttrain's ndcg@3: 0.951669\ttrain's ndcg@4: 0.960799\ttrain's ndcg@5: 0.965576\tvalid's ndcg@1: 0.884074\tvalid's ndcg@2: 0.91983\tvalid's ndcg@3: 0.937978\tvalid's ndcg@4: 0.949078\tvalid's ndcg@5: 0.954613\n",
      "[400]\ttrain's ndcg@1: 0.927926\ttrain's ndcg@2: 0.943668\ttrain's ndcg@3: 0.956159\ttrain's ndcg@4: 0.964355\ttrain's ndcg@5: 0.968672\tvalid's ndcg@1: 0.890433\tvalid's ndcg@2: 0.924441\tvalid's ndcg@3: 0.942072\tvalid's ndcg@4: 0.952196\tvalid's ndcg@5: 0.957316\n",
      "[450]\ttrain's ndcg@1: 0.935412\ttrain's ndcg@2: 0.948899\ttrain's ndcg@3: 0.960092\ttrain's ndcg@4: 0.967628\ttrain's ndcg@5: 0.971617\tvalid's ndcg@1: 0.895437\tvalid's ndcg@2: 0.929056\tvalid's ndcg@3: 0.94512\tvalid's ndcg@4: 0.954791\tvalid's ndcg@5: 0.959619\n",
      "[500]\ttrain's ndcg@1: 0.941113\ttrain's ndcg@2: 0.952911\ttrain's ndcg@3: 0.963172\ttrain's ndcg@4: 0.970076\ttrain's ndcg@5: 0.973862\tvalid's ndcg@1: 0.899809\tvalid's ndcg@2: 0.931654\tvalid's ndcg@3: 0.94764\tvalid's ndcg@4: 0.956817\tvalid's ndcg@5: 0.961326\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[496]\ttrain's ndcg@1: 0.940768\ttrain's ndcg@2: 0.952656\ttrain's ndcg@3: 0.963011\ttrain's ndcg@4: 0.969929\ttrain's ndcg@5: 0.973722\tvalid's ndcg@1: 0.899958\tvalid's ndcg@2: 0.931755\tvalid's ndcg@3: 0.947661\tvalid's ndcg@4: 0.956845\tvalid's ndcg@5: 0.961357\n",
      "Best iteration: 496\n"
     ]
    }
   ],
   "source": [
    "# We’ll do early stopping to watch the valid set\n",
    "gbm = lgb.train(\n",
    "    params,\n",
    "    train_dataset,\n",
    "    num_boost_round=500,\n",
    "    valid_sets=[train_dataset, valid_dataset],\n",
    "    valid_names=[\"train\", \"valid\"],\n",
    "    # remove early_stopping_rounds=..., \n",
    "    # and instead specify callbacks:\n",
    "    callbacks=[\n",
    "        lgb.early_stopping(stopping_rounds=10),    # early stopping\n",
    "        lgb.log_evaluation(period=50)              # optional: log every 50 iters\n",
    "    ]\n",
    ")\n",
    "print(\"Best iteration:\", gbm.best_iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f75e1b-4e59-408d-bceb-f58fe83bc345",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cde1550c-ebc4-47e6-915c-c1d98f1b6ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = gbm.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a50685d1-987b-4cae-b59a-25d0fb8e52d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ -4.99662379 -12.48886799 -10.62581736 ...  -7.0348425   -7.35584338\n",
      "  -3.12386357]\n"
     ]
    }
   ],
   "source": [
    "print(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fadd9aa3-b4ea-4e05-bb57-79ff831c0247",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning with Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3e79f589-a9f9-45f7-9243-77a5649ddb10",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 12:51:31,804] A new study created in memory with name: no-name-9310f913-b529-4d97-94f2-42a4c9fb5cf3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttrain's ndcg@5: 0.899533\tvalid's ndcg@5: 0.888374\n",
      "[200]\ttrain's ndcg@5: 0.924693\tvalid's ndcg@5: 0.910423\n",
      "[300]\ttrain's ndcg@5: 0.938001\tvalid's ndcg@5: 0.921365\n",
      "[400]\ttrain's ndcg@5: 0.947407\tvalid's ndcg@5: 0.928678\n",
      "[500]\ttrain's ndcg@5: 0.95436\tvalid's ndcg@5: 0.934095\n",
      "[600]\ttrain's ndcg@5: 0.959561\tvalid's ndcg@5: 0.938355\n",
      "[700]\ttrain's ndcg@5: 0.964063\tvalid's ndcg@5: 0.941809\n",
      "[800]\ttrain's ndcg@5: 0.967641\tvalid's ndcg@5: 0.944864\n",
      "[900]\ttrain's ndcg@5: 0.970565\tvalid's ndcg@5: 0.947303\n",
      "[1000]\ttrain's ndcg@5: 0.973315\tvalid's ndcg@5: 0.949862\n",
      "[1100]\ttrain's ndcg@5: 0.975475\tvalid's ndcg@5: 0.951415\n",
      "[1200]\ttrain's ndcg@5: 0.977247\tvalid's ndcg@5: 0.952826\n",
      "[1300]\ttrain's ndcg@5: 0.978909\tvalid's ndcg@5: 0.954544\n",
      "[1400]\ttrain's ndcg@5: 0.980267\tvalid's ndcg@5: 0.956029\n",
      "[1500]\ttrain's ndcg@5: 0.981473\tvalid's ndcg@5: 0.956978\n",
      "[1600]\ttrain's ndcg@5: 0.982542\tvalid's ndcg@5: 0.958026\n",
      "[1700]\ttrain's ndcg@5: 0.983517\tvalid's ndcg@5: 0.958708\n",
      "[1800]\ttrain's ndcg@5: 0.984411\tvalid's ndcg@5: 0.95942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 12:52:05,128] Trial 0 finished with value: -0.9597764941584922 and parameters: {'num_leaves': 62, 'learning_rate': 0.024274663366726477, 'feature_fraction': 0.8785838964063862, 'min_data_in_leaf': 116, 'lambda_l1': 3.569720178350061, 'lambda_l2': 1.2086477773291886}. Best is trial 0 with value: -0.9597764941584922.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1847]\ttrain's ndcg@5: 0.984665\tvalid's ndcg@5: 0.959776\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttrain's ndcg@5: 0.926265\tvalid's ndcg@5: 0.919289\n",
      "[200]\ttrain's ndcg@5: 0.947194\tvalid's ndcg@5: 0.936498\n",
      "[300]\ttrain's ndcg@5: 0.958772\tvalid's ndcg@5: 0.945793\n",
      "[400]\ttrain's ndcg@5: 0.966521\tvalid's ndcg@5: 0.952659\n",
      "[500]\ttrain's ndcg@5: 0.971713\tvalid's ndcg@5: 0.956884\n",
      "[600]\ttrain's ndcg@5: 0.97558\tvalid's ndcg@5: 0.959779\n",
      "[700]\ttrain's ndcg@5: 0.978642\tvalid's ndcg@5: 0.96176\n",
      "[800]\ttrain's ndcg@5: 0.980781\tvalid's ndcg@5: 0.963802\n",
      "[900]\ttrain's ndcg@5: 0.982695\tvalid's ndcg@5: 0.965205\n",
      "[1000]\ttrain's ndcg@5: 0.984298\tvalid's ndcg@5: 0.966296\n",
      "[1100]\ttrain's ndcg@5: 0.985587\tvalid's ndcg@5: 0.96696\n",
      "[1200]\ttrain's ndcg@5: 0.986559\tvalid's ndcg@5: 0.968043\n",
      "[1300]\ttrain's ndcg@5: 0.987498\tvalid's ndcg@5: 0.968621\n",
      "[1400]\ttrain's ndcg@5: 0.988293\tvalid's ndcg@5: 0.969181\n",
      "[1500]\ttrain's ndcg@5: 0.989006\tvalid's ndcg@5: 0.969625\n",
      "[1600]\ttrain's ndcg@5: 0.989564\tvalid's ndcg@5: 0.970247\n",
      "[1700]\ttrain's ndcg@5: 0.990046\tvalid's ndcg@5: 0.970654\n",
      "[1800]\ttrain's ndcg@5: 0.990477\tvalid's ndcg@5: 0.97096\n",
      "[1900]\ttrain's ndcg@5: 0.990799\tvalid's ndcg@5: 0.971318\n",
      "[2000]\ttrain's ndcg@5: 0.991201\tvalid's ndcg@5: 0.971578\n",
      "[2100]\ttrain's ndcg@5: 0.991547\tvalid's ndcg@5: 0.971923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 12:52:25,634] Trial 1 finished with value: -0.9720949631115816 and parameters: {'num_leaves': 27, 'learning_rate': 0.07045532370102482, 'feature_fraction': 0.7498279715103052, 'min_data_in_leaf': 125, 'lambda_l1': 3.432599910066916, 'lambda_l2': 0.7299505199439726}. Best is trial 0 with value: -0.9597764941584922.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[2118]\ttrain's ndcg@5: 0.991586\tvalid's ndcg@5: 0.972095\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttrain's ndcg@5: 0.851989\tvalid's ndcg@5: 0.850539\n",
      "[200]\ttrain's ndcg@5: 0.858569\tvalid's ndcg@5: 0.85532\n",
      "[300]\ttrain's ndcg@5: 0.86414\tvalid's ndcg@5: 0.860158\n",
      "[400]\ttrain's ndcg@5: 0.868772\tvalid's ndcg@5: 0.864907\n",
      "[500]\ttrain's ndcg@5: 0.872835\tvalid's ndcg@5: 0.868446\n",
      "[600]\ttrain's ndcg@5: 0.877196\tvalid's ndcg@5: 0.871984\n",
      "[700]\ttrain's ndcg@5: 0.88118\tvalid's ndcg@5: 0.875343\n",
      "[800]\ttrain's ndcg@5: 0.885064\tvalid's ndcg@5: 0.87922\n",
      "[900]\ttrain's ndcg@5: 0.888755\tvalid's ndcg@5: 0.882567\n",
      "[1000]\ttrain's ndcg@5: 0.892302\tvalid's ndcg@5: 0.885493\n",
      "[1100]\ttrain's ndcg@5: 0.895612\tvalid's ndcg@5: 0.888116\n",
      "[1200]\ttrain's ndcg@5: 0.898564\tvalid's ndcg@5: 0.890685\n",
      "[1300]\ttrain's ndcg@5: 0.90148\tvalid's ndcg@5: 0.893414\n",
      "[1400]\ttrain's ndcg@5: 0.904157\tvalid's ndcg@5: 0.895931\n",
      "[1500]\ttrain's ndcg@5: 0.906566\tvalid's ndcg@5: 0.898301\n",
      "[1600]\ttrain's ndcg@5: 0.90871\tvalid's ndcg@5: 0.900158\n",
      "[1700]\ttrain's ndcg@5: 0.910715\tvalid's ndcg@5: 0.902132\n",
      "[1800]\ttrain's ndcg@5: 0.912937\tvalid's ndcg@5: 0.903958\n",
      "[1900]\ttrain's ndcg@5: 0.91475\tvalid's ndcg@5: 0.905633\n",
      "[2000]\ttrain's ndcg@5: 0.916381\tvalid's ndcg@5: 0.907159\n",
      "[2100]\ttrain's ndcg@5: 0.91801\tvalid's ndcg@5: 0.908428\n",
      "[2200]\ttrain's ndcg@5: 0.919635\tvalid's ndcg@5: 0.909961\n",
      "[2300]\ttrain's ndcg@5: 0.92124\tvalid's ndcg@5: 0.911239\n",
      "[2400]\ttrain's ndcg@5: 0.922778\tvalid's ndcg@5: 0.912576\n",
      "[2500]\ttrain's ndcg@5: 0.9241\tvalid's ndcg@5: 0.913758\n",
      "[2600]\ttrain's ndcg@5: 0.925378\tvalid's ndcg@5: 0.914897\n",
      "[2700]\ttrain's ndcg@5: 0.926523\tvalid's ndcg@5: 0.915892\n",
      "[2800]\ttrain's ndcg@5: 0.927674\tvalid's ndcg@5: 0.917033\n",
      "[2900]\ttrain's ndcg@5: 0.92879\tvalid's ndcg@5: 0.918141\n",
      "[3000]\ttrain's ndcg@5: 0.929862\tvalid's ndcg@5: 0.91903\n",
      "[3100]\ttrain's ndcg@5: 0.930771\tvalid's ndcg@5: 0.919561\n",
      "[3200]\ttrain's ndcg@5: 0.931847\tvalid's ndcg@5: 0.920477\n",
      "[3300]\ttrain's ndcg@5: 0.932734\tvalid's ndcg@5: 0.921308\n",
      "[3400]\ttrain's ndcg@5: 0.933619\tvalid's ndcg@5: 0.921943\n",
      "[3500]\ttrain's ndcg@5: 0.934503\tvalid's ndcg@5: 0.922732\n",
      "[3600]\ttrain's ndcg@5: 0.935527\tvalid's ndcg@5: 0.923519\n",
      "[3700]\ttrain's ndcg@5: 0.936403\tvalid's ndcg@5: 0.924309\n",
      "[3800]\ttrain's ndcg@5: 0.937288\tvalid's ndcg@5: 0.924923\n",
      "[3900]\ttrain's ndcg@5: 0.938024\tvalid's ndcg@5: 0.925509\n",
      "[4000]\ttrain's ndcg@5: 0.938874\tvalid's ndcg@5: 0.926315\n",
      "[4100]\ttrain's ndcg@5: 0.939609\tvalid's ndcg@5: 0.927121\n",
      "[4200]\ttrain's ndcg@5: 0.94035\tvalid's ndcg@5: 0.927832\n",
      "[4300]\ttrain's ndcg@5: 0.941076\tvalid's ndcg@5: 0.928262\n",
      "[4400]\ttrain's ndcg@5: 0.941785\tvalid's ndcg@5: 0.928941\n",
      "[4500]\ttrain's ndcg@5: 0.942471\tvalid's ndcg@5: 0.929566\n",
      "[4600]\ttrain's ndcg@5: 0.94315\tvalid's ndcg@5: 0.930008\n",
      "[4700]\ttrain's ndcg@5: 0.94378\tvalid's ndcg@5: 0.93054\n",
      "[4800]\ttrain's ndcg@5: 0.94446\tvalid's ndcg@5: 0.931147\n",
      "[4900]\ttrain's ndcg@5: 0.945082\tvalid's ndcg@5: 0.931529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 12:53:29,088] Trial 2 finished with value: -0.9319720619246685 and parameters: {'num_leaves': 39, 'learning_rate': 0.002151994350416267, 'feature_fraction': 0.7913939283425091, 'min_data_in_leaf': 139, 'lambda_l1': 1.0267290982007675, 'lambda_l2': 3.2873309504060897}. Best is trial 2 with value: -0.9319720619246685.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5000]\ttrain's ndcg@5: 0.945686\tvalid's ndcg@5: 0.931943\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[4996]\ttrain's ndcg@5: 0.945639\tvalid's ndcg@5: 0.931972\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttrain's ndcg@5: 0.878098\tvalid's ndcg@5: 0.873545\n",
      "[200]\ttrain's ndcg@5: 0.902729\tvalid's ndcg@5: 0.897667\n",
      "[300]\ttrain's ndcg@5: 0.916409\tvalid's ndcg@5: 0.910331\n",
      "[400]\ttrain's ndcg@5: 0.925325\tvalid's ndcg@5: 0.918829\n",
      "[500]\ttrain's ndcg@5: 0.931858\tvalid's ndcg@5: 0.924542\n",
      "[600]\ttrain's ndcg@5: 0.937253\tvalid's ndcg@5: 0.92887\n",
      "[700]\ttrain's ndcg@5: 0.941621\tvalid's ndcg@5: 0.932487\n",
      "[800]\ttrain's ndcg@5: 0.945362\tvalid's ndcg@5: 0.935604\n",
      "[900]\ttrain's ndcg@5: 0.948655\tvalid's ndcg@5: 0.938588\n",
      "[1000]\ttrain's ndcg@5: 0.951652\tvalid's ndcg@5: 0.940711\n",
      "[1100]\ttrain's ndcg@5: 0.954225\tvalid's ndcg@5: 0.942943\n",
      "[1200]\ttrain's ndcg@5: 0.956681\tvalid's ndcg@5: 0.944944\n",
      "[1300]\ttrain's ndcg@5: 0.958905\tvalid's ndcg@5: 0.946482\n",
      "[1400]\ttrain's ndcg@5: 0.960872\tvalid's ndcg@5: 0.948148\n",
      "[1500]\ttrain's ndcg@5: 0.962629\tvalid's ndcg@5: 0.949855\n",
      "[1600]\ttrain's ndcg@5: 0.964283\tvalid's ndcg@5: 0.951407\n",
      "[1700]\ttrain's ndcg@5: 0.965847\tvalid's ndcg@5: 0.953045\n",
      "[1800]\ttrain's ndcg@5: 0.967208\tvalid's ndcg@5: 0.95437\n",
      "[1900]\ttrain's ndcg@5: 0.968525\tvalid's ndcg@5: 0.955272\n",
      "[2000]\ttrain's ndcg@5: 0.969712\tvalid's ndcg@5: 0.956403\n",
      "[2100]\ttrain's ndcg@5: 0.970825\tvalid's ndcg@5: 0.957266\n",
      "[2200]\ttrain's ndcg@5: 0.971817\tvalid's ndcg@5: 0.957977\n",
      "[2300]\ttrain's ndcg@5: 0.972738\tvalid's ndcg@5: 0.958687\n",
      "[2400]\ttrain's ndcg@5: 0.973585\tvalid's ndcg@5: 0.959531\n",
      "[2500]\ttrain's ndcg@5: 0.974632\tvalid's ndcg@5: 0.96013\n",
      "[2600]\ttrain's ndcg@5: 0.975414\tvalid's ndcg@5: 0.960869\n",
      "[2700]\ttrain's ndcg@5: 0.976202\tvalid's ndcg@5: 0.961157\n",
      "[2800]\ttrain's ndcg@5: 0.976824\tvalid's ndcg@5: 0.961799\n",
      "[2900]\ttrain's ndcg@5: 0.977482\tvalid's ndcg@5: 0.962048\n",
      "[3000]\ttrain's ndcg@5: 0.97796\tvalid's ndcg@5: 0.962604\n",
      "[3100]\ttrain's ndcg@5: 0.97845\tvalid's ndcg@5: 0.96307\n",
      "[3200]\ttrain's ndcg@5: 0.979008\tvalid's ndcg@5: 0.963597\n",
      "[3300]\ttrain's ndcg@5: 0.979556\tvalid's ndcg@5: 0.964044\n",
      "[3400]\ttrain's ndcg@5: 0.980027\tvalid's ndcg@5: 0.964499\n",
      "[3500]\ttrain's ndcg@5: 0.980561\tvalid's ndcg@5: 0.964904\n",
      "[3600]\ttrain's ndcg@5: 0.981135\tvalid's ndcg@5: 0.965097\n",
      "[3700]\ttrain's ndcg@5: 0.98164\tvalid's ndcg@5: 0.96548\n",
      "[3800]\ttrain's ndcg@5: 0.982093\tvalid's ndcg@5: 0.96582\n",
      "[3900]\ttrain's ndcg@5: 0.982446\tvalid's ndcg@5: 0.966187\n",
      "[4000]\ttrain's ndcg@5: 0.982817\tvalid's ndcg@5: 0.966493\n",
      "[4100]\ttrain's ndcg@5: 0.983104\tvalid's ndcg@5: 0.966851\n",
      "[4200]\ttrain's ndcg@5: 0.983404\tvalid's ndcg@5: 0.967135\n",
      "[4300]\ttrain's ndcg@5: 0.983709\tvalid's ndcg@5: 0.967368\n",
      "[4400]\ttrain's ndcg@5: 0.984048\tvalid's ndcg@5: 0.967724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 12:54:08,435] Trial 3 finished with value: -0.967913209601446 and parameters: {'num_leaves': 24, 'learning_rate': 0.016752675675819534, 'feature_fraction': 0.921272427541896, 'min_data_in_leaf': 132, 'lambda_l1': 3.8807014740045753, 'lambda_l2': 0.45792095648876485}. Best is trial 2 with value: -0.9319720619246685.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4500]\ttrain's ndcg@5: 0.984331\tvalid's ndcg@5: 0.967849\n",
      "Early stopping, best iteration is:\n",
      "[4455]\ttrain's ndcg@5: 0.984235\tvalid's ndcg@5: 0.967913\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttrain's ndcg@5: 0.84204\tvalid's ndcg@5: 0.840311\n",
      "[200]\ttrain's ndcg@5: 0.855138\tvalid's ndcg@5: 0.853058\n",
      "[300]\ttrain's ndcg@5: 0.867783\tvalid's ndcg@5: 0.864738\n",
      "[400]\ttrain's ndcg@5: 0.877976\tvalid's ndcg@5: 0.874611\n",
      "[500]\ttrain's ndcg@5: 0.886412\tvalid's ndcg@5: 0.88247\n",
      "[600]\ttrain's ndcg@5: 0.893017\tvalid's ndcg@5: 0.888749\n",
      "[700]\ttrain's ndcg@5: 0.898605\tvalid's ndcg@5: 0.894296\n",
      "[800]\ttrain's ndcg@5: 0.903117\tvalid's ndcg@5: 0.898484\n",
      "[900]\ttrain's ndcg@5: 0.906955\tvalid's ndcg@5: 0.902265\n",
      "[1000]\ttrain's ndcg@5: 0.910548\tvalid's ndcg@5: 0.90544\n",
      "[1100]\ttrain's ndcg@5: 0.913884\tvalid's ndcg@5: 0.908504\n",
      "[1200]\ttrain's ndcg@5: 0.916526\tvalid's ndcg@5: 0.911206\n",
      "[1300]\ttrain's ndcg@5: 0.919008\tvalid's ndcg@5: 0.913314\n",
      "[1400]\ttrain's ndcg@5: 0.921195\tvalid's ndcg@5: 0.915318\n",
      "[1500]\ttrain's ndcg@5: 0.923297\tvalid's ndcg@5: 0.917383\n",
      "[1600]\ttrain's ndcg@5: 0.925236\tvalid's ndcg@5: 0.919281\n",
      "[1700]\ttrain's ndcg@5: 0.926901\tvalid's ndcg@5: 0.920944\n",
      "[1800]\ttrain's ndcg@5: 0.928698\tvalid's ndcg@5: 0.922443\n",
      "[1900]\ttrain's ndcg@5: 0.930274\tvalid's ndcg@5: 0.924174\n",
      "[2000]\ttrain's ndcg@5: 0.931791\tvalid's ndcg@5: 0.925176\n",
      "[2100]\ttrain's ndcg@5: 0.933115\tvalid's ndcg@5: 0.926359\n",
      "[2200]\ttrain's ndcg@5: 0.934396\tvalid's ndcg@5: 0.927494\n",
      "[2300]\ttrain's ndcg@5: 0.935713\tvalid's ndcg@5: 0.928665\n",
      "[2400]\ttrain's ndcg@5: 0.936852\tvalid's ndcg@5: 0.929505\n",
      "[2500]\ttrain's ndcg@5: 0.937989\tvalid's ndcg@5: 0.930373\n",
      "[2600]\ttrain's ndcg@5: 0.939085\tvalid's ndcg@5: 0.9313\n",
      "[2700]\ttrain's ndcg@5: 0.940101\tvalid's ndcg@5: 0.932148\n",
      "[2800]\ttrain's ndcg@5: 0.94106\tvalid's ndcg@5: 0.932976\n",
      "[2900]\ttrain's ndcg@5: 0.942075\tvalid's ndcg@5: 0.933892\n",
      "[3000]\ttrain's ndcg@5: 0.942987\tvalid's ndcg@5: 0.93463\n",
      "[3100]\ttrain's ndcg@5: 0.943887\tvalid's ndcg@5: 0.935487\n",
      "[3200]\ttrain's ndcg@5: 0.944823\tvalid's ndcg@5: 0.936236\n",
      "[3300]\ttrain's ndcg@5: 0.945589\tvalid's ndcg@5: 0.936866\n",
      "[3400]\ttrain's ndcg@5: 0.946331\tvalid's ndcg@5: 0.937532\n",
      "[3500]\ttrain's ndcg@5: 0.947131\tvalid's ndcg@5: 0.938188\n",
      "[3600]\ttrain's ndcg@5: 0.947904\tvalid's ndcg@5: 0.938793\n",
      "[3700]\ttrain's ndcg@5: 0.948607\tvalid's ndcg@5: 0.939517\n",
      "[3800]\ttrain's ndcg@5: 0.949328\tvalid's ndcg@5: 0.939887\n",
      "[3900]\ttrain's ndcg@5: 0.949942\tvalid's ndcg@5: 0.94034\n",
      "[4000]\ttrain's ndcg@5: 0.950652\tvalid's ndcg@5: 0.940986\n",
      "[4100]\ttrain's ndcg@5: 0.951356\tvalid's ndcg@5: 0.941514\n",
      "[4200]\ttrain's ndcg@5: 0.951915\tvalid's ndcg@5: 0.942124\n",
      "[4300]\ttrain's ndcg@5: 0.952551\tvalid's ndcg@5: 0.942677\n",
      "[4400]\ttrain's ndcg@5: 0.95316\tvalid's ndcg@5: 0.943368\n",
      "[4500]\ttrain's ndcg@5: 0.953775\tvalid's ndcg@5: 0.943988\n",
      "[4600]\ttrain's ndcg@5: 0.954304\tvalid's ndcg@5: 0.94434\n",
      "[4700]\ttrain's ndcg@5: 0.954872\tvalid's ndcg@5: 0.944883\n",
      "[4800]\ttrain's ndcg@5: 0.955437\tvalid's ndcg@5: 0.945131\n",
      "[4900]\ttrain's ndcg@5: 0.956027\tvalid's ndcg@5: 0.945589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 12:54:49,766] Trial 4 finished with value: -0.9458859090208002 and parameters: {'num_leaves': 21, 'learning_rate': 0.004323754185548125, 'feature_fraction': 0.989000613317518, 'min_data_in_leaf': 10, 'lambda_l1': 4.673654505244503, 'lambda_l2': 3.447108912098789}. Best is trial 2 with value: -0.9319720619246685.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5000]\ttrain's ndcg@5: 0.956449\tvalid's ndcg@5: 0.945886\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[5000]\ttrain's ndcg@5: 0.956449\tvalid's ndcg@5: 0.945886\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttrain's ndcg@5: 0.848239\tvalid's ndcg@5: 0.846371\n",
      "[200]\ttrain's ndcg@5: 0.85715\tvalid's ndcg@5: 0.855892\n",
      "[300]\ttrain's ndcg@5: 0.866507\tvalid's ndcg@5: 0.86387\n",
      "[400]\ttrain's ndcg@5: 0.875548\tvalid's ndcg@5: 0.872014\n",
      "[500]\ttrain's ndcg@5: 0.882975\tvalid's ndcg@5: 0.87904\n",
      "[600]\ttrain's ndcg@5: 0.889404\tvalid's ndcg@5: 0.885405\n",
      "[700]\ttrain's ndcg@5: 0.894681\tvalid's ndcg@5: 0.890808\n",
      "[800]\ttrain's ndcg@5: 0.899369\tvalid's ndcg@5: 0.895533\n",
      "[900]\ttrain's ndcg@5: 0.903158\tvalid's ndcg@5: 0.899146\n",
      "[1000]\ttrain's ndcg@5: 0.906534\tvalid's ndcg@5: 0.902454\n",
      "[1100]\ttrain's ndcg@5: 0.909622\tvalid's ndcg@5: 0.905273\n",
      "[1200]\ttrain's ndcg@5: 0.91249\tvalid's ndcg@5: 0.907837\n",
      "[1300]\ttrain's ndcg@5: 0.915097\tvalid's ndcg@5: 0.910321\n",
      "[1400]\ttrain's ndcg@5: 0.917502\tvalid's ndcg@5: 0.912381\n",
      "[1500]\ttrain's ndcg@5: 0.919536\tvalid's ndcg@5: 0.914486\n",
      "[1600]\ttrain's ndcg@5: 0.921435\tvalid's ndcg@5: 0.916479\n",
      "[1700]\ttrain's ndcg@5: 0.92331\tvalid's ndcg@5: 0.917968\n",
      "[1800]\ttrain's ndcg@5: 0.92494\tvalid's ndcg@5: 0.919294\n",
      "[1900]\ttrain's ndcg@5: 0.926503\tvalid's ndcg@5: 0.920561\n",
      "[2000]\ttrain's ndcg@5: 0.92801\tvalid's ndcg@5: 0.921901\n",
      "[2100]\ttrain's ndcg@5: 0.929343\tvalid's ndcg@5: 0.923067\n",
      "[2200]\ttrain's ndcg@5: 0.930649\tvalid's ndcg@5: 0.924357\n",
      "[2300]\ttrain's ndcg@5: 0.931994\tvalid's ndcg@5: 0.925327\n",
      "[2400]\ttrain's ndcg@5: 0.933239\tvalid's ndcg@5: 0.926422\n",
      "[2500]\ttrain's ndcg@5: 0.934383\tvalid's ndcg@5: 0.92752\n",
      "[2600]\ttrain's ndcg@5: 0.935434\tvalid's ndcg@5: 0.928594\n",
      "[2700]\ttrain's ndcg@5: 0.936514\tvalid's ndcg@5: 0.929642\n",
      "[2800]\ttrain's ndcg@5: 0.937642\tvalid's ndcg@5: 0.930683\n",
      "[2900]\ttrain's ndcg@5: 0.938608\tvalid's ndcg@5: 0.931335\n",
      "[3000]\ttrain's ndcg@5: 0.939489\tvalid's ndcg@5: 0.932386\n",
      "[3100]\ttrain's ndcg@5: 0.94038\tvalid's ndcg@5: 0.933267\n",
      "[3200]\ttrain's ndcg@5: 0.941307\tvalid's ndcg@5: 0.933964\n",
      "[3300]\ttrain's ndcg@5: 0.942187\tvalid's ndcg@5: 0.934506\n",
      "[3400]\ttrain's ndcg@5: 0.942947\tvalid's ndcg@5: 0.935304\n",
      "[3500]\ttrain's ndcg@5: 0.943608\tvalid's ndcg@5: 0.935993\n",
      "[3600]\ttrain's ndcg@5: 0.944335\tvalid's ndcg@5: 0.936535\n",
      "[3700]\ttrain's ndcg@5: 0.945142\tvalid's ndcg@5: 0.937175\n",
      "[3800]\ttrain's ndcg@5: 0.945901\tvalid's ndcg@5: 0.937817\n",
      "[3900]\ttrain's ndcg@5: 0.946632\tvalid's ndcg@5: 0.938425\n",
      "[4000]\ttrain's ndcg@5: 0.947249\tvalid's ndcg@5: 0.938967\n",
      "[4100]\ttrain's ndcg@5: 0.947809\tvalid's ndcg@5: 0.939571\n",
      "[4200]\ttrain's ndcg@5: 0.948396\tvalid's ndcg@5: 0.940133\n",
      "[4300]\ttrain's ndcg@5: 0.949085\tvalid's ndcg@5: 0.940722\n",
      "[4400]\ttrain's ndcg@5: 0.949675\tvalid's ndcg@5: 0.941182\n",
      "[4500]\ttrain's ndcg@5: 0.950193\tvalid's ndcg@5: 0.941622\n",
      "[4600]\ttrain's ndcg@5: 0.950728\tvalid's ndcg@5: 0.942167\n",
      "[4700]\ttrain's ndcg@5: 0.951389\tvalid's ndcg@5: 0.94259\n",
      "[4800]\ttrain's ndcg@5: 0.952003\tvalid's ndcg@5: 0.94285\n",
      "[4900]\ttrain's ndcg@5: 0.952503\tvalid's ndcg@5: 0.943354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 12:55:26,088] Trial 5 finished with value: -0.9438891950872371 and parameters: {'num_leaves': 18, 'learning_rate': 0.003939506773241729, 'feature_fraction': 0.8299173161166797, 'min_data_in_leaf': 123, 'lambda_l1': 2.117313078220433, 'lambda_l2': 1.9137464304953}. Best is trial 2 with value: -0.9319720619246685.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5000]\ttrain's ndcg@5: 0.953026\tvalid's ndcg@5: 0.943889\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[4977]\ttrain's ndcg@5: 0.952895\tvalid's ndcg@5: 0.943889\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttrain's ndcg@5: 0.843775\tvalid's ndcg@5: 0.84216\n",
      "[200]\ttrain's ndcg@5: 0.852485\tvalid's ndcg@5: 0.850703\n",
      "[300]\ttrain's ndcg@5: 0.861837\tvalid's ndcg@5: 0.859304\n",
      "[400]\ttrain's ndcg@5: 0.870752\tvalid's ndcg@5: 0.868426\n",
      "[500]\ttrain's ndcg@5: 0.878346\tvalid's ndcg@5: 0.875217\n",
      "[600]\ttrain's ndcg@5: 0.884824\tvalid's ndcg@5: 0.881205\n",
      "[700]\ttrain's ndcg@5: 0.890327\tvalid's ndcg@5: 0.886655\n",
      "[800]\ttrain's ndcg@5: 0.89518\tvalid's ndcg@5: 0.891247\n",
      "[900]\ttrain's ndcg@5: 0.89931\tvalid's ndcg@5: 0.895565\n",
      "[1000]\ttrain's ndcg@5: 0.902805\tvalid's ndcg@5: 0.898901\n",
      "[1100]\ttrain's ndcg@5: 0.905902\tvalid's ndcg@5: 0.902023\n",
      "[1200]\ttrain's ndcg@5: 0.908832\tvalid's ndcg@5: 0.905017\n",
      "[1300]\ttrain's ndcg@5: 0.911299\tvalid's ndcg@5: 0.907176\n",
      "[1400]\ttrain's ndcg@5: 0.913823\tvalid's ndcg@5: 0.909351\n",
      "[1500]\ttrain's ndcg@5: 0.916051\tvalid's ndcg@5: 0.911432\n",
      "[1600]\ttrain's ndcg@5: 0.918096\tvalid's ndcg@5: 0.913251\n",
      "[1700]\ttrain's ndcg@5: 0.919898\tvalid's ndcg@5: 0.915017\n",
      "[1800]\ttrain's ndcg@5: 0.921547\tvalid's ndcg@5: 0.916688\n",
      "[1900]\ttrain's ndcg@5: 0.923147\tvalid's ndcg@5: 0.917736\n",
      "[2000]\ttrain's ndcg@5: 0.924665\tvalid's ndcg@5: 0.919131\n",
      "[2100]\ttrain's ndcg@5: 0.926085\tvalid's ndcg@5: 0.920328\n",
      "[2200]\ttrain's ndcg@5: 0.927575\tvalid's ndcg@5: 0.921603\n",
      "[2300]\ttrain's ndcg@5: 0.928828\tvalid's ndcg@5: 0.922761\n",
      "[2400]\ttrain's ndcg@5: 0.930068\tvalid's ndcg@5: 0.923878\n",
      "[2500]\ttrain's ndcg@5: 0.93133\tvalid's ndcg@5: 0.925089\n",
      "[2600]\ttrain's ndcg@5: 0.932427\tvalid's ndcg@5: 0.925913\n",
      "[2700]\ttrain's ndcg@5: 0.933373\tvalid's ndcg@5: 0.926989\n",
      "[2800]\ttrain's ndcg@5: 0.934339\tvalid's ndcg@5: 0.927824\n",
      "[2900]\ttrain's ndcg@5: 0.935399\tvalid's ndcg@5: 0.928704\n",
      "[3000]\ttrain's ndcg@5: 0.936292\tvalid's ndcg@5: 0.929506\n",
      "[3100]\ttrain's ndcg@5: 0.937292\tvalid's ndcg@5: 0.930284\n",
      "[3200]\ttrain's ndcg@5: 0.938213\tvalid's ndcg@5: 0.930979\n",
      "[3300]\ttrain's ndcg@5: 0.939005\tvalid's ndcg@5: 0.931765\n",
      "[3400]\ttrain's ndcg@5: 0.939788\tvalid's ndcg@5: 0.932555\n",
      "[3500]\ttrain's ndcg@5: 0.940493\tvalid's ndcg@5: 0.933168\n",
      "[3600]\ttrain's ndcg@5: 0.94126\tvalid's ndcg@5: 0.933687\n",
      "[3700]\ttrain's ndcg@5: 0.942027\tvalid's ndcg@5: 0.934263\n",
      "[3800]\ttrain's ndcg@5: 0.94275\tvalid's ndcg@5: 0.934785\n",
      "[3900]\ttrain's ndcg@5: 0.943542\tvalid's ndcg@5: 0.935382\n",
      "[4000]\ttrain's ndcg@5: 0.944116\tvalid's ndcg@5: 0.936102\n",
      "[4100]\ttrain's ndcg@5: 0.944783\tvalid's ndcg@5: 0.936689\n",
      "[4200]\ttrain's ndcg@5: 0.945416\tvalid's ndcg@5: 0.937309\n",
      "[4300]\ttrain's ndcg@5: 0.946121\tvalid's ndcg@5: 0.937894\n",
      "[4400]\ttrain's ndcg@5: 0.946738\tvalid's ndcg@5: 0.938356\n",
      "[4500]\ttrain's ndcg@5: 0.947326\tvalid's ndcg@5: 0.938824\n",
      "[4600]\ttrain's ndcg@5: 0.947826\tvalid's ndcg@5: 0.939425\n",
      "[4700]\ttrain's ndcg@5: 0.948379\tvalid's ndcg@5: 0.939983\n",
      "[4800]\ttrain's ndcg@5: 0.948895\tvalid's ndcg@5: 0.940572\n",
      "[4900]\ttrain's ndcg@5: 0.9494\tvalid's ndcg@5: 0.941042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 12:56:02,271] Trial 6 finished with value: -0.9414076353382095 and parameters: {'num_leaves': 18, 'learning_rate': 0.003487779799388416, 'feature_fraction': 0.9079774105795375, 'min_data_in_leaf': 83, 'lambda_l1': 1.5883181814340175, 'lambda_l2': 2.301762806783457}. Best is trial 2 with value: -0.9319720619246685.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5000]\ttrain's ndcg@5: 0.949941\tvalid's ndcg@5: 0.941408\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[5000]\ttrain's ndcg@5: 0.949941\tvalid's ndcg@5: 0.941408\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttrain's ndcg@5: 0.931875\tvalid's ndcg@5: 0.9236\n",
      "[200]\ttrain's ndcg@5: 0.951967\tvalid's ndcg@5: 0.940114\n",
      "[300]\ttrain's ndcg@5: 0.963095\tvalid's ndcg@5: 0.949606\n",
      "[400]\ttrain's ndcg@5: 0.970145\tvalid's ndcg@5: 0.95598\n",
      "[500]\ttrain's ndcg@5: 0.974794\tvalid's ndcg@5: 0.959671\n",
      "[600]\ttrain's ndcg@5: 0.97827\tvalid's ndcg@5: 0.962013\n",
      "[700]\ttrain's ndcg@5: 0.980712\tvalid's ndcg@5: 0.964036\n",
      "[800]\ttrain's ndcg@5: 0.98277\tvalid's ndcg@5: 0.965387\n",
      "[900]\ttrain's ndcg@5: 0.984328\tvalid's ndcg@5: 0.966433\n",
      "[1000]\ttrain's ndcg@5: 0.985582\tvalid's ndcg@5: 0.967174\n",
      "[1100]\ttrain's ndcg@5: 0.986645\tvalid's ndcg@5: 0.967579\n",
      "[1200]\ttrain's ndcg@5: 0.987552\tvalid's ndcg@5: 0.968506\n",
      "[1300]\ttrain's ndcg@5: 0.988245\tvalid's ndcg@5: 0.969019\n",
      "[1400]\ttrain's ndcg@5: 0.98885\tvalid's ndcg@5: 0.969425\n",
      "[1500]\ttrain's ndcg@5: 0.989384\tvalid's ndcg@5: 0.969925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 12:56:17,216] Trial 7 finished with value: -0.9702098375455621 and parameters: {'num_leaves': 27, 'learning_rate': 0.08471767963392653, 'feature_fraction': 0.7293049180149884, 'min_data_in_leaf': 66, 'lambda_l1': 4.903499324933148, 'lambda_l2': 1.4137018827696557}. Best is trial 2 with value: -0.9319720619246685.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1600]\ttrain's ndcg@5: 0.989838\tvalid's ndcg@5: 0.970182\n",
      "Early stopping, best iteration is:\n",
      "[1554]\ttrain's ndcg@5: 0.989607\tvalid's ndcg@5: 0.97021\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttrain's ndcg@5: 0.851802\tvalid's ndcg@5: 0.848701\n",
      "[200]\ttrain's ndcg@5: 0.859039\tvalid's ndcg@5: 0.854445\n",
      "[300]\ttrain's ndcg@5: 0.86635\tvalid's ndcg@5: 0.861103\n",
      "[400]\ttrain's ndcg@5: 0.873319\tvalid's ndcg@5: 0.866894\n",
      "[500]\ttrain's ndcg@5: 0.879926\tvalid's ndcg@5: 0.87243\n",
      "[600]\ttrain's ndcg@5: 0.885955\tvalid's ndcg@5: 0.878096\n",
      "[700]\ttrain's ndcg@5: 0.891502\tvalid's ndcg@5: 0.883252\n",
      "[800]\ttrain's ndcg@5: 0.896566\tvalid's ndcg@5: 0.887484\n",
      "[900]\ttrain's ndcg@5: 0.900939\tvalid's ndcg@5: 0.891151\n",
      "[1000]\ttrain's ndcg@5: 0.904797\tvalid's ndcg@5: 0.894669\n",
      "[1100]\ttrain's ndcg@5: 0.908218\tvalid's ndcg@5: 0.898019\n",
      "[1200]\ttrain's ndcg@5: 0.911456\tvalid's ndcg@5: 0.900871\n",
      "[1300]\ttrain's ndcg@5: 0.914431\tvalid's ndcg@5: 0.903485\n",
      "[1400]\ttrain's ndcg@5: 0.916961\tvalid's ndcg@5: 0.906252\n",
      "[1500]\ttrain's ndcg@5: 0.919376\tvalid's ndcg@5: 0.908025\n",
      "[1600]\ttrain's ndcg@5: 0.921612\tvalid's ndcg@5: 0.910109\n",
      "[1700]\ttrain's ndcg@5: 0.923863\tvalid's ndcg@5: 0.91197\n",
      "[1800]\ttrain's ndcg@5: 0.925931\tvalid's ndcg@5: 0.913471\n",
      "[1900]\ttrain's ndcg@5: 0.927676\tvalid's ndcg@5: 0.915258\n",
      "[2000]\ttrain's ndcg@5: 0.929437\tvalid's ndcg@5: 0.916701\n",
      "[2100]\ttrain's ndcg@5: 0.931054\tvalid's ndcg@5: 0.918014\n",
      "[2200]\ttrain's ndcg@5: 0.93264\tvalid's ndcg@5: 0.919338\n",
      "[2300]\ttrain's ndcg@5: 0.934235\tvalid's ndcg@5: 0.920295\n",
      "[2400]\ttrain's ndcg@5: 0.935555\tvalid's ndcg@5: 0.92146\n",
      "[2500]\ttrain's ndcg@5: 0.936788\tvalid's ndcg@5: 0.922288\n",
      "[2600]\ttrain's ndcg@5: 0.938106\tvalid's ndcg@5: 0.923452\n",
      "[2700]\ttrain's ndcg@5: 0.939363\tvalid's ndcg@5: 0.924529\n",
      "[2800]\ttrain's ndcg@5: 0.940502\tvalid's ndcg@5: 0.925527\n",
      "[2900]\ttrain's ndcg@5: 0.941613\tvalid's ndcg@5: 0.926355\n",
      "[3000]\ttrain's ndcg@5: 0.942724\tvalid's ndcg@5: 0.927245\n",
      "[3100]\ttrain's ndcg@5: 0.943821\tvalid's ndcg@5: 0.927991\n",
      "[3200]\ttrain's ndcg@5: 0.944885\tvalid's ndcg@5: 0.92878\n",
      "[3300]\ttrain's ndcg@5: 0.945957\tvalid's ndcg@5: 0.929679\n",
      "[3400]\ttrain's ndcg@5: 0.946842\tvalid's ndcg@5: 0.930292\n",
      "[3500]\ttrain's ndcg@5: 0.947718\tvalid's ndcg@5: 0.931244\n",
      "[3600]\ttrain's ndcg@5: 0.948637\tvalid's ndcg@5: 0.931978\n",
      "[3700]\ttrain's ndcg@5: 0.949543\tvalid's ndcg@5: 0.932572\n",
      "[3800]\ttrain's ndcg@5: 0.950346\tvalid's ndcg@5: 0.933354\n",
      "[3900]\ttrain's ndcg@5: 0.951232\tvalid's ndcg@5: 0.933919\n",
      "[4000]\ttrain's ndcg@5: 0.951954\tvalid's ndcg@5: 0.934445\n",
      "[4100]\ttrain's ndcg@5: 0.952728\tvalid's ndcg@5: 0.935142\n",
      "[4200]\ttrain's ndcg@5: 0.953512\tvalid's ndcg@5: 0.93576\n",
      "[4300]\ttrain's ndcg@5: 0.954156\tvalid's ndcg@5: 0.936193\n",
      "[4400]\ttrain's ndcg@5: 0.954828\tvalid's ndcg@5: 0.936755\n",
      "[4500]\ttrain's ndcg@5: 0.955503\tvalid's ndcg@5: 0.937162\n",
      "[4600]\ttrain's ndcg@5: 0.956094\tvalid's ndcg@5: 0.937696\n",
      "[4700]\ttrain's ndcg@5: 0.956732\tvalid's ndcg@5: 0.938157\n",
      "[4800]\ttrain's ndcg@5: 0.95734\tvalid's ndcg@5: 0.938666\n",
      "[4900]\ttrain's ndcg@5: 0.957951\tvalid's ndcg@5: 0.939059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 12:57:35,265] Trial 8 finished with value: -0.9395962462155983 and parameters: {'num_leaves': 52, 'learning_rate': 0.002889703214664316, 'feature_fraction': 0.9214588902566169, 'min_data_in_leaf': 18, 'lambda_l1': 1.2060371727489345, 'lambda_l2': 2.1406995246670806}. Best is trial 2 with value: -0.9319720619246685.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5000]\ttrain's ndcg@5: 0.958523\tvalid's ndcg@5: 0.939596\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[5000]\ttrain's ndcg@5: 0.958523\tvalid's ndcg@5: 0.939596\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttrain's ndcg@5: 0.863106\tvalid's ndcg@5: 0.859802\n",
      "[200]\ttrain's ndcg@5: 0.87377\tvalid's ndcg@5: 0.868865\n",
      "[300]\ttrain's ndcg@5: 0.88397\tvalid's ndcg@5: 0.877958\n",
      "[400]\ttrain's ndcg@5: 0.893321\tvalid's ndcg@5: 0.886299\n",
      "[500]\ttrain's ndcg@5: 0.900949\tvalid's ndcg@5: 0.893094\n",
      "[600]\ttrain's ndcg@5: 0.907435\tvalid's ndcg@5: 0.89909\n",
      "[700]\ttrain's ndcg@5: 0.912947\tvalid's ndcg@5: 0.90427\n",
      "[800]\ttrain's ndcg@5: 0.917378\tvalid's ndcg@5: 0.908504\n",
      "[900]\ttrain's ndcg@5: 0.921253\tvalid's ndcg@5: 0.911582\n",
      "[1000]\ttrain's ndcg@5: 0.924837\tvalid's ndcg@5: 0.914383\n",
      "[1100]\ttrain's ndcg@5: 0.927908\tvalid's ndcg@5: 0.916871\n",
      "[1200]\ttrain's ndcg@5: 0.930679\tvalid's ndcg@5: 0.919202\n",
      "[1300]\ttrain's ndcg@5: 0.93313\tvalid's ndcg@5: 0.921353\n",
      "[1400]\ttrain's ndcg@5: 0.93539\tvalid's ndcg@5: 0.92353\n",
      "[1500]\ttrain's ndcg@5: 0.937531\tvalid's ndcg@5: 0.925137\n",
      "[1600]\ttrain's ndcg@5: 0.93961\tvalid's ndcg@5: 0.926702\n",
      "[1700]\ttrain's ndcg@5: 0.941573\tvalid's ndcg@5: 0.928216\n",
      "[1800]\ttrain's ndcg@5: 0.94304\tvalid's ndcg@5: 0.929825\n",
      "[1900]\ttrain's ndcg@5: 0.944698\tvalid's ndcg@5: 0.931195\n",
      "[2000]\ttrain's ndcg@5: 0.94621\tvalid's ndcg@5: 0.93248\n",
      "[2100]\ttrain's ndcg@5: 0.947754\tvalid's ndcg@5: 0.933654\n",
      "[2200]\ttrain's ndcg@5: 0.949201\tvalid's ndcg@5: 0.934727\n",
      "[2300]\ttrain's ndcg@5: 0.950459\tvalid's ndcg@5: 0.9359\n",
      "[2400]\ttrain's ndcg@5: 0.951612\tvalid's ndcg@5: 0.936917\n",
      "[2500]\ttrain's ndcg@5: 0.95277\tvalid's ndcg@5: 0.937763\n",
      "[2600]\ttrain's ndcg@5: 0.954\tvalid's ndcg@5: 0.938826\n",
      "[2700]\ttrain's ndcg@5: 0.955163\tvalid's ndcg@5: 0.939594\n",
      "[2800]\ttrain's ndcg@5: 0.956197\tvalid's ndcg@5: 0.94055\n",
      "[2900]\ttrain's ndcg@5: 0.957126\tvalid's ndcg@5: 0.94131\n",
      "[3000]\ttrain's ndcg@5: 0.958061\tvalid's ndcg@5: 0.941886\n",
      "[3100]\ttrain's ndcg@5: 0.958916\tvalid's ndcg@5: 0.942873\n",
      "[3200]\ttrain's ndcg@5: 0.959712\tvalid's ndcg@5: 0.943406\n",
      "[3300]\ttrain's ndcg@5: 0.960608\tvalid's ndcg@5: 0.944092\n",
      "[3400]\ttrain's ndcg@5: 0.961416\tvalid's ndcg@5: 0.944807\n",
      "[3500]\ttrain's ndcg@5: 0.962154\tvalid's ndcg@5: 0.945355\n",
      "[3600]\ttrain's ndcg@5: 0.962903\tvalid's ndcg@5: 0.946229\n",
      "[3700]\ttrain's ndcg@5: 0.96357\tvalid's ndcg@5: 0.946753\n",
      "[3800]\ttrain's ndcg@5: 0.964329\tvalid's ndcg@5: 0.947397\n",
      "[3900]\ttrain's ndcg@5: 0.965044\tvalid's ndcg@5: 0.948026\n",
      "[4000]\ttrain's ndcg@5: 0.965697\tvalid's ndcg@5: 0.948523\n",
      "[4100]\ttrain's ndcg@5: 0.966357\tvalid's ndcg@5: 0.948892\n",
      "[4200]\ttrain's ndcg@5: 0.967071\tvalid's ndcg@5: 0.949327\n",
      "[4300]\ttrain's ndcg@5: 0.967675\tvalid's ndcg@5: 0.949791\n",
      "[4400]\ttrain's ndcg@5: 0.968295\tvalid's ndcg@5: 0.950326\n",
      "[4500]\ttrain's ndcg@5: 0.968885\tvalid's ndcg@5: 0.950824\n",
      "[4600]\ttrain's ndcg@5: 0.969483\tvalid's ndcg@5: 0.951176\n",
      "[4700]\ttrain's ndcg@5: 0.969974\tvalid's ndcg@5: 0.951654\n",
      "[4800]\ttrain's ndcg@5: 0.970557\tvalid's ndcg@5: 0.952002\n",
      "[4900]\ttrain's ndcg@5: 0.971034\tvalid's ndcg@5: 0.952345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 12:58:36,549] Trial 9 finished with value: -0.952800127288335 and parameters: {'num_leaves': 38, 'learning_rate': 0.005612368073152373, 'feature_fraction': 0.7532789209324807, 'min_data_in_leaf': 175, 'lambda_l1': 2.955392173610626, 'lambda_l2': 0.10568837328455705}. Best is trial 2 with value: -0.9319720619246685.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5000]\ttrain's ndcg@5: 0.971488\tvalid's ndcg@5: 0.952789\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[4994]\ttrain's ndcg@5: 0.97144\tvalid's ndcg@5: 0.9528\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttrain's ndcg@5: 0.847467\tvalid's ndcg@5: 0.846042\n",
      "[200]\ttrain's ndcg@5: 0.852191\tvalid's ndcg@5: 0.850155\n",
      "[300]\ttrain's ndcg@5: 0.856287\tvalid's ndcg@5: 0.853609\n",
      "[400]\ttrain's ndcg@5: 0.85924\tvalid's ndcg@5: 0.855917\n",
      "[500]\ttrain's ndcg@5: 0.86193\tvalid's ndcg@5: 0.857812\n",
      "[600]\ttrain's ndcg@5: 0.863949\tvalid's ndcg@5: 0.859423\n",
      "[700]\ttrain's ndcg@5: 0.866171\tvalid's ndcg@5: 0.861199\n",
      "[800]\ttrain's ndcg@5: 0.868295\tvalid's ndcg@5: 0.863199\n",
      "[900]\ttrain's ndcg@5: 0.870363\tvalid's ndcg@5: 0.865013\n",
      "[1000]\ttrain's ndcg@5: 0.872321\tvalid's ndcg@5: 0.867119\n",
      "[1100]\ttrain's ndcg@5: 0.874286\tvalid's ndcg@5: 0.868824\n",
      "[1200]\ttrain's ndcg@5: 0.876588\tvalid's ndcg@5: 0.870763\n",
      "[1300]\ttrain's ndcg@5: 0.878611\tvalid's ndcg@5: 0.872415\n",
      "[1400]\ttrain's ndcg@5: 0.880587\tvalid's ndcg@5: 0.873848\n",
      "[1500]\ttrain's ndcg@5: 0.882349\tvalid's ndcg@5: 0.876045\n",
      "[1600]\ttrain's ndcg@5: 0.884318\tvalid's ndcg@5: 0.877811\n",
      "[1700]\ttrain's ndcg@5: 0.886235\tvalid's ndcg@5: 0.879527\n",
      "[1800]\ttrain's ndcg@5: 0.887943\tvalid's ndcg@5: 0.881281\n",
      "[1900]\ttrain's ndcg@5: 0.889776\tvalid's ndcg@5: 0.882908\n",
      "[2000]\ttrain's ndcg@5: 0.891568\tvalid's ndcg@5: 0.88448\n",
      "[2100]\ttrain's ndcg@5: 0.893376\tvalid's ndcg@5: 0.885808\n",
      "[2200]\ttrain's ndcg@5: 0.894898\tvalid's ndcg@5: 0.887495\n",
      "[2300]\ttrain's ndcg@5: 0.896539\tvalid's ndcg@5: 0.888141\n",
      "[2400]\ttrain's ndcg@5: 0.898052\tvalid's ndcg@5: 0.889521\n",
      "[2500]\ttrain's ndcg@5: 0.899507\tvalid's ndcg@5: 0.890819\n",
      "[2600]\ttrain's ndcg@5: 0.900806\tvalid's ndcg@5: 0.892127\n",
      "[2700]\ttrain's ndcg@5: 0.902117\tvalid's ndcg@5: 0.893382\n",
      "[2800]\ttrain's ndcg@5: 0.903461\tvalid's ndcg@5: 0.894453\n",
      "[2900]\ttrain's ndcg@5: 0.90466\tvalid's ndcg@5: 0.895544\n",
      "[3000]\ttrain's ndcg@5: 0.905913\tvalid's ndcg@5: 0.896655\n",
      "[3100]\ttrain's ndcg@5: 0.907074\tvalid's ndcg@5: 0.897661\n",
      "[3200]\ttrain's ndcg@5: 0.908048\tvalid's ndcg@5: 0.898548\n",
      "[3300]\ttrain's ndcg@5: 0.90906\tvalid's ndcg@5: 0.899697\n",
      "[3400]\ttrain's ndcg@5: 0.910164\tvalid's ndcg@5: 0.900563\n",
      "[3500]\ttrain's ndcg@5: 0.911264\tvalid's ndcg@5: 0.901424\n",
      "[3600]\ttrain's ndcg@5: 0.912339\tvalid's ndcg@5: 0.902392\n",
      "[3700]\ttrain's ndcg@5: 0.91326\tvalid's ndcg@5: 0.903359\n",
      "[3800]\ttrain's ndcg@5: 0.914185\tvalid's ndcg@5: 0.904221\n",
      "[3900]\ttrain's ndcg@5: 0.915051\tvalid's ndcg@5: 0.905194\n",
      "[4000]\ttrain's ndcg@5: 0.915954\tvalid's ndcg@5: 0.906011\n",
      "[4100]\ttrain's ndcg@5: 0.916731\tvalid's ndcg@5: 0.906806\n",
      "[4200]\ttrain's ndcg@5: 0.917456\tvalid's ndcg@5: 0.907528\n",
      "[4300]\ttrain's ndcg@5: 0.918315\tvalid's ndcg@5: 0.908355\n",
      "[4400]\ttrain's ndcg@5: 0.919054\tvalid's ndcg@5: 0.9091\n",
      "[4500]\ttrain's ndcg@5: 0.919898\tvalid's ndcg@5: 0.909637\n",
      "[4600]\ttrain's ndcg@5: 0.920795\tvalid's ndcg@5: 0.910363\n",
      "[4700]\ttrain's ndcg@5: 0.921451\tvalid's ndcg@5: 0.910893\n",
      "[4800]\ttrain's ndcg@5: 0.922182\tvalid's ndcg@5: 0.911662\n",
      "[4900]\ttrain's ndcg@5: 0.922884\tvalid's ndcg@5: 0.912281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 12:59:48,505] Trial 10 finished with value: -0.9129489625588364 and parameters: {'num_leaves': 44, 'learning_rate': 0.0010245295728755562, 'feature_fraction': 0.8132353440492331, 'min_data_in_leaf': 199, 'lambda_l1': 0.008793853056818346, 'lambda_l2': 4.843588302590973}. Best is trial 10 with value: -0.9129489625588364.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5000]\ttrain's ndcg@5: 0.923577\tvalid's ndcg@5: 0.912949\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[4999]\ttrain's ndcg@5: 0.923572\tvalid's ndcg@5: 0.912949\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttrain's ndcg@5: 0.848278\tvalid's ndcg@5: 0.846881\n",
      "[200]\ttrain's ndcg@5: 0.853142\tvalid's ndcg@5: 0.85087\n",
      "[300]\ttrain's ndcg@5: 0.857566\tvalid's ndcg@5: 0.854886\n",
      "[400]\ttrain's ndcg@5: 0.86057\tvalid's ndcg@5: 0.85685\n",
      "[500]\ttrain's ndcg@5: 0.863458\tvalid's ndcg@5: 0.859014\n",
      "[600]\ttrain's ndcg@5: 0.865668\tvalid's ndcg@5: 0.861093\n",
      "[700]\ttrain's ndcg@5: 0.868015\tvalid's ndcg@5: 0.863201\n",
      "[800]\ttrain's ndcg@5: 0.870353\tvalid's ndcg@5: 0.86511\n",
      "[900]\ttrain's ndcg@5: 0.872781\tvalid's ndcg@5: 0.867583\n",
      "[1000]\ttrain's ndcg@5: 0.8751\tvalid's ndcg@5: 0.869529\n",
      "[1100]\ttrain's ndcg@5: 0.877149\tvalid's ndcg@5: 0.87142\n",
      "[1200]\ttrain's ndcg@5: 0.879477\tvalid's ndcg@5: 0.873169\n",
      "[1300]\ttrain's ndcg@5: 0.881518\tvalid's ndcg@5: 0.875096\n",
      "[1400]\ttrain's ndcg@5: 0.883543\tvalid's ndcg@5: 0.877166\n",
      "[1500]\ttrain's ndcg@5: 0.88567\tvalid's ndcg@5: 0.879222\n",
      "[1600]\ttrain's ndcg@5: 0.887822\tvalid's ndcg@5: 0.881007\n",
      "[1700]\ttrain's ndcg@5: 0.889664\tvalid's ndcg@5: 0.882607\n",
      "[1800]\ttrain's ndcg@5: 0.891596\tvalid's ndcg@5: 0.884257\n",
      "[1900]\ttrain's ndcg@5: 0.89357\tvalid's ndcg@5: 0.885546\n",
      "[2000]\ttrain's ndcg@5: 0.895353\tvalid's ndcg@5: 0.887246\n",
      "[2100]\ttrain's ndcg@5: 0.897099\tvalid's ndcg@5: 0.888537\n",
      "[2200]\ttrain's ndcg@5: 0.898821\tvalid's ndcg@5: 0.889834\n",
      "[2300]\ttrain's ndcg@5: 0.900269\tvalid's ndcg@5: 0.891306\n",
      "[2400]\ttrain's ndcg@5: 0.901566\tvalid's ndcg@5: 0.892633\n",
      "[2500]\ttrain's ndcg@5: 0.902917\tvalid's ndcg@5: 0.893914\n",
      "[2600]\ttrain's ndcg@5: 0.904312\tvalid's ndcg@5: 0.895322\n",
      "[2700]\ttrain's ndcg@5: 0.905751\tvalid's ndcg@5: 0.896608\n",
      "[2800]\ttrain's ndcg@5: 0.907123\tvalid's ndcg@5: 0.897794\n",
      "[2900]\ttrain's ndcg@5: 0.908355\tvalid's ndcg@5: 0.898722\n",
      "[3000]\ttrain's ndcg@5: 0.909615\tvalid's ndcg@5: 0.899745\n",
      "[3100]\ttrain's ndcg@5: 0.910791\tvalid's ndcg@5: 0.900958\n",
      "[3200]\ttrain's ndcg@5: 0.911914\tvalid's ndcg@5: 0.901893\n",
      "[3300]\ttrain's ndcg@5: 0.91309\tvalid's ndcg@5: 0.903148\n",
      "[3400]\ttrain's ndcg@5: 0.914112\tvalid's ndcg@5: 0.904196\n",
      "[3500]\ttrain's ndcg@5: 0.915171\tvalid's ndcg@5: 0.905198\n",
      "[3600]\ttrain's ndcg@5: 0.916075\tvalid's ndcg@5: 0.906078\n",
      "[3700]\ttrain's ndcg@5: 0.916932\tvalid's ndcg@5: 0.906606\n",
      "[3800]\ttrain's ndcg@5: 0.917911\tvalid's ndcg@5: 0.907566\n",
      "[3900]\ttrain's ndcg@5: 0.918802\tvalid's ndcg@5: 0.908273\n",
      "[4000]\ttrain's ndcg@5: 0.919608\tvalid's ndcg@5: 0.909057\n",
      "[4100]\ttrain's ndcg@5: 0.920425\tvalid's ndcg@5: 0.909877\n",
      "[4200]\ttrain's ndcg@5: 0.921266\tvalid's ndcg@5: 0.910448\n",
      "[4300]\ttrain's ndcg@5: 0.922066\tvalid's ndcg@5: 0.911282\n",
      "[4400]\ttrain's ndcg@5: 0.922966\tvalid's ndcg@5: 0.912017\n",
      "[4500]\ttrain's ndcg@5: 0.923683\tvalid's ndcg@5: 0.912575\n",
      "[4600]\ttrain's ndcg@5: 0.924427\tvalid's ndcg@5: 0.913266\n",
      "[4700]\ttrain's ndcg@5: 0.925188\tvalid's ndcg@5: 0.913861\n",
      "[4800]\ttrain's ndcg@5: 0.925902\tvalid's ndcg@5: 0.914508\n",
      "[4900]\ttrain's ndcg@5: 0.926614\tvalid's ndcg@5: 0.914959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 13:01:00,518] Trial 11 finished with value: -0.9154584082105343 and parameters: {'num_leaves': 45, 'learning_rate': 0.0011328331522086183, 'feature_fraction': 0.8114366615447127, 'min_data_in_leaf': 195, 'lambda_l1': 0.08027804181498978, 'lambda_l2': 4.965571833803136}. Best is trial 10 with value: -0.9129489625588364.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5000]\ttrain's ndcg@5: 0.927277\tvalid's ndcg@5: 0.915458\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[5000]\ttrain's ndcg@5: 0.927277\tvalid's ndcg@5: 0.915458\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttrain's ndcg@5: 0.848071\tvalid's ndcg@5: 0.845963\n",
      "[200]\ttrain's ndcg@5: 0.852144\tvalid's ndcg@5: 0.850006\n",
      "[300]\ttrain's ndcg@5: 0.856297\tvalid's ndcg@5: 0.85351\n",
      "[400]\ttrain's ndcg@5: 0.859312\tvalid's ndcg@5: 0.855788\n",
      "[500]\ttrain's ndcg@5: 0.862097\tvalid's ndcg@5: 0.857658\n",
      "[600]\ttrain's ndcg@5: 0.864117\tvalid's ndcg@5: 0.859178\n",
      "[700]\ttrain's ndcg@5: 0.866491\tvalid's ndcg@5: 0.860961\n",
      "[800]\ttrain's ndcg@5: 0.868573\tvalid's ndcg@5: 0.863159\n",
      "[900]\ttrain's ndcg@5: 0.870875\tvalid's ndcg@5: 0.865324\n",
      "[1000]\ttrain's ndcg@5: 0.872966\tvalid's ndcg@5: 0.867087\n",
      "[1100]\ttrain's ndcg@5: 0.874988\tvalid's ndcg@5: 0.868926\n",
      "[1200]\ttrain's ndcg@5: 0.877255\tvalid's ndcg@5: 0.870744\n",
      "[1300]\ttrain's ndcg@5: 0.879285\tvalid's ndcg@5: 0.872321\n",
      "[1400]\ttrain's ndcg@5: 0.881375\tvalid's ndcg@5: 0.874307\n",
      "[1500]\ttrain's ndcg@5: 0.883145\tvalid's ndcg@5: 0.876144\n",
      "[1600]\ttrain's ndcg@5: 0.885198\tvalid's ndcg@5: 0.877808\n",
      "[1700]\ttrain's ndcg@5: 0.887049\tvalid's ndcg@5: 0.879817\n",
      "[1800]\ttrain's ndcg@5: 0.888884\tvalid's ndcg@5: 0.88138\n",
      "[1900]\ttrain's ndcg@5: 0.890784\tvalid's ndcg@5: 0.883247\n",
      "[2000]\ttrain's ndcg@5: 0.892646\tvalid's ndcg@5: 0.884928\n",
      "[2100]\ttrain's ndcg@5: 0.894308\tvalid's ndcg@5: 0.8863\n",
      "[2200]\ttrain's ndcg@5: 0.895879\tvalid's ndcg@5: 0.887322\n",
      "[2300]\ttrain's ndcg@5: 0.897463\tvalid's ndcg@5: 0.888615\n",
      "[2400]\ttrain's ndcg@5: 0.898901\tvalid's ndcg@5: 0.889782\n",
      "[2500]\ttrain's ndcg@5: 0.900422\tvalid's ndcg@5: 0.891131\n",
      "[2600]\ttrain's ndcg@5: 0.901677\tvalid's ndcg@5: 0.892202\n",
      "[2700]\ttrain's ndcg@5: 0.903032\tvalid's ndcg@5: 0.893331\n",
      "[2800]\ttrain's ndcg@5: 0.904173\tvalid's ndcg@5: 0.894513\n",
      "[2900]\ttrain's ndcg@5: 0.905598\tvalid's ndcg@5: 0.89575\n",
      "[3000]\ttrain's ndcg@5: 0.90688\tvalid's ndcg@5: 0.896651\n",
      "[3100]\ttrain's ndcg@5: 0.908064\tvalid's ndcg@5: 0.897705\n",
      "[3200]\ttrain's ndcg@5: 0.909265\tvalid's ndcg@5: 0.898897\n",
      "[3300]\ttrain's ndcg@5: 0.910249\tvalid's ndcg@5: 0.900014\n",
      "[3400]\ttrain's ndcg@5: 0.911324\tvalid's ndcg@5: 0.901033\n",
      "[3500]\ttrain's ndcg@5: 0.91235\tvalid's ndcg@5: 0.902061\n",
      "[3600]\ttrain's ndcg@5: 0.913347\tvalid's ndcg@5: 0.903131\n",
      "[3700]\ttrain's ndcg@5: 0.914342\tvalid's ndcg@5: 0.903927\n",
      "[3800]\ttrain's ndcg@5: 0.915211\tvalid's ndcg@5: 0.904875\n",
      "[3900]\ttrain's ndcg@5: 0.916193\tvalid's ndcg@5: 0.905722\n",
      "[4000]\ttrain's ndcg@5: 0.917066\tvalid's ndcg@5: 0.906634\n",
      "[4100]\ttrain's ndcg@5: 0.917953\tvalid's ndcg@5: 0.907545\n",
      "[4200]\ttrain's ndcg@5: 0.918806\tvalid's ndcg@5: 0.908124\n",
      "[4300]\ttrain's ndcg@5: 0.919734\tvalid's ndcg@5: 0.908581\n",
      "[4400]\ttrain's ndcg@5: 0.920499\tvalid's ndcg@5: 0.909315\n",
      "[4500]\ttrain's ndcg@5: 0.921265\tvalid's ndcg@5: 0.910003\n",
      "[4600]\ttrain's ndcg@5: 0.921966\tvalid's ndcg@5: 0.910697\n",
      "[4700]\ttrain's ndcg@5: 0.922729\tvalid's ndcg@5: 0.911265\n",
      "[4800]\ttrain's ndcg@5: 0.923417\tvalid's ndcg@5: 0.911991\n",
      "[4900]\ttrain's ndcg@5: 0.924164\tvalid's ndcg@5: 0.912665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 13:02:16,345] Trial 12 finished with value: -0.9131920774579019 and parameters: {'num_leaves': 48, 'learning_rate': 0.001034306964022719, 'feature_fraction': 0.8262845305592834, 'min_data_in_leaf': 195, 'lambda_l1': 0.13103601021753367, 'lambda_l2': 4.967782714670486}. Best is trial 10 with value: -0.9129489625588364.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5000]\ttrain's ndcg@5: 0.924844\tvalid's ndcg@5: 0.913181\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[4995]\ttrain's ndcg@5: 0.924805\tvalid's ndcg@5: 0.913192\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttrain's ndcg@5: 0.848669\tvalid's ndcg@5: 0.847026\n",
      "[200]\ttrain's ndcg@5: 0.853078\tvalid's ndcg@5: 0.850609\n",
      "[300]\ttrain's ndcg@5: 0.856948\tvalid's ndcg@5: 0.853745\n",
      "[400]\ttrain's ndcg@5: 0.860046\tvalid's ndcg@5: 0.856062\n",
      "[500]\ttrain's ndcg@5: 0.863074\tvalid's ndcg@5: 0.858358\n",
      "[600]\ttrain's ndcg@5: 0.865712\tvalid's ndcg@5: 0.860352\n",
      "[700]\ttrain's ndcg@5: 0.868109\tvalid's ndcg@5: 0.862316\n",
      "[800]\ttrain's ndcg@5: 0.870674\tvalid's ndcg@5: 0.864652\n",
      "[900]\ttrain's ndcg@5: 0.873171\tvalid's ndcg@5: 0.866837\n",
      "[1000]\ttrain's ndcg@5: 0.875719\tvalid's ndcg@5: 0.868906\n",
      "[1100]\ttrain's ndcg@5: 0.877899\tvalid's ndcg@5: 0.870864\n",
      "[1200]\ttrain's ndcg@5: 0.880325\tvalid's ndcg@5: 0.87334\n",
      "[1300]\ttrain's ndcg@5: 0.882659\tvalid's ndcg@5: 0.875184\n",
      "[1400]\ttrain's ndcg@5: 0.884999\tvalid's ndcg@5: 0.877169\n",
      "[1500]\ttrain's ndcg@5: 0.887265\tvalid's ndcg@5: 0.879419\n",
      "[1600]\ttrain's ndcg@5: 0.889442\tvalid's ndcg@5: 0.881498\n",
      "[1700]\ttrain's ndcg@5: 0.891775\tvalid's ndcg@5: 0.883278\n",
      "[1800]\ttrain's ndcg@5: 0.893691\tvalid's ndcg@5: 0.88529\n",
      "[1900]\ttrain's ndcg@5: 0.895666\tvalid's ndcg@5: 0.886878\n",
      "[2000]\ttrain's ndcg@5: 0.897381\tvalid's ndcg@5: 0.888266\n",
      "[2100]\ttrain's ndcg@5: 0.899069\tvalid's ndcg@5: 0.889552\n",
      "[2200]\ttrain's ndcg@5: 0.900684\tvalid's ndcg@5: 0.890788\n",
      "[2300]\ttrain's ndcg@5: 0.902159\tvalid's ndcg@5: 0.89209\n",
      "[2400]\ttrain's ndcg@5: 0.903634\tvalid's ndcg@5: 0.89344\n",
      "[2500]\ttrain's ndcg@5: 0.905108\tvalid's ndcg@5: 0.894784\n",
      "[2600]\ttrain's ndcg@5: 0.906437\tvalid's ndcg@5: 0.895844\n",
      "[2700]\ttrain's ndcg@5: 0.907831\tvalid's ndcg@5: 0.897295\n",
      "[2800]\ttrain's ndcg@5: 0.909085\tvalid's ndcg@5: 0.898566\n",
      "[2900]\ttrain's ndcg@5: 0.910533\tvalid's ndcg@5: 0.899661\n",
      "[3000]\ttrain's ndcg@5: 0.911784\tvalid's ndcg@5: 0.900822\n",
      "[3100]\ttrain's ndcg@5: 0.913043\tvalid's ndcg@5: 0.901915\n",
      "[3200]\ttrain's ndcg@5: 0.91417\tvalid's ndcg@5: 0.902831\n",
      "[3300]\ttrain's ndcg@5: 0.915205\tvalid's ndcg@5: 0.903946\n",
      "[3400]\ttrain's ndcg@5: 0.916291\tvalid's ndcg@5: 0.904825\n",
      "[3500]\ttrain's ndcg@5: 0.917208\tvalid's ndcg@5: 0.905865\n",
      "[3600]\ttrain's ndcg@5: 0.918278\tvalid's ndcg@5: 0.906876\n",
      "[3700]\ttrain's ndcg@5: 0.91919\tvalid's ndcg@5: 0.907939\n",
      "[3800]\ttrain's ndcg@5: 0.920206\tvalid's ndcg@5: 0.908618\n",
      "[3900]\ttrain's ndcg@5: 0.921147\tvalid's ndcg@5: 0.909253\n",
      "[4000]\ttrain's ndcg@5: 0.921977\tvalid's ndcg@5: 0.909955\n",
      "[4100]\ttrain's ndcg@5: 0.922837\tvalid's ndcg@5: 0.910706\n",
      "[4200]\ttrain's ndcg@5: 0.923677\tvalid's ndcg@5: 0.911484\n",
      "[4300]\ttrain's ndcg@5: 0.924535\tvalid's ndcg@5: 0.912258\n",
      "[4400]\ttrain's ndcg@5: 0.925249\tvalid's ndcg@5: 0.912969\n",
      "[4500]\ttrain's ndcg@5: 0.926003\tvalid's ndcg@5: 0.913579\n",
      "[4600]\ttrain's ndcg@5: 0.926785\tvalid's ndcg@5: 0.914157\n",
      "[4700]\ttrain's ndcg@5: 0.927484\tvalid's ndcg@5: 0.914738\n",
      "[4800]\ttrain's ndcg@5: 0.92821\tvalid's ndcg@5: 0.915272\n",
      "[4900]\ttrain's ndcg@5: 0.928871\tvalid's ndcg@5: 0.915821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 13:03:36,366] Trial 13 finished with value: -0.9164648449217007 and parameters: {'num_leaves': 51, 'learning_rate': 0.0011674306994454771, 'feature_fraction': 0.8484687918934379, 'min_data_in_leaf': 167, 'lambda_l1': 0.0958565395263895, 'lambda_l2': 4.993542360864469}. Best is trial 10 with value: -0.9129489625588364.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5000]\ttrain's ndcg@5: 0.929614\tvalid's ndcg@5: 0.916465\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[5000]\ttrain's ndcg@5: 0.929614\tvalid's ndcg@5: 0.916465\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttrain's ndcg@5: 0.84447\tvalid's ndcg@5: 0.843374\n",
      "[200]\ttrain's ndcg@5: 0.849209\tvalid's ndcg@5: 0.847039\n",
      "[300]\ttrain's ndcg@5: 0.853065\tvalid's ndcg@5: 0.850901\n",
      "[400]\ttrain's ndcg@5: 0.855998\tvalid's ndcg@5: 0.853223\n",
      "[500]\ttrain's ndcg@5: 0.858591\tvalid's ndcg@5: 0.855521\n",
      "[600]\ttrain's ndcg@5: 0.860869\tvalid's ndcg@5: 0.857717\n",
      "[700]\ttrain's ndcg@5: 0.862952\tvalid's ndcg@5: 0.859588\n",
      "[800]\ttrain's ndcg@5: 0.865088\tvalid's ndcg@5: 0.861585\n",
      "[900]\ttrain's ndcg@5: 0.867372\tvalid's ndcg@5: 0.863896\n",
      "[1000]\ttrain's ndcg@5: 0.869163\tvalid's ndcg@5: 0.865805\n",
      "[1100]\ttrain's ndcg@5: 0.870899\tvalid's ndcg@5: 0.86712\n",
      "[1200]\ttrain's ndcg@5: 0.872905\tvalid's ndcg@5: 0.86915\n",
      "[1300]\ttrain's ndcg@5: 0.875066\tvalid's ndcg@5: 0.87066\n",
      "[1400]\ttrain's ndcg@5: 0.877353\tvalid's ndcg@5: 0.872341\n",
      "[1500]\ttrain's ndcg@5: 0.879347\tvalid's ndcg@5: 0.874366\n",
      "[1600]\ttrain's ndcg@5: 0.881365\tvalid's ndcg@5: 0.876558\n",
      "[1700]\ttrain's ndcg@5: 0.883141\tvalid's ndcg@5: 0.878529\n",
      "[1800]\ttrain's ndcg@5: 0.885111\tvalid's ndcg@5: 0.88016\n",
      "[1900]\ttrain's ndcg@5: 0.886934\tvalid's ndcg@5: 0.881647\n",
      "[2000]\ttrain's ndcg@5: 0.888666\tvalid's ndcg@5: 0.883067\n",
      "[2100]\ttrain's ndcg@5: 0.890267\tvalid's ndcg@5: 0.884651\n",
      "[2200]\ttrain's ndcg@5: 0.891796\tvalid's ndcg@5: 0.886021\n",
      "[2300]\ttrain's ndcg@5: 0.89334\tvalid's ndcg@5: 0.887293\n",
      "[2400]\ttrain's ndcg@5: 0.895053\tvalid's ndcg@5: 0.888401\n",
      "[2500]\ttrain's ndcg@5: 0.8966\tvalid's ndcg@5: 0.889609\n",
      "[2600]\ttrain's ndcg@5: 0.897811\tvalid's ndcg@5: 0.890731\n",
      "[2700]\ttrain's ndcg@5: 0.899145\tvalid's ndcg@5: 0.892095\n",
      "[2800]\ttrain's ndcg@5: 0.900367\tvalid's ndcg@5: 0.893353\n",
      "[2900]\ttrain's ndcg@5: 0.901683\tvalid's ndcg@5: 0.894492\n",
      "[3000]\ttrain's ndcg@5: 0.9029\tvalid's ndcg@5: 0.895386\n",
      "[3100]\ttrain's ndcg@5: 0.904051\tvalid's ndcg@5: 0.896481\n",
      "[3200]\ttrain's ndcg@5: 0.905217\tvalid's ndcg@5: 0.897736\n",
      "[3300]\ttrain's ndcg@5: 0.906169\tvalid's ndcg@5: 0.898868\n",
      "[3400]\ttrain's ndcg@5: 0.907149\tvalid's ndcg@5: 0.899661\n",
      "[3500]\ttrain's ndcg@5: 0.908125\tvalid's ndcg@5: 0.900918\n",
      "[3600]\ttrain's ndcg@5: 0.909072\tvalid's ndcg@5: 0.902053\n",
      "[3700]\ttrain's ndcg@5: 0.910025\tvalid's ndcg@5: 0.902784\n",
      "[3800]\ttrain's ndcg@5: 0.910992\tvalid's ndcg@5: 0.903638\n",
      "[3900]\ttrain's ndcg@5: 0.911838\tvalid's ndcg@5: 0.904473\n",
      "[4000]\ttrain's ndcg@5: 0.912616\tvalid's ndcg@5: 0.905233\n",
      "[4100]\ttrain's ndcg@5: 0.913585\tvalid's ndcg@5: 0.905962\n",
      "[4200]\ttrain's ndcg@5: 0.914415\tvalid's ndcg@5: 0.90659\n",
      "[4300]\ttrain's ndcg@5: 0.915293\tvalid's ndcg@5: 0.907326\n",
      "[4400]\ttrain's ndcg@5: 0.916073\tvalid's ndcg@5: 0.907852\n",
      "[4500]\ttrain's ndcg@5: 0.916714\tvalid's ndcg@5: 0.908581\n",
      "[4600]\ttrain's ndcg@5: 0.91743\tvalid's ndcg@5: 0.909356\n",
      "[4700]\ttrain's ndcg@5: 0.918182\tvalid's ndcg@5: 0.910027\n",
      "[4800]\ttrain's ndcg@5: 0.918851\tvalid's ndcg@5: 0.910452\n",
      "[4900]\ttrain's ndcg@5: 0.919495\tvalid's ndcg@5: 0.911235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 13:04:35,737] Trial 14 finished with value: -0.9116917696622929 and parameters: {'num_leaves': 34, 'learning_rate': 0.001008327545545068, 'feature_fraction': 0.8020277602730795, 'min_data_in_leaf': 198, 'lambda_l1': 0.5937545786519233, 'lambda_l2': 3.9866388089892144}. Best is trial 14 with value: -0.9116917696622929.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5000]\ttrain's ndcg@5: 0.920144\tvalid's ndcg@5: 0.911692\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[5000]\ttrain's ndcg@5: 0.920144\tvalid's ndcg@5: 0.911692\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttrain's ndcg@5: 0.856017\tvalid's ndcg@5: 0.853932\n",
      "[200]\ttrain's ndcg@5: 0.859879\tvalid's ndcg@5: 0.857661\n",
      "[300]\ttrain's ndcg@5: 0.864575\tvalid's ndcg@5: 0.86157\n",
      "[400]\ttrain's ndcg@5: 0.868328\tvalid's ndcg@5: 0.865043\n",
      "[500]\ttrain's ndcg@5: 0.871998\tvalid's ndcg@5: 0.868019\n",
      "[600]\ttrain's ndcg@5: 0.875461\tvalid's ndcg@5: 0.87074\n",
      "[700]\ttrain's ndcg@5: 0.87887\tvalid's ndcg@5: 0.873833\n",
      "[800]\ttrain's ndcg@5: 0.882315\tvalid's ndcg@5: 0.876959\n",
      "[900]\ttrain's ndcg@5: 0.8857\tvalid's ndcg@5: 0.88006\n",
      "[1000]\ttrain's ndcg@5: 0.888865\tvalid's ndcg@5: 0.883058\n",
      "[1100]\ttrain's ndcg@5: 0.891676\tvalid's ndcg@5: 0.885437\n",
      "[1200]\ttrain's ndcg@5: 0.894643\tvalid's ndcg@5: 0.887893\n",
      "[1300]\ttrain's ndcg@5: 0.897477\tvalid's ndcg@5: 0.890215\n",
      "[1400]\ttrain's ndcg@5: 0.899894\tvalid's ndcg@5: 0.892724\n",
      "[1500]\ttrain's ndcg@5: 0.902087\tvalid's ndcg@5: 0.894781\n",
      "[1600]\ttrain's ndcg@5: 0.904248\tvalid's ndcg@5: 0.896412\n",
      "[1700]\ttrain's ndcg@5: 0.906486\tvalid's ndcg@5: 0.898582\n",
      "[1800]\ttrain's ndcg@5: 0.908321\tvalid's ndcg@5: 0.900854\n",
      "[1900]\ttrain's ndcg@5: 0.910312\tvalid's ndcg@5: 0.902475\n",
      "[2000]\ttrain's ndcg@5: 0.911994\tvalid's ndcg@5: 0.903975\n",
      "[2100]\ttrain's ndcg@5: 0.913727\tvalid's ndcg@5: 0.905559\n",
      "[2200]\ttrain's ndcg@5: 0.915256\tvalid's ndcg@5: 0.90691\n",
      "[2300]\ttrain's ndcg@5: 0.916688\tvalid's ndcg@5: 0.908224\n",
      "[2400]\ttrain's ndcg@5: 0.918074\tvalid's ndcg@5: 0.909445\n",
      "[2500]\ttrain's ndcg@5: 0.919473\tvalid's ndcg@5: 0.910491\n",
      "[2600]\ttrain's ndcg@5: 0.920765\tvalid's ndcg@5: 0.911654\n",
      "[2700]\ttrain's ndcg@5: 0.922058\tvalid's ndcg@5: 0.912656\n",
      "[2800]\ttrain's ndcg@5: 0.923192\tvalid's ndcg@5: 0.913802\n",
      "[2900]\ttrain's ndcg@5: 0.924359\tvalid's ndcg@5: 0.914901\n",
      "[3000]\ttrain's ndcg@5: 0.925403\tvalid's ndcg@5: 0.915613\n",
      "[3100]\ttrain's ndcg@5: 0.926345\tvalid's ndcg@5: 0.916579\n",
      "[3200]\ttrain's ndcg@5: 0.927343\tvalid's ndcg@5: 0.917292\n",
      "[3300]\ttrain's ndcg@5: 0.928315\tvalid's ndcg@5: 0.918046\n",
      "[3400]\ttrain's ndcg@5: 0.929246\tvalid's ndcg@5: 0.918882\n",
      "[3500]\ttrain's ndcg@5: 0.930182\tvalid's ndcg@5: 0.919681\n",
      "[3600]\ttrain's ndcg@5: 0.930999\tvalid's ndcg@5: 0.92054\n",
      "[3700]\ttrain's ndcg@5: 0.931954\tvalid's ndcg@5: 0.921171\n",
      "[3800]\ttrain's ndcg@5: 0.932776\tvalid's ndcg@5: 0.921985\n",
      "[3900]\ttrain's ndcg@5: 0.93361\tvalid's ndcg@5: 0.922624\n",
      "[4000]\ttrain's ndcg@5: 0.934326\tvalid's ndcg@5: 0.923273\n",
      "[4100]\ttrain's ndcg@5: 0.935168\tvalid's ndcg@5: 0.923917\n",
      "[4200]\ttrain's ndcg@5: 0.935926\tvalid's ndcg@5: 0.924647\n",
      "[4300]\ttrain's ndcg@5: 0.93671\tvalid's ndcg@5: 0.925343\n",
      "[4400]\ttrain's ndcg@5: 0.937484\tvalid's ndcg@5: 0.925755\n",
      "[4500]\ttrain's ndcg@5: 0.93806\tvalid's ndcg@5: 0.926231\n",
      "[4600]\ttrain's ndcg@5: 0.938767\tvalid's ndcg@5: 0.926903\n",
      "[4700]\ttrain's ndcg@5: 0.939418\tvalid's ndcg@5: 0.92739\n",
      "[4800]\ttrain's ndcg@5: 0.939946\tvalid's ndcg@5: 0.927996\n",
      "[4900]\ttrain's ndcg@5: 0.940543\tvalid's ndcg@5: 0.928558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 13:05:33,575] Trial 15 finished with value: -0.9291217341489663 and parameters: {'num_leaves': 34, 'learning_rate': 0.0019650352759397393, 'feature_fraction': 0.701873082632344, 'min_data_in_leaf': 162, 'lambda_l1': 0.7061770646208116, 'lambda_l2': 3.9131484493440367}. Best is trial 14 with value: -0.9116917696622929.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5000]\ttrain's ndcg@5: 0.941096\tvalid's ndcg@5: 0.929097\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[4995]\ttrain's ndcg@5: 0.941071\tvalid's ndcg@5: 0.929122\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttrain's ndcg@5: 0.868418\tvalid's ndcg@5: 0.864954\n",
      "[200]\ttrain's ndcg@5: 0.886975\tvalid's ndcg@5: 0.881768\n",
      "[300]\ttrain's ndcg@5: 0.901029\tvalid's ndcg@5: 0.894352\n",
      "[400]\ttrain's ndcg@5: 0.911036\tvalid's ndcg@5: 0.903751\n",
      "[500]\ttrain's ndcg@5: 0.918555\tvalid's ndcg@5: 0.910322\n",
      "[600]\ttrain's ndcg@5: 0.924434\tvalid's ndcg@5: 0.915475\n",
      "[700]\ttrain's ndcg@5: 0.929413\tvalid's ndcg@5: 0.919855\n",
      "[800]\ttrain's ndcg@5: 0.933547\tvalid's ndcg@5: 0.923344\n",
      "[900]\ttrain's ndcg@5: 0.937261\tvalid's ndcg@5: 0.926214\n",
      "[1000]\ttrain's ndcg@5: 0.940436\tvalid's ndcg@5: 0.928917\n",
      "[1100]\ttrain's ndcg@5: 0.943004\tvalid's ndcg@5: 0.931216\n",
      "[1200]\ttrain's ndcg@5: 0.945716\tvalid's ndcg@5: 0.93332\n",
      "[1300]\ttrain's ndcg@5: 0.948074\tvalid's ndcg@5: 0.935442\n",
      "[1400]\ttrain's ndcg@5: 0.950139\tvalid's ndcg@5: 0.937471\n",
      "[1500]\ttrain's ndcg@5: 0.952209\tvalid's ndcg@5: 0.938896\n",
      "[1600]\ttrain's ndcg@5: 0.954071\tvalid's ndcg@5: 0.940339\n",
      "[1700]\ttrain's ndcg@5: 0.955823\tvalid's ndcg@5: 0.941946\n",
      "[1800]\ttrain's ndcg@5: 0.957395\tvalid's ndcg@5: 0.943096\n",
      "[1900]\ttrain's ndcg@5: 0.958953\tvalid's ndcg@5: 0.944533\n",
      "[2000]\ttrain's ndcg@5: 0.960568\tvalid's ndcg@5: 0.945553\n",
      "[2100]\ttrain's ndcg@5: 0.961887\tvalid's ndcg@5: 0.946702\n",
      "[2200]\ttrain's ndcg@5: 0.963053\tvalid's ndcg@5: 0.947462\n",
      "[2300]\ttrain's ndcg@5: 0.964218\tvalid's ndcg@5: 0.948593\n",
      "[2400]\ttrain's ndcg@5: 0.965323\tvalid's ndcg@5: 0.949592\n",
      "[2500]\ttrain's ndcg@5: 0.966363\tvalid's ndcg@5: 0.950573\n",
      "[2600]\ttrain's ndcg@5: 0.967281\tvalid's ndcg@5: 0.951481\n",
      "[2700]\ttrain's ndcg@5: 0.968287\tvalid's ndcg@5: 0.952225\n",
      "[2800]\ttrain's ndcg@5: 0.969197\tvalid's ndcg@5: 0.953202\n",
      "[2900]\ttrain's ndcg@5: 0.970167\tvalid's ndcg@5: 0.953778\n",
      "[3000]\ttrain's ndcg@5: 0.97091\tvalid's ndcg@5: 0.954352\n",
      "[3100]\ttrain's ndcg@5: 0.971623\tvalid's ndcg@5: 0.954788\n",
      "[3200]\ttrain's ndcg@5: 0.972398\tvalid's ndcg@5: 0.955478\n",
      "[3300]\ttrain's ndcg@5: 0.97313\tvalid's ndcg@5: 0.956171\n",
      "[3400]\ttrain's ndcg@5: 0.973717\tvalid's ndcg@5: 0.956579\n",
      "[3500]\ttrain's ndcg@5: 0.974332\tvalid's ndcg@5: 0.95703\n",
      "[3600]\ttrain's ndcg@5: 0.974938\tvalid's ndcg@5: 0.957412\n",
      "[3700]\ttrain's ndcg@5: 0.975585\tvalid's ndcg@5: 0.957993\n",
      "[3800]\ttrain's ndcg@5: 0.976204\tvalid's ndcg@5: 0.958476\n",
      "[3900]\ttrain's ndcg@5: 0.976771\tvalid's ndcg@5: 0.958981\n",
      "[4000]\ttrain's ndcg@5: 0.977202\tvalid's ndcg@5: 0.959384\n",
      "[4100]\ttrain's ndcg@5: 0.977683\tvalid's ndcg@5: 0.959718\n",
      "[4200]\ttrain's ndcg@5: 0.97807\tvalid's ndcg@5: 0.959925\n",
      "[4300]\ttrain's ndcg@5: 0.978529\tvalid's ndcg@5: 0.960406\n",
      "[4400]\ttrain's ndcg@5: 0.97895\tvalid's ndcg@5: 0.96069\n",
      "[4500]\ttrain's ndcg@5: 0.979342\tvalid's ndcg@5: 0.961135\n",
      "[4600]\ttrain's ndcg@5: 0.979778\tvalid's ndcg@5: 0.9615\n",
      "[4700]\ttrain's ndcg@5: 0.980201\tvalid's ndcg@5: 0.9618\n",
      "[4800]\ttrain's ndcg@5: 0.980512\tvalid's ndcg@5: 0.96228\n",
      "[4900]\ttrain's ndcg@5: 0.980835\tvalid's ndcg@5: 0.962332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 13:06:28,206] Trial 16 finished with value: -0.9626688124128853 and parameters: {'num_leaves': 33, 'learning_rate': 0.009825324235797883, 'feature_fraction': 0.7801609858555089, 'min_data_in_leaf': 197, 'lambda_l1': 2.1965363491068373, 'lambda_l2': 4.189084287482105}. Best is trial 14 with value: -0.9116917696622929.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5000]\ttrain's ndcg@5: 0.981181\tvalid's ndcg@5: 0.962614\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[4977]\ttrain's ndcg@5: 0.981108\tvalid's ndcg@5: 0.962669\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttrain's ndcg@5: 0.851683\tvalid's ndcg@5: 0.848586\n",
      "[200]\ttrain's ndcg@5: 0.857393\tvalid's ndcg@5: 0.853512\n",
      "[300]\ttrain's ndcg@5: 0.86254\tvalid's ndcg@5: 0.856998\n",
      "[400]\ttrain's ndcg@5: 0.867112\tvalid's ndcg@5: 0.860963\n",
      "[500]\ttrain's ndcg@5: 0.871837\tvalid's ndcg@5: 0.864977\n",
      "[600]\ttrain's ndcg@5: 0.876118\tvalid's ndcg@5: 0.868335\n",
      "[700]\ttrain's ndcg@5: 0.880372\tvalid's ndcg@5: 0.871901\n",
      "[800]\ttrain's ndcg@5: 0.884353\tvalid's ndcg@5: 0.87561\n",
      "[900]\ttrain's ndcg@5: 0.888304\tvalid's ndcg@5: 0.879419\n",
      "[1000]\ttrain's ndcg@5: 0.892064\tvalid's ndcg@5: 0.882592\n",
      "[1100]\ttrain's ndcg@5: 0.895279\tvalid's ndcg@5: 0.885623\n",
      "[1200]\ttrain's ndcg@5: 0.898456\tvalid's ndcg@5: 0.888122\n",
      "[1300]\ttrain's ndcg@5: 0.901415\tvalid's ndcg@5: 0.890268\n",
      "[1400]\ttrain's ndcg@5: 0.904082\tvalid's ndcg@5: 0.892633\n",
      "[1500]\ttrain's ndcg@5: 0.906654\tvalid's ndcg@5: 0.895135\n",
      "[1600]\ttrain's ndcg@5: 0.909003\tvalid's ndcg@5: 0.897238\n",
      "[1700]\ttrain's ndcg@5: 0.911324\tvalid's ndcg@5: 0.899289\n",
      "[1800]\ttrain's ndcg@5: 0.913533\tvalid's ndcg@5: 0.901263\n",
      "[1900]\ttrain's ndcg@5: 0.915529\tvalid's ndcg@5: 0.902937\n",
      "[2000]\ttrain's ndcg@5: 0.917267\tvalid's ndcg@5: 0.904944\n",
      "[2100]\ttrain's ndcg@5: 0.918883\tvalid's ndcg@5: 0.906491\n",
      "[2200]\ttrain's ndcg@5: 0.920492\tvalid's ndcg@5: 0.907917\n",
      "[2300]\ttrain's ndcg@5: 0.922136\tvalid's ndcg@5: 0.909022\n",
      "[2400]\ttrain's ndcg@5: 0.923627\tvalid's ndcg@5: 0.910272\n",
      "[2500]\ttrain's ndcg@5: 0.925037\tvalid's ndcg@5: 0.911732\n",
      "[2600]\ttrain's ndcg@5: 0.926331\tvalid's ndcg@5: 0.91255\n",
      "[2700]\ttrain's ndcg@5: 0.92761\tvalid's ndcg@5: 0.913648\n",
      "[2800]\ttrain's ndcg@5: 0.928916\tvalid's ndcg@5: 0.914793\n",
      "[2900]\ttrain's ndcg@5: 0.930146\tvalid's ndcg@5: 0.915865\n",
      "[3000]\ttrain's ndcg@5: 0.931232\tvalid's ndcg@5: 0.916688\n",
      "[3100]\ttrain's ndcg@5: 0.9323\tvalid's ndcg@5: 0.917417\n",
      "[3200]\ttrain's ndcg@5: 0.933455\tvalid's ndcg@5: 0.917995\n",
      "[3300]\ttrain's ndcg@5: 0.9345\tvalid's ndcg@5: 0.918725\n",
      "[3400]\ttrain's ndcg@5: 0.935467\tvalid's ndcg@5: 0.919626\n",
      "[3500]\ttrain's ndcg@5: 0.93646\tvalid's ndcg@5: 0.920648\n",
      "[3600]\ttrain's ndcg@5: 0.937408\tvalid's ndcg@5: 0.921289\n",
      "[3700]\ttrain's ndcg@5: 0.93829\tvalid's ndcg@5: 0.921961\n",
      "[3800]\ttrain's ndcg@5: 0.939234\tvalid's ndcg@5: 0.922725\n",
      "[3900]\ttrain's ndcg@5: 0.940012\tvalid's ndcg@5: 0.923572\n",
      "[4000]\ttrain's ndcg@5: 0.940893\tvalid's ndcg@5: 0.924357\n",
      "[4100]\ttrain's ndcg@5: 0.941679\tvalid's ndcg@5: 0.924711\n",
      "[4200]\ttrain's ndcg@5: 0.942532\tvalid's ndcg@5: 0.925339\n",
      "[4300]\ttrain's ndcg@5: 0.943327\tvalid's ndcg@5: 0.925796\n",
      "[4400]\ttrain's ndcg@5: 0.944033\tvalid's ndcg@5: 0.926471\n",
      "[4500]\ttrain's ndcg@5: 0.944825\tvalid's ndcg@5: 0.927324\n",
      "[4600]\ttrain's ndcg@5: 0.945565\tvalid's ndcg@5: 0.927905\n",
      "[4700]\ttrain's ndcg@5: 0.946165\tvalid's ndcg@5: 0.928409\n",
      "[4800]\ttrain's ndcg@5: 0.946885\tvalid's ndcg@5: 0.928976\n",
      "[4900]\ttrain's ndcg@5: 0.947545\tvalid's ndcg@5: 0.929452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 13:07:55,336] Trial 17 finished with value: -0.9300746511599777 and parameters: {'num_leaves': 58, 'learning_rate': 0.0019571478799449422, 'feature_fraction': 0.87524450315304, 'min_data_in_leaf': 154, 'lambda_l1': 0.737542723232777, 'lambda_l2': 3.1143106993962415}. Best is trial 14 with value: -0.9116917696622929.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5000]\ttrain's ndcg@5: 0.948167\tvalid's ndcg@5: 0.930075\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[5000]\ttrain's ndcg@5: 0.948167\tvalid's ndcg@5: 0.930075\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttrain's ndcg@5: 0.867824\tvalid's ndcg@5: 0.863357\n",
      "[200]\ttrain's ndcg@5: 0.883799\tvalid's ndcg@5: 0.877734\n",
      "[300]\ttrain's ndcg@5: 0.897337\tvalid's ndcg@5: 0.88938\n",
      "[400]\ttrain's ndcg@5: 0.907599\tvalid's ndcg@5: 0.898423\n",
      "[500]\ttrain's ndcg@5: 0.915393\tvalid's ndcg@5: 0.90561\n",
      "[600]\ttrain's ndcg@5: 0.92149\tvalid's ndcg@5: 0.910872\n",
      "[700]\ttrain's ndcg@5: 0.926884\tvalid's ndcg@5: 0.91533\n",
      "[800]\ttrain's ndcg@5: 0.931128\tvalid's ndcg@5: 0.918799\n",
      "[900]\ttrain's ndcg@5: 0.934749\tvalid's ndcg@5: 0.921835\n",
      "[1000]\ttrain's ndcg@5: 0.938086\tvalid's ndcg@5: 0.92493\n",
      "[1100]\ttrain's ndcg@5: 0.941126\tvalid's ndcg@5: 0.927494\n",
      "[1200]\ttrain's ndcg@5: 0.94379\tvalid's ndcg@5: 0.929662\n",
      "[1300]\ttrain's ndcg@5: 0.946239\tvalid's ndcg@5: 0.931765\n",
      "[1400]\ttrain's ndcg@5: 0.948543\tvalid's ndcg@5: 0.933373\n",
      "[1500]\ttrain's ndcg@5: 0.950684\tvalid's ndcg@5: 0.935104\n",
      "[1600]\ttrain's ndcg@5: 0.952672\tvalid's ndcg@5: 0.9365\n",
      "[1700]\ttrain's ndcg@5: 0.954366\tvalid's ndcg@5: 0.938222\n",
      "[1800]\ttrain's ndcg@5: 0.956084\tvalid's ndcg@5: 0.939616\n",
      "[1900]\ttrain's ndcg@5: 0.957604\tvalid's ndcg@5: 0.940748\n",
      "[2000]\ttrain's ndcg@5: 0.959009\tvalid's ndcg@5: 0.941888\n",
      "[2100]\ttrain's ndcg@5: 0.960309\tvalid's ndcg@5: 0.942816\n",
      "[2200]\ttrain's ndcg@5: 0.961671\tvalid's ndcg@5: 0.944047\n",
      "[2300]\ttrain's ndcg@5: 0.963077\tvalid's ndcg@5: 0.944709\n",
      "[2400]\ttrain's ndcg@5: 0.964148\tvalid's ndcg@5: 0.945775\n",
      "[2500]\ttrain's ndcg@5: 0.965279\tvalid's ndcg@5: 0.946788\n",
      "[2600]\ttrain's ndcg@5: 0.966369\tvalid's ndcg@5: 0.947685\n",
      "[2700]\ttrain's ndcg@5: 0.967409\tvalid's ndcg@5: 0.948471\n",
      "[2800]\ttrain's ndcg@5: 0.968363\tvalid's ndcg@5: 0.949267\n",
      "[2900]\ttrain's ndcg@5: 0.969219\tvalid's ndcg@5: 0.949933\n",
      "[3000]\ttrain's ndcg@5: 0.970075\tvalid's ndcg@5: 0.95071\n",
      "[3100]\ttrain's ndcg@5: 0.970967\tvalid's ndcg@5: 0.951441\n",
      "[3200]\ttrain's ndcg@5: 0.971738\tvalid's ndcg@5: 0.952052\n",
      "[3300]\ttrain's ndcg@5: 0.97252\tvalid's ndcg@5: 0.952746\n",
      "[3400]\ttrain's ndcg@5: 0.973178\tvalid's ndcg@5: 0.953426\n",
      "[3500]\ttrain's ndcg@5: 0.973772\tvalid's ndcg@5: 0.953933\n",
      "[3600]\ttrain's ndcg@5: 0.974381\tvalid's ndcg@5: 0.954505\n",
      "[3700]\ttrain's ndcg@5: 0.974947\tvalid's ndcg@5: 0.955104\n",
      "[3800]\ttrain's ndcg@5: 0.975583\tvalid's ndcg@5: 0.955562\n",
      "[3900]\ttrain's ndcg@5: 0.976182\tvalid's ndcg@5: 0.956061\n",
      "[4000]\ttrain's ndcg@5: 0.976749\tvalid's ndcg@5: 0.956444\n",
      "[4100]\ttrain's ndcg@5: 0.977283\tvalid's ndcg@5: 0.956882\n",
      "[4200]\ttrain's ndcg@5: 0.977836\tvalid's ndcg@5: 0.957114\n",
      "[4300]\ttrain's ndcg@5: 0.978349\tvalid's ndcg@5: 0.957445\n",
      "[4400]\ttrain's ndcg@5: 0.978747\tvalid's ndcg@5: 0.95792\n",
      "[4500]\ttrain's ndcg@5: 0.979148\tvalid's ndcg@5: 0.958233\n",
      "[4600]\ttrain's ndcg@5: 0.97958\tvalid's ndcg@5: 0.958676\n",
      "[4700]\ttrain's ndcg@5: 0.979982\tvalid's ndcg@5: 0.958817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 13:08:59,343] Trial 18 finished with value: -0.9588859086200617 and parameters: {'num_leaves': 43, 'learning_rate': 0.008188864321010599, 'feature_fraction': 0.7832902138141269, 'min_data_in_leaf': 48, 'lambda_l1': 1.6473507747633458, 'lambda_l2': 4.329584946664756}. Best is trial 14 with value: -0.9116917696622929.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[4664]\ttrain's ndcg@5: 0.97985\tvalid's ndcg@5: 0.958886\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttrain's ndcg@5: 0.915981\tvalid's ndcg@5: 0.909158\n",
      "[200]\ttrain's ndcg@5: 0.938003\tvalid's ndcg@5: 0.927238\n",
      "[300]\ttrain's ndcg@5: 0.950473\tvalid's ndcg@5: 0.937134\n",
      "[400]\ttrain's ndcg@5: 0.958879\tvalid's ndcg@5: 0.943845\n",
      "[500]\ttrain's ndcg@5: 0.964898\tvalid's ndcg@5: 0.948647\n",
      "[600]\ttrain's ndcg@5: 0.969602\tvalid's ndcg@5: 0.953069\n",
      "[700]\ttrain's ndcg@5: 0.973446\tvalid's ndcg@5: 0.955725\n",
      "[800]\ttrain's ndcg@5: 0.976473\tvalid's ndcg@5: 0.958094\n",
      "[900]\ttrain's ndcg@5: 0.978933\tvalid's ndcg@5: 0.959556\n",
      "[1000]\ttrain's ndcg@5: 0.980755\tvalid's ndcg@5: 0.961255\n",
      "[1100]\ttrain's ndcg@5: 0.982474\tvalid's ndcg@5: 0.962728\n",
      "[1200]\ttrain's ndcg@5: 0.983961\tvalid's ndcg@5: 0.963834\n",
      "[1300]\ttrain's ndcg@5: 0.98525\tvalid's ndcg@5: 0.964582\n",
      "[1400]\ttrain's ndcg@5: 0.986307\tvalid's ndcg@5: 0.965401\n",
      "[1500]\ttrain's ndcg@5: 0.987256\tvalid's ndcg@5: 0.965984\n",
      "[1600]\ttrain's ndcg@5: 0.988207\tvalid's ndcg@5: 0.966778\n",
      "[1700]\ttrain's ndcg@5: 0.989011\tvalid's ndcg@5: 0.96694\n",
      "[1800]\ttrain's ndcg@5: 0.989704\tvalid's ndcg@5: 0.967708\n",
      "[1900]\ttrain's ndcg@5: 0.99025\tvalid's ndcg@5: 0.968439\n",
      "[2000]\ttrain's ndcg@5: 0.990819\tvalid's ndcg@5: 0.969025\n",
      "[2100]\ttrain's ndcg@5: 0.991224\tvalid's ndcg@5: 0.969354\n",
      "[2200]\ttrain's ndcg@5: 0.991617\tvalid's ndcg@5: 0.969405\n",
      "[2300]\ttrain's ndcg@5: 0.991981\tvalid's ndcg@5: 0.969789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 13:09:25,840] Trial 19 finished with value: -0.9698918015725989 and parameters: {'num_leaves': 33, 'learning_rate': 0.04640307644320729, 'feature_fraction': 0.9665242828869501, 'min_data_in_leaf': 98, 'lambda_l1': 0.7743221183884839, 'lambda_l2': 3.8195084584317094}. Best is trial 14 with value: -0.9116917696622929.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[2288]\ttrain's ndcg@5: 0.991956\tvalid's ndcg@5: 0.969892\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttrain's ndcg@5: 0.846572\tvalid's ndcg@5: 0.845246\n",
      "[200]\ttrain's ndcg@5: 0.851778\tvalid's ndcg@5: 0.849003\n",
      "[300]\ttrain's ndcg@5: 0.856674\tvalid's ndcg@5: 0.853253\n",
      "[400]\ttrain's ndcg@5: 0.860578\tvalid's ndcg@5: 0.857218\n",
      "[500]\ttrain's ndcg@5: 0.864612\tvalid's ndcg@5: 0.860562\n",
      "[600]\ttrain's ndcg@5: 0.867924\tvalid's ndcg@5: 0.86345\n",
      "[700]\ttrain's ndcg@5: 0.871452\tvalid's ndcg@5: 0.866756\n",
      "[800]\ttrain's ndcg@5: 0.875214\tvalid's ndcg@5: 0.870025\n",
      "[900]\ttrain's ndcg@5: 0.878639\tvalid's ndcg@5: 0.872692\n",
      "[1000]\ttrain's ndcg@5: 0.881901\tvalid's ndcg@5: 0.875846\n",
      "[1100]\ttrain's ndcg@5: 0.885165\tvalid's ndcg@5: 0.878936\n",
      "[1200]\ttrain's ndcg@5: 0.888327\tvalid's ndcg@5: 0.882343\n",
      "[1300]\ttrain's ndcg@5: 0.891017\tvalid's ndcg@5: 0.884708\n",
      "[1400]\ttrain's ndcg@5: 0.893687\tvalid's ndcg@5: 0.886711\n",
      "[1500]\ttrain's ndcg@5: 0.896316\tvalid's ndcg@5: 0.888894\n",
      "[1600]\ttrain's ndcg@5: 0.898643\tvalid's ndcg@5: 0.890826\n",
      "[1700]\ttrain's ndcg@5: 0.900819\tvalid's ndcg@5: 0.892608\n",
      "[1800]\ttrain's ndcg@5: 0.902937\tvalid's ndcg@5: 0.894309\n",
      "[1900]\ttrain's ndcg@5: 0.904852\tvalid's ndcg@5: 0.896386\n",
      "[2000]\ttrain's ndcg@5: 0.906577\tvalid's ndcg@5: 0.898374\n",
      "[2100]\ttrain's ndcg@5: 0.908141\tvalid's ndcg@5: 0.899662\n",
      "[2200]\ttrain's ndcg@5: 0.909747\tvalid's ndcg@5: 0.901218\n",
      "[2300]\ttrain's ndcg@5: 0.911342\tvalid's ndcg@5: 0.902923\n",
      "[2400]\ttrain's ndcg@5: 0.912797\tvalid's ndcg@5: 0.904232\n",
      "[2500]\ttrain's ndcg@5: 0.914325\tvalid's ndcg@5: 0.90559\n",
      "[2600]\ttrain's ndcg@5: 0.915672\tvalid's ndcg@5: 0.906754\n",
      "[2700]\ttrain's ndcg@5: 0.916888\tvalid's ndcg@5: 0.907824\n",
      "[2800]\ttrain's ndcg@5: 0.917995\tvalid's ndcg@5: 0.908883\n",
      "[2900]\ttrain's ndcg@5: 0.919158\tvalid's ndcg@5: 0.909939\n",
      "[3000]\ttrain's ndcg@5: 0.920393\tvalid's ndcg@5: 0.910891\n",
      "[3100]\ttrain's ndcg@5: 0.92163\tvalid's ndcg@5: 0.912118\n",
      "[3200]\ttrain's ndcg@5: 0.922831\tvalid's ndcg@5: 0.913124\n",
      "[3300]\ttrain's ndcg@5: 0.92385\tvalid's ndcg@5: 0.913841\n",
      "[3400]\ttrain's ndcg@5: 0.924801\tvalid's ndcg@5: 0.914856\n",
      "[3500]\ttrain's ndcg@5: 0.925732\tvalid's ndcg@5: 0.915487\n",
      "[3600]\ttrain's ndcg@5: 0.926677\tvalid's ndcg@5: 0.91623\n",
      "[3700]\ttrain's ndcg@5: 0.927498\tvalid's ndcg@5: 0.91668\n",
      "[3800]\ttrain's ndcg@5: 0.928323\tvalid's ndcg@5: 0.917159\n",
      "[3900]\ttrain's ndcg@5: 0.929176\tvalid's ndcg@5: 0.91779\n",
      "[4000]\ttrain's ndcg@5: 0.930031\tvalid's ndcg@5: 0.918601\n",
      "[4100]\ttrain's ndcg@5: 0.930825\tvalid's ndcg@5: 0.919245\n",
      "[4200]\ttrain's ndcg@5: 0.931534\tvalid's ndcg@5: 0.91999\n",
      "[4300]\ttrain's ndcg@5: 0.932289\tvalid's ndcg@5: 0.920708\n",
      "[4400]\ttrain's ndcg@5: 0.932982\tvalid's ndcg@5: 0.921371\n",
      "[4500]\ttrain's ndcg@5: 0.933674\tvalid's ndcg@5: 0.922008\n",
      "[4600]\ttrain's ndcg@5: 0.934351\tvalid's ndcg@5: 0.922804\n",
      "[4700]\ttrain's ndcg@5: 0.934947\tvalid's ndcg@5: 0.923558\n",
      "[4800]\ttrain's ndcg@5: 0.935748\tvalid's ndcg@5: 0.924103\n",
      "[4900]\ttrain's ndcg@5: 0.936388\tvalid's ndcg@5: 0.924628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 13:10:29,148] Trial 20 finished with value: -0.9251946603114609 and parameters: {'num_leaves': 39, 'learning_rate': 0.0016260083096329367, 'feature_fraction': 0.8560267027421075, 'min_data_in_leaf': 179, 'lambda_l1': 1.5163209647367974, 'lambda_l2': 2.7893664627986325}. Best is trial 14 with value: -0.9116917696622929.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5000]\ttrain's ndcg@5: 0.93701\tvalid's ndcg@5: 0.925181\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[4996]\ttrain's ndcg@5: 0.93698\tvalid's ndcg@5: 0.925195\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttrain's ndcg@5: 0.8486\tvalid's ndcg@5: 0.847142\n",
      "[200]\ttrain's ndcg@5: 0.853618\tvalid's ndcg@5: 0.851117\n",
      "[300]\ttrain's ndcg@5: 0.857909\tvalid's ndcg@5: 0.855025\n",
      "[400]\ttrain's ndcg@5: 0.860716\tvalid's ndcg@5: 0.857175\n",
      "[500]\ttrain's ndcg@5: 0.863534\tvalid's ndcg@5: 0.859082\n",
      "[600]\ttrain's ndcg@5: 0.865695\tvalid's ndcg@5: 0.860861\n",
      "[700]\ttrain's ndcg@5: 0.868022\tvalid's ndcg@5: 0.862623\n",
      "[800]\ttrain's ndcg@5: 0.870171\tvalid's ndcg@5: 0.864764\n",
      "[900]\ttrain's ndcg@5: 0.872496\tvalid's ndcg@5: 0.866931\n",
      "[1000]\ttrain's ndcg@5: 0.874674\tvalid's ndcg@5: 0.868656\n",
      "[1100]\ttrain's ndcg@5: 0.876748\tvalid's ndcg@5: 0.870293\n",
      "[1200]\ttrain's ndcg@5: 0.87885\tvalid's ndcg@5: 0.871982\n",
      "[1300]\ttrain's ndcg@5: 0.880803\tvalid's ndcg@5: 0.873866\n",
      "[1400]\ttrain's ndcg@5: 0.882807\tvalid's ndcg@5: 0.875644\n",
      "[1500]\ttrain's ndcg@5: 0.884667\tvalid's ndcg@5: 0.87755\n",
      "[1600]\ttrain's ndcg@5: 0.886734\tvalid's ndcg@5: 0.879568\n",
      "[1700]\ttrain's ndcg@5: 0.888691\tvalid's ndcg@5: 0.881154\n",
      "[1800]\ttrain's ndcg@5: 0.890561\tvalid's ndcg@5: 0.882883\n",
      "[1900]\ttrain's ndcg@5: 0.892468\tvalid's ndcg@5: 0.884639\n",
      "[2000]\ttrain's ndcg@5: 0.894288\tvalid's ndcg@5: 0.886034\n",
      "[2100]\ttrain's ndcg@5: 0.895987\tvalid's ndcg@5: 0.887392\n",
      "[2200]\ttrain's ndcg@5: 0.897644\tvalid's ndcg@5: 0.888578\n",
      "[2300]\ttrain's ndcg@5: 0.899078\tvalid's ndcg@5: 0.889665\n",
      "[2400]\ttrain's ndcg@5: 0.900538\tvalid's ndcg@5: 0.891093\n",
      "[2500]\ttrain's ndcg@5: 0.90206\tvalid's ndcg@5: 0.892265\n",
      "[2600]\ttrain's ndcg@5: 0.903366\tvalid's ndcg@5: 0.893574\n",
      "[2700]\ttrain's ndcg@5: 0.904748\tvalid's ndcg@5: 0.895047\n",
      "[2800]\ttrain's ndcg@5: 0.906022\tvalid's ndcg@5: 0.896156\n",
      "[2900]\ttrain's ndcg@5: 0.907293\tvalid's ndcg@5: 0.897126\n",
      "[3000]\ttrain's ndcg@5: 0.908464\tvalid's ndcg@5: 0.898134\n",
      "[3100]\ttrain's ndcg@5: 0.909597\tvalid's ndcg@5: 0.899215\n",
      "[3200]\ttrain's ndcg@5: 0.910692\tvalid's ndcg@5: 0.900441\n",
      "[3300]\ttrain's ndcg@5: 0.911765\tvalid's ndcg@5: 0.901458\n",
      "[3400]\ttrain's ndcg@5: 0.912868\tvalid's ndcg@5: 0.902658\n",
      "[3500]\ttrain's ndcg@5: 0.914044\tvalid's ndcg@5: 0.903553\n",
      "[3600]\ttrain's ndcg@5: 0.915086\tvalid's ndcg@5: 0.904511\n",
      "[3700]\ttrain's ndcg@5: 0.915998\tvalid's ndcg@5: 0.905425\n",
      "[3800]\ttrain's ndcg@5: 0.916964\tvalid's ndcg@5: 0.90629\n",
      "[3900]\ttrain's ndcg@5: 0.917829\tvalid's ndcg@5: 0.907053\n",
      "[4000]\ttrain's ndcg@5: 0.91868\tvalid's ndcg@5: 0.907687\n",
      "[4100]\ttrain's ndcg@5: 0.919482\tvalid's ndcg@5: 0.908385\n",
      "[4200]\ttrain's ndcg@5: 0.920277\tvalid's ndcg@5: 0.909082\n",
      "[4300]\ttrain's ndcg@5: 0.921077\tvalid's ndcg@5: 0.909779\n",
      "[4400]\ttrain's ndcg@5: 0.921952\tvalid's ndcg@5: 0.91036\n",
      "[4500]\ttrain's ndcg@5: 0.922753\tvalid's ndcg@5: 0.910976\n",
      "[4600]\ttrain's ndcg@5: 0.923564\tvalid's ndcg@5: 0.91183\n",
      "[4700]\ttrain's ndcg@5: 0.924309\tvalid's ndcg@5: 0.912559\n",
      "[4800]\ttrain's ndcg@5: 0.925027\tvalid's ndcg@5: 0.913042\n",
      "[4900]\ttrain's ndcg@5: 0.925708\tvalid's ndcg@5: 0.913485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 13:11:45,131] Trial 21 finished with value: -0.9139391830981642 and parameters: {'num_leaves': 48, 'learning_rate': 0.0010774285276792795, 'feature_fraction': 0.8127519420629732, 'min_data_in_leaf': 198, 'lambda_l1': 0.019676973656827274, 'lambda_l2': 4.562893232502252}. Best is trial 14 with value: -0.9116917696622929.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5000]\ttrain's ndcg@5: 0.926455\tvalid's ndcg@5: 0.913939\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[5000]\ttrain's ndcg@5: 0.926455\tvalid's ndcg@5: 0.913939\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttrain's ndcg@5: 0.847404\tvalid's ndcg@5: 0.845916\n",
      "[200]\ttrain's ndcg@5: 0.851493\tvalid's ndcg@5: 0.84933\n",
      "[300]\ttrain's ndcg@5: 0.855649\tvalid's ndcg@5: 0.852816\n",
      "[400]\ttrain's ndcg@5: 0.858658\tvalid's ndcg@5: 0.855267\n",
      "[500]\ttrain's ndcg@5: 0.861309\tvalid's ndcg@5: 0.857566\n",
      "[600]\ttrain's ndcg@5: 0.863439\tvalid's ndcg@5: 0.858877\n",
      "[700]\ttrain's ndcg@5: 0.865651\tvalid's ndcg@5: 0.860818\n",
      "[800]\ttrain's ndcg@5: 0.867918\tvalid's ndcg@5: 0.862968\n",
      "[900]\ttrain's ndcg@5: 0.870166\tvalid's ndcg@5: 0.864807\n",
      "[1000]\ttrain's ndcg@5: 0.872382\tvalid's ndcg@5: 0.866907\n",
      "[1100]\ttrain's ndcg@5: 0.874353\tvalid's ndcg@5: 0.868562\n",
      "[1200]\ttrain's ndcg@5: 0.876536\tvalid's ndcg@5: 0.87029\n",
      "[1300]\ttrain's ndcg@5: 0.878538\tvalid's ndcg@5: 0.871871\n",
      "[1400]\ttrain's ndcg@5: 0.880654\tvalid's ndcg@5: 0.87399\n",
      "[1500]\ttrain's ndcg@5: 0.88254\tvalid's ndcg@5: 0.875854\n",
      "[1600]\ttrain's ndcg@5: 0.884482\tvalid's ndcg@5: 0.877621\n",
      "[1700]\ttrain's ndcg@5: 0.886455\tvalid's ndcg@5: 0.879614\n",
      "[1800]\ttrain's ndcg@5: 0.888291\tvalid's ndcg@5: 0.881307\n",
      "[1900]\ttrain's ndcg@5: 0.890184\tvalid's ndcg@5: 0.88307\n",
      "[2000]\ttrain's ndcg@5: 0.891919\tvalid's ndcg@5: 0.884641\n",
      "[2100]\ttrain's ndcg@5: 0.893694\tvalid's ndcg@5: 0.886141\n",
      "[2200]\ttrain's ndcg@5: 0.895385\tvalid's ndcg@5: 0.887506\n",
      "[2300]\ttrain's ndcg@5: 0.897003\tvalid's ndcg@5: 0.88847\n",
      "[2400]\ttrain's ndcg@5: 0.898525\tvalid's ndcg@5: 0.889957\n",
      "[2500]\ttrain's ndcg@5: 0.900075\tvalid's ndcg@5: 0.891089\n",
      "[2600]\ttrain's ndcg@5: 0.901306\tvalid's ndcg@5: 0.89231\n",
      "[2700]\ttrain's ndcg@5: 0.902484\tvalid's ndcg@5: 0.893654\n",
      "[2800]\ttrain's ndcg@5: 0.903842\tvalid's ndcg@5: 0.894841\n",
      "[2900]\ttrain's ndcg@5: 0.90527\tvalid's ndcg@5: 0.895939\n",
      "[3000]\ttrain's ndcg@5: 0.906502\tvalid's ndcg@5: 0.897036\n",
      "[3100]\ttrain's ndcg@5: 0.907655\tvalid's ndcg@5: 0.898015\n",
      "[3200]\ttrain's ndcg@5: 0.90869\tvalid's ndcg@5: 0.899176\n",
      "[3300]\ttrain's ndcg@5: 0.909789\tvalid's ndcg@5: 0.900234\n",
      "[3400]\ttrain's ndcg@5: 0.910862\tvalid's ndcg@5: 0.901239\n",
      "[3500]\ttrain's ndcg@5: 0.91194\tvalid's ndcg@5: 0.901981\n",
      "[3600]\ttrain's ndcg@5: 0.912873\tvalid's ndcg@5: 0.903103\n",
      "[3700]\ttrain's ndcg@5: 0.913861\tvalid's ndcg@5: 0.904212\n",
      "[3800]\ttrain's ndcg@5: 0.914786\tvalid's ndcg@5: 0.905061\n",
      "[3900]\ttrain's ndcg@5: 0.915642\tvalid's ndcg@5: 0.905793\n",
      "[4000]\ttrain's ndcg@5: 0.916622\tvalid's ndcg@5: 0.906571\n",
      "[4100]\ttrain's ndcg@5: 0.917441\tvalid's ndcg@5: 0.907175\n",
      "[4200]\ttrain's ndcg@5: 0.918337\tvalid's ndcg@5: 0.907932\n",
      "[4300]\ttrain's ndcg@5: 0.919194\tvalid's ndcg@5: 0.908658\n",
      "[4400]\ttrain's ndcg@5: 0.919989\tvalid's ndcg@5: 0.909151\n",
      "[4500]\ttrain's ndcg@5: 0.920696\tvalid's ndcg@5: 0.909751\n",
      "[4600]\ttrain's ndcg@5: 0.921468\tvalid's ndcg@5: 0.9103\n",
      "[4700]\ttrain's ndcg@5: 0.922221\tvalid's ndcg@5: 0.911023\n",
      "[4800]\ttrain's ndcg@5: 0.922911\tvalid's ndcg@5: 0.911927\n",
      "[4900]\ttrain's ndcg@5: 0.923624\tvalid's ndcg@5: 0.912578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 13:12:56,717] Trial 22 finished with value: -0.9132461311866453 and parameters: {'num_leaves': 45, 'learning_rate': 0.0010369676659605577, 'feature_fraction': 0.8262678368947506, 'min_data_in_leaf': 184, 'lambda_l1': 0.4623379022410875, 'lambda_l2': 4.555608655102446}. Best is trial 14 with value: -0.9116917696622929.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5000]\ttrain's ndcg@5: 0.924305\tvalid's ndcg@5: 0.913246\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[5000]\ttrain's ndcg@5: 0.924305\tvalid's ndcg@5: 0.913246\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttrain's ndcg@5: 0.855155\tvalid's ndcg@5: 0.852084\n",
      "[200]\ttrain's ndcg@5: 0.8606\tvalid's ndcg@5: 0.856903\n",
      "[300]\ttrain's ndcg@5: 0.865685\tvalid's ndcg@5: 0.86075\n",
      "[400]\ttrain's ndcg@5: 0.869564\tvalid's ndcg@5: 0.863636\n",
      "[500]\ttrain's ndcg@5: 0.87312\tvalid's ndcg@5: 0.866564\n",
      "[600]\ttrain's ndcg@5: 0.876318\tvalid's ndcg@5: 0.869114\n",
      "[700]\ttrain's ndcg@5: 0.879806\tvalid's ndcg@5: 0.872501\n",
      "[800]\ttrain's ndcg@5: 0.882471\tvalid's ndcg@5: 0.87469\n",
      "[900]\ttrain's ndcg@5: 0.885496\tvalid's ndcg@5: 0.877681\n",
      "[1000]\ttrain's ndcg@5: 0.888475\tvalid's ndcg@5: 0.880481\n",
      "[1100]\ttrain's ndcg@5: 0.89133\tvalid's ndcg@5: 0.882892\n",
      "[1200]\ttrain's ndcg@5: 0.894051\tvalid's ndcg@5: 0.885262\n",
      "[1300]\ttrain's ndcg@5: 0.896869\tvalid's ndcg@5: 0.887102\n",
      "[1400]\ttrain's ndcg@5: 0.89914\tvalid's ndcg@5: 0.888905\n",
      "[1500]\ttrain's ndcg@5: 0.901404\tvalid's ndcg@5: 0.890728\n",
      "[1600]\ttrain's ndcg@5: 0.903748\tvalid's ndcg@5: 0.892604\n",
      "[1700]\ttrain's ndcg@5: 0.905782\tvalid's ndcg@5: 0.894563\n",
      "[1800]\ttrain's ndcg@5: 0.907881\tvalid's ndcg@5: 0.896509\n",
      "[1900]\ttrain's ndcg@5: 0.909863\tvalid's ndcg@5: 0.89813\n",
      "[2000]\ttrain's ndcg@5: 0.91179\tvalid's ndcg@5: 0.899738\n",
      "[2100]\ttrain's ndcg@5: 0.913471\tvalid's ndcg@5: 0.901224\n",
      "[2200]\ttrain's ndcg@5: 0.915072\tvalid's ndcg@5: 0.903109\n",
      "[2300]\ttrain's ndcg@5: 0.916571\tvalid's ndcg@5: 0.904536\n",
      "[2400]\ttrain's ndcg@5: 0.917966\tvalid's ndcg@5: 0.905597\n",
      "[2500]\ttrain's ndcg@5: 0.919356\tvalid's ndcg@5: 0.906876\n",
      "[2600]\ttrain's ndcg@5: 0.920765\tvalid's ndcg@5: 0.908029\n",
      "[2700]\ttrain's ndcg@5: 0.922179\tvalid's ndcg@5: 0.909322\n",
      "[2800]\ttrain's ndcg@5: 0.923463\tvalid's ndcg@5: 0.910578\n",
      "[2900]\ttrain's ndcg@5: 0.92467\tvalid's ndcg@5: 0.91166\n",
      "[3000]\ttrain's ndcg@5: 0.925952\tvalid's ndcg@5: 0.912845\n",
      "[3100]\ttrain's ndcg@5: 0.927009\tvalid's ndcg@5: 0.913773\n",
      "[3200]\ttrain's ndcg@5: 0.928006\tvalid's ndcg@5: 0.914588\n",
      "[3300]\ttrain's ndcg@5: 0.929015\tvalid's ndcg@5: 0.915488\n",
      "[3400]\ttrain's ndcg@5: 0.930076\tvalid's ndcg@5: 0.916253\n",
      "[3500]\ttrain's ndcg@5: 0.931088\tvalid's ndcg@5: 0.916784\n",
      "[3600]\ttrain's ndcg@5: 0.932031\tvalid's ndcg@5: 0.917556\n",
      "[3700]\ttrain's ndcg@5: 0.932935\tvalid's ndcg@5: 0.918347\n",
      "[3800]\ttrain's ndcg@5: 0.933765\tvalid's ndcg@5: 0.91901\n",
      "[3900]\ttrain's ndcg@5: 0.934671\tvalid's ndcg@5: 0.919602\n",
      "[4000]\ttrain's ndcg@5: 0.935433\tvalid's ndcg@5: 0.920118\n",
      "[4100]\ttrain's ndcg@5: 0.9363\tvalid's ndcg@5: 0.920946\n",
      "[4200]\ttrain's ndcg@5: 0.937186\tvalid's ndcg@5: 0.921759\n",
      "[4300]\ttrain's ndcg@5: 0.937968\tvalid's ndcg@5: 0.922498\n",
      "[4400]\ttrain's ndcg@5: 0.938773\tvalid's ndcg@5: 0.923049\n",
      "[4500]\ttrain's ndcg@5: 0.939522\tvalid's ndcg@5: 0.923661\n",
      "[4600]\ttrain's ndcg@5: 0.940194\tvalid's ndcg@5: 0.924213\n",
      "[4700]\ttrain's ndcg@5: 0.940945\tvalid's ndcg@5: 0.924744\n",
      "[4800]\ttrain's ndcg@5: 0.941562\tvalid's ndcg@5: 0.925214\n",
      "[4900]\ttrain's ndcg@5: 0.942161\tvalid's ndcg@5: 0.925794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 13:14:21,611] Trial 23 finished with value: -0.9261946323558976 and parameters: {'num_leaves': 55, 'learning_rate': 0.001693689455432931, 'feature_fraction': 0.7652682130485706, 'min_data_in_leaf': 157, 'lambda_l1': 0.36431109114500126, 'lambda_l2': 3.7389761915178505}. Best is trial 14 with value: -0.9116917696622929.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5000]\ttrain's ndcg@5: 0.942733\tvalid's ndcg@5: 0.926195\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[5000]\ttrain's ndcg@5: 0.942733\tvalid's ndcg@5: 0.926195\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttrain's ndcg@5: 0.854028\tvalid's ndcg@5: 0.851611\n",
      "[200]\ttrain's ndcg@5: 0.861286\tvalid's ndcg@5: 0.85743\n",
      "[300]\ttrain's ndcg@5: 0.868046\tvalid's ndcg@5: 0.863335\n",
      "[400]\ttrain's ndcg@5: 0.873946\tvalid's ndcg@5: 0.869011\n",
      "[500]\ttrain's ndcg@5: 0.879571\tvalid's ndcg@5: 0.873334\n",
      "[600]\ttrain's ndcg@5: 0.884703\tvalid's ndcg@5: 0.878524\n",
      "[700]\ttrain's ndcg@5: 0.889409\tvalid's ndcg@5: 0.882789\n",
      "[800]\ttrain's ndcg@5: 0.894167\tvalid's ndcg@5: 0.88689\n",
      "[900]\ttrain's ndcg@5: 0.898316\tvalid's ndcg@5: 0.890236\n",
      "[1000]\ttrain's ndcg@5: 0.902004\tvalid's ndcg@5: 0.893346\n",
      "[1100]\ttrain's ndcg@5: 0.905372\tvalid's ndcg@5: 0.896192\n",
      "[1200]\ttrain's ndcg@5: 0.908365\tvalid's ndcg@5: 0.899477\n",
      "[1300]\ttrain's ndcg@5: 0.911212\tvalid's ndcg@5: 0.902057\n",
      "[1400]\ttrain's ndcg@5: 0.913709\tvalid's ndcg@5: 0.904308\n",
      "[1500]\ttrain's ndcg@5: 0.916109\tvalid's ndcg@5: 0.906862\n",
      "[1600]\ttrain's ndcg@5: 0.918433\tvalid's ndcg@5: 0.90871\n",
      "[1700]\ttrain's ndcg@5: 0.920419\tvalid's ndcg@5: 0.91031\n",
      "[1800]\ttrain's ndcg@5: 0.922455\tvalid's ndcg@5: 0.912113\n",
      "[1900]\ttrain's ndcg@5: 0.924329\tvalid's ndcg@5: 0.913828\n",
      "[2000]\ttrain's ndcg@5: 0.926027\tvalid's ndcg@5: 0.914823\n",
      "[2100]\ttrain's ndcg@5: 0.927622\tvalid's ndcg@5: 0.916403\n",
      "[2200]\ttrain's ndcg@5: 0.929108\tvalid's ndcg@5: 0.9177\n",
      "[2300]\ttrain's ndcg@5: 0.930482\tvalid's ndcg@5: 0.918844\n",
      "[2400]\ttrain's ndcg@5: 0.931719\tvalid's ndcg@5: 0.919718\n",
      "[2500]\ttrain's ndcg@5: 0.933097\tvalid's ndcg@5: 0.920966\n",
      "[2600]\ttrain's ndcg@5: 0.934217\tvalid's ndcg@5: 0.92182\n",
      "[2700]\ttrain's ndcg@5: 0.935346\tvalid's ndcg@5: 0.922935\n",
      "[2800]\ttrain's ndcg@5: 0.936634\tvalid's ndcg@5: 0.923897\n",
      "[2900]\ttrain's ndcg@5: 0.937784\tvalid's ndcg@5: 0.92495\n",
      "[3000]\ttrain's ndcg@5: 0.93884\tvalid's ndcg@5: 0.925766\n",
      "[3100]\ttrain's ndcg@5: 0.939953\tvalid's ndcg@5: 0.926708\n",
      "[3200]\ttrain's ndcg@5: 0.941022\tvalid's ndcg@5: 0.92751\n",
      "[3300]\ttrain's ndcg@5: 0.942003\tvalid's ndcg@5: 0.928371\n",
      "[3400]\ttrain's ndcg@5: 0.942827\tvalid's ndcg@5: 0.929082\n",
      "[3500]\ttrain's ndcg@5: 0.943717\tvalid's ndcg@5: 0.929738\n",
      "[3600]\ttrain's ndcg@5: 0.944573\tvalid's ndcg@5: 0.930448\n",
      "[3700]\ttrain's ndcg@5: 0.945435\tvalid's ndcg@5: 0.931052\n",
      "[3800]\ttrain's ndcg@5: 0.946236\tvalid's ndcg@5: 0.931778\n",
      "[3900]\ttrain's ndcg@5: 0.947028\tvalid's ndcg@5: 0.932601\n",
      "[4000]\ttrain's ndcg@5: 0.947839\tvalid's ndcg@5: 0.93324\n",
      "[4100]\ttrain's ndcg@5: 0.948574\tvalid's ndcg@5: 0.933939\n",
      "[4200]\ttrain's ndcg@5: 0.949318\tvalid's ndcg@5: 0.934258\n",
      "[4300]\ttrain's ndcg@5: 0.949997\tvalid's ndcg@5: 0.934962\n",
      "[4400]\ttrain's ndcg@5: 0.950662\tvalid's ndcg@5: 0.935414\n",
      "[4500]\ttrain's ndcg@5: 0.951365\tvalid's ndcg@5: 0.936011\n",
      "[4600]\ttrain's ndcg@5: 0.952023\tvalid's ndcg@5: 0.93632\n",
      "[4700]\ttrain's ndcg@5: 0.952641\tvalid's ndcg@5: 0.936902\n",
      "[4800]\ttrain's ndcg@5: 0.953192\tvalid's ndcg@5: 0.937345\n",
      "[4900]\ttrain's ndcg@5: 0.953784\tvalid's ndcg@5: 0.937755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 13:15:29,366] Trial 24 finished with value: -0.938086649338521 and parameters: {'num_leaves': 42, 'learning_rate': 0.002791302548349264, 'feature_fraction': 0.8081275391660196, 'min_data_in_leaf': 148, 'lambda_l1': 0.4708015691740024, 'lambda_l2': 4.608097210047903}. Best is trial 14 with value: -0.9116917696622929.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5000]\ttrain's ndcg@5: 0.954379\tvalid's ndcg@5: 0.938081\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[4998]\ttrain's ndcg@5: 0.954376\tvalid's ndcg@5: 0.938087\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttrain's ndcg@5: 0.844568\tvalid's ndcg@5: 0.843417\n",
      "[200]\ttrain's ndcg@5: 0.84966\tvalid's ndcg@5: 0.847392\n",
      "[300]\ttrain's ndcg@5: 0.854352\tvalid's ndcg@5: 0.851407\n",
      "[400]\ttrain's ndcg@5: 0.858053\tvalid's ndcg@5: 0.854866\n",
      "[500]\ttrain's ndcg@5: 0.861694\tvalid's ndcg@5: 0.858307\n",
      "[600]\ttrain's ndcg@5: 0.864948\tvalid's ndcg@5: 0.861426\n",
      "[700]\ttrain's ndcg@5: 0.868426\tvalid's ndcg@5: 0.864408\n",
      "[800]\ttrain's ndcg@5: 0.871629\tvalid's ndcg@5: 0.867931\n",
      "[900]\ttrain's ndcg@5: 0.875174\tvalid's ndcg@5: 0.870297\n",
      "[1000]\ttrain's ndcg@5: 0.878448\tvalid's ndcg@5: 0.873058\n",
      "[1100]\ttrain's ndcg@5: 0.881367\tvalid's ndcg@5: 0.876132\n",
      "[1200]\ttrain's ndcg@5: 0.884206\tvalid's ndcg@5: 0.878867\n",
      "[1300]\ttrain's ndcg@5: 0.887076\tvalid's ndcg@5: 0.881366\n",
      "[1400]\ttrain's ndcg@5: 0.889693\tvalid's ndcg@5: 0.883808\n",
      "[1500]\ttrain's ndcg@5: 0.892081\tvalid's ndcg@5: 0.886081\n",
      "[1600]\ttrain's ndcg@5: 0.894568\tvalid's ndcg@5: 0.888083\n",
      "[1700]\ttrain's ndcg@5: 0.896935\tvalid's ndcg@5: 0.889966\n",
      "[1800]\ttrain's ndcg@5: 0.898783\tvalid's ndcg@5: 0.891704\n",
      "[1900]\ttrain's ndcg@5: 0.900728\tvalid's ndcg@5: 0.893253\n",
      "[2000]\ttrain's ndcg@5: 0.902595\tvalid's ndcg@5: 0.894769\n",
      "[2100]\ttrain's ndcg@5: 0.904268\tvalid's ndcg@5: 0.896479\n",
      "[2200]\ttrain's ndcg@5: 0.905797\tvalid's ndcg@5: 0.898001\n",
      "[2300]\ttrain's ndcg@5: 0.907321\tvalid's ndcg@5: 0.899541\n",
      "[2400]\ttrain's ndcg@5: 0.908734\tvalid's ndcg@5: 0.90118\n",
      "[2500]\ttrain's ndcg@5: 0.910154\tvalid's ndcg@5: 0.902329\n",
      "[2600]\ttrain's ndcg@5: 0.911532\tvalid's ndcg@5: 0.903461\n",
      "[2700]\ttrain's ndcg@5: 0.912796\tvalid's ndcg@5: 0.904813\n",
      "[2800]\ttrain's ndcg@5: 0.91404\tvalid's ndcg@5: 0.905824\n",
      "[2900]\ttrain's ndcg@5: 0.915246\tvalid's ndcg@5: 0.907056\n",
      "[3000]\ttrain's ndcg@5: 0.916349\tvalid's ndcg@5: 0.908238\n",
      "[3100]\ttrain's ndcg@5: 0.917437\tvalid's ndcg@5: 0.909056\n",
      "[3200]\ttrain's ndcg@5: 0.918467\tvalid's ndcg@5: 0.910021\n",
      "[3300]\ttrain's ndcg@5: 0.919547\tvalid's ndcg@5: 0.91075\n",
      "[3400]\ttrain's ndcg@5: 0.920555\tvalid's ndcg@5: 0.911803\n",
      "[3500]\ttrain's ndcg@5: 0.9216\tvalid's ndcg@5: 0.91265\n",
      "[3600]\ttrain's ndcg@5: 0.922531\tvalid's ndcg@5: 0.913491\n",
      "[3700]\ttrain's ndcg@5: 0.923495\tvalid's ndcg@5: 0.914143\n",
      "[3800]\ttrain's ndcg@5: 0.924321\tvalid's ndcg@5: 0.914764\n",
      "[3900]\ttrain's ndcg@5: 0.92514\tvalid's ndcg@5: 0.915487\n",
      "[4000]\ttrain's ndcg@5: 0.925978\tvalid's ndcg@5: 0.91613\n",
      "[4100]\ttrain's ndcg@5: 0.926699\tvalid's ndcg@5: 0.916664\n",
      "[4200]\ttrain's ndcg@5: 0.927528\tvalid's ndcg@5: 0.91722\n",
      "[4300]\ttrain's ndcg@5: 0.928301\tvalid's ndcg@5: 0.917607\n",
      "[4400]\ttrain's ndcg@5: 0.929014\tvalid's ndcg@5: 0.918365\n",
      "[4500]\ttrain's ndcg@5: 0.929739\tvalid's ndcg@5: 0.919051\n",
      "[4600]\ttrain's ndcg@5: 0.930322\tvalid's ndcg@5: 0.919674\n",
      "[4700]\ttrain's ndcg@5: 0.930951\tvalid's ndcg@5: 0.920249\n",
      "[4800]\ttrain's ndcg@5: 0.931595\tvalid's ndcg@5: 0.921013\n",
      "[4900]\ttrain's ndcg@5: 0.932228\tvalid's ndcg@5: 0.921671\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 13:16:29,341] Trial 25 finished with value: -0.9221006655812793 and parameters: {'num_leaves': 35, 'learning_rate': 0.0014903346168002385, 'feature_fraction': 0.8560582450768023, 'min_data_in_leaf': 185, 'lambda_l1': 1.2638692128629865, 'lambda_l2': 4.994060944363538}. Best is trial 14 with value: -0.9116917696622929.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5000]\ttrain's ndcg@5: 0.932887\tvalid's ndcg@5: 0.922101\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[5000]\ttrain's ndcg@5: 0.932887\tvalid's ndcg@5: 0.922101\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttrain's ndcg@5: 0.851986\tvalid's ndcg@5: 0.849387\n",
      "[200]\ttrain's ndcg@5: 0.85818\tvalid's ndcg@5: 0.854184\n",
      "[300]\ttrain's ndcg@5: 0.863968\tvalid's ndcg@5: 0.859355\n",
      "[400]\ttrain's ndcg@5: 0.869678\tvalid's ndcg@5: 0.863993\n",
      "[500]\ttrain's ndcg@5: 0.875379\tvalid's ndcg@5: 0.868955\n",
      "[600]\ttrain's ndcg@5: 0.880353\tvalid's ndcg@5: 0.873208\n",
      "[700]\ttrain's ndcg@5: 0.88543\tvalid's ndcg@5: 0.877913\n",
      "[800]\ttrain's ndcg@5: 0.890344\tvalid's ndcg@5: 0.882099\n",
      "[900]\ttrain's ndcg@5: 0.89452\tvalid's ndcg@5: 0.885994\n",
      "[1000]\ttrain's ndcg@5: 0.898271\tvalid's ndcg@5: 0.889388\n",
      "[1100]\ttrain's ndcg@5: 0.901694\tvalid's ndcg@5: 0.89236\n",
      "[1200]\ttrain's ndcg@5: 0.904762\tvalid's ndcg@5: 0.89514\n",
      "[1300]\ttrain's ndcg@5: 0.907742\tvalid's ndcg@5: 0.8977\n",
      "[1400]\ttrain's ndcg@5: 0.910211\tvalid's ndcg@5: 0.899736\n",
      "[1500]\ttrain's ndcg@5: 0.912769\tvalid's ndcg@5: 0.902335\n",
      "[1600]\ttrain's ndcg@5: 0.915127\tvalid's ndcg@5: 0.904531\n",
      "[1700]\ttrain's ndcg@5: 0.917184\tvalid's ndcg@5: 0.906613\n",
      "[1800]\ttrain's ndcg@5: 0.919067\tvalid's ndcg@5: 0.908563\n",
      "[1900]\ttrain's ndcg@5: 0.920985\tvalid's ndcg@5: 0.910121\n",
      "[2000]\ttrain's ndcg@5: 0.922902\tvalid's ndcg@5: 0.911481\n",
      "[2100]\ttrain's ndcg@5: 0.924502\tvalid's ndcg@5: 0.912984\n",
      "[2200]\ttrain's ndcg@5: 0.926085\tvalid's ndcg@5: 0.913969\n",
      "[2300]\ttrain's ndcg@5: 0.927546\tvalid's ndcg@5: 0.915129\n",
      "[2400]\ttrain's ndcg@5: 0.928981\tvalid's ndcg@5: 0.916562\n",
      "[2500]\ttrain's ndcg@5: 0.930239\tvalid's ndcg@5: 0.917889\n",
      "[2600]\ttrain's ndcg@5: 0.931605\tvalid's ndcg@5: 0.918797\n",
      "[2700]\ttrain's ndcg@5: 0.932858\tvalid's ndcg@5: 0.919604\n",
      "[2800]\ttrain's ndcg@5: 0.93401\tvalid's ndcg@5: 0.920653\n",
      "[2900]\ttrain's ndcg@5: 0.935103\tvalid's ndcg@5: 0.921679\n",
      "[3000]\ttrain's ndcg@5: 0.936197\tvalid's ndcg@5: 0.922624\n",
      "[3100]\ttrain's ndcg@5: 0.937304\tvalid's ndcg@5: 0.923523\n",
      "[3200]\ttrain's ndcg@5: 0.93831\tvalid's ndcg@5: 0.924299\n",
      "[3300]\ttrain's ndcg@5: 0.939276\tvalid's ndcg@5: 0.924957\n",
      "[3400]\ttrain's ndcg@5: 0.940269\tvalid's ndcg@5: 0.92569\n",
      "[3500]\ttrain's ndcg@5: 0.94117\tvalid's ndcg@5: 0.926447\n",
      "[3600]\ttrain's ndcg@5: 0.942169\tvalid's ndcg@5: 0.926953\n",
      "[3700]\ttrain's ndcg@5: 0.943093\tvalid's ndcg@5: 0.927795\n",
      "[3800]\ttrain's ndcg@5: 0.943874\tvalid's ndcg@5: 0.928587\n",
      "[3900]\ttrain's ndcg@5: 0.944675\tvalid's ndcg@5: 0.929188\n",
      "[4000]\ttrain's ndcg@5: 0.945501\tvalid's ndcg@5: 0.929855\n",
      "[4100]\ttrain's ndcg@5: 0.946272\tvalid's ndcg@5: 0.930342\n",
      "[4200]\ttrain's ndcg@5: 0.946994\tvalid's ndcg@5: 0.930951\n",
      "[4300]\ttrain's ndcg@5: 0.94775\tvalid's ndcg@5: 0.931583\n",
      "[4400]\ttrain's ndcg@5: 0.948469\tvalid's ndcg@5: 0.932188\n",
      "[4500]\ttrain's ndcg@5: 0.949064\tvalid's ndcg@5: 0.932672\n",
      "[4600]\ttrain's ndcg@5: 0.949728\tvalid's ndcg@5: 0.93316\n",
      "[4700]\ttrain's ndcg@5: 0.95038\tvalid's ndcg@5: 0.933751\n",
      "[4800]\ttrain's ndcg@5: 0.951071\tvalid's ndcg@5: 0.934161\n",
      "[4900]\ttrain's ndcg@5: 0.951719\tvalid's ndcg@5: 0.934648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 13:18:59,996] Trial 26 finished with value: -0.9352598094360351 and parameters: {'num_leaves': 49, 'learning_rate': 0.0024504244067481773, 'feature_fraction': 0.888197920857513, 'min_data_in_leaf': 171, 'lambda_l1': 2.0483405633875904, 'lambda_l2': 4.128824966130777}. Best is trial 14 with value: -0.9116917696622929.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5000]\ttrain's ndcg@5: 0.952331\tvalid's ndcg@5: 0.935238\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[4999]\ttrain's ndcg@5: 0.952332\tvalid's ndcg@5: 0.93526\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttrain's ndcg@5: 0.850756\tvalid's ndcg@5: 0.848473\n",
      "[200]\ttrain's ndcg@5: 0.855297\tvalid's ndcg@5: 0.852309\n",
      "[300]\ttrain's ndcg@5: 0.859474\tvalid's ndcg@5: 0.855438\n",
      "[400]\ttrain's ndcg@5: 0.862838\tvalid's ndcg@5: 0.857607\n",
      "[500]\ttrain's ndcg@5: 0.866336\tvalid's ndcg@5: 0.860516\n",
      "[600]\ttrain's ndcg@5: 0.868787\tvalid's ndcg@5: 0.862842\n",
      "[700]\ttrain's ndcg@5: 0.871816\tvalid's ndcg@5: 0.865314\n",
      "[800]\ttrain's ndcg@5: 0.874952\tvalid's ndcg@5: 0.867996\n",
      "[900]\ttrain's ndcg@5: 0.877737\tvalid's ndcg@5: 0.870135\n",
      "[1000]\ttrain's ndcg@5: 0.880132\tvalid's ndcg@5: 0.872391\n",
      "[1100]\ttrain's ndcg@5: 0.8825\tvalid's ndcg@5: 0.874301\n",
      "[1200]\ttrain's ndcg@5: 0.88527\tvalid's ndcg@5: 0.877\n",
      "[1300]\ttrain's ndcg@5: 0.88788\tvalid's ndcg@5: 0.879514\n",
      "[1400]\ttrain's ndcg@5: 0.890554\tvalid's ndcg@5: 0.881708\n",
      "[1500]\ttrain's ndcg@5: 0.892797\tvalid's ndcg@5: 0.883792\n",
      "[1600]\ttrain's ndcg@5: 0.895365\tvalid's ndcg@5: 0.88573\n",
      "[1700]\ttrain's ndcg@5: 0.897376\tvalid's ndcg@5: 0.887569\n",
      "[1800]\ttrain's ndcg@5: 0.899259\tvalid's ndcg@5: 0.889129\n",
      "[1900]\ttrain's ndcg@5: 0.901131\tvalid's ndcg@5: 0.890601\n",
      "[2000]\ttrain's ndcg@5: 0.903035\tvalid's ndcg@5: 0.892456\n",
      "[2100]\ttrain's ndcg@5: 0.904801\tvalid's ndcg@5: 0.893942\n",
      "[2200]\ttrain's ndcg@5: 0.906548\tvalid's ndcg@5: 0.895545\n",
      "[2300]\ttrain's ndcg@5: 0.90816\tvalid's ndcg@5: 0.897067\n",
      "[2400]\ttrain's ndcg@5: 0.909739\tvalid's ndcg@5: 0.898443\n",
      "[2500]\ttrain's ndcg@5: 0.911277\tvalid's ndcg@5: 0.899916\n",
      "[2600]\ttrain's ndcg@5: 0.912666\tvalid's ndcg@5: 0.901087\n",
      "[2700]\ttrain's ndcg@5: 0.914082\tvalid's ndcg@5: 0.902471\n",
      "[2800]\ttrain's ndcg@5: 0.915262\tvalid's ndcg@5: 0.903612\n",
      "[2900]\ttrain's ndcg@5: 0.91648\tvalid's ndcg@5: 0.904541\n",
      "[3000]\ttrain's ndcg@5: 0.917787\tvalid's ndcg@5: 0.905784\n",
      "[3100]\ttrain's ndcg@5: 0.918929\tvalid's ndcg@5: 0.906708\n",
      "[3200]\ttrain's ndcg@5: 0.920043\tvalid's ndcg@5: 0.907676\n",
      "[3300]\ttrain's ndcg@5: 0.920995\tvalid's ndcg@5: 0.908295\n",
      "[3400]\ttrain's ndcg@5: 0.922082\tvalid's ndcg@5: 0.909398\n",
      "[3500]\ttrain's ndcg@5: 0.92306\tvalid's ndcg@5: 0.91036\n",
      "[3600]\ttrain's ndcg@5: 0.923984\tvalid's ndcg@5: 0.911357\n",
      "[3700]\ttrain's ndcg@5: 0.925002\tvalid's ndcg@5: 0.912053\n",
      "[3800]\ttrain's ndcg@5: 0.925894\tvalid's ndcg@5: 0.913007\n",
      "[3900]\ttrain's ndcg@5: 0.926768\tvalid's ndcg@5: 0.913651\n",
      "[4000]\ttrain's ndcg@5: 0.927648\tvalid's ndcg@5: 0.914231\n",
      "[4100]\ttrain's ndcg@5: 0.928425\tvalid's ndcg@5: 0.914916\n",
      "[4200]\ttrain's ndcg@5: 0.929302\tvalid's ndcg@5: 0.915546\n",
      "[4300]\ttrain's ndcg@5: 0.930112\tvalid's ndcg@5: 0.916162\n",
      "[4400]\ttrain's ndcg@5: 0.930838\tvalid's ndcg@5: 0.916651\n",
      "[4500]\ttrain's ndcg@5: 0.93155\tvalid's ndcg@5: 0.917291\n",
      "[4600]\ttrain's ndcg@5: 0.932211\tvalid's ndcg@5: 0.917852\n",
      "[4700]\ttrain's ndcg@5: 0.932962\tvalid's ndcg@5: 0.918496\n",
      "[4800]\ttrain's ndcg@5: 0.933781\tvalid's ndcg@5: 0.919014\n",
      "[4900]\ttrain's ndcg@5: 0.934462\tvalid's ndcg@5: 0.919548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 13:20:25,247] Trial 27 finished with value: -0.9201390257119099 and parameters: {'num_leaves': 55, 'learning_rate': 0.0013456922201492223, 'feature_fraction': 0.8392056755028624, 'min_data_in_leaf': 200, 'lambda_l1': 1.0085318262673961, 'lambda_l2': 2.750329621867805}. Best is trial 14 with value: -0.9116917696622929.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5000]\ttrain's ndcg@5: 0.935162\tvalid's ndcg@5: 0.920125\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[4998]\ttrain's ndcg@5: 0.93516\tvalid's ndcg@5: 0.920139\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttrain's ndcg@5: 0.876349\tvalid's ndcg@5: 0.871744\n",
      "[200]\ttrain's ndcg@5: 0.899806\tvalid's ndcg@5: 0.8932\n",
      "[300]\ttrain's ndcg@5: 0.913788\tvalid's ndcg@5: 0.905955\n",
      "[400]\ttrain's ndcg@5: 0.923387\tvalid's ndcg@5: 0.914715\n",
      "[500]\ttrain's ndcg@5: 0.930289\tvalid's ndcg@5: 0.920736\n",
      "[600]\ttrain's ndcg@5: 0.935832\tvalid's ndcg@5: 0.925533\n",
      "[700]\ttrain's ndcg@5: 0.940478\tvalid's ndcg@5: 0.929211\n",
      "[800]\ttrain's ndcg@5: 0.944388\tvalid's ndcg@5: 0.932378\n",
      "[900]\ttrain's ndcg@5: 0.947803\tvalid's ndcg@5: 0.935355\n",
      "[1000]\ttrain's ndcg@5: 0.950815\tvalid's ndcg@5: 0.938043\n",
      "[1100]\ttrain's ndcg@5: 0.953353\tvalid's ndcg@5: 0.940062\n",
      "[1200]\ttrain's ndcg@5: 0.955935\tvalid's ndcg@5: 0.942146\n",
      "[1300]\ttrain's ndcg@5: 0.95834\tvalid's ndcg@5: 0.943965\n",
      "[1400]\ttrain's ndcg@5: 0.960376\tvalid's ndcg@5: 0.946131\n",
      "[1500]\ttrain's ndcg@5: 0.962208\tvalid's ndcg@5: 0.947931\n",
      "[1600]\ttrain's ndcg@5: 0.9639\tvalid's ndcg@5: 0.94912\n",
      "[1700]\ttrain's ndcg@5: 0.965512\tvalid's ndcg@5: 0.950324\n",
      "[1800]\ttrain's ndcg@5: 0.96692\tvalid's ndcg@5: 0.951687\n",
      "[1900]\ttrain's ndcg@5: 0.968345\tvalid's ndcg@5: 0.952935\n",
      "[2000]\ttrain's ndcg@5: 0.969566\tvalid's ndcg@5: 0.95375\n",
      "[2100]\ttrain's ndcg@5: 0.970732\tvalid's ndcg@5: 0.954712\n",
      "[2200]\ttrain's ndcg@5: 0.971898\tvalid's ndcg@5: 0.955531\n",
      "[2300]\ttrain's ndcg@5: 0.972881\tvalid's ndcg@5: 0.956356\n",
      "[2400]\ttrain's ndcg@5: 0.973732\tvalid's ndcg@5: 0.957372\n",
      "[2500]\ttrain's ndcg@5: 0.974591\tvalid's ndcg@5: 0.957998\n",
      "[2600]\ttrain's ndcg@5: 0.975454\tvalid's ndcg@5: 0.958612\n",
      "[2700]\ttrain's ndcg@5: 0.976243\tvalid's ndcg@5: 0.959162\n",
      "[2800]\ttrain's ndcg@5: 0.976933\tvalid's ndcg@5: 0.959642\n",
      "[2900]\ttrain's ndcg@5: 0.977591\tvalid's ndcg@5: 0.96018\n",
      "[3000]\ttrain's ndcg@5: 0.978181\tvalid's ndcg@5: 0.96071\n",
      "[3100]\ttrain's ndcg@5: 0.978755\tvalid's ndcg@5: 0.96121\n",
      "[3200]\ttrain's ndcg@5: 0.979366\tvalid's ndcg@5: 0.96156\n",
      "[3300]\ttrain's ndcg@5: 0.979898\tvalid's ndcg@5: 0.961789\n",
      "[3400]\ttrain's ndcg@5: 0.980388\tvalid's ndcg@5: 0.962246\n",
      "[3500]\ttrain's ndcg@5: 0.980858\tvalid's ndcg@5: 0.96265\n",
      "[3600]\ttrain's ndcg@5: 0.981357\tvalid's ndcg@5: 0.963059\n",
      "[3700]\ttrain's ndcg@5: 0.981831\tvalid's ndcg@5: 0.963379\n",
      "[3800]\ttrain's ndcg@5: 0.982298\tvalid's ndcg@5: 0.963573\n",
      "[3900]\ttrain's ndcg@5: 0.982711\tvalid's ndcg@5: 0.964041\n",
      "[4000]\ttrain's ndcg@5: 0.983087\tvalid's ndcg@5: 0.964422\n",
      "[4100]\ttrain's ndcg@5: 0.983451\tvalid's ndcg@5: 0.964641\n",
      "[4200]\ttrain's ndcg@5: 0.983816\tvalid's ndcg@5: 0.965073\n",
      "[4300]\ttrain's ndcg@5: 0.984172\tvalid's ndcg@5: 0.965243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 13:21:10,686] Trial 28 finished with value: -0.9654180857718249 and parameters: {'num_leaves': 31, 'learning_rate': 0.014655663151451972, 'feature_fraction': 0.7992909541270723, 'min_data_in_leaf': 185, 'lambda_l1': 2.8171042734245053, 'lambda_l2': 4.437088215592638}. Best is trial 14 with value: -0.9116917696622929.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[4314]\ttrain's ndcg@5: 0.9842\tvalid's ndcg@5: 0.965418\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttrain's ndcg@5: 0.865437\tvalid's ndcg@5: 0.859698\n",
      "[200]\ttrain's ndcg@5: 0.878816\tvalid's ndcg@5: 0.870708\n",
      "[300]\ttrain's ndcg@5: 0.891699\tvalid's ndcg@5: 0.881856\n",
      "[400]\ttrain's ndcg@5: 0.902307\tvalid's ndcg@5: 0.890434\n",
      "[500]\ttrain's ndcg@5: 0.91048\tvalid's ndcg@5: 0.89788\n",
      "[600]\ttrain's ndcg@5: 0.91717\tvalid's ndcg@5: 0.904092\n",
      "[700]\ttrain's ndcg@5: 0.922465\tvalid's ndcg@5: 0.909092\n",
      "[800]\ttrain's ndcg@5: 0.927256\tvalid's ndcg@5: 0.912239\n",
      "[900]\ttrain's ndcg@5: 0.931288\tvalid's ndcg@5: 0.915696\n",
      "[1000]\ttrain's ndcg@5: 0.934993\tvalid's ndcg@5: 0.918502\n",
      "[1100]\ttrain's ndcg@5: 0.938042\tvalid's ndcg@5: 0.921278\n",
      "[1200]\ttrain's ndcg@5: 0.941005\tvalid's ndcg@5: 0.923511\n",
      "[1300]\ttrain's ndcg@5: 0.943703\tvalid's ndcg@5: 0.925458\n",
      "[1400]\ttrain's ndcg@5: 0.94617\tvalid's ndcg@5: 0.927384\n",
      "[1500]\ttrain's ndcg@5: 0.948454\tvalid's ndcg@5: 0.92934\n",
      "[1600]\ttrain's ndcg@5: 0.950515\tvalid's ndcg@5: 0.930791\n",
      "[1700]\ttrain's ndcg@5: 0.952443\tvalid's ndcg@5: 0.932284\n",
      "[1800]\ttrain's ndcg@5: 0.954267\tvalid's ndcg@5: 0.933756\n",
      "[1900]\ttrain's ndcg@5: 0.955871\tvalid's ndcg@5: 0.935067\n",
      "[2000]\ttrain's ndcg@5: 0.957394\tvalid's ndcg@5: 0.936294\n",
      "[2100]\ttrain's ndcg@5: 0.958776\tvalid's ndcg@5: 0.937482\n",
      "[2200]\ttrain's ndcg@5: 0.960181\tvalid's ndcg@5: 0.938754\n",
      "[2300]\ttrain's ndcg@5: 0.961459\tvalid's ndcg@5: 0.939515\n",
      "[2400]\ttrain's ndcg@5: 0.962783\tvalid's ndcg@5: 0.94048\n",
      "[2500]\ttrain's ndcg@5: 0.963973\tvalid's ndcg@5: 0.941517\n",
      "[2600]\ttrain's ndcg@5: 0.965155\tvalid's ndcg@5: 0.942453\n",
      "[2700]\ttrain's ndcg@5: 0.966174\tvalid's ndcg@5: 0.943409\n",
      "[2800]\ttrain's ndcg@5: 0.967219\tvalid's ndcg@5: 0.944076\n",
      "[2900]\ttrain's ndcg@5: 0.968278\tvalid's ndcg@5: 0.944751\n",
      "[3000]\ttrain's ndcg@5: 0.96918\tvalid's ndcg@5: 0.945599\n",
      "[3100]\ttrain's ndcg@5: 0.970072\tvalid's ndcg@5: 0.946515\n",
      "[3200]\ttrain's ndcg@5: 0.970994\tvalid's ndcg@5: 0.947064\n",
      "[3300]\ttrain's ndcg@5: 0.971783\tvalid's ndcg@5: 0.947725\n",
      "[3400]\ttrain's ndcg@5: 0.972563\tvalid's ndcg@5: 0.948255\n",
      "[3500]\ttrain's ndcg@5: 0.973362\tvalid's ndcg@5: 0.948796\n",
      "[3600]\ttrain's ndcg@5: 0.974041\tvalid's ndcg@5: 0.949432\n",
      "[3700]\ttrain's ndcg@5: 0.974711\tvalid's ndcg@5: 0.950224\n",
      "[3800]\ttrain's ndcg@5: 0.975333\tvalid's ndcg@5: 0.9508\n",
      "[3900]\ttrain's ndcg@5: 0.975953\tvalid's ndcg@5: 0.951173\n",
      "[4000]\ttrain's ndcg@5: 0.976568\tvalid's ndcg@5: 0.951548\n",
      "[4100]\ttrain's ndcg@5: 0.977183\tvalid's ndcg@5: 0.952006\n",
      "[4200]\ttrain's ndcg@5: 0.977759\tvalid's ndcg@5: 0.952596\n",
      "[4300]\ttrain's ndcg@5: 0.978301\tvalid's ndcg@5: 0.952954\n",
      "[4400]\ttrain's ndcg@5: 0.978775\tvalid's ndcg@5: 0.953493\n",
      "[4500]\ttrain's ndcg@5: 0.979292\tvalid's ndcg@5: 0.953947\n",
      "[4600]\ttrain's ndcg@5: 0.979786\tvalid's ndcg@5: 0.954388\n",
      "[4700]\ttrain's ndcg@5: 0.980215\tvalid's ndcg@5: 0.95473\n",
      "[4800]\ttrain's ndcg@5: 0.980656\tvalid's ndcg@5: 0.955025\n",
      "[4900]\ttrain's ndcg@5: 0.981084\tvalid's ndcg@5: 0.955361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 13:22:41,677] Trial 29 finished with value: -0.9557648989145013 and parameters: {'num_leaves': 63, 'learning_rate': 0.006291463978309513, 'feature_fraction': 0.8803296416762687, 'min_data_in_leaf': 110, 'lambda_l1': 0.355309236790717, 'lambda_l2': 3.5749131988052905}. Best is trial 14 with value: -0.9116917696622929.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5000]\ttrain's ndcg@5: 0.981517\tvalid's ndcg@5: 0.955755\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[4998]\ttrain's ndcg@5: 0.981503\tvalid's ndcg@5: 0.955765\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttrain's ndcg@5: 0.916874\tvalid's ndcg@5: 0.904684\n",
      "[200]\ttrain's ndcg@5: 0.940384\tvalid's ndcg@5: 0.924151\n",
      "[300]\ttrain's ndcg@5: 0.95345\tvalid's ndcg@5: 0.933765\n",
      "[400]\ttrain's ndcg@5: 0.962272\tvalid's ndcg@5: 0.940865\n",
      "[500]\ttrain's ndcg@5: 0.968774\tvalid's ndcg@5: 0.945865\n",
      "[600]\ttrain's ndcg@5: 0.973466\tvalid's ndcg@5: 0.949172\n",
      "[700]\ttrain's ndcg@5: 0.977105\tvalid's ndcg@5: 0.951907\n",
      "[800]\ttrain's ndcg@5: 0.979863\tvalid's ndcg@5: 0.954509\n",
      "[900]\ttrain's ndcg@5: 0.982199\tvalid's ndcg@5: 0.956678\n",
      "[1000]\ttrain's ndcg@5: 0.984113\tvalid's ndcg@5: 0.958544\n",
      "[1100]\ttrain's ndcg@5: 0.985723\tvalid's ndcg@5: 0.9595\n",
      "[1200]\ttrain's ndcg@5: 0.987105\tvalid's ndcg@5: 0.960733\n",
      "[1300]\ttrain's ndcg@5: 0.988362\tvalid's ndcg@5: 0.961645\n",
      "[1400]\ttrain's ndcg@5: 0.989234\tvalid's ndcg@5: 0.9625\n",
      "[1500]\ttrain's ndcg@5: 0.990067\tvalid's ndcg@5: 0.963306\n",
      "[1600]\ttrain's ndcg@5: 0.990723\tvalid's ndcg@5: 0.963824\n",
      "[1700]\ttrain's ndcg@5: 0.991297\tvalid's ndcg@5: 0.964445\n",
      "[1800]\ttrain's ndcg@5: 0.991731\tvalid's ndcg@5: 0.964973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 13:23:12,820] Trial 30 finished with value: -0.9650828214556206 and parameters: {'num_leaves': 58, 'learning_rate': 0.040045292762755036, 'feature_fraction': 0.7354008633578737, 'min_data_in_leaf': 142, 'lambda_l1': 0.670913127124309, 'lambda_l2': 4.676462705889813}. Best is trial 14 with value: -0.9116917696622929.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1798]\ttrain's ndcg@5: 0.991718\tvalid's ndcg@5: 0.965083\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttrain's ndcg@5: 0.847555\tvalid's ndcg@5: 0.845843\n",
      "[200]\ttrain's ndcg@5: 0.851556\tvalid's ndcg@5: 0.84957\n",
      "[300]\ttrain's ndcg@5: 0.855796\tvalid's ndcg@5: 0.853156\n",
      "[400]\ttrain's ndcg@5: 0.858943\tvalid's ndcg@5: 0.855411\n",
      "[500]\ttrain's ndcg@5: 0.86154\tvalid's ndcg@5: 0.857229\n",
      "[600]\ttrain's ndcg@5: 0.863703\tvalid's ndcg@5: 0.859072\n",
      "[700]\ttrain's ndcg@5: 0.865949\tvalid's ndcg@5: 0.860895\n",
      "[800]\ttrain's ndcg@5: 0.868179\tvalid's ndcg@5: 0.863207\n",
      "[900]\ttrain's ndcg@5: 0.870551\tvalid's ndcg@5: 0.865062\n",
      "[1000]\ttrain's ndcg@5: 0.87259\tvalid's ndcg@5: 0.867297\n",
      "[1100]\ttrain's ndcg@5: 0.874662\tvalid's ndcg@5: 0.86896\n",
      "[1200]\ttrain's ndcg@5: 0.877012\tvalid's ndcg@5: 0.870909\n",
      "[1300]\ttrain's ndcg@5: 0.878925\tvalid's ndcg@5: 0.872349\n",
      "[1400]\ttrain's ndcg@5: 0.881003\tvalid's ndcg@5: 0.874551\n",
      "[1500]\ttrain's ndcg@5: 0.882943\tvalid's ndcg@5: 0.876227\n",
      "[1600]\ttrain's ndcg@5: 0.885075\tvalid's ndcg@5: 0.878236\n",
      "[1700]\ttrain's ndcg@5: 0.887017\tvalid's ndcg@5: 0.880006\n",
      "[1800]\ttrain's ndcg@5: 0.888833\tvalid's ndcg@5: 0.881727\n",
      "[1900]\ttrain's ndcg@5: 0.890644\tvalid's ndcg@5: 0.883616\n",
      "[2000]\ttrain's ndcg@5: 0.892487\tvalid's ndcg@5: 0.885221\n",
      "[2100]\ttrain's ndcg@5: 0.894258\tvalid's ndcg@5: 0.886329\n",
      "[2200]\ttrain's ndcg@5: 0.895821\tvalid's ndcg@5: 0.887764\n",
      "[2300]\ttrain's ndcg@5: 0.897448\tvalid's ndcg@5: 0.888954\n",
      "[2400]\ttrain's ndcg@5: 0.898965\tvalid's ndcg@5: 0.89005\n",
      "[2500]\ttrain's ndcg@5: 0.900387\tvalid's ndcg@5: 0.891469\n",
      "[2600]\ttrain's ndcg@5: 0.901663\tvalid's ndcg@5: 0.89262\n",
      "[2700]\ttrain's ndcg@5: 0.903005\tvalid's ndcg@5: 0.893806\n",
      "[2800]\ttrain's ndcg@5: 0.904434\tvalid's ndcg@5: 0.894878\n",
      "[2900]\ttrain's ndcg@5: 0.905738\tvalid's ndcg@5: 0.896005\n",
      "[3000]\ttrain's ndcg@5: 0.907019\tvalid's ndcg@5: 0.897256\n",
      "[3100]\ttrain's ndcg@5: 0.908116\tvalid's ndcg@5: 0.898374\n",
      "[3200]\ttrain's ndcg@5: 0.909211\tvalid's ndcg@5: 0.899397\n",
      "[3300]\ttrain's ndcg@5: 0.910299\tvalid's ndcg@5: 0.900445\n",
      "[3400]\ttrain's ndcg@5: 0.911455\tvalid's ndcg@5: 0.901413\n",
      "[3500]\ttrain's ndcg@5: 0.912457\tvalid's ndcg@5: 0.902094\n",
      "[3600]\ttrain's ndcg@5: 0.913346\tvalid's ndcg@5: 0.903106\n",
      "[3700]\ttrain's ndcg@5: 0.914261\tvalid's ndcg@5: 0.903966\n",
      "[3800]\ttrain's ndcg@5: 0.915185\tvalid's ndcg@5: 0.905071\n",
      "[3900]\ttrain's ndcg@5: 0.916162\tvalid's ndcg@5: 0.905768\n",
      "[4000]\ttrain's ndcg@5: 0.917043\tvalid's ndcg@5: 0.906608\n",
      "[4100]\ttrain's ndcg@5: 0.917823\tvalid's ndcg@5: 0.907733\n",
      "[4200]\ttrain's ndcg@5: 0.918661\tvalid's ndcg@5: 0.908327\n",
      "[4300]\ttrain's ndcg@5: 0.919526\tvalid's ndcg@5: 0.909075\n",
      "[4400]\ttrain's ndcg@5: 0.920374\tvalid's ndcg@5: 0.909715\n",
      "[4500]\ttrain's ndcg@5: 0.921155\tvalid's ndcg@5: 0.910322\n",
      "[4600]\ttrain's ndcg@5: 0.921942\tvalid's ndcg@5: 0.91096\n",
      "[4700]\ttrain's ndcg@5: 0.922701\tvalid's ndcg@5: 0.911551\n",
      "[4800]\ttrain's ndcg@5: 0.923416\tvalid's ndcg@5: 0.912279\n",
      "[4900]\ttrain's ndcg@5: 0.92412\tvalid's ndcg@5: 0.912969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 13:24:27,962] Trial 31 finished with value: -0.9135076395655084 and parameters: {'num_leaves': 46, 'learning_rate': 0.0010411272399330459, 'feature_fraction': 0.8268320711801888, 'min_data_in_leaf': 186, 'lambda_l1': 0.29828260117564614, 'lambda_l2': 4.057888121818955}. Best is trial 14 with value: -0.9116917696622929.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5000]\ttrain's ndcg@5: 0.924776\tvalid's ndcg@5: 0.913508\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[5000]\ttrain's ndcg@5: 0.924776\tvalid's ndcg@5: 0.913508\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttrain's ndcg@5: 0.851044\tvalid's ndcg@5: 0.849325\n",
      "[200]\ttrain's ndcg@5: 0.856512\tvalid's ndcg@5: 0.853774\n",
      "[300]\ttrain's ndcg@5: 0.860496\tvalid's ndcg@5: 0.85729\n",
      "[400]\ttrain's ndcg@5: 0.864178\tvalid's ndcg@5: 0.860196\n",
      "[500]\ttrain's ndcg@5: 0.867638\tvalid's ndcg@5: 0.863323\n",
      "[600]\ttrain's ndcg@5: 0.870373\tvalid's ndcg@5: 0.866127\n",
      "[700]\ttrain's ndcg@5: 0.873219\tvalid's ndcg@5: 0.868487\n",
      "[800]\ttrain's ndcg@5: 0.87607\tvalid's ndcg@5: 0.870695\n",
      "[900]\ttrain's ndcg@5: 0.878896\tvalid's ndcg@5: 0.873253\n",
      "[1000]\ttrain's ndcg@5: 0.881444\tvalid's ndcg@5: 0.875512\n",
      "[1100]\ttrain's ndcg@5: 0.883839\tvalid's ndcg@5: 0.877561\n",
      "[1200]\ttrain's ndcg@5: 0.886475\tvalid's ndcg@5: 0.879969\n",
      "[1300]\ttrain's ndcg@5: 0.889097\tvalid's ndcg@5: 0.882346\n",
      "[1400]\ttrain's ndcg@5: 0.891391\tvalid's ndcg@5: 0.884402\n",
      "[1500]\ttrain's ndcg@5: 0.893652\tvalid's ndcg@5: 0.886505\n",
      "[1600]\ttrain's ndcg@5: 0.895916\tvalid's ndcg@5: 0.888161\n",
      "[1700]\ttrain's ndcg@5: 0.897973\tvalid's ndcg@5: 0.889783\n",
      "[1800]\ttrain's ndcg@5: 0.900117\tvalid's ndcg@5: 0.891527\n",
      "[1900]\ttrain's ndcg@5: 0.901833\tvalid's ndcg@5: 0.893125\n",
      "[2000]\ttrain's ndcg@5: 0.90364\tvalid's ndcg@5: 0.894771\n",
      "[2100]\ttrain's ndcg@5: 0.905256\tvalid's ndcg@5: 0.896304\n",
      "[2200]\ttrain's ndcg@5: 0.906997\tvalid's ndcg@5: 0.897885\n",
      "[2300]\ttrain's ndcg@5: 0.908451\tvalid's ndcg@5: 0.899237\n",
      "[2400]\ttrain's ndcg@5: 0.910007\tvalid's ndcg@5: 0.900806\n",
      "[2500]\ttrain's ndcg@5: 0.911428\tvalid's ndcg@5: 0.90236\n",
      "[2600]\ttrain's ndcg@5: 0.912821\tvalid's ndcg@5: 0.903463\n",
      "[2700]\ttrain's ndcg@5: 0.914117\tvalid's ndcg@5: 0.904611\n",
      "[2800]\ttrain's ndcg@5: 0.91526\tvalid's ndcg@5: 0.905814\n",
      "[2900]\ttrain's ndcg@5: 0.916553\tvalid's ndcg@5: 0.906975\n",
      "[3000]\ttrain's ndcg@5: 0.917654\tvalid's ndcg@5: 0.907864\n",
      "[3100]\ttrain's ndcg@5: 0.918682\tvalid's ndcg@5: 0.908846\n",
      "[3200]\ttrain's ndcg@5: 0.91989\tvalid's ndcg@5: 0.909676\n",
      "[3300]\ttrain's ndcg@5: 0.92095\tvalid's ndcg@5: 0.910457\n",
      "[3400]\ttrain's ndcg@5: 0.92199\tvalid's ndcg@5: 0.911273\n",
      "[3500]\ttrain's ndcg@5: 0.92292\tvalid's ndcg@5: 0.912128\n",
      "[3600]\ttrain's ndcg@5: 0.923801\tvalid's ndcg@5: 0.912942\n",
      "[3700]\ttrain's ndcg@5: 0.924716\tvalid's ndcg@5: 0.913883\n",
      "[3800]\ttrain's ndcg@5: 0.925617\tvalid's ndcg@5: 0.914646\n",
      "[3900]\ttrain's ndcg@5: 0.926418\tvalid's ndcg@5: 0.915199\n",
      "[4000]\ttrain's ndcg@5: 0.927216\tvalid's ndcg@5: 0.915847\n",
      "[4100]\ttrain's ndcg@5: 0.927971\tvalid's ndcg@5: 0.916394\n",
      "[4200]\ttrain's ndcg@5: 0.928822\tvalid's ndcg@5: 0.917321\n",
      "[4300]\ttrain's ndcg@5: 0.929544\tvalid's ndcg@5: 0.918052\n",
      "[4400]\ttrain's ndcg@5: 0.930183\tvalid's ndcg@5: 0.918758\n",
      "[4500]\ttrain's ndcg@5: 0.930964\tvalid's ndcg@5: 0.919268\n",
      "[4600]\ttrain's ndcg@5: 0.93173\tvalid's ndcg@5: 0.919747\n",
      "[4700]\ttrain's ndcg@5: 0.932452\tvalid's ndcg@5: 0.920272\n",
      "[4800]\ttrain's ndcg@5: 0.933177\tvalid's ndcg@5: 0.920816\n",
      "[4900]\ttrain's ndcg@5: 0.933801\tvalid's ndcg@5: 0.921446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 13:25:36,121] Trial 32 finished with value: -0.9219950422597198 and parameters: {'num_leaves': 42, 'learning_rate': 0.0014573514228819015, 'feature_fraction': 0.7699078984211365, 'min_data_in_leaf': 186, 'lambda_l1': 0.5118583767910101, 'lambda_l2': 4.724077650017804}. Best is trial 14 with value: -0.9116917696622929.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5000]\ttrain's ndcg@5: 0.934429\tvalid's ndcg@5: 0.921995\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[5000]\ttrain's ndcg@5: 0.934429\tvalid's ndcg@5: 0.921995\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttrain's ndcg@5: 0.847247\tvalid's ndcg@5: 0.845514\n",
      "[200]\ttrain's ndcg@5: 0.851338\tvalid's ndcg@5: 0.849189\n",
      "[300]\ttrain's ndcg@5: 0.855446\tvalid's ndcg@5: 0.852698\n",
      "[400]\ttrain's ndcg@5: 0.858347\tvalid's ndcg@5: 0.855077\n",
      "[500]\ttrain's ndcg@5: 0.861009\tvalid's ndcg@5: 0.857273\n",
      "[600]\ttrain's ndcg@5: 0.863169\tvalid's ndcg@5: 0.858628\n",
      "[700]\ttrain's ndcg@5: 0.865313\tvalid's ndcg@5: 0.860434\n",
      "[800]\ttrain's ndcg@5: 0.867495\tvalid's ndcg@5: 0.862161\n",
      "[900]\ttrain's ndcg@5: 0.869828\tvalid's ndcg@5: 0.8643\n",
      "[1000]\ttrain's ndcg@5: 0.871778\tvalid's ndcg@5: 0.866301\n",
      "[1100]\ttrain's ndcg@5: 0.873786\tvalid's ndcg@5: 0.868134\n",
      "[1200]\ttrain's ndcg@5: 0.876078\tvalid's ndcg@5: 0.869985\n",
      "[1300]\ttrain's ndcg@5: 0.878171\tvalid's ndcg@5: 0.871587\n",
      "[1400]\ttrain's ndcg@5: 0.880269\tvalid's ndcg@5: 0.873266\n",
      "[1500]\ttrain's ndcg@5: 0.882095\tvalid's ndcg@5: 0.87534\n",
      "[1600]\ttrain's ndcg@5: 0.884009\tvalid's ndcg@5: 0.877461\n",
      "[1700]\ttrain's ndcg@5: 0.885853\tvalid's ndcg@5: 0.879322\n",
      "[1800]\ttrain's ndcg@5: 0.887731\tvalid's ndcg@5: 0.880978\n",
      "[1900]\ttrain's ndcg@5: 0.889617\tvalid's ndcg@5: 0.882703\n",
      "[2000]\ttrain's ndcg@5: 0.89142\tvalid's ndcg@5: 0.883883\n",
      "[2100]\ttrain's ndcg@5: 0.893099\tvalid's ndcg@5: 0.885536\n",
      "[2200]\ttrain's ndcg@5: 0.894742\tvalid's ndcg@5: 0.886855\n",
      "[2300]\ttrain's ndcg@5: 0.896301\tvalid's ndcg@5: 0.888035\n",
      "[2400]\ttrain's ndcg@5: 0.897717\tvalid's ndcg@5: 0.889218\n",
      "[2500]\ttrain's ndcg@5: 0.899181\tvalid's ndcg@5: 0.89056\n",
      "[2600]\ttrain's ndcg@5: 0.900638\tvalid's ndcg@5: 0.891915\n",
      "[2700]\ttrain's ndcg@5: 0.901911\tvalid's ndcg@5: 0.892845\n",
      "[2800]\ttrain's ndcg@5: 0.903184\tvalid's ndcg@5: 0.894189\n",
      "[2900]\ttrain's ndcg@5: 0.904478\tvalid's ndcg@5: 0.895276\n",
      "[3000]\ttrain's ndcg@5: 0.905776\tvalid's ndcg@5: 0.896223\n",
      "[3100]\ttrain's ndcg@5: 0.906943\tvalid's ndcg@5: 0.897305\n",
      "[3200]\ttrain's ndcg@5: 0.907992\tvalid's ndcg@5: 0.898192\n",
      "[3300]\ttrain's ndcg@5: 0.909124\tvalid's ndcg@5: 0.899367\n",
      "[3400]\ttrain's ndcg@5: 0.910196\tvalid's ndcg@5: 0.900533\n",
      "[3500]\ttrain's ndcg@5: 0.91123\tvalid's ndcg@5: 0.901561\n",
      "[3600]\ttrain's ndcg@5: 0.912141\tvalid's ndcg@5: 0.902398\n",
      "[3700]\ttrain's ndcg@5: 0.913247\tvalid's ndcg@5: 0.903241\n",
      "[3800]\ttrain's ndcg@5: 0.9141\tvalid's ndcg@5: 0.904229\n",
      "[3900]\ttrain's ndcg@5: 0.914976\tvalid's ndcg@5: 0.904838\n",
      "[4000]\ttrain's ndcg@5: 0.915952\tvalid's ndcg@5: 0.905799\n",
      "[4100]\ttrain's ndcg@5: 0.916862\tvalid's ndcg@5: 0.906857\n",
      "[4200]\ttrain's ndcg@5: 0.917666\tvalid's ndcg@5: 0.90761\n",
      "[4300]\ttrain's ndcg@5: 0.918509\tvalid's ndcg@5: 0.908252\n",
      "[4400]\ttrain's ndcg@5: 0.919321\tvalid's ndcg@5: 0.908933\n",
      "[4500]\ttrain's ndcg@5: 0.92021\tvalid's ndcg@5: 0.909536\n",
      "[4600]\ttrain's ndcg@5: 0.920933\tvalid's ndcg@5: 0.910129\n",
      "[4700]\ttrain's ndcg@5: 0.921695\tvalid's ndcg@5: 0.91093\n",
      "[4800]\ttrain's ndcg@5: 0.922401\tvalid's ndcg@5: 0.911545\n",
      "[4900]\ttrain's ndcg@5: 0.923129\tvalid's ndcg@5: 0.912305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 13:26:47,056] Trial 33 finished with value: -0.9129876601460147 and parameters: {'num_leaves': 45, 'learning_rate': 0.001016873884197654, 'feature_fraction': 0.8241635122745453, 'min_data_in_leaf': 166, 'lambda_l1': 0.011758135308752892, 'lambda_l2': 4.424948414858561}. Best is trial 14 with value: -0.9116917696622929.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5000]\ttrain's ndcg@5: 0.923763\tvalid's ndcg@5: 0.912988\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[5000]\ttrain's ndcg@5: 0.923763\tvalid's ndcg@5: 0.912988\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttrain's ndcg@5: 0.848841\tvalid's ndcg@5: 0.847399\n",
      "[200]\ttrain's ndcg@5: 0.85558\tvalid's ndcg@5: 0.853504\n",
      "[300]\ttrain's ndcg@5: 0.860549\tvalid's ndcg@5: 0.857984\n",
      "[400]\ttrain's ndcg@5: 0.865516\tvalid's ndcg@5: 0.862313\n",
      "[500]\ttrain's ndcg@5: 0.869923\tvalid's ndcg@5: 0.866534\n",
      "[600]\ttrain's ndcg@5: 0.874079\tvalid's ndcg@5: 0.870066\n",
      "[700]\ttrain's ndcg@5: 0.878271\tvalid's ndcg@5: 0.873451\n",
      "[800]\ttrain's ndcg@5: 0.882266\tvalid's ndcg@5: 0.877266\n",
      "[900]\ttrain's ndcg@5: 0.886126\tvalid's ndcg@5: 0.880947\n",
      "[1000]\ttrain's ndcg@5: 0.889755\tvalid's ndcg@5: 0.884241\n",
      "[1100]\ttrain's ndcg@5: 0.892964\tvalid's ndcg@5: 0.887044\n",
      "[1200]\ttrain's ndcg@5: 0.896196\tvalid's ndcg@5: 0.889955\n",
      "[1300]\ttrain's ndcg@5: 0.898964\tvalid's ndcg@5: 0.892549\n",
      "[1400]\ttrain's ndcg@5: 0.901551\tvalid's ndcg@5: 0.894841\n",
      "[1500]\ttrain's ndcg@5: 0.903768\tvalid's ndcg@5: 0.896825\n",
      "[1600]\ttrain's ndcg@5: 0.905989\tvalid's ndcg@5: 0.899349\n",
      "[1700]\ttrain's ndcg@5: 0.907957\tvalid's ndcg@5: 0.901418\n",
      "[1800]\ttrain's ndcg@5: 0.910054\tvalid's ndcg@5: 0.903069\n",
      "[1900]\ttrain's ndcg@5: 0.911834\tvalid's ndcg@5: 0.904881\n",
      "[2000]\ttrain's ndcg@5: 0.913522\tvalid's ndcg@5: 0.906406\n",
      "[2100]\ttrain's ndcg@5: 0.91518\tvalid's ndcg@5: 0.907929\n",
      "[2200]\ttrain's ndcg@5: 0.916727\tvalid's ndcg@5: 0.909291\n",
      "[2300]\ttrain's ndcg@5: 0.91809\tvalid's ndcg@5: 0.91063\n",
      "[2400]\ttrain's ndcg@5: 0.919538\tvalid's ndcg@5: 0.911768\n",
      "[2500]\ttrain's ndcg@5: 0.920838\tvalid's ndcg@5: 0.91293\n",
      "[2600]\ttrain's ndcg@5: 0.922124\tvalid's ndcg@5: 0.914181\n",
      "[2700]\ttrain's ndcg@5: 0.923204\tvalid's ndcg@5: 0.915295\n",
      "[2800]\ttrain's ndcg@5: 0.924425\tvalid's ndcg@5: 0.916218\n",
      "[2900]\ttrain's ndcg@5: 0.925453\tvalid's ndcg@5: 0.917195\n",
      "[3000]\ttrain's ndcg@5: 0.926548\tvalid's ndcg@5: 0.918313\n",
      "[3100]\ttrain's ndcg@5: 0.927658\tvalid's ndcg@5: 0.918752\n",
      "[3200]\ttrain's ndcg@5: 0.928721\tvalid's ndcg@5: 0.919682\n",
      "[3300]\ttrain's ndcg@5: 0.929666\tvalid's ndcg@5: 0.920437\n",
      "[3400]\ttrain's ndcg@5: 0.930634\tvalid's ndcg@5: 0.921186\n",
      "[3500]\ttrain's ndcg@5: 0.931511\tvalid's ndcg@5: 0.922137\n",
      "[3600]\ttrain's ndcg@5: 0.932302\tvalid's ndcg@5: 0.922863\n",
      "[3700]\ttrain's ndcg@5: 0.933052\tvalid's ndcg@5: 0.923665\n",
      "[3800]\ttrain's ndcg@5: 0.933762\tvalid's ndcg@5: 0.92438\n",
      "[3900]\ttrain's ndcg@5: 0.934578\tvalid's ndcg@5: 0.924997\n",
      "[4000]\ttrain's ndcg@5: 0.935539\tvalid's ndcg@5: 0.92559\n",
      "[4100]\ttrain's ndcg@5: 0.936256\tvalid's ndcg@5: 0.926423\n",
      "[4200]\ttrain's ndcg@5: 0.936955\tvalid's ndcg@5: 0.926989\n",
      "[4300]\ttrain's ndcg@5: 0.937722\tvalid's ndcg@5: 0.927576\n",
      "[4400]\ttrain's ndcg@5: 0.938396\tvalid's ndcg@5: 0.928351\n",
      "[4500]\ttrain's ndcg@5: 0.939113\tvalid's ndcg@5: 0.92878\n",
      "[4600]\ttrain's ndcg@5: 0.939835\tvalid's ndcg@5: 0.929243\n",
      "[4700]\ttrain's ndcg@5: 0.940501\tvalid's ndcg@5: 0.929763\n",
      "[4800]\ttrain's ndcg@5: 0.941053\tvalid's ndcg@5: 0.930207\n",
      "[4900]\ttrain's ndcg@5: 0.941639\tvalid's ndcg@5: 0.9307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 13:27:37,675] Trial 34 finished with value: -0.931124852293583 and parameters: {'num_leaves': 29, 'learning_rate': 0.002148079359492874, 'feature_fraction': 0.7906002224256233, 'min_data_in_leaf': 167, 'lambda_l1': 0.04581952742053276, 'lambda_l2': 4.294819681314078}. Best is trial 14 with value: -0.9116917696622929.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5000]\ttrain's ndcg@5: 0.942159\tvalid's ndcg@5: 0.931125\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[5000]\ttrain's ndcg@5: 0.942159\tvalid's ndcg@5: 0.931125\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttrain's ndcg@5: 0.845493\tvalid's ndcg@5: 0.843842\n",
      "[200]\ttrain's ndcg@5: 0.85002\tvalid's ndcg@5: 0.847841\n",
      "[300]\ttrain's ndcg@5: 0.854782\tvalid's ndcg@5: 0.851719\n",
      "[400]\ttrain's ndcg@5: 0.858221\tvalid's ndcg@5: 0.855103\n",
      "[500]\ttrain's ndcg@5: 0.861919\tvalid's ndcg@5: 0.858409\n",
      "[600]\ttrain's ndcg@5: 0.865099\tvalid's ndcg@5: 0.861076\n",
      "[700]\ttrain's ndcg@5: 0.868215\tvalid's ndcg@5: 0.864042\n",
      "[800]\ttrain's ndcg@5: 0.871455\tvalid's ndcg@5: 0.866803\n",
      "[900]\ttrain's ndcg@5: 0.874569\tvalid's ndcg@5: 0.869505\n",
      "[1000]\ttrain's ndcg@5: 0.877781\tvalid's ndcg@5: 0.872158\n",
      "[1100]\ttrain's ndcg@5: 0.880517\tvalid's ndcg@5: 0.874933\n",
      "[1200]\ttrain's ndcg@5: 0.883289\tvalid's ndcg@5: 0.877748\n",
      "[1300]\ttrain's ndcg@5: 0.886112\tvalid's ndcg@5: 0.879988\n",
      "[1400]\ttrain's ndcg@5: 0.888776\tvalid's ndcg@5: 0.882267\n",
      "[1500]\ttrain's ndcg@5: 0.891208\tvalid's ndcg@5: 0.884576\n",
      "[1600]\ttrain's ndcg@5: 0.893483\tvalid's ndcg@5: 0.88661\n",
      "[1700]\ttrain's ndcg@5: 0.895763\tvalid's ndcg@5: 0.888626\n",
      "[1800]\ttrain's ndcg@5: 0.897927\tvalid's ndcg@5: 0.890301\n",
      "[1900]\ttrain's ndcg@5: 0.899686\tvalid's ndcg@5: 0.891851\n",
      "[2000]\ttrain's ndcg@5: 0.901501\tvalid's ndcg@5: 0.893562\n",
      "[2100]\ttrain's ndcg@5: 0.903353\tvalid's ndcg@5: 0.895379\n",
      "[2200]\ttrain's ndcg@5: 0.904994\tvalid's ndcg@5: 0.896792\n",
      "[2300]\ttrain's ndcg@5: 0.90662\tvalid's ndcg@5: 0.898324\n",
      "[2400]\ttrain's ndcg@5: 0.907978\tvalid's ndcg@5: 0.900011\n",
      "[2500]\ttrain's ndcg@5: 0.909393\tvalid's ndcg@5: 0.901139\n",
      "[2600]\ttrain's ndcg@5: 0.910737\tvalid's ndcg@5: 0.902232\n",
      "[2700]\ttrain's ndcg@5: 0.911939\tvalid's ndcg@5: 0.903354\n",
      "[2800]\ttrain's ndcg@5: 0.913299\tvalid's ndcg@5: 0.904726\n",
      "[2900]\ttrain's ndcg@5: 0.9145\tvalid's ndcg@5: 0.905764\n",
      "[3000]\ttrain's ndcg@5: 0.915738\tvalid's ndcg@5: 0.906995\n",
      "[3100]\ttrain's ndcg@5: 0.916846\tvalid's ndcg@5: 0.908139\n",
      "[3200]\ttrain's ndcg@5: 0.917879\tvalid's ndcg@5: 0.908873\n",
      "[3300]\ttrain's ndcg@5: 0.918921\tvalid's ndcg@5: 0.909846\n",
      "[3400]\ttrain's ndcg@5: 0.91993\tvalid's ndcg@5: 0.910804\n",
      "[3500]\ttrain's ndcg@5: 0.920897\tvalid's ndcg@5: 0.911882\n",
      "[3600]\ttrain's ndcg@5: 0.921896\tvalid's ndcg@5: 0.912646\n",
      "[3700]\ttrain's ndcg@5: 0.922908\tvalid's ndcg@5: 0.913475\n",
      "[3800]\ttrain's ndcg@5: 0.923813\tvalid's ndcg@5: 0.914089\n",
      "[3900]\ttrain's ndcg@5: 0.924715\tvalid's ndcg@5: 0.914661\n",
      "[4000]\ttrain's ndcg@5: 0.925471\tvalid's ndcg@5: 0.915122\n",
      "[4100]\ttrain's ndcg@5: 0.926258\tvalid's ndcg@5: 0.915772\n",
      "[4200]\ttrain's ndcg@5: 0.927031\tvalid's ndcg@5: 0.91629\n",
      "[4300]\ttrain's ndcg@5: 0.927835\tvalid's ndcg@5: 0.916869\n",
      "[4400]\ttrain's ndcg@5: 0.928582\tvalid's ndcg@5: 0.917423\n",
      "[4500]\ttrain's ndcg@5: 0.929338\tvalid's ndcg@5: 0.918104\n",
      "[4600]\ttrain's ndcg@5: 0.930004\tvalid's ndcg@5: 0.91858\n",
      "[4700]\ttrain's ndcg@5: 0.930688\tvalid's ndcg@5: 0.919379\n",
      "[4800]\ttrain's ndcg@5: 0.931359\tvalid's ndcg@5: 0.920005\n",
      "[4900]\ttrain's ndcg@5: 0.932007\tvalid's ndcg@5: 0.920563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 13:28:41,076] Trial 35 finished with value: -0.921007634920041 and parameters: {'num_leaves': 38, 'learning_rate': 0.0014221560172224803, 'feature_fraction': 0.8619443113317244, 'min_data_in_leaf': 177, 'lambda_l1': 1.0775587987670259, 'lambda_l2': 3.2218339367347815}. Best is trial 14 with value: -0.9116917696622929.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5000]\ttrain's ndcg@5: 0.932602\tvalid's ndcg@5: 0.921008\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[5000]\ttrain's ndcg@5: 0.932602\tvalid's ndcg@5: 0.921008\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttrain's ndcg@5: 0.853473\tvalid's ndcg@5: 0.851519\n",
      "[200]\ttrain's ndcg@5: 0.860818\tvalid's ndcg@5: 0.857736\n",
      "[300]\ttrain's ndcg@5: 0.868242\tvalid's ndcg@5: 0.864698\n",
      "[400]\ttrain's ndcg@5: 0.875193\tvalid's ndcg@5: 0.870565\n",
      "[500]\ttrain's ndcg@5: 0.881618\tvalid's ndcg@5: 0.876101\n",
      "[600]\ttrain's ndcg@5: 0.887598\tvalid's ndcg@5: 0.881834\n",
      "[700]\ttrain's ndcg@5: 0.89276\tvalid's ndcg@5: 0.886133\n",
      "[800]\ttrain's ndcg@5: 0.897892\tvalid's ndcg@5: 0.890779\n",
      "[900]\ttrain's ndcg@5: 0.901956\tvalid's ndcg@5: 0.894383\n",
      "[1000]\ttrain's ndcg@5: 0.90557\tvalid's ndcg@5: 0.898107\n",
      "[1100]\ttrain's ndcg@5: 0.908745\tvalid's ndcg@5: 0.900944\n",
      "[1200]\ttrain's ndcg@5: 0.911595\tvalid's ndcg@5: 0.903577\n",
      "[1300]\ttrain's ndcg@5: 0.914555\tvalid's ndcg@5: 0.906051\n",
      "[1400]\ttrain's ndcg@5: 0.916941\tvalid's ndcg@5: 0.90808\n",
      "[1500]\ttrain's ndcg@5: 0.919065\tvalid's ndcg@5: 0.910209\n",
      "[1600]\ttrain's ndcg@5: 0.921172\tvalid's ndcg@5: 0.912208\n",
      "[1700]\ttrain's ndcg@5: 0.923355\tvalid's ndcg@5: 0.913986\n",
      "[1800]\ttrain's ndcg@5: 0.925246\tvalid's ndcg@5: 0.915433\n",
      "[1900]\ttrain's ndcg@5: 0.927069\tvalid's ndcg@5: 0.91705\n",
      "[2000]\ttrain's ndcg@5: 0.928609\tvalid's ndcg@5: 0.918395\n",
      "[2100]\ttrain's ndcg@5: 0.930065\tvalid's ndcg@5: 0.919727\n",
      "[2200]\ttrain's ndcg@5: 0.931529\tvalid's ndcg@5: 0.920824\n",
      "[2300]\ttrain's ndcg@5: 0.932825\tvalid's ndcg@5: 0.921983\n",
      "[2400]\ttrain's ndcg@5: 0.934132\tvalid's ndcg@5: 0.922918\n",
      "[2500]\ttrain's ndcg@5: 0.93544\tvalid's ndcg@5: 0.924168\n",
      "[2600]\ttrain's ndcg@5: 0.936593\tvalid's ndcg@5: 0.925205\n",
      "[2700]\ttrain's ndcg@5: 0.937697\tvalid's ndcg@5: 0.926242\n",
      "[2800]\ttrain's ndcg@5: 0.93885\tvalid's ndcg@5: 0.927076\n",
      "[2900]\ttrain's ndcg@5: 0.939943\tvalid's ndcg@5: 0.927937\n",
      "[3000]\ttrain's ndcg@5: 0.940936\tvalid's ndcg@5: 0.928694\n",
      "[3100]\ttrain's ndcg@5: 0.941832\tvalid's ndcg@5: 0.92956\n",
      "[3200]\ttrain's ndcg@5: 0.942727\tvalid's ndcg@5: 0.930218\n",
      "[3300]\ttrain's ndcg@5: 0.943714\tvalid's ndcg@5: 0.931046\n",
      "[3400]\ttrain's ndcg@5: 0.944527\tvalid's ndcg@5: 0.93193\n",
      "[3500]\ttrain's ndcg@5: 0.945415\tvalid's ndcg@5: 0.932675\n",
      "[3600]\ttrain's ndcg@5: 0.946317\tvalid's ndcg@5: 0.933442\n",
      "[3700]\ttrain's ndcg@5: 0.947131\tvalid's ndcg@5: 0.934152\n",
      "[3800]\ttrain's ndcg@5: 0.947886\tvalid's ndcg@5: 0.934695\n",
      "[3900]\ttrain's ndcg@5: 0.948661\tvalid's ndcg@5: 0.935356\n",
      "[4000]\ttrain's ndcg@5: 0.949315\tvalid's ndcg@5: 0.935747\n",
      "[4100]\ttrain's ndcg@5: 0.950066\tvalid's ndcg@5: 0.936299\n",
      "[4200]\ttrain's ndcg@5: 0.950697\tvalid's ndcg@5: 0.936852\n",
      "[4300]\ttrain's ndcg@5: 0.951292\tvalid's ndcg@5: 0.937285\n",
      "[4400]\ttrain's ndcg@5: 0.951841\tvalid's ndcg@5: 0.938086\n",
      "[4500]\ttrain's ndcg@5: 0.952508\tvalid's ndcg@5: 0.93861\n",
      "[4600]\ttrain's ndcg@5: 0.953158\tvalid's ndcg@5: 0.939071\n",
      "[4700]\ttrain's ndcg@5: 0.953747\tvalid's ndcg@5: 0.939559\n",
      "[4800]\ttrain's ndcg@5: 0.954364\tvalid's ndcg@5: 0.940095\n",
      "[4900]\ttrain's ndcg@5: 0.955042\tvalid's ndcg@5: 0.940416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 13:29:41,030] Trial 36 finished with value: -0.9409466842237734 and parameters: {'num_leaves': 36, 'learning_rate': 0.003245632094490063, 'feature_fraction': 0.8250894707229848, 'min_data_in_leaf': 192, 'lambda_l1': 3.754922994969476, 'lambda_l2': 4.758827312176335}. Best is trial 14 with value: -0.9116917696622929.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5000]\ttrain's ndcg@5: 0.95567\tvalid's ndcg@5: 0.940947\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[5000]\ttrain's ndcg@5: 0.95567\tvalid's ndcg@5: 0.940947\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttrain's ndcg@5: 0.86132\tvalid's ndcg@5: 0.857889\n",
      "[200]\ttrain's ndcg@5: 0.871601\tvalid's ndcg@5: 0.866411\n",
      "[300]\ttrain's ndcg@5: 0.881489\tvalid's ndcg@5: 0.874377\n",
      "[400]\ttrain's ndcg@5: 0.890588\tvalid's ndcg@5: 0.882813\n",
      "[500]\ttrain's ndcg@5: 0.898182\tvalid's ndcg@5: 0.888974\n",
      "[600]\ttrain's ndcg@5: 0.904735\tvalid's ndcg@5: 0.895088\n",
      "[700]\ttrain's ndcg@5: 0.91025\tvalid's ndcg@5: 0.899644\n",
      "[800]\ttrain's ndcg@5: 0.91487\tvalid's ndcg@5: 0.903998\n",
      "[900]\ttrain's ndcg@5: 0.918978\tvalid's ndcg@5: 0.9078\n",
      "[1000]\ttrain's ndcg@5: 0.922722\tvalid's ndcg@5: 0.911093\n",
      "[1100]\ttrain's ndcg@5: 0.925957\tvalid's ndcg@5: 0.913635\n",
      "[1200]\ttrain's ndcg@5: 0.928876\tvalid's ndcg@5: 0.916398\n",
      "[1300]\ttrain's ndcg@5: 0.931467\tvalid's ndcg@5: 0.918473\n",
      "[1400]\ttrain's ndcg@5: 0.933893\tvalid's ndcg@5: 0.920281\n",
      "[1500]\ttrain's ndcg@5: 0.936226\tvalid's ndcg@5: 0.922304\n",
      "[1600]\ttrain's ndcg@5: 0.938339\tvalid's ndcg@5: 0.92444\n",
      "[1700]\ttrain's ndcg@5: 0.94028\tvalid's ndcg@5: 0.925863\n",
      "[1800]\ttrain's ndcg@5: 0.942117\tvalid's ndcg@5: 0.927203\n",
      "[1900]\ttrain's ndcg@5: 0.943931\tvalid's ndcg@5: 0.928685\n",
      "[2000]\ttrain's ndcg@5: 0.94556\tvalid's ndcg@5: 0.929873\n",
      "[2100]\ttrain's ndcg@5: 0.947033\tvalid's ndcg@5: 0.930894\n",
      "[2200]\ttrain's ndcg@5: 0.948538\tvalid's ndcg@5: 0.932145\n",
      "[2300]\ttrain's ndcg@5: 0.949877\tvalid's ndcg@5: 0.933233\n",
      "[2400]\ttrain's ndcg@5: 0.951137\tvalid's ndcg@5: 0.934507\n",
      "[2500]\ttrain's ndcg@5: 0.952347\tvalid's ndcg@5: 0.935273\n",
      "[2600]\ttrain's ndcg@5: 0.953514\tvalid's ndcg@5: 0.936214\n",
      "[2700]\ttrain's ndcg@5: 0.954702\tvalid's ndcg@5: 0.936856\n",
      "[2800]\ttrain's ndcg@5: 0.955736\tvalid's ndcg@5: 0.937987\n",
      "[2900]\ttrain's ndcg@5: 0.956942\tvalid's ndcg@5: 0.938776\n",
      "[3000]\ttrain's ndcg@5: 0.957872\tvalid's ndcg@5: 0.939398\n",
      "[3100]\ttrain's ndcg@5: 0.958754\tvalid's ndcg@5: 0.940113\n",
      "[3200]\ttrain's ndcg@5: 0.959698\tvalid's ndcg@5: 0.940967\n",
      "[3300]\ttrain's ndcg@5: 0.960632\tvalid's ndcg@5: 0.941597\n",
      "[3400]\ttrain's ndcg@5: 0.961522\tvalid's ndcg@5: 0.942275\n",
      "[3500]\ttrain's ndcg@5: 0.962345\tvalid's ndcg@5: 0.942849\n",
      "[3600]\ttrain's ndcg@5: 0.963105\tvalid's ndcg@5: 0.943316\n",
      "[3700]\ttrain's ndcg@5: 0.963906\tvalid's ndcg@5: 0.943928\n",
      "[3800]\ttrain's ndcg@5: 0.964673\tvalid's ndcg@5: 0.94445\n",
      "[3900]\ttrain's ndcg@5: 0.965415\tvalid's ndcg@5: 0.944987\n",
      "[4000]\ttrain's ndcg@5: 0.966073\tvalid's ndcg@5: 0.945721\n",
      "[4100]\ttrain's ndcg@5: 0.966734\tvalid's ndcg@5: 0.946255\n",
      "[4200]\ttrain's ndcg@5: 0.967363\tvalid's ndcg@5: 0.946849\n",
      "[4300]\ttrain's ndcg@5: 0.96808\tvalid's ndcg@5: 0.947245\n",
      "[4400]\ttrain's ndcg@5: 0.968654\tvalid's ndcg@5: 0.947612\n",
      "[4500]\ttrain's ndcg@5: 0.969322\tvalid's ndcg@5: 0.948405\n",
      "[4600]\ttrain's ndcg@5: 0.969932\tvalid's ndcg@5: 0.948974\n",
      "[4700]\ttrain's ndcg@5: 0.970537\tvalid's ndcg@5: 0.949422\n",
      "[4800]\ttrain's ndcg@5: 0.971153\tvalid's ndcg@5: 0.949868\n",
      "[4900]\ttrain's ndcg@5: 0.971734\tvalid's ndcg@5: 0.950189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 13:30:54,552] Trial 37 finished with value: -0.9505136255519439 and parameters: {'num_leaves': 48, 'learning_rate': 0.004841319856807832, 'feature_fraction': 0.8009962272520421, 'min_data_in_leaf': 131, 'lambda_l1': 0.008103676767264978, 'lambda_l2': 3.531701610583383}. Best is trial 14 with value: -0.9116917696622929.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5000]\ttrain's ndcg@5: 0.97222\tvalid's ndcg@5: 0.950511\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[4999]\ttrain's ndcg@5: 0.97222\tvalid's ndcg@5: 0.950514\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttrain's ndcg@5: 0.894161\tvalid's ndcg@5: 0.886641\n",
      "[200]\ttrain's ndcg@5: 0.918572\tvalid's ndcg@5: 0.908751\n",
      "[300]\ttrain's ndcg@5: 0.932253\tvalid's ndcg@5: 0.92052\n",
      "[400]\ttrain's ndcg@5: 0.941355\tvalid's ndcg@5: 0.927389\n",
      "[500]\ttrain's ndcg@5: 0.948405\tvalid's ndcg@5: 0.932844\n",
      "[600]\ttrain's ndcg@5: 0.953837\tvalid's ndcg@5: 0.937758\n",
      "[700]\ttrain's ndcg@5: 0.958701\tvalid's ndcg@5: 0.941464\n",
      "[800]\ttrain's ndcg@5: 0.962426\tvalid's ndcg@5: 0.944164\n",
      "[900]\ttrain's ndcg@5: 0.965758\tvalid's ndcg@5: 0.946807\n",
      "[1000]\ttrain's ndcg@5: 0.968567\tvalid's ndcg@5: 0.949069\n",
      "[1100]\ttrain's ndcg@5: 0.971118\tvalid's ndcg@5: 0.951114\n",
      "[1200]\ttrain's ndcg@5: 0.97317\tvalid's ndcg@5: 0.952685\n",
      "[1300]\ttrain's ndcg@5: 0.974994\tvalid's ndcg@5: 0.954198\n",
      "[1400]\ttrain's ndcg@5: 0.976865\tvalid's ndcg@5: 0.955352\n",
      "[1500]\ttrain's ndcg@5: 0.978324\tvalid's ndcg@5: 0.956559\n",
      "[1600]\ttrain's ndcg@5: 0.979701\tvalid's ndcg@5: 0.957896\n",
      "[1700]\ttrain's ndcg@5: 0.980723\tvalid's ndcg@5: 0.958933\n",
      "[1800]\ttrain's ndcg@5: 0.981806\tvalid's ndcg@5: 0.95981\n",
      "[1900]\ttrain's ndcg@5: 0.98277\tvalid's ndcg@5: 0.960753\n",
      "[2000]\ttrain's ndcg@5: 0.983704\tvalid's ndcg@5: 0.961356\n",
      "[2100]\ttrain's ndcg@5: 0.984492\tvalid's ndcg@5: 0.962044\n",
      "[2200]\ttrain's ndcg@5: 0.985315\tvalid's ndcg@5: 0.962828\n",
      "[2300]\ttrain's ndcg@5: 0.986018\tvalid's ndcg@5: 0.963688\n",
      "[2400]\ttrain's ndcg@5: 0.986715\tvalid's ndcg@5: 0.964026\n",
      "[2500]\ttrain's ndcg@5: 0.987385\tvalid's ndcg@5: 0.964527\n",
      "[2600]\ttrain's ndcg@5: 0.988067\tvalid's ndcg@5: 0.96479\n",
      "[2700]\ttrain's ndcg@5: 0.988524\tvalid's ndcg@5: 0.965185\n",
      "[2800]\ttrain's ndcg@5: 0.988979\tvalid's ndcg@5: 0.965402\n",
      "[2900]\ttrain's ndcg@5: 0.9894\tvalid's ndcg@5: 0.965872\n",
      "[3000]\ttrain's ndcg@5: 0.989791\tvalid's ndcg@5: 0.966158\n",
      "[3100]\ttrain's ndcg@5: 0.990139\tvalid's ndcg@5: 0.966362\n",
      "[3200]\ttrain's ndcg@5: 0.990455\tvalid's ndcg@5: 0.966753\n",
      "[3300]\ttrain's ndcg@5: 0.990803\tvalid's ndcg@5: 0.967008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 13:31:37,408] Trial 38 finished with value: -0.9671021231160225 and parameters: {'num_leaves': 42, 'learning_rate': 0.022813030027605503, 'feature_fraction': 0.8412086437651572, 'min_data_in_leaf': 159, 'lambda_l1': 0.9061626884832444, 'lambda_l2': 1.0918784829526689}. Best is trial 14 with value: -0.9116917696622929.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[3313]\ttrain's ndcg@5: 0.990833\tvalid's ndcg@5: 0.967102\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttrain's ndcg@5: 0.84908\tvalid's ndcg@5: 0.847777\n",
      "[200]\ttrain's ndcg@5: 0.856044\tvalid's ndcg@5: 0.853317\n",
      "[300]\ttrain's ndcg@5: 0.861529\tvalid's ndcg@5: 0.85913\n",
      "[400]\ttrain's ndcg@5: 0.866519\tvalid's ndcg@5: 0.863798\n",
      "[500]\ttrain's ndcg@5: 0.871443\tvalid's ndcg@5: 0.868216\n",
      "[600]\ttrain's ndcg@5: 0.876113\tvalid's ndcg@5: 0.872407\n",
      "[700]\ttrain's ndcg@5: 0.880804\tvalid's ndcg@5: 0.876502\n",
      "[800]\ttrain's ndcg@5: 0.885418\tvalid's ndcg@5: 0.880772\n",
      "[900]\ttrain's ndcg@5: 0.889643\tvalid's ndcg@5: 0.88421\n",
      "[1000]\ttrain's ndcg@5: 0.893137\tvalid's ndcg@5: 0.88741\n",
      "[1100]\ttrain's ndcg@5: 0.896475\tvalid's ndcg@5: 0.890851\n",
      "[1200]\ttrain's ndcg@5: 0.899389\tvalid's ndcg@5: 0.893376\n",
      "[1300]\ttrain's ndcg@5: 0.901925\tvalid's ndcg@5: 0.896255\n",
      "[1400]\ttrain's ndcg@5: 0.904424\tvalid's ndcg@5: 0.898643\n",
      "[1500]\ttrain's ndcg@5: 0.90671\tvalid's ndcg@5: 0.900856\n",
      "[1600]\ttrain's ndcg@5: 0.908848\tvalid's ndcg@5: 0.90314\n",
      "[1700]\ttrain's ndcg@5: 0.910997\tvalid's ndcg@5: 0.904777\n",
      "[1800]\ttrain's ndcg@5: 0.912928\tvalid's ndcg@5: 0.906376\n",
      "[1900]\ttrain's ndcg@5: 0.914552\tvalid's ndcg@5: 0.907978\n",
      "[2000]\ttrain's ndcg@5: 0.916261\tvalid's ndcg@5: 0.909338\n",
      "[2100]\ttrain's ndcg@5: 0.917863\tvalid's ndcg@5: 0.910975\n",
      "[2200]\ttrain's ndcg@5: 0.919357\tvalid's ndcg@5: 0.912458\n",
      "[2300]\ttrain's ndcg@5: 0.920727\tvalid's ndcg@5: 0.913817\n",
      "[2400]\ttrain's ndcg@5: 0.922057\tvalid's ndcg@5: 0.915017\n",
      "[2500]\ttrain's ndcg@5: 0.923301\tvalid's ndcg@5: 0.915805\n",
      "[2600]\ttrain's ndcg@5: 0.924706\tvalid's ndcg@5: 0.917082\n",
      "[2700]\ttrain's ndcg@5: 0.925825\tvalid's ndcg@5: 0.918178\n",
      "[2800]\ttrain's ndcg@5: 0.927008\tvalid's ndcg@5: 0.91914\n",
      "[2900]\ttrain's ndcg@5: 0.928037\tvalid's ndcg@5: 0.919909\n",
      "[3000]\ttrain's ndcg@5: 0.928985\tvalid's ndcg@5: 0.920865\n",
      "[3100]\ttrain's ndcg@5: 0.929959\tvalid's ndcg@5: 0.921852\n",
      "[3200]\ttrain's ndcg@5: 0.930825\tvalid's ndcg@5: 0.92264\n",
      "[3300]\ttrain's ndcg@5: 0.931732\tvalid's ndcg@5: 0.923455\n",
      "[3400]\ttrain's ndcg@5: 0.932695\tvalid's ndcg@5: 0.924325\n",
      "[3500]\ttrain's ndcg@5: 0.933571\tvalid's ndcg@5: 0.92511\n",
      "[3600]\ttrain's ndcg@5: 0.934388\tvalid's ndcg@5: 0.925796\n",
      "[3700]\ttrain's ndcg@5: 0.935279\tvalid's ndcg@5: 0.926505\n",
      "[3800]\ttrain's ndcg@5: 0.936132\tvalid's ndcg@5: 0.927211\n",
      "[3900]\ttrain's ndcg@5: 0.936914\tvalid's ndcg@5: 0.92785\n",
      "[4000]\ttrain's ndcg@5: 0.937676\tvalid's ndcg@5: 0.928288\n",
      "[4100]\ttrain's ndcg@5: 0.93836\tvalid's ndcg@5: 0.928908\n",
      "[4200]\ttrain's ndcg@5: 0.939032\tvalid's ndcg@5: 0.929729\n",
      "[4300]\ttrain's ndcg@5: 0.939628\tvalid's ndcg@5: 0.930088\n",
      "[4400]\ttrain's ndcg@5: 0.940279\tvalid's ndcg@5: 0.93076\n",
      "[4500]\ttrain's ndcg@5: 0.940948\tvalid's ndcg@5: 0.931216\n",
      "[4600]\ttrain's ndcg@5: 0.941526\tvalid's ndcg@5: 0.93171\n",
      "[4700]\ttrain's ndcg@5: 0.94217\tvalid's ndcg@5: 0.9322\n",
      "[4800]\ttrain's ndcg@5: 0.942769\tvalid's ndcg@5: 0.932618\n",
      "[4900]\ttrain's ndcg@5: 0.943401\tvalid's ndcg@5: 0.933195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 13:32:23,901] Trial 39 finished with value: -0.933699958817779 and parameters: {'num_leaves': 25, 'learning_rate': 0.002451940084784993, 'feature_fraction': 0.76066193359697, 'min_data_in_leaf': 171, 'lambda_l1': 1.296291927017427, 'lambda_l2': 3.9803314394106177}. Best is trial 14 with value: -0.9116917696622929.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5000]\ttrain's ndcg@5: 0.944013\tvalid's ndcg@5: 0.933661\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[4997]\ttrain's ndcg@5: 0.943998\tvalid's ndcg@5: 0.9337\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttrain's ndcg@5: 0.849108\tvalid's ndcg@5: 0.846075\n",
      "[200]\ttrain's ndcg@5: 0.854612\tvalid's ndcg@5: 0.851258\n",
      "[300]\ttrain's ndcg@5: 0.859565\tvalid's ndcg@5: 0.85519\n",
      "[400]\ttrain's ndcg@5: 0.864178\tvalid's ndcg@5: 0.858849\n",
      "[500]\ttrain's ndcg@5: 0.868585\tvalid's ndcg@5: 0.863425\n",
      "[600]\ttrain's ndcg@5: 0.872588\tvalid's ndcg@5: 0.866356\n",
      "[700]\ttrain's ndcg@5: 0.876934\tvalid's ndcg@5: 0.870093\n",
      "[800]\ttrain's ndcg@5: 0.881033\tvalid's ndcg@5: 0.873808\n",
      "[900]\ttrain's ndcg@5: 0.884773\tvalid's ndcg@5: 0.877118\n",
      "[1000]\ttrain's ndcg@5: 0.888458\tvalid's ndcg@5: 0.880038\n",
      "[1100]\ttrain's ndcg@5: 0.891796\tvalid's ndcg@5: 0.883\n",
      "[1200]\ttrain's ndcg@5: 0.894982\tvalid's ndcg@5: 0.886163\n",
      "[1300]\ttrain's ndcg@5: 0.897894\tvalid's ndcg@5: 0.888431\n",
      "[1400]\ttrain's ndcg@5: 0.900475\tvalid's ndcg@5: 0.890948\n",
      "[1500]\ttrain's ndcg@5: 0.902957\tvalid's ndcg@5: 0.893155\n",
      "[1600]\ttrain's ndcg@5: 0.905283\tvalid's ndcg@5: 0.895108\n",
      "[1700]\ttrain's ndcg@5: 0.907618\tvalid's ndcg@5: 0.89736\n",
      "[1800]\ttrain's ndcg@5: 0.909732\tvalid's ndcg@5: 0.899252\n",
      "[1900]\ttrain's ndcg@5: 0.911608\tvalid's ndcg@5: 0.901048\n",
      "[2000]\ttrain's ndcg@5: 0.913447\tvalid's ndcg@5: 0.902619\n",
      "[2100]\ttrain's ndcg@5: 0.915248\tvalid's ndcg@5: 0.904331\n",
      "[2200]\ttrain's ndcg@5: 0.916863\tvalid's ndcg@5: 0.905737\n",
      "[2300]\ttrain's ndcg@5: 0.918282\tvalid's ndcg@5: 0.907024\n",
      "[2400]\ttrain's ndcg@5: 0.919641\tvalid's ndcg@5: 0.908487\n",
      "[2500]\ttrain's ndcg@5: 0.921101\tvalid's ndcg@5: 0.909661\n",
      "[2600]\ttrain's ndcg@5: 0.922427\tvalid's ndcg@5: 0.91081\n",
      "[2700]\ttrain's ndcg@5: 0.923839\tvalid's ndcg@5: 0.911972\n",
      "[2800]\ttrain's ndcg@5: 0.924951\tvalid's ndcg@5: 0.913125\n",
      "[2900]\ttrain's ndcg@5: 0.926153\tvalid's ndcg@5: 0.914101\n",
      "[3000]\ttrain's ndcg@5: 0.927368\tvalid's ndcg@5: 0.914871\n",
      "[3100]\ttrain's ndcg@5: 0.928362\tvalid's ndcg@5: 0.915755\n",
      "[3200]\ttrain's ndcg@5: 0.929367\tvalid's ndcg@5: 0.916638\n",
      "[3300]\ttrain's ndcg@5: 0.930326\tvalid's ndcg@5: 0.917392\n",
      "[3400]\ttrain's ndcg@5: 0.931376\tvalid's ndcg@5: 0.918183\n",
      "[3500]\ttrain's ndcg@5: 0.932313\tvalid's ndcg@5: 0.918837\n",
      "[3600]\ttrain's ndcg@5: 0.933188\tvalid's ndcg@5: 0.919581\n",
      "[3700]\ttrain's ndcg@5: 0.934072\tvalid's ndcg@5: 0.920313\n",
      "[3800]\ttrain's ndcg@5: 0.934909\tvalid's ndcg@5: 0.920952\n",
      "[3900]\ttrain's ndcg@5: 0.93567\tvalid's ndcg@5: 0.921635\n",
      "[4000]\ttrain's ndcg@5: 0.936507\tvalid's ndcg@5: 0.922463\n",
      "[4100]\ttrain's ndcg@5: 0.93737\tvalid's ndcg@5: 0.923048\n",
      "[4200]\ttrain's ndcg@5: 0.938114\tvalid's ndcg@5: 0.923771\n",
      "[4300]\ttrain's ndcg@5: 0.938837\tvalid's ndcg@5: 0.92438\n",
      "[4400]\ttrain's ndcg@5: 0.939582\tvalid's ndcg@5: 0.925004\n",
      "[4500]\ttrain's ndcg@5: 0.940261\tvalid's ndcg@5: 0.925528\n",
      "[4600]\ttrain's ndcg@5: 0.940994\tvalid's ndcg@5: 0.925983\n",
      "[4700]\ttrain's ndcg@5: 0.941647\tvalid's ndcg@5: 0.926611\n",
      "[4800]\ttrain's ndcg@5: 0.942242\tvalid's ndcg@5: 0.92718\n",
      "[4900]\ttrain's ndcg@5: 0.942908\tvalid's ndcg@5: 0.927606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 13:33:45,478] Trial 40 finished with value: -0.9279673566500127 and parameters: {'num_leaves': 52, 'learning_rate': 0.0018545176170569947, 'feature_fraction': 0.9044498876062494, 'min_data_in_leaf': 141, 'lambda_l1': 4.523369160492756, 'lambda_l2': 1.6494051582831144}. Best is trial 14 with value: -0.9116917696622929.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5000]\ttrain's ndcg@5: 0.943535\tvalid's ndcg@5: 0.927967\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[5000]\ttrain's ndcg@5: 0.943535\tvalid's ndcg@5: 0.927967\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttrain's ndcg@5: 0.84748\tvalid's ndcg@5: 0.845489\n",
      "[200]\ttrain's ndcg@5: 0.851463\tvalid's ndcg@5: 0.849783\n",
      "[300]\ttrain's ndcg@5: 0.85565\tvalid's ndcg@5: 0.852822\n",
      "[400]\ttrain's ndcg@5: 0.858506\tvalid's ndcg@5: 0.855123\n",
      "[500]\ttrain's ndcg@5: 0.8614\tvalid's ndcg@5: 0.857514\n",
      "[600]\ttrain's ndcg@5: 0.863554\tvalid's ndcg@5: 0.858951\n",
      "[700]\ttrain's ndcg@5: 0.865864\tvalid's ndcg@5: 0.861002\n",
      "[800]\ttrain's ndcg@5: 0.86797\tvalid's ndcg@5: 0.863262\n",
      "[900]\ttrain's ndcg@5: 0.870277\tvalid's ndcg@5: 0.865078\n",
      "[1000]\ttrain's ndcg@5: 0.872327\tvalid's ndcg@5: 0.867\n",
      "[1100]\ttrain's ndcg@5: 0.874216\tvalid's ndcg@5: 0.8687\n",
      "[1200]\ttrain's ndcg@5: 0.876618\tvalid's ndcg@5: 0.870666\n",
      "[1300]\ttrain's ndcg@5: 0.878767\tvalid's ndcg@5: 0.872404\n",
      "[1400]\ttrain's ndcg@5: 0.880874\tvalid's ndcg@5: 0.874399\n",
      "[1500]\ttrain's ndcg@5: 0.882681\tvalid's ndcg@5: 0.876237\n",
      "[1600]\ttrain's ndcg@5: 0.88459\tvalid's ndcg@5: 0.877903\n",
      "[1700]\ttrain's ndcg@5: 0.886608\tvalid's ndcg@5: 0.879764\n",
      "[1800]\ttrain's ndcg@5: 0.888523\tvalid's ndcg@5: 0.881449\n",
      "[1900]\ttrain's ndcg@5: 0.890329\tvalid's ndcg@5: 0.88329\n",
      "[2000]\ttrain's ndcg@5: 0.892224\tvalid's ndcg@5: 0.88474\n",
      "[2100]\ttrain's ndcg@5: 0.893877\tvalid's ndcg@5: 0.886257\n",
      "[2200]\ttrain's ndcg@5: 0.895473\tvalid's ndcg@5: 0.887409\n",
      "[2300]\ttrain's ndcg@5: 0.896934\tvalid's ndcg@5: 0.888857\n",
      "[2400]\ttrain's ndcg@5: 0.898549\tvalid's ndcg@5: 0.889974\n",
      "[2500]\ttrain's ndcg@5: 0.900011\tvalid's ndcg@5: 0.89102\n",
      "[2600]\ttrain's ndcg@5: 0.901332\tvalid's ndcg@5: 0.892186\n",
      "[2700]\ttrain's ndcg@5: 0.902705\tvalid's ndcg@5: 0.893638\n",
      "[2800]\ttrain's ndcg@5: 0.904071\tvalid's ndcg@5: 0.894915\n",
      "[2900]\ttrain's ndcg@5: 0.905425\tvalid's ndcg@5: 0.89604\n",
      "[3000]\ttrain's ndcg@5: 0.90669\tvalid's ndcg@5: 0.896949\n",
      "[3100]\ttrain's ndcg@5: 0.907735\tvalid's ndcg@5: 0.897982\n",
      "[3200]\ttrain's ndcg@5: 0.908842\tvalid's ndcg@5: 0.899073\n",
      "[3300]\ttrain's ndcg@5: 0.909909\tvalid's ndcg@5: 0.900183\n",
      "[3400]\ttrain's ndcg@5: 0.910924\tvalid's ndcg@5: 0.9014\n",
      "[3500]\ttrain's ndcg@5: 0.911941\tvalid's ndcg@5: 0.902348\n",
      "[3600]\ttrain's ndcg@5: 0.912969\tvalid's ndcg@5: 0.903268\n",
      "[3700]\ttrain's ndcg@5: 0.913919\tvalid's ndcg@5: 0.90433\n",
      "[3800]\ttrain's ndcg@5: 0.914934\tvalid's ndcg@5: 0.905072\n",
      "[3900]\ttrain's ndcg@5: 0.91581\tvalid's ndcg@5: 0.906043\n",
      "[4000]\ttrain's ndcg@5: 0.916654\tvalid's ndcg@5: 0.906701\n",
      "[4100]\ttrain's ndcg@5: 0.917499\tvalid's ndcg@5: 0.907407\n",
      "[4200]\ttrain's ndcg@5: 0.918428\tvalid's ndcg@5: 0.908297\n",
      "[4300]\ttrain's ndcg@5: 0.919237\tvalid's ndcg@5: 0.908864\n",
      "[4400]\ttrain's ndcg@5: 0.919919\tvalid's ndcg@5: 0.909464\n",
      "[4500]\ttrain's ndcg@5: 0.920693\tvalid's ndcg@5: 0.910001\n",
      "[4600]\ttrain's ndcg@5: 0.921455\tvalid's ndcg@5: 0.910559\n",
      "[4700]\ttrain's ndcg@5: 0.922139\tvalid's ndcg@5: 0.911346\n",
      "[4800]\ttrain's ndcg@5: 0.922941\tvalid's ndcg@5: 0.911923\n",
      "[4900]\ttrain's ndcg@5: 0.923764\tvalid's ndcg@5: 0.912604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 13:34:57,329] Trial 41 finished with value: -0.9130666410770332 and parameters: {'num_leaves': 45, 'learning_rate': 0.001039878457375145, 'feature_fraction': 0.8226086881473359, 'min_data_in_leaf': 188, 'lambda_l1': 0.322804975053271, 'lambda_l2': 4.408786763799273}. Best is trial 14 with value: -0.9116917696622929.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5000]\ttrain's ndcg@5: 0.924454\tvalid's ndcg@5: 0.913067\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[5000]\ttrain's ndcg@5: 0.924454\tvalid's ndcg@5: 0.913067\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttrain's ndcg@5: 0.847639\tvalid's ndcg@5: 0.846738\n",
      "[200]\ttrain's ndcg@5: 0.852008\tvalid's ndcg@5: 0.850166\n",
      "[300]\ttrain's ndcg@5: 0.856194\tvalid's ndcg@5: 0.853695\n",
      "[400]\ttrain's ndcg@5: 0.859801\tvalid's ndcg@5: 0.856208\n",
      "[500]\ttrain's ndcg@5: 0.862945\tvalid's ndcg@5: 0.859266\n",
      "[600]\ttrain's ndcg@5: 0.865481\tvalid's ndcg@5: 0.861084\n",
      "[700]\ttrain's ndcg@5: 0.868244\tvalid's ndcg@5: 0.864009\n",
      "[800]\ttrain's ndcg@5: 0.870822\tvalid's ndcg@5: 0.866623\n",
      "[900]\ttrain's ndcg@5: 0.873681\tvalid's ndcg@5: 0.86908\n",
      "[1000]\ttrain's ndcg@5: 0.876084\tvalid's ndcg@5: 0.870988\n",
      "[1100]\ttrain's ndcg@5: 0.878726\tvalid's ndcg@5: 0.872969\n",
      "[1200]\ttrain's ndcg@5: 0.881272\tvalid's ndcg@5: 0.875212\n",
      "[1300]\ttrain's ndcg@5: 0.883809\tvalid's ndcg@5: 0.877776\n",
      "[1400]\ttrain's ndcg@5: 0.886333\tvalid's ndcg@5: 0.880279\n",
      "[1500]\ttrain's ndcg@5: 0.888541\tvalid's ndcg@5: 0.882285\n",
      "[1600]\ttrain's ndcg@5: 0.890834\tvalid's ndcg@5: 0.884456\n",
      "[1700]\ttrain's ndcg@5: 0.892922\tvalid's ndcg@5: 0.886217\n",
      "[1800]\ttrain's ndcg@5: 0.894916\tvalid's ndcg@5: 0.88765\n",
      "[1900]\ttrain's ndcg@5: 0.896956\tvalid's ndcg@5: 0.889062\n",
      "[2000]\ttrain's ndcg@5: 0.898795\tvalid's ndcg@5: 0.890931\n",
      "[2100]\ttrain's ndcg@5: 0.900522\tvalid's ndcg@5: 0.892451\n",
      "[2200]\ttrain's ndcg@5: 0.902127\tvalid's ndcg@5: 0.893906\n",
      "[2300]\ttrain's ndcg@5: 0.903606\tvalid's ndcg@5: 0.895556\n",
      "[2400]\ttrain's ndcg@5: 0.905281\tvalid's ndcg@5: 0.897065\n",
      "[2500]\ttrain's ndcg@5: 0.906765\tvalid's ndcg@5: 0.898306\n",
      "[2600]\ttrain's ndcg@5: 0.908025\tvalid's ndcg@5: 0.899735\n",
      "[2700]\ttrain's ndcg@5: 0.909289\tvalid's ndcg@5: 0.900768\n",
      "[2800]\ttrain's ndcg@5: 0.910645\tvalid's ndcg@5: 0.901936\n",
      "[2900]\ttrain's ndcg@5: 0.911768\tvalid's ndcg@5: 0.903154\n",
      "[3000]\ttrain's ndcg@5: 0.91297\tvalid's ndcg@5: 0.903901\n",
      "[3100]\ttrain's ndcg@5: 0.914044\tvalid's ndcg@5: 0.905056\n",
      "[3200]\ttrain's ndcg@5: 0.915288\tvalid's ndcg@5: 0.906205\n",
      "[3300]\ttrain's ndcg@5: 0.916406\tvalid's ndcg@5: 0.907296\n",
      "[3400]\ttrain's ndcg@5: 0.917374\tvalid's ndcg@5: 0.908224\n",
      "[3500]\ttrain's ndcg@5: 0.918319\tvalid's ndcg@5: 0.909097\n",
      "[3600]\ttrain's ndcg@5: 0.919235\tvalid's ndcg@5: 0.909782\n",
      "[3700]\ttrain's ndcg@5: 0.920186\tvalid's ndcg@5: 0.91038\n",
      "[3800]\ttrain's ndcg@5: 0.921168\tvalid's ndcg@5: 0.911136\n",
      "[3900]\ttrain's ndcg@5: 0.922135\tvalid's ndcg@5: 0.911894\n",
      "[4000]\ttrain's ndcg@5: 0.922928\tvalid's ndcg@5: 0.912739\n",
      "[4100]\ttrain's ndcg@5: 0.92368\tvalid's ndcg@5: 0.913499\n",
      "[4200]\ttrain's ndcg@5: 0.924489\tvalid's ndcg@5: 0.914198\n",
      "[4300]\ttrain's ndcg@5: 0.925304\tvalid's ndcg@5: 0.915008\n",
      "[4400]\ttrain's ndcg@5: 0.926197\tvalid's ndcg@5: 0.915569\n",
      "[4500]\ttrain's ndcg@5: 0.926877\tvalid's ndcg@5: 0.916019\n",
      "[4600]\ttrain's ndcg@5: 0.927553\tvalid's ndcg@5: 0.916791\n",
      "[4700]\ttrain's ndcg@5: 0.928223\tvalid's ndcg@5: 0.917361\n",
      "[4800]\ttrain's ndcg@5: 0.928848\tvalid's ndcg@5: 0.917758\n",
      "[4900]\ttrain's ndcg@5: 0.929559\tvalid's ndcg@5: 0.91812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 13:36:03,391] Trial 42 finished with value: -0.9186420626252153 and parameters: {'num_leaves': 40, 'learning_rate': 0.0012923760539873747, 'feature_fraction': 0.8186764249259266, 'min_data_in_leaf': 200, 'lambda_l1': 0.29830380623887026, 'lambda_l2': 4.355836494058032}. Best is trial 14 with value: -0.9116917696622929.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5000]\ttrain's ndcg@5: 0.930184\tvalid's ndcg@5: 0.918606\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[4994]\ttrain's ndcg@5: 0.93015\tvalid's ndcg@5: 0.918642\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttrain's ndcg@5: 0.848081\tvalid's ndcg@5: 0.846697\n",
      "[200]\ttrain's ndcg@5: 0.85242\tvalid's ndcg@5: 0.850533\n",
      "[300]\ttrain's ndcg@5: 0.856569\tvalid's ndcg@5: 0.853235\n",
      "[400]\ttrain's ndcg@5: 0.859785\tvalid's ndcg@5: 0.855842\n",
      "[500]\ttrain's ndcg@5: 0.86294\tvalid's ndcg@5: 0.858615\n",
      "[600]\ttrain's ndcg@5: 0.865645\tvalid's ndcg@5: 0.860853\n",
      "[700]\ttrain's ndcg@5: 0.868401\tvalid's ndcg@5: 0.863556\n",
      "[800]\ttrain's ndcg@5: 0.871201\tvalid's ndcg@5: 0.866122\n",
      "[900]\ttrain's ndcg@5: 0.873938\tvalid's ndcg@5: 0.868492\n",
      "[1000]\ttrain's ndcg@5: 0.87662\tvalid's ndcg@5: 0.870324\n",
      "[1100]\ttrain's ndcg@5: 0.879139\tvalid's ndcg@5: 0.872773\n",
      "[1200]\ttrain's ndcg@5: 0.881693\tvalid's ndcg@5: 0.875078\n",
      "[1300]\ttrain's ndcg@5: 0.88423\tvalid's ndcg@5: 0.877336\n",
      "[1400]\ttrain's ndcg@5: 0.886661\tvalid's ndcg@5: 0.879925\n",
      "[1500]\ttrain's ndcg@5: 0.888923\tvalid's ndcg@5: 0.882172\n",
      "[1600]\ttrain's ndcg@5: 0.891236\tvalid's ndcg@5: 0.883929\n",
      "[1700]\ttrain's ndcg@5: 0.893315\tvalid's ndcg@5: 0.8857\n",
      "[1800]\ttrain's ndcg@5: 0.895386\tvalid's ndcg@5: 0.887477\n",
      "[1900]\ttrain's ndcg@5: 0.897326\tvalid's ndcg@5: 0.889121\n",
      "[2000]\ttrain's ndcg@5: 0.899257\tvalid's ndcg@5: 0.890658\n",
      "[2100]\ttrain's ndcg@5: 0.900874\tvalid's ndcg@5: 0.892048\n",
      "[2200]\ttrain's ndcg@5: 0.902633\tvalid's ndcg@5: 0.893536\n",
      "[2300]\ttrain's ndcg@5: 0.904119\tvalid's ndcg@5: 0.894944\n",
      "[2400]\ttrain's ndcg@5: 0.905613\tvalid's ndcg@5: 0.896407\n",
      "[2500]\ttrain's ndcg@5: 0.907013\tvalid's ndcg@5: 0.89773\n",
      "[2600]\ttrain's ndcg@5: 0.908296\tvalid's ndcg@5: 0.898902\n",
      "[2700]\ttrain's ndcg@5: 0.909647\tvalid's ndcg@5: 0.900099\n",
      "[2800]\ttrain's ndcg@5: 0.910977\tvalid's ndcg@5: 0.901302\n",
      "[2900]\ttrain's ndcg@5: 0.912288\tvalid's ndcg@5: 0.902711\n",
      "[3000]\ttrain's ndcg@5: 0.913535\tvalid's ndcg@5: 0.903838\n",
      "[3100]\ttrain's ndcg@5: 0.914678\tvalid's ndcg@5: 0.904747\n",
      "[3200]\ttrain's ndcg@5: 0.915851\tvalid's ndcg@5: 0.905648\n",
      "[3300]\ttrain's ndcg@5: 0.916835\tvalid's ndcg@5: 0.906639\n",
      "[3400]\ttrain's ndcg@5: 0.917915\tvalid's ndcg@5: 0.907643\n",
      "[3500]\ttrain's ndcg@5: 0.918868\tvalid's ndcg@5: 0.908403\n",
      "[3600]\ttrain's ndcg@5: 0.919874\tvalid's ndcg@5: 0.909208\n",
      "[3700]\ttrain's ndcg@5: 0.920794\tvalid's ndcg@5: 0.910108\n",
      "[3800]\ttrain's ndcg@5: 0.921857\tvalid's ndcg@5: 0.910913\n",
      "[3900]\ttrain's ndcg@5: 0.922819\tvalid's ndcg@5: 0.911597\n",
      "[4000]\ttrain's ndcg@5: 0.923691\tvalid's ndcg@5: 0.912375\n",
      "[4100]\ttrain's ndcg@5: 0.924538\tvalid's ndcg@5: 0.913084\n",
      "[4200]\ttrain's ndcg@5: 0.92532\tvalid's ndcg@5: 0.913783\n",
      "[4300]\ttrain's ndcg@5: 0.926072\tvalid's ndcg@5: 0.914612\n",
      "[4400]\ttrain's ndcg@5: 0.926793\tvalid's ndcg@5: 0.915178\n",
      "[4500]\ttrain's ndcg@5: 0.927598\tvalid's ndcg@5: 0.915676\n",
      "[4600]\ttrain's ndcg@5: 0.928315\tvalid's ndcg@5: 0.916219\n",
      "[4700]\ttrain's ndcg@5: 0.929022\tvalid's ndcg@5: 0.916706\n",
      "[4800]\ttrain's ndcg@5: 0.929653\tvalid's ndcg@5: 0.91735\n",
      "[4900]\ttrain's ndcg@5: 0.930317\tvalid's ndcg@5: 0.918028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 13:37:15,547] Trial 43 finished with value: -0.9187151596157888 and parameters: {'num_leaves': 45, 'learning_rate': 0.0012699617158644606, 'feature_fraction': 0.8397411093628553, 'min_data_in_leaf': 190, 'lambda_l1': 0.25293433753434136, 'lambda_l2': 4.86759865434737}. Best is trial 14 with value: -0.9116917696622929.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5000]\ttrain's ndcg@5: 0.931042\tvalid's ndcg@5: 0.918715\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[5000]\ttrain's ndcg@5: 0.931042\tvalid's ndcg@5: 0.918715\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttrain's ndcg@5: 0.848532\tvalid's ndcg@5: 0.84683\n",
      "[200]\ttrain's ndcg@5: 0.853364\tvalid's ndcg@5: 0.850938\n",
      "[300]\ttrain's ndcg@5: 0.857701\tvalid's ndcg@5: 0.854764\n",
      "[400]\ttrain's ndcg@5: 0.860729\tvalid's ndcg@5: 0.856671\n",
      "[500]\ttrain's ndcg@5: 0.863197\tvalid's ndcg@5: 0.858684\n",
      "[600]\ttrain's ndcg@5: 0.865232\tvalid's ndcg@5: 0.860407\n",
      "[700]\ttrain's ndcg@5: 0.86755\tvalid's ndcg@5: 0.862282\n",
      "[800]\ttrain's ndcg@5: 0.869495\tvalid's ndcg@5: 0.864167\n",
      "[900]\ttrain's ndcg@5: 0.87171\tvalid's ndcg@5: 0.866115\n",
      "[1000]\ttrain's ndcg@5: 0.873671\tvalid's ndcg@5: 0.867799\n",
      "[1100]\ttrain's ndcg@5: 0.875757\tvalid's ndcg@5: 0.869425\n",
      "[1200]\ttrain's ndcg@5: 0.877904\tvalid's ndcg@5: 0.871094\n",
      "[1300]\ttrain's ndcg@5: 0.879952\tvalid's ndcg@5: 0.872793\n",
      "[1400]\ttrain's ndcg@5: 0.881856\tvalid's ndcg@5: 0.874641\n",
      "[1500]\ttrain's ndcg@5: 0.883679\tvalid's ndcg@5: 0.876394\n",
      "[1600]\ttrain's ndcg@5: 0.885623\tvalid's ndcg@5: 0.87816\n",
      "[1700]\ttrain's ndcg@5: 0.887572\tvalid's ndcg@5: 0.880151\n",
      "[1800]\ttrain's ndcg@5: 0.889268\tvalid's ndcg@5: 0.881684\n",
      "[1900]\ttrain's ndcg@5: 0.891129\tvalid's ndcg@5: 0.883434\n",
      "[2000]\ttrain's ndcg@5: 0.892853\tvalid's ndcg@5: 0.884812\n",
      "[2100]\ttrain's ndcg@5: 0.894639\tvalid's ndcg@5: 0.886073\n",
      "[2200]\ttrain's ndcg@5: 0.896184\tvalid's ndcg@5: 0.887298\n",
      "[2300]\ttrain's ndcg@5: 0.897611\tvalid's ndcg@5: 0.888601\n",
      "[2400]\ttrain's ndcg@5: 0.899175\tvalid's ndcg@5: 0.889773\n",
      "[2500]\ttrain's ndcg@5: 0.900657\tvalid's ndcg@5: 0.891031\n",
      "[2600]\ttrain's ndcg@5: 0.90203\tvalid's ndcg@5: 0.892097\n",
      "[2700]\ttrain's ndcg@5: 0.903256\tvalid's ndcg@5: 0.893338\n",
      "[2800]\ttrain's ndcg@5: 0.904492\tvalid's ndcg@5: 0.894588\n",
      "[2900]\ttrain's ndcg@5: 0.905774\tvalid's ndcg@5: 0.895823\n",
      "[3000]\ttrain's ndcg@5: 0.907045\tvalid's ndcg@5: 0.896631\n",
      "[3100]\ttrain's ndcg@5: 0.908203\tvalid's ndcg@5: 0.897738\n",
      "[3200]\ttrain's ndcg@5: 0.909297\tvalid's ndcg@5: 0.898709\n",
      "[3300]\ttrain's ndcg@5: 0.910544\tvalid's ndcg@5: 0.899611\n",
      "[3400]\ttrain's ndcg@5: 0.911604\tvalid's ndcg@5: 0.90076\n",
      "[3500]\ttrain's ndcg@5: 0.912598\tvalid's ndcg@5: 0.901491\n",
      "[3600]\ttrain's ndcg@5: 0.913631\tvalid's ndcg@5: 0.902817\n",
      "[3700]\ttrain's ndcg@5: 0.914608\tvalid's ndcg@5: 0.903753\n",
      "[3800]\ttrain's ndcg@5: 0.915602\tvalid's ndcg@5: 0.904616\n",
      "[3900]\ttrain's ndcg@5: 0.916567\tvalid's ndcg@5: 0.905587\n",
      "[4000]\ttrain's ndcg@5: 0.917387\tvalid's ndcg@5: 0.906342\n",
      "[4100]\ttrain's ndcg@5: 0.918207\tvalid's ndcg@5: 0.907292\n",
      "[4200]\ttrain's ndcg@5: 0.919026\tvalid's ndcg@5: 0.907737\n",
      "[4300]\ttrain's ndcg@5: 0.919758\tvalid's ndcg@5: 0.90833\n",
      "[4400]\ttrain's ndcg@5: 0.920493\tvalid's ndcg@5: 0.90899\n",
      "[4500]\ttrain's ndcg@5: 0.921249\tvalid's ndcg@5: 0.90946\n",
      "[4600]\ttrain's ndcg@5: 0.921992\tvalid's ndcg@5: 0.91018\n",
      "[4700]\ttrain's ndcg@5: 0.922879\tvalid's ndcg@5: 0.91076\n",
      "[4800]\ttrain's ndcg@5: 0.923685\tvalid's ndcg@5: 0.91138\n",
      "[4900]\ttrain's ndcg@5: 0.924392\tvalid's ndcg@5: 0.91218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 13:38:33,187] Trial 44 finished with value: -0.9126790140243383 and parameters: {'num_leaves': 49, 'learning_rate': 0.0010324719332851968, 'feature_fraction': 0.7942848693833326, 'min_data_in_leaf': 177, 'lambda_l1': 0.5506125451445146, 'lambda_l2': 4.40191098096905}. Best is trial 14 with value: -0.9116917696622929.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5000]\ttrain's ndcg@5: 0.925026\tvalid's ndcg@5: 0.912679\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[5000]\ttrain's ndcg@5: 0.925026\tvalid's ndcg@5: 0.912679\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttrain's ndcg@5: 0.841558\tvalid's ndcg@5: 0.841152\n",
      "[200]\ttrain's ndcg@5: 0.847303\tvalid's ndcg@5: 0.845976\n",
      "[300]\ttrain's ndcg@5: 0.852107\tvalid's ndcg@5: 0.850519\n",
      "[400]\ttrain's ndcg@5: 0.855703\tvalid's ndcg@5: 0.854097\n",
      "[500]\ttrain's ndcg@5: 0.859422\tvalid's ndcg@5: 0.857513\n",
      "[600]\ttrain's ndcg@5: 0.863148\tvalid's ndcg@5: 0.860648\n",
      "[700]\ttrain's ndcg@5: 0.866424\tvalid's ndcg@5: 0.864444\n",
      "[800]\ttrain's ndcg@5: 0.869917\tvalid's ndcg@5: 0.867746\n",
      "[900]\ttrain's ndcg@5: 0.873297\tvalid's ndcg@5: 0.870838\n",
      "[1000]\ttrain's ndcg@5: 0.876544\tvalid's ndcg@5: 0.873971\n",
      "[1100]\ttrain's ndcg@5: 0.879438\tvalid's ndcg@5: 0.876655\n",
      "[1200]\ttrain's ndcg@5: 0.882328\tvalid's ndcg@5: 0.879139\n",
      "[1300]\ttrain's ndcg@5: 0.88514\tvalid's ndcg@5: 0.88187\n",
      "[1400]\ttrain's ndcg@5: 0.887624\tvalid's ndcg@5: 0.884358\n",
      "[1500]\ttrain's ndcg@5: 0.890172\tvalid's ndcg@5: 0.886632\n",
      "[1600]\ttrain's ndcg@5: 0.892187\tvalid's ndcg@5: 0.888983\n",
      "[1700]\ttrain's ndcg@5: 0.894183\tvalid's ndcg@5: 0.890753\n",
      "[1800]\ttrain's ndcg@5: 0.896147\tvalid's ndcg@5: 0.892733\n",
      "[1900]\ttrain's ndcg@5: 0.898\tvalid's ndcg@5: 0.89429\n",
      "[2000]\ttrain's ndcg@5: 0.899641\tvalid's ndcg@5: 0.896019\n",
      "[2100]\ttrain's ndcg@5: 0.901064\tvalid's ndcg@5: 0.89737\n",
      "[2200]\ttrain's ndcg@5: 0.902692\tvalid's ndcg@5: 0.898786\n",
      "[2300]\ttrain's ndcg@5: 0.90403\tvalid's ndcg@5: 0.899978\n",
      "[2400]\ttrain's ndcg@5: 0.905412\tvalid's ndcg@5: 0.901285\n",
      "[2500]\ttrain's ndcg@5: 0.906663\tvalid's ndcg@5: 0.902887\n",
      "[2600]\ttrain's ndcg@5: 0.907896\tvalid's ndcg@5: 0.903982\n",
      "[2700]\ttrain's ndcg@5: 0.90907\tvalid's ndcg@5: 0.904933\n",
      "[2800]\ttrain's ndcg@5: 0.910351\tvalid's ndcg@5: 0.905944\n",
      "[2900]\ttrain's ndcg@5: 0.911492\tvalid's ndcg@5: 0.907149\n",
      "[3000]\ttrain's ndcg@5: 0.912517\tvalid's ndcg@5: 0.908166\n",
      "[3100]\ttrain's ndcg@5: 0.913542\tvalid's ndcg@5: 0.909155\n",
      "[3200]\ttrain's ndcg@5: 0.91447\tvalid's ndcg@5: 0.910044\n",
      "[3300]\ttrain's ndcg@5: 0.915437\tvalid's ndcg@5: 0.911004\n",
      "[3400]\ttrain's ndcg@5: 0.916433\tvalid's ndcg@5: 0.911656\n",
      "[3500]\ttrain's ndcg@5: 0.91745\tvalid's ndcg@5: 0.912602\n",
      "[3600]\ttrain's ndcg@5: 0.918213\tvalid's ndcg@5: 0.913444\n",
      "[3700]\ttrain's ndcg@5: 0.918933\tvalid's ndcg@5: 0.914102\n",
      "[3800]\ttrain's ndcg@5: 0.919786\tvalid's ndcg@5: 0.914841\n",
      "[3900]\ttrain's ndcg@5: 0.920583\tvalid's ndcg@5: 0.915494\n",
      "[4000]\ttrain's ndcg@5: 0.921269\tvalid's ndcg@5: 0.916259\n",
      "[4100]\ttrain's ndcg@5: 0.922002\tvalid's ndcg@5: 0.917049\n",
      "[4200]\ttrain's ndcg@5: 0.922672\tvalid's ndcg@5: 0.917556\n",
      "[4300]\ttrain's ndcg@5: 0.923397\tvalid's ndcg@5: 0.918049\n",
      "[4400]\ttrain's ndcg@5: 0.924107\tvalid's ndcg@5: 0.918852\n",
      "[4500]\ttrain's ndcg@5: 0.924774\tvalid's ndcg@5: 0.919273\n",
      "[4600]\ttrain's ndcg@5: 0.92545\tvalid's ndcg@5: 0.919784\n",
      "[4700]\ttrain's ndcg@5: 0.926065\tvalid's ndcg@5: 0.920315\n",
      "[4800]\ttrain's ndcg@5: 0.92666\tvalid's ndcg@5: 0.920936\n",
      "[4900]\ttrain's ndcg@5: 0.927265\tvalid's ndcg@5: 0.92148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 13:39:06,186] Trial 45 finished with value: -0.9221659113026994 and parameters: {'num_leaves': 15, 'learning_rate': 0.00165825638388508, 'feature_fraction': 0.743372659306777, 'min_data_in_leaf': 176, 'lambda_l1': 0.5882888189595887, 'lambda_l2': 3.6929712976671993}. Best is trial 14 with value: -0.9116917696622929.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5000]\ttrain's ndcg@5: 0.927901\tvalid's ndcg@5: 0.922166\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[5000]\ttrain's ndcg@5: 0.927901\tvalid's ndcg@5: 0.922166\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttrain's ndcg@5: 0.84955\tvalid's ndcg@5: 0.847683\n",
      "[200]\ttrain's ndcg@5: 0.854289\tvalid's ndcg@5: 0.852292\n",
      "[300]\ttrain's ndcg@5: 0.858432\tvalid's ndcg@5: 0.855544\n",
      "[400]\ttrain's ndcg@5: 0.861321\tvalid's ndcg@5: 0.8576\n",
      "[500]\ttrain's ndcg@5: 0.864121\tvalid's ndcg@5: 0.859673\n",
      "[600]\ttrain's ndcg@5: 0.86608\tvalid's ndcg@5: 0.86122\n",
      "[700]\ttrain's ndcg@5: 0.868255\tvalid's ndcg@5: 0.862814\n",
      "[800]\ttrain's ndcg@5: 0.870131\tvalid's ndcg@5: 0.864428\n",
      "[900]\ttrain's ndcg@5: 0.872069\tvalid's ndcg@5: 0.866268\n",
      "[1000]\ttrain's ndcg@5: 0.874111\tvalid's ndcg@5: 0.867981\n",
      "[1100]\ttrain's ndcg@5: 0.875855\tvalid's ndcg@5: 0.869513\n",
      "[1200]\ttrain's ndcg@5: 0.877885\tvalid's ndcg@5: 0.871327\n",
      "[1300]\ttrain's ndcg@5: 0.879844\tvalid's ndcg@5: 0.872874\n",
      "[1400]\ttrain's ndcg@5: 0.881599\tvalid's ndcg@5: 0.874611\n",
      "[1500]\ttrain's ndcg@5: 0.883475\tvalid's ndcg@5: 0.876334\n",
      "[1600]\ttrain's ndcg@5: 0.885174\tvalid's ndcg@5: 0.877795\n",
      "[1700]\ttrain's ndcg@5: 0.88708\tvalid's ndcg@5: 0.879472\n",
      "[1800]\ttrain's ndcg@5: 0.888795\tvalid's ndcg@5: 0.88089\n",
      "[1900]\ttrain's ndcg@5: 0.890394\tvalid's ndcg@5: 0.882411\n",
      "[2000]\ttrain's ndcg@5: 0.892178\tvalid's ndcg@5: 0.883703\n",
      "[2100]\ttrain's ndcg@5: 0.893768\tvalid's ndcg@5: 0.885106\n",
      "[2200]\ttrain's ndcg@5: 0.895437\tvalid's ndcg@5: 0.88648\n",
      "[2300]\ttrain's ndcg@5: 0.896885\tvalid's ndcg@5: 0.887823\n",
      "[2400]\ttrain's ndcg@5: 0.898408\tvalid's ndcg@5: 0.888702\n",
      "[2500]\ttrain's ndcg@5: 0.899747\tvalid's ndcg@5: 0.890154\n",
      "[2600]\ttrain's ndcg@5: 0.901019\tvalid's ndcg@5: 0.890973\n",
      "[2700]\ttrain's ndcg@5: 0.902379\tvalid's ndcg@5: 0.892262\n",
      "[2800]\ttrain's ndcg@5: 0.903603\tvalid's ndcg@5: 0.89356\n",
      "[2900]\ttrain's ndcg@5: 0.904887\tvalid's ndcg@5: 0.894685\n",
      "[3000]\ttrain's ndcg@5: 0.906123\tvalid's ndcg@5: 0.895679\n",
      "[3100]\ttrain's ndcg@5: 0.907278\tvalid's ndcg@5: 0.896522\n",
      "[3200]\ttrain's ndcg@5: 0.908366\tvalid's ndcg@5: 0.897483\n",
      "[3300]\ttrain's ndcg@5: 0.909492\tvalid's ndcg@5: 0.898563\n",
      "[3400]\ttrain's ndcg@5: 0.910513\tvalid's ndcg@5: 0.899663\n",
      "[3500]\ttrain's ndcg@5: 0.911683\tvalid's ndcg@5: 0.900883\n",
      "[3600]\ttrain's ndcg@5: 0.912634\tvalid's ndcg@5: 0.901914\n",
      "[3700]\ttrain's ndcg@5: 0.91364\tvalid's ndcg@5: 0.902963\n",
      "[3800]\ttrain's ndcg@5: 0.91461\tvalid's ndcg@5: 0.903749\n",
      "[3900]\ttrain's ndcg@5: 0.915511\tvalid's ndcg@5: 0.904585\n",
      "[4000]\ttrain's ndcg@5: 0.916462\tvalid's ndcg@5: 0.90531\n",
      "[4100]\ttrain's ndcg@5: 0.917247\tvalid's ndcg@5: 0.906097\n",
      "[4200]\ttrain's ndcg@5: 0.91799\tvalid's ndcg@5: 0.906984\n",
      "[4300]\ttrain's ndcg@5: 0.918711\tvalid's ndcg@5: 0.907695\n",
      "[4400]\ttrain's ndcg@5: 0.919473\tvalid's ndcg@5: 0.908153\n",
      "[4500]\ttrain's ndcg@5: 0.920311\tvalid's ndcg@5: 0.908642\n",
      "[4600]\ttrain's ndcg@5: 0.921011\tvalid's ndcg@5: 0.909369\n",
      "[4700]\ttrain's ndcg@5: 0.921757\tvalid's ndcg@5: 0.910167\n",
      "[4800]\ttrain's ndcg@5: 0.922604\tvalid's ndcg@5: 0.910704\n",
      "[4900]\ttrain's ndcg@5: 0.923331\tvalid's ndcg@5: 0.91141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 13:40:32,193] Trial 46 finished with value: -0.9117668317732284 and parameters: {'num_leaves': 50, 'learning_rate': 0.0010007638594064386, 'feature_fraction': 0.7789157577452654, 'min_data_in_leaf': 165, 'lambda_l1': 1.7332642301669225, 'lambda_l2': 4.136102965470915}. Best is trial 14 with value: -0.9116917696622929.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5000]\ttrain's ndcg@5: 0.923953\tvalid's ndcg@5: 0.911751\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[4995]\ttrain's ndcg@5: 0.923927\tvalid's ndcg@5: 0.911767\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttrain's ndcg@5: 0.861909\tvalid's ndcg@5: 0.859024\n",
      "[200]\ttrain's ndcg@5: 0.867063\tvalid's ndcg@5: 0.862524\n",
      "[300]\ttrain's ndcg@5: 0.872522\tvalid's ndcg@5: 0.866015\n",
      "[400]\ttrain's ndcg@5: 0.876483\tvalid's ndcg@5: 0.869726\n",
      "[500]\ttrain's ndcg@5: 0.880626\tvalid's ndcg@5: 0.873508\n",
      "[600]\ttrain's ndcg@5: 0.884398\tvalid's ndcg@5: 0.876804\n",
      "[700]\ttrain's ndcg@5: 0.888359\tvalid's ndcg@5: 0.880367\n",
      "[800]\ttrain's ndcg@5: 0.891983\tvalid's ndcg@5: 0.883483\n",
      "[900]\ttrain's ndcg@5: 0.895961\tvalid's ndcg@5: 0.886434\n",
      "[1000]\ttrain's ndcg@5: 0.899171\tvalid's ndcg@5: 0.889481\n",
      "[1100]\ttrain's ndcg@5: 0.90231\tvalid's ndcg@5: 0.89194\n",
      "[1200]\ttrain's ndcg@5: 0.905128\tvalid's ndcg@5: 0.894508\n",
      "[1300]\ttrain's ndcg@5: 0.908073\tvalid's ndcg@5: 0.897047\n",
      "[1400]\ttrain's ndcg@5: 0.910648\tvalid's ndcg@5: 0.899129\n",
      "[1500]\ttrain's ndcg@5: 0.912954\tvalid's ndcg@5: 0.90166\n",
      "[1600]\ttrain's ndcg@5: 0.915167\tvalid's ndcg@5: 0.903566\n",
      "[1700]\ttrain's ndcg@5: 0.917193\tvalid's ndcg@5: 0.905326\n",
      "[1800]\ttrain's ndcg@5: 0.91901\tvalid's ndcg@5: 0.907132\n",
      "[1900]\ttrain's ndcg@5: 0.920911\tvalid's ndcg@5: 0.908799\n",
      "[2000]\ttrain's ndcg@5: 0.92266\tvalid's ndcg@5: 0.910099\n",
      "[2100]\ttrain's ndcg@5: 0.924369\tvalid's ndcg@5: 0.911363\n",
      "[2200]\ttrain's ndcg@5: 0.925979\tvalid's ndcg@5: 0.912869\n",
      "[2300]\ttrain's ndcg@5: 0.927457\tvalid's ndcg@5: 0.914012\n",
      "[2400]\ttrain's ndcg@5: 0.928841\tvalid's ndcg@5: 0.915026\n",
      "[2500]\ttrain's ndcg@5: 0.930214\tvalid's ndcg@5: 0.916063\n",
      "[2600]\ttrain's ndcg@5: 0.931516\tvalid's ndcg@5: 0.917553\n",
      "[2700]\ttrain's ndcg@5: 0.93274\tvalid's ndcg@5: 0.918724\n",
      "[2800]\ttrain's ndcg@5: 0.933888\tvalid's ndcg@5: 0.919967\n",
      "[2900]\ttrain's ndcg@5: 0.935052\tvalid's ndcg@5: 0.920525\n",
      "[3000]\ttrain's ndcg@5: 0.936171\tvalid's ndcg@5: 0.921322\n",
      "[3100]\ttrain's ndcg@5: 0.937327\tvalid's ndcg@5: 0.922115\n",
      "[3200]\ttrain's ndcg@5: 0.938383\tvalid's ndcg@5: 0.922929\n",
      "[3300]\ttrain's ndcg@5: 0.939359\tvalid's ndcg@5: 0.923718\n",
      "[3400]\ttrain's ndcg@5: 0.940259\tvalid's ndcg@5: 0.92493\n",
      "[3500]\ttrain's ndcg@5: 0.941175\tvalid's ndcg@5: 0.92557\n",
      "[3600]\ttrain's ndcg@5: 0.942068\tvalid's ndcg@5: 0.926066\n",
      "[3700]\ttrain's ndcg@5: 0.942883\tvalid's ndcg@5: 0.926742\n",
      "[3800]\ttrain's ndcg@5: 0.943779\tvalid's ndcg@5: 0.927418\n",
      "[3900]\ttrain's ndcg@5: 0.944679\tvalid's ndcg@5: 0.928033\n",
      "[4000]\ttrain's ndcg@5: 0.945441\tvalid's ndcg@5: 0.928674\n",
      "[4100]\ttrain's ndcg@5: 0.946219\tvalid's ndcg@5: 0.929288\n",
      "[4200]\ttrain's ndcg@5: 0.947051\tvalid's ndcg@5: 0.930024\n",
      "[4300]\ttrain's ndcg@5: 0.947643\tvalid's ndcg@5: 0.930447\n",
      "[4400]\ttrain's ndcg@5: 0.94836\tvalid's ndcg@5: 0.930966\n",
      "[4500]\ttrain's ndcg@5: 0.949088\tvalid's ndcg@5: 0.931408\n",
      "[4600]\ttrain's ndcg@5: 0.949697\tvalid's ndcg@5: 0.931976\n",
      "[4700]\ttrain's ndcg@5: 0.950402\tvalid's ndcg@5: 0.932649\n",
      "[4800]\ttrain's ndcg@5: 0.951102\tvalid's ndcg@5: 0.933076\n",
      "[4900]\ttrain's ndcg@5: 0.951719\tvalid's ndcg@5: 0.933591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 13:42:00,753] Trial 47 finished with value: -0.9340787297130889 and parameters: {'num_leaves': 54, 'learning_rate': 0.002356329660567718, 'feature_fraction': 0.7125575006574991, 'min_data_in_leaf': 123, 'lambda_l1': 1.9570977447825888, 'lambda_l2': 4.105017220247908}. Best is trial 14 with value: -0.9116917696622929.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5000]\ttrain's ndcg@5: 0.95237\tvalid's ndcg@5: 0.934079\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[5000]\ttrain's ndcg@5: 0.95237\tvalid's ndcg@5: 0.934079\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttrain's ndcg@5: 0.851005\tvalid's ndcg@5: 0.84888\n",
      "[200]\ttrain's ndcg@5: 0.856319\tvalid's ndcg@5: 0.853573\n",
      "[300]\ttrain's ndcg@5: 0.860422\tvalid's ndcg@5: 0.857001\n",
      "[400]\ttrain's ndcg@5: 0.863687\tvalid's ndcg@5: 0.85907\n",
      "[500]\ttrain's ndcg@5: 0.866535\tvalid's ndcg@5: 0.861642\n",
      "[600]\ttrain's ndcg@5: 0.869177\tvalid's ndcg@5: 0.863499\n",
      "[700]\ttrain's ndcg@5: 0.871597\tvalid's ndcg@5: 0.865532\n",
      "[800]\ttrain's ndcg@5: 0.873876\tvalid's ndcg@5: 0.867966\n",
      "[900]\ttrain's ndcg@5: 0.876452\tvalid's ndcg@5: 0.870102\n",
      "[1000]\ttrain's ndcg@5: 0.878776\tvalid's ndcg@5: 0.871996\n",
      "[1100]\ttrain's ndcg@5: 0.880702\tvalid's ndcg@5: 0.873611\n",
      "[1200]\ttrain's ndcg@5: 0.882939\tvalid's ndcg@5: 0.875721\n",
      "[1300]\ttrain's ndcg@5: 0.885083\tvalid's ndcg@5: 0.877746\n",
      "[1400]\ttrain's ndcg@5: 0.887443\tvalid's ndcg@5: 0.879892\n",
      "[1500]\ttrain's ndcg@5: 0.889628\tvalid's ndcg@5: 0.881646\n",
      "[1600]\ttrain's ndcg@5: 0.89173\tvalid's ndcg@5: 0.883462\n",
      "[1700]\ttrain's ndcg@5: 0.893606\tvalid's ndcg@5: 0.885395\n",
      "[1800]\ttrain's ndcg@5: 0.895487\tvalid's ndcg@5: 0.886807\n",
      "[1900]\ttrain's ndcg@5: 0.897521\tvalid's ndcg@5: 0.888111\n",
      "[2000]\ttrain's ndcg@5: 0.899351\tvalid's ndcg@5: 0.88951\n",
      "[2100]\ttrain's ndcg@5: 0.900888\tvalid's ndcg@5: 0.890914\n",
      "[2200]\ttrain's ndcg@5: 0.902423\tvalid's ndcg@5: 0.892471\n",
      "[2300]\ttrain's ndcg@5: 0.903872\tvalid's ndcg@5: 0.893871\n",
      "[2400]\ttrain's ndcg@5: 0.905292\tvalid's ndcg@5: 0.895317\n",
      "[2500]\ttrain's ndcg@5: 0.906722\tvalid's ndcg@5: 0.896476\n",
      "[2600]\ttrain's ndcg@5: 0.908166\tvalid's ndcg@5: 0.897456\n",
      "[2700]\ttrain's ndcg@5: 0.909601\tvalid's ndcg@5: 0.898674\n",
      "[2800]\ttrain's ndcg@5: 0.910903\tvalid's ndcg@5: 0.899999\n",
      "[2900]\ttrain's ndcg@5: 0.912236\tvalid's ndcg@5: 0.901401\n",
      "[3000]\ttrain's ndcg@5: 0.913505\tvalid's ndcg@5: 0.902311\n",
      "[3100]\ttrain's ndcg@5: 0.914675\tvalid's ndcg@5: 0.903696\n",
      "[3200]\ttrain's ndcg@5: 0.915709\tvalid's ndcg@5: 0.904686\n",
      "[3300]\ttrain's ndcg@5: 0.916815\tvalid's ndcg@5: 0.905712\n",
      "[3400]\ttrain's ndcg@5: 0.91791\tvalid's ndcg@5: 0.906457\n",
      "[3500]\ttrain's ndcg@5: 0.918762\tvalid's ndcg@5: 0.907202\n",
      "[3600]\ttrain's ndcg@5: 0.919667\tvalid's ndcg@5: 0.90818\n",
      "[3700]\ttrain's ndcg@5: 0.920489\tvalid's ndcg@5: 0.908964\n",
      "[3800]\ttrain's ndcg@5: 0.921523\tvalid's ndcg@5: 0.909627\n",
      "[3900]\ttrain's ndcg@5: 0.92237\tvalid's ndcg@5: 0.910268\n",
      "[4000]\ttrain's ndcg@5: 0.923288\tvalid's ndcg@5: 0.910969\n",
      "[4100]\ttrain's ndcg@5: 0.924099\tvalid's ndcg@5: 0.91174\n",
      "[4200]\ttrain's ndcg@5: 0.924905\tvalid's ndcg@5: 0.912581\n",
      "[4300]\ttrain's ndcg@5: 0.925703\tvalid's ndcg@5: 0.913262\n",
      "[4400]\ttrain's ndcg@5: 0.926422\tvalid's ndcg@5: 0.914067\n",
      "[4500]\ttrain's ndcg@5: 0.927231\tvalid's ndcg@5: 0.914561\n",
      "[4600]\ttrain's ndcg@5: 0.927917\tvalid's ndcg@5: 0.915134\n",
      "[4700]\ttrain's ndcg@5: 0.928582\tvalid's ndcg@5: 0.91574\n",
      "[4800]\ttrain's ndcg@5: 0.929247\tvalid's ndcg@5: 0.916433\n",
      "[4900]\ttrain's ndcg@5: 0.929941\tvalid's ndcg@5: 0.91689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 13:43:25,598] Trial 48 finished with value: -0.9175042300233207 and parameters: {'num_leaves': 50, 'learning_rate': 0.0012339986978531466, 'feature_fraction': 0.7748714526578045, 'min_data_in_leaf': 151, 'lambda_l1': 2.6775870195462015, 'lambda_l2': 3.4193918031204102}. Best is trial 14 with value: -0.9116917696622929.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5000]\ttrain's ndcg@5: 0.930612\tvalid's ndcg@5: 0.917481\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[4999]\ttrain's ndcg@5: 0.930603\tvalid's ndcg@5: 0.917504\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttrain's ndcg@5: 0.863532\tvalid's ndcg@5: 0.859035\n",
      "[200]\ttrain's ndcg@5: 0.871324\tvalid's ndcg@5: 0.864787\n",
      "[300]\ttrain's ndcg@5: 0.878822\tvalid's ndcg@5: 0.871204\n",
      "[400]\ttrain's ndcg@5: 0.885253\tvalid's ndcg@5: 0.877041\n",
      "[500]\ttrain's ndcg@5: 0.891393\tvalid's ndcg@5: 0.881835\n",
      "[600]\ttrain's ndcg@5: 0.897393\tvalid's ndcg@5: 0.886747\n",
      "[700]\ttrain's ndcg@5: 0.902391\tvalid's ndcg@5: 0.890676\n",
      "[800]\ttrain's ndcg@5: 0.907248\tvalid's ndcg@5: 0.895107\n",
      "[900]\ttrain's ndcg@5: 0.911456\tvalid's ndcg@5: 0.898909\n",
      "[1000]\ttrain's ndcg@5: 0.915238\tvalid's ndcg@5: 0.902388\n",
      "[1100]\ttrain's ndcg@5: 0.918388\tvalid's ndcg@5: 0.905592\n",
      "[1200]\ttrain's ndcg@5: 0.921307\tvalid's ndcg@5: 0.908196\n",
      "[1300]\ttrain's ndcg@5: 0.924203\tvalid's ndcg@5: 0.91033\n",
      "[1400]\ttrain's ndcg@5: 0.926729\tvalid's ndcg@5: 0.912345\n",
      "[1500]\ttrain's ndcg@5: 0.929145\tvalid's ndcg@5: 0.914194\n",
      "[1600]\ttrain's ndcg@5: 0.931335\tvalid's ndcg@5: 0.916051\n",
      "[1700]\ttrain's ndcg@5: 0.93342\tvalid's ndcg@5: 0.917697\n",
      "[1800]\ttrain's ndcg@5: 0.93535\tvalid's ndcg@5: 0.919207\n",
      "[1900]\ttrain's ndcg@5: 0.937127\tvalid's ndcg@5: 0.920611\n",
      "[2000]\ttrain's ndcg@5: 0.938866\tvalid's ndcg@5: 0.922251\n",
      "[2100]\ttrain's ndcg@5: 0.940398\tvalid's ndcg@5: 0.923618\n",
      "[2200]\ttrain's ndcg@5: 0.941844\tvalid's ndcg@5: 0.924651\n",
      "[2300]\ttrain's ndcg@5: 0.943335\tvalid's ndcg@5: 0.925852\n",
      "[2400]\ttrain's ndcg@5: 0.944732\tvalid's ndcg@5: 0.927069\n",
      "[2500]\ttrain's ndcg@5: 0.946109\tvalid's ndcg@5: 0.927846\n",
      "[2600]\ttrain's ndcg@5: 0.947274\tvalid's ndcg@5: 0.928541\n",
      "[2700]\ttrain's ndcg@5: 0.948422\tvalid's ndcg@5: 0.929325\n",
      "[2800]\ttrain's ndcg@5: 0.949707\tvalid's ndcg@5: 0.930443\n",
      "[2900]\ttrain's ndcg@5: 0.950766\tvalid's ndcg@5: 0.931174\n",
      "[3000]\ttrain's ndcg@5: 0.951858\tvalid's ndcg@5: 0.931846\n",
      "[3100]\ttrain's ndcg@5: 0.952821\tvalid's ndcg@5: 0.93278\n",
      "[3200]\ttrain's ndcg@5: 0.95384\tvalid's ndcg@5: 0.933761\n",
      "[3300]\ttrain's ndcg@5: 0.95475\tvalid's ndcg@5: 0.934404\n",
      "[3400]\ttrain's ndcg@5: 0.955599\tvalid's ndcg@5: 0.934845\n",
      "[3500]\ttrain's ndcg@5: 0.95651\tvalid's ndcg@5: 0.93554\n",
      "[3600]\ttrain's ndcg@5: 0.957262\tvalid's ndcg@5: 0.936425\n",
      "[3700]\ttrain's ndcg@5: 0.958055\tvalid's ndcg@5: 0.937276\n",
      "[3800]\ttrain's ndcg@5: 0.958934\tvalid's ndcg@5: 0.937847\n",
      "[3900]\ttrain's ndcg@5: 0.959697\tvalid's ndcg@5: 0.93844\n",
      "[4000]\ttrain's ndcg@5: 0.960452\tvalid's ndcg@5: 0.939068\n",
      "[4100]\ttrain's ndcg@5: 0.961121\tvalid's ndcg@5: 0.939734\n",
      "[4200]\ttrain's ndcg@5: 0.9618\tvalid's ndcg@5: 0.940335\n",
      "[4300]\ttrain's ndcg@5: 0.962494\tvalid's ndcg@5: 0.941068\n",
      "[4400]\ttrain's ndcg@5: 0.963105\tvalid's ndcg@5: 0.941566\n",
      "[4500]\ttrain's ndcg@5: 0.963708\tvalid's ndcg@5: 0.941953\n",
      "[4600]\ttrain's ndcg@5: 0.964395\tvalid's ndcg@5: 0.942434\n",
      "[4700]\ttrain's ndcg@5: 0.965068\tvalid's ndcg@5: 0.943073\n",
      "[4800]\ttrain's ndcg@5: 0.965632\tvalid's ndcg@5: 0.943553\n",
      "[4900]\ttrain's ndcg@5: 0.966244\tvalid's ndcg@5: 0.943841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-06 13:44:54,175] Trial 49 finished with value: -0.9442198124532711 and parameters: {'num_leaves': 60, 'learning_rate': 0.003636638180821231, 'feature_fraction': 0.7516042460526272, 'min_data_in_leaf': 94, 'lambda_l1': 1.4660305029252756, 'lambda_l2': 3.0018934525696657}. Best is trial 14 with value: -0.9116917696622929.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5000]\ttrain's ndcg@5: 0.966842\tvalid's ndcg@5: 0.94422\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[5000]\ttrain's ndcg@5: 0.966842\tvalid's ndcg@5: 0.94422\n",
      "Best params: {'num_leaves': 34, 'learning_rate': 0.001008327545545068, 'feature_fraction': 0.8020277602730795, 'min_data_in_leaf': 198, 'lambda_l1': 0.5937545786519233, 'lambda_l2': 3.9866388089892144}\n",
      "Best ndcg@5: 0.9116917696622929\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "import lightgbm as lgb\n",
    "\n",
    "def objective(trial):\n",
    "    # Hyperparam suggestions\n",
    "    num_leaves = trial.suggest_int(\"num_leaves\", 15, 63)\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-3, 0.1, log=True)\n",
    "    feature_fraction = trial.suggest_float(\"feature_fraction\", 0.7, 1.0)\n",
    "    min_data_in_leaf = trial.suggest_int(\"min_data_in_leaf\", 10, 200)\n",
    "    lambda_l1 = trial.suggest_float(\"lambda_l1\", 0.0, 5.0)\n",
    "    lambda_l2 = trial.suggest_float(\"lambda_l2\", 0.0, 5.0)\n",
    "\n",
    "    params = {\n",
    "        \"objective\": \"lambdarank\",\n",
    "        \"metric\": \"ndcg\",           # main metric\n",
    "        \"ndcg_eval_at\": [5],        # we want ndcg@5 specifically\n",
    "        \"boosting_type\": \"gbdt\",\n",
    "        \"device_type\": \"gpu\",\n",
    "        \"num_leaves\": num_leaves,\n",
    "        \"learning_rate\": learning_rate,\n",
    "        \"feature_fraction\": feature_fraction,\n",
    "        \"min_data_in_leaf\": min_data_in_leaf,\n",
    "        \"lambda_l1\": lambda_l1,\n",
    "        \"lambda_l2\": lambda_l2,\n",
    "        \"verbosity\": -1\n",
    "    }\n",
    "\n",
    "    train_dataset = lgb.Dataset(X_train, label=y_train, group=group_train)\n",
    "    valid_dataset = lgb.Dataset(X_valid, label=y_valid, group=group_valid, reference=train_dataset)\n",
    "\n",
    "    gbm = lgb.train(\n",
    "        params,\n",
    "        train_dataset,\n",
    "        num_boost_round=5000,\n",
    "        valid_sets=[train_dataset, valid_dataset],\n",
    "        valid_names=[\"train\", \"valid\"],\n",
    "        callbacks=[\n",
    "            lgb.log_evaluation(period=100),\n",
    "            lgb.early_stopping(stopping_rounds=50)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Now you must fetch \"ndcg@5\"\n",
    "    best_score_ndcg5 = gbm.best_score[\"valid\"][\"ndcg@5\"]\n",
    "    return -best_score_ndcg5\n",
    "\n",
    "def run_optuna():\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    study.optimize(objective, n_trials=50)\n",
    "    return study\n",
    "\n",
    "study = run_optuna()\n",
    "best_params = study.best_params\n",
    "best_value = study.best_value   # negative of best ndcg@5\n",
    "best_ndcg5 = -best_value\n",
    "\n",
    "print(\"Best params:\", best_params)\n",
    "print(\"Best ndcg@5:\", best_ndcg5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18743eac-bc6c-45e1-a549-67b70079c0f8",
   "metadata": {},
   "source": [
    "# Final LGB Run with Optuna Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6a238ec9-a832-450f-ad62-296bc70ca9c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'num_leaves': 34, 'learning_rate': 0.001008327545545068, 'feature_fraction': 0.8020277602730795, 'min_data_in_leaf': 198, 'lambda_l1': 0.5937545786519233, 'lambda_l2': 3.9866388089892144}\n",
      "Best ndcg@5: 0.9116917696622929\n"
     ]
    }
   ],
   "source": [
    "print(\"Best params:\", best_params)\n",
    "print(\"Best ndcg@5:\", best_ndcg5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a1243fee-c622-4cbc-b039-49f800eb5581",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_params = {\n",
    "    \"objective\": \"lambdarank\",\n",
    "    \"metric\": \"ndcg\",           # main metric\n",
    "    \"ndcg_eval_at\": [5],        # we want ndcg@5 specifically\n",
    "    \"boosting_type\": \"gbdt\",\n",
    "    \"device_type\": \"gpu\",\n",
    "    \"verbosity\": -1,\n",
    "    \"num_leaves\": 34,\n",
    "    \"learning_rate\": 0.001008327545545068,\n",
    "    \"feature_fraction\": 0.8020277602730795,\n",
    "    \"min_data_in_leaf\": 198,\n",
    "    \"lambda_l1\": 0.5937545786519233,\n",
    "    \"lambda_l2\": 3.9866388089892144\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8e664a81-848a-46da-95df-de30938f194a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_full = np.concatenate([X_train, X_valid], axis=0)\n",
    "y_full = np.concatenate([y_train, y_valid], axis=0)\n",
    "group_full = np.concatenate([group_train, group_valid], axis=0)\n",
    "\n",
    "full_dataset = lgb.Dataset(X_full, label=y_full, group=group_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3c15a6ac-65b2-4b7a-aec5-36d7e1d0f73b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/exx/anaconda3/envs/mamba_env/envs/rapids-23.08/lib/python3.10/site-packages/lightgbm/callback.py:341: UserWarning: Only training set found, disabling early stopping.\n",
      "  _log_warning(\"Only training set found, disabling early stopping.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tfull's ndcg@5: 0.844236\n",
      "[200]\tfull's ndcg@5: 0.848783\n",
      "[300]\tfull's ndcg@5: 0.852963\n",
      "[400]\tfull's ndcg@5: 0.85573\n",
      "[500]\tfull's ndcg@5: 0.85847\n",
      "[600]\tfull's ndcg@5: 0.860429\n",
      "[700]\tfull's ndcg@5: 0.86251\n",
      "[800]\tfull's ndcg@5: 0.864635\n",
      "[900]\tfull's ndcg@5: 0.866889\n",
      "[1000]\tfull's ndcg@5: 0.868828\n",
      "[1100]\tfull's ndcg@5: 0.870519\n",
      "[1200]\tfull's ndcg@5: 0.872614\n",
      "[1300]\tfull's ndcg@5: 0.874478\n",
      "[1400]\tfull's ndcg@5: 0.876502\n",
      "[1500]\tfull's ndcg@5: 0.878481\n",
      "[1600]\tfull's ndcg@5: 0.88043\n",
      "[1700]\tfull's ndcg@5: 0.882282\n",
      "[1800]\tfull's ndcg@5: 0.883997\n",
      "[1900]\tfull's ndcg@5: 0.885723\n",
      "[2000]\tfull's ndcg@5: 0.887453\n",
      "[2100]\tfull's ndcg@5: 0.889075\n",
      "[2200]\tfull's ndcg@5: 0.890676\n",
      "[2300]\tfull's ndcg@5: 0.892277\n",
      "[2400]\tfull's ndcg@5: 0.893779\n",
      "[2500]\tfull's ndcg@5: 0.895272\n",
      "[2600]\tfull's ndcg@5: 0.896683\n",
      "[2700]\tfull's ndcg@5: 0.897933\n",
      "[2800]\tfull's ndcg@5: 0.899357\n",
      "[2900]\tfull's ndcg@5: 0.900672\n",
      "[3000]\tfull's ndcg@5: 0.901773\n",
      "[3100]\tfull's ndcg@5: 0.902866\n",
      "[3200]\tfull's ndcg@5: 0.904007\n",
      "[3300]\tfull's ndcg@5: 0.905033\n",
      "[3400]\tfull's ndcg@5: 0.906061\n",
      "[3500]\tfull's ndcg@5: 0.90702\n",
      "[3600]\tfull's ndcg@5: 0.908029\n",
      "[3700]\tfull's ndcg@5: 0.908996\n",
      "[3800]\tfull's ndcg@5: 0.909791\n",
      "[3900]\tfull's ndcg@5: 0.910677\n",
      "[4000]\tfull's ndcg@5: 0.911616\n",
      "[4100]\tfull's ndcg@5: 0.912567\n",
      "[4200]\tfull's ndcg@5: 0.913435\n",
      "[4300]\tfull's ndcg@5: 0.91423\n",
      "[4400]\tfull's ndcg@5: 0.914908\n",
      "[4500]\tfull's ndcg@5: 0.915714\n",
      "[4600]\tfull's ndcg@5: 0.916478\n",
      "[4700]\tfull's ndcg@5: 0.917118\n",
      "[4800]\tfull's ndcg@5: 0.917758\n",
      "[4900]\tfull's ndcg@5: 0.918399\n",
      "[5000]\tfull's ndcg@5: 0.919064\n"
     ]
    }
   ],
   "source": [
    "lgbm_final = lgb.train(\n",
    "    final_params,\n",
    "    full_dataset,\n",
    "    num_boost_round=5000,\n",
    "    valid_sets=[full_dataset],  # optional\n",
    "    valid_names=[\"full\"],\n",
    "    callbacks=[\n",
    "        lgb.log_evaluation(period=100),\n",
    "        lgb.early_stopping(stopping_rounds=50)\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc4d751-7a89-49ed-93ff-51c2f56e1638",
   "metadata": {},
   "source": [
    "### Save the best LGB Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "dbdfb695-67b8-40a8-b236-6de0e96d0678",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lightgbm.basic.Booster at 0x7fa874c85b10>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm_final.save_model(\"/home/exx/myCode/horse-racing/FoxRiverAIRacing/src/LGBfinal_optuna_ranking_model.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548e36e2-8887-4bf9-8a85-f1010ee29f50",
   "metadata": {},
   "source": [
    "# Review below for making predictions -- not tested code!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4655a07-da5d-4cf8-ad76-c662714ad3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(gbm_final, \"final_optuna_ranking_model.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14acc300-4cc0-48c5-ab38-9dc93ab3f3d7",
   "metadata": {},
   "source": [
    "### Later (e.g. tomorrow), you load the model and make predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2fb47c-4be8-4694-ac0b-38cdd3b3a930",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For text:\n",
    "reloaded_model = lgb.Booster(model_file=\"final_optuna_ranking_model.txt\")\n",
    "\n",
    "# For pickle:\n",
    "# reloaded_model = joblib.load(\"final_optuna_ranking_model.pkl\")\n",
    "\n",
    "tomorrow_preds = reloaded_model.predict(X_tomorrow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12332156-3dca-4127-b059-71673d6d026b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d097695-c300-4549-963b-4741f1ac5343",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "031a5402-e3f0-401b-a3bd-3ba39d0a3cf2",
   "metadata": {},
   "source": [
    "# Save the LGB model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b7f5cb-1045-4154-a58d-5ca5cd5cfc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import optuna\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 1) After you have found best_params via Optuna\n",
    "# -------------------------------------------------\n",
    "best_params = {\n",
    "    \"objective\": \"lambdarank\",\n",
    "    \"metric\": \"ndcg\",\n",
    "    \"boosting_type\": \"gbdt\",\n",
    "    \"verbosity\": -1,\n",
    "    \"num_leaves\": 31,\n",
    "    \"learning_rate\": 0.05,\n",
    "    \"feature_fraction\": 0.9,\n",
    "    # etc. (whatever Optuna found best)\n",
    "}\n",
    "\n",
    "# Suppose you re-train your final model on the full (train + valid) data:\n",
    "final_train_dataset = lgb.Dataset(X_train_full, label=y_train_full, group=group_train_full)\n",
    "# If you have a separate test set, you can provide it for monitoring,\n",
    "# but not strictly required for final training.\n",
    "\n",
    "gbm_final = lgb.train(\n",
    "    best_params,\n",
    "    final_train_dataset,\n",
    "    num_boost_round=5000,  # or your chosen number of rounds\n",
    "    valid_sets=[final_train_dataset],  # optional\n",
    "    valid_names=[\"train\"],\n",
    "    callbacks=[\n",
    "        lgb.early_stopping(stopping_rounds=50),\n",
    "        lgb.log_evaluation(period=100)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 2) Save the trained model\n",
    "# -------------------------------------------------\n",
    "# Option A: Save to LightGBM's native text file\n",
    "gbm_final.save_model(\"optuna_lgb_ranking_model.txt\")\n",
    "\n",
    "# Option B: Or use Python's joblib/pickle\n",
    "joblib.dump(gbm_final, \"optuna_lgb_ranking_model.pkl\")\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 3) Later (e.g., the next day), load the model\n",
    "# -------------------------------------------------\n",
    "# For text-file approach:\n",
    "reloaded_model = lgb.Booster(model_file=\"optuna_lgb_ranking_model.txt\")\n",
    "\n",
    "# Or, if you used joblib/pickle:\n",
    "# reloaded_model = joblib.load(\"optuna_lgb_ranking_model.pkl\")\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 4) Predict for tomorrow’s races\n",
    "# -------------------------------------------------\n",
    "# (A) Prepare your feature DataFrame for the new races.\n",
    "#     E.g., load tomorrow’s race data from your database or CSV.\n",
    "#     Make sure columns match those used in training (same feature names/order).\n",
    "\n",
    "tomorrow_df = pd.read_csv(\"tomorrow_races.csv\")  # or however you get data\n",
    "# Filter out columns not used. Suppose your feature list is:\n",
    "feature_cols = [\n",
    "    \"purse\", \"distance\", \"avgspd\", \"days_off\", \"jock_win_percent\",\n",
    "    # ...\n",
    "    # (whatever subset you used in training)\n",
    "]\n",
    "\n",
    "X_tomorrow = tomorrow_df[feature_cols].copy()\n",
    "\n",
    "# (B) Group array is not needed at prediction time for simple .predict calls.\n",
    "#     For ranking, you’ll still eventually want to group the predictions\n",
    "#     by race (and then rank horses within each race).\n",
    "\n",
    "preds = reloaded_model.predict(X_tomorrow)\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 5) Ranking the horses within each race\n",
    "# -------------------------------------------------\n",
    "# Suppose tomorrow_df has \"race_id\" to identify each race (like 'AQU_20250107_3' etc.)\n",
    "tomorrow_df[\"predicted_score\"] = preds\n",
    "\n",
    "# Group by race_id and sort descending by predicted_score\n",
    "ranked_df = (\n",
    "    tomorrow_df\n",
    "    .groupby(\"race_id\", as_index=False)\n",
    "    .apply(lambda g: g.sort_values(\"predicted_score\", ascending=False))\n",
    ")\n",
    "\n",
    "# Display or save your ranking\n",
    "print(ranked_df.head(20))  # top 20 lines\n",
    "ranked_df.to_csv(\"tomorrow_ranked_predictions.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
