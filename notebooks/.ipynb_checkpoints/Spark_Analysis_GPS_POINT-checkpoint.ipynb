{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d31374ea-f808-4394-a60c-c3f0a08e2627",
   "metadata": {},
   "source": [
    "# Spark Anaysis of Total Performance Data: GPS and Sectional Data\n",
    "\n",
    "Analyzing the TPD GPS data alongside Equibase (EQB) data can provide significant predictive insights into horse performance. By focusing on the granular details of a horse’s movement during a race, you can derive valuable metrics that complement traditional EQB ratings and help identify under- or over-rated horses. \n",
    "\n",
    "## Roadmap for maximizing the predictive capabilities of the TPD GPS data:\n",
    "\n",
    "### Key Ideas and Strategies\n",
    "\n",
    "1. Derive Advanced Pace Metrics\n",
    "\n",
    "Understanding how a horse’s speed changes over the course of a race can reveal its racing style and potential strengths or weaknesses:\n",
    "\n",
    "\t•\tEarly Pace: Average speed and acceleration during the first segment (e.g., first 20% of the race).\n",
    "\t•\tMid-Race Pace: Average speed and deceleration during the middle segments.\n",
    "\t•\tLate Pace: Average speed and deceleration in the final segment.\n",
    "\t•\tSustained Speed: Identify segments where the horse maintains a steady speed.\n",
    "\t•\tPeak Speed Timing: The point in the race where the horse reaches its peak speed.\n",
    "\n",
    "2. Fatigue Factor\n",
    "\n",
    "Calculate how much the horse slows down as the race progresses:\n",
    "\n",
    "\t•\tUse metrics like:\n",
    "\t•\tPercentage drop from peak speed to finish speed.\n",
    "\t•\tMaximum acceleration vs. deceleration ratios.\n",
    "\t•\tChange in stride frequency as the race progresses.\n",
    "\n",
    "3. Sectional Efficiency\n",
    "\n",
    "Quantify how efficiently the horse runs its sections:\n",
    "\n",
    "    •\tCompare actual times vs. expected times for each section based on the route characteristics.\n",
    "\t•\tEfficiency Ratio:\n",
    "    •\tA high ratio might indicate a horse ran extra distance due to poor cornering or positioning.\n",
    "\n",
    "4. Overlay TPD with EQB Ratings\n",
    "\n",
    "Use EQB’s traditional metrics (e.g., speed ratings, form) to cross-reference with TPD data:\n",
    "\n",
    "\t•\tIdentify horses that consistently outperform EQB predictions.\n",
    "\t•\tInvestigate horses with high EQB ratings but poor TPD-based performance (e.g., poor fatigue factors or inefficient sectional running).\n",
    "\n",
    "5. Route Characteristics\n",
    "\n",
    "If the routes table contains track-specific details (e.g., turn sharpness, surface type, gradient):\n",
    "\n",
    "\t•\tIncorporate these into the analysis.\n",
    "\t•\tEvaluate how specific horses handle different track conditions (e.g., wide turns, long stretches).\n",
    "\t•\tIdentify patterns like “performs better on flatter tracks” or “struggles on uphill finishes.”\n",
    "\n",
    "6. Horse vs. Peer Comparisons\n",
    "\n",
    "Evaluate how each horse performs relative to its competition in the same race:\n",
    "\n",
    "\t•\tCompare sectional times and speeds with other horses in the race.\n",
    "\t•\tRank horses based on performance within each race segment.\n",
    "\n",
    "7. Acceleration Profiles\n",
    "\n",
    "\t•\tPlot acceleration over time to identify patterns (e.g., burst speed vs. steady acceleration).\n",
    "    •\tHighlight horses with exceptional closing speed (valuable in longer races) or fast starts (important in short sprints).\n",
    "\n",
    "9. Cluster Analysis of Racing Styles\n",
    "\n",
    "Use clustering techniques to group horses by similar racing profiles:\n",
    "\n",
    "\t•\tInputs: Early pace, mid-pace, late pace, fatigue factor, sectional efficiency.\n",
    "\t•\tOutput: Clusters representing different racing styles (e.g., “early speed burners,” “closers,” “steady sustainers”).\n",
    "\n",
    "9. Historical Analysis\n",
    "\n",
    "Identify trends over a horse’s career:\n",
    "\n",
    "\t•\tDoes the horse improve or decline over time?\n",
    "\t•\tAre there patterns in performance tied to specific jockeys, trainers, or race conditions?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "730b2d7b-00ae-4a2c-9081-e27a7e1e1573",
   "metadata": {},
   "source": [
    "# Using Spark for Efficient Processing\n",
    "\n",
    "Steps to Implement\n",
    "\n",
    "\t1.\tLoad the Data\n",
    "\t•\tLoad gpspoint, gps_aggregated_results, and routes into Spark DataFrames.\n",
    "\t2.\tSegment the Race\n",
    "\t•\tDivide each race into sections (e.g., by distance markers or time intervals).\n",
    "\t•\tUse PARTITION BY in Spark to process horses within each race separately.\n",
    "\t3.\tDerive Metrics\n",
    "\t•\tSpeed Metrics: Use window functions to calculate average, min, max speeds.\n",
    "\t•\tAcceleration/Deceleration: Compute using differences in speed and timestamps.\n",
    "\t•\tEfficiency: Calculate distance ran vs. track distance.\n",
    "\t4.\tIntegrate with EQB Data\n",
    "\t•\tJoin with EQB tables on course_cd, race_date, and race_number for comparison.\n",
    "\t5.\tSave Aggregated Data\n",
    "\t•\tSave results into gps_aggregated_results and tpd_features.\n",
    "\n",
    "Example Spark Code\n",
    "\n",
    "Here’s a high-level implementation for deriving pace metrics:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c520e11-da4a-43c1-8db8-33f2c1ac3771",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import configparser\n",
    "import logging\n",
    "import os\n",
    "\n",
    "\n",
    "def setup_logging(script_dir, log_dir=None):\n",
    "    \"\"\"Sets up logging configuration to write logs to a file and the console.\"\"\"\n",
    "    try:\n",
    "        # Default log directory\n",
    "        if not log_dir:\n",
    "            log_dir = '/home/exx/myCode/horse-racing/FoxRiverAIRacing/logs'\n",
    "        \n",
    "        # Ensure the log directory exists\n",
    "        os.makedirs(log_dir, exist_ok=True)\n",
    "        log_file = os.path.join(log_dir, 'SparkPy_load.log')\n",
    "\n",
    "        # Create a logger and clear existing handlers\n",
    "        logger = logging.getLogger()\n",
    "        if logger.hasHandlers():\n",
    "            logger.handlers.clear()\n",
    "\n",
    "        logger.setLevel(logging.INFO)\n",
    "\n",
    "        # Create file handler\n",
    "        file_handler = logging.FileHandler(log_file)\n",
    "        file_handler.setLevel(logging.INFO)\n",
    "\n",
    "        # Create console handler\n",
    "        console_handler = logging.StreamHandler()\n",
    "        console_handler.setLevel(logging.INFO)\n",
    "\n",
    "        # Define a common format\n",
    "        formatter = logging.Formatter(\n",
    "            '%(asctime)s - %(levelname)s - %(message)s',\n",
    "            datefmt='%Y-%m-%d %H:%M:%S'\n",
    "        )\n",
    "        file_handler.setFormatter(formatter)\n",
    "        console_handler.setFormatter(formatter)\n",
    "\n",
    "        # Add handlers to the logger\n",
    "        logger.addHandler(file_handler)\n",
    "        logger.addHandler(console_handler)\n",
    "\n",
    "        logger.info(\"Logging has been set up successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to set up logging: {e}\", file=sys.stderr)\n",
    "        sys.exit(1)\n",
    "\n",
    "def read_config(config_file_path=\"config.ini\"):\n",
    "    \"\"\"Read database configuration from config.ini.\"\"\"\n",
    "    config = configparser.ConfigParser()\n",
    "    config.read(config_file_path)\n",
    "    if 'database' not in config:\n",
    "        raise KeyError(\"Database configuration missing in config.ini\")\n",
    "    return config['database']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c25a67a-9e31-4552-89be-efc2522a79d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkPy24!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"DB_PASSWORD\"] = \"SparkPy24!\"\n",
    "print(os.getenv(\"DB_PASSWORD\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a55500b7-732c-441a-aec4-c21b190ba7bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Starting Spark Processing for GPS Data\n",
      "INFO:root:Variables defined successfully.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession, Window\n",
    "from pyspark.sql.functions import col, lag, avg, max, min, stddev, expr, unix_timestamp\n",
    "import logging\n",
    "import os\n",
    "from sqlalchemy import create_engine, text\n",
    "import configparser\n",
    "\n",
    "# Reduce Py4J logging\n",
    "logger = logging.getLogger(\"py4j\")\n",
    "logger.setLevel(logging.ERROR)\n",
    "\n",
    "\n",
    "# Configure logging\n",
    "log_file = \"/home/exx/myCode/horse-racing/FoxRiverAIRacing/logs/SparkPy_load.log\"\n",
    "logging.basicConfig(level=logging.INFO, handlers=[\n",
    "    logging.FileHandler(log_file),\n",
    "    logging.StreamHandler()\n",
    "])\n",
    "logging.info(\"Starting Spark Processing for GPS Data\")\n",
    "\n",
    "db_config = {\n",
    "    \"host\": \"192.168.4.25\",\n",
    "    \"port\": \"5433\",\n",
    "    \"dbname\": \"foxriverai\",\n",
    "    \"user\": \"rshane\",\n",
    "    \"password\": os.getenv(\"DB_PASSWORD\")  # Fetch from environment variable\n",
    "}\n",
    "\n",
    "if not db_config[\"password\"]:\n",
    "    raise Exception(\"Database password is missing. Set it in the DB_PASSWORD environment variable.\")\n",
    "\n",
    "jdbc_url = f\"jdbc:postgresql://{db_config['host']}:{db_config['port']}/{db_config['dbname']}\"\n",
    "jdbc_properties = {\n",
    "    \"user\": db_config[\"user\"],\n",
    "    \"password\": db_config[\"password\"],\n",
    "    \"driver\": \"org.postgresql.Driver\"\n",
    "}\n",
    "jdbc_driver_path = \"/home/exx/myCode/horse-racing/FoxRiverAIRacing/jdbc/postgresql-42.7.4.jar\"\n",
    "\n",
    "logging.info(\"Variables defined successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67ed15e4-cdb0-49fa-ba8e-c15a7a04d57b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/12/05 22:20:23 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "24/12/05 22:20:24 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "INFO:root:Spark session created successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing course: CNL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Loading data from database for course: CNL\n",
      "INFO:root:None\n",
      "INFO:root:None\n",
      "INFO:root:None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- gate_name: string (nullable = true)\n",
      " |-- avg_speed: double (nullable = true)\n",
      " |-- avg_acceleration: double (nullable = true)\n",
      " |-- max_speed: double (nullable = true)\n",
      " |-- min_speed: double (nullable = true)\n",
      " |-- fatigue_factor: double (nullable = true)\n",
      " |-- is_fastest_gate: integer (nullable = true)\n",
      " |-- is_slowest_gate: integer (nullable = true)\n",
      "\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- gate_name: string (nullable = true)\n",
      " |-- avg_speed: double (nullable = true)\n",
      " |-- avg_acceleration: double (nullable = true)\n",
      " |-- max_speed: double (nullable = true)\n",
      " |-- min_speed: double (nullable = true)\n",
      " |-- fatigue_factor: double (nullable = true)\n",
      " |-- is_fastest_gate: integer (nullable = true)\n",
      " |-- is_slowest_gate: integer (nullable = true)\n",
      "\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- total_distance_run: double (nullable = true)\n",
      " |-- ground_loss: double (nullable = true)\n",
      "\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- total_distance_run: double (nullable = true)\n",
      " |-- ground_loss: double (nullable = true)\n",
      "\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- gate_name: string (nullable = true)\n",
      " |-- avg_speed: double (nullable = true)\n",
      " |-- avg_acceleration: double (nullable = true)\n",
      " |-- max_speed: double (nullable = true)\n",
      " |-- min_speed: double (nullable = true)\n",
      " |-- fatigue_factor: double (nullable = true)\n",
      " |-- is_fastest_gate: integer (nullable = true)\n",
      " |-- is_slowest_gate: integer (nullable = true)\n",
      " |-- total_distance_run: double (nullable = true)\n",
      " |-- ground_loss: double (nullable = true)\n",
      "\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- gate_name: string (nullable = true)\n",
      " |-- avg_speed: double (nullable = true)\n",
      " |-- avg_acceleration: double (nullable = true)\n",
      " |-- max_speed: double (nullable = true)\n",
      " |-- min_speed: double (nullable = true)\n",
      " |-- fatigue_factor: double (nullable = true)\n",
      " |-- is_fastest_gate: integer (nullable = true)\n",
      " |-- is_slowest_gate: integer (nullable = true)\n",
      " |-- total_distance_run: double (nullable = true)\n",
      " |-- ground_loss: double (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/05 22:20:31 ERROR Executor: Exception in task 23.0 in stage 14.0 (TID 45)]\n",
      "java.sql.BatchUpdateException: Batch entry 0 INSERT INTO gps_aggregated_results_with_gates (\"course_cd\",\"race_date\",\"race_number\",\"saddle_cloth_number\",\"gate_name\",\"avg_speed\",\"avg_acceleration\",\"max_speed\",\"min_speed\",\"fatigue_factor\",\"is_fastest_gate\",\"is_slowest_gate\",\"total_distance_run\",\"ground_loss\") VALUES (('CNL'),('2022-07-11 -05'::date),('9'::int4),('5  '),('0.5f'),('16.4'::double precision),('0.0'::double precision),('16.4'::double precision),('16.4'::double precision),('0.18172213417855254'::double precision),('0'::int4),('0'::int4),('1261.3965676748849'::double precision),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(CNL, 2022-07-11, 9, 5  , 0.5f) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.ResultHandlerDelegate.handleError(ResultHandlerDelegate.java:52)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2421)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2153)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.flushIfDeadlockRisk(QueryExecutorImpl.java:1503)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.sendQuery(QueryExecutorImpl.java:1528)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:566)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:888)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1739)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:740)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:896)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:895)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1012)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1012)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2298)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(CNL, 2022-07-11, 9, 5  , 0.5f) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2733)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2420)\n",
      "\t... 22 more\n",
      "24/12/05 22:20:31 ERROR TaskSetManager: Task 23 in stage 14.0 failed 1 times; aborting job\n",
      "ERROR:root:Error processing course CNL: An error occurred while calling o464.jdbc.\n",
      ": org.apache.spark.SparkException: Job aborted due to stage failure: Task 23 in stage 14.0 failed 1 times, most recent failure: Lost task 23.0 in stage 14.0 (TID 45) (mail.relufox.ai executor driver): java.sql.BatchUpdateException: Batch entry 0 INSERT INTO gps_aggregated_results_with_gates (\"course_cd\",\"race_date\",\"race_number\",\"saddle_cloth_number\",\"gate_name\",\"avg_speed\",\"avg_acceleration\",\"max_speed\",\"min_speed\",\"fatigue_factor\",\"is_fastest_gate\",\"is_slowest_gate\",\"total_distance_run\",\"ground_loss\") VALUES (('CNL'),('2022-07-11 -05'::date),('9'::int4),('5  '),('0.5f'),('16.4'::double precision),('0.0'::double precision),('16.4'::double precision),('16.4'::double precision),('0.18172213417855254'::double precision),('0'::int4),('0'::int4),('1261.3965676748849'::double precision),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(CNL, 2022-07-11, 9, 5  , 0.5f) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.ResultHandlerDelegate.handleError(ResultHandlerDelegate.java:52)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2421)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2153)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.flushIfDeadlockRisk(QueryExecutorImpl.java:1503)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.sendQuery(QueryExecutorImpl.java:1528)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:566)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:888)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1739)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:740)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:896)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:895)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1012)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1012)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2298)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(CNL, 2022-07-11, 9, 5  , 0.5f) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2733)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2420)\n",
      "\t... 22 more\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2790)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2726)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2725)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2725)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1211)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1211)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1211)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2989)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2928)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2917)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:976)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2258)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2279)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2298)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2323)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$1(RDD.scala:1012)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n",
      "\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:408)\n",
      "\tat org.apache.spark.rdd.RDD.foreachPartition(RDD.scala:1010)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.saveTable(JdbcUtils.scala:895)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:70)\n",
      "\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:47)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:118)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:195)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:827)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:65)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:94)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:512)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:104)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:512)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:31)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:31)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:31)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:488)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:94)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:81)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:79)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:133)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:856)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:387)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:360)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:247)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.jdbc(DataFrameWriter.scala:753)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: java.sql.BatchUpdateException: Batch entry 0 INSERT INTO gps_aggregated_results_with_gates (\"course_cd\",\"race_date\",\"race_number\",\"saddle_cloth_number\",\"gate_name\",\"avg_speed\",\"avg_acceleration\",\"max_speed\",\"min_speed\",\"fatigue_factor\",\"is_fastest_gate\",\"is_slowest_gate\",\"total_distance_run\",\"ground_loss\") VALUES (('CNL'),('2022-07-11 -05'::date),('9'::int4),('5  '),('0.5f'),('16.4'::double precision),('0.0'::double precision),('16.4'::double precision),('16.4'::double precision),('0.18172213417855254'::double precision),('0'::int4),('0'::int4),('1261.3965676748849'::double precision),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(CNL, 2022-07-11, 9, 5  , 0.5f) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.ResultHandlerDelegate.handleError(ResultHandlerDelegate.java:52)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2421)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2153)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.flushIfDeadlockRisk(QueryExecutorImpl.java:1503)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.sendQuery(QueryExecutorImpl.java:1528)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:566)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:888)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1739)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:740)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:896)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:895)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1012)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1012)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2298)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\t... 1 more\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(CNL, 2022-07-11, 9, 5  , 0.5f) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2733)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2420)\n",
      "\t... 22 more\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Loading data from database for course: SAR\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing course: SAR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:None\n",
      "INFO:root:None\n",
      "INFO:root:None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- gate_name: string (nullable = true)\n",
      " |-- avg_speed: double (nullable = true)\n",
      " |-- avg_acceleration: double (nullable = true)\n",
      " |-- max_speed: double (nullable = true)\n",
      " |-- min_speed: double (nullable = true)\n",
      " |-- fatigue_factor: double (nullable = true)\n",
      " |-- is_fastest_gate: integer (nullable = true)\n",
      " |-- is_slowest_gate: integer (nullable = true)\n",
      "\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- gate_name: string (nullable = true)\n",
      " |-- avg_speed: double (nullable = true)\n",
      " |-- avg_acceleration: double (nullable = true)\n",
      " |-- max_speed: double (nullable = true)\n",
      " |-- min_speed: double (nullable = true)\n",
      " |-- fatigue_factor: double (nullable = true)\n",
      " |-- is_fastest_gate: integer (nullable = true)\n",
      " |-- is_slowest_gate: integer (nullable = true)\n",
      "\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- total_distance_run: double (nullable = true)\n",
      " |-- ground_loss: double (nullable = true)\n",
      "\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- total_distance_run: double (nullable = true)\n",
      " |-- ground_loss: double (nullable = true)\n",
      "\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- gate_name: string (nullable = true)\n",
      " |-- avg_speed: double (nullable = true)\n",
      " |-- avg_acceleration: double (nullable = true)\n",
      " |-- max_speed: double (nullable = true)\n",
      " |-- min_speed: double (nullable = true)\n",
      " |-- fatigue_factor: double (nullable = true)\n",
      " |-- is_fastest_gate: integer (nullable = true)\n",
      " |-- is_slowest_gate: integer (nullable = true)\n",
      " |-- total_distance_run: double (nullable = true)\n",
      " |-- ground_loss: double (nullable = true)\n",
      "\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- gate_name: string (nullable = true)\n",
      " |-- avg_speed: double (nullable = true)\n",
      " |-- avg_acceleration: double (nullable = true)\n",
      " |-- max_speed: double (nullable = true)\n",
      " |-- min_speed: double (nullable = true)\n",
      " |-- fatigue_factor: double (nullable = true)\n",
      " |-- is_fastest_gate: integer (nullable = true)\n",
      " |-- is_slowest_gate: integer (nullable = true)\n",
      " |-- total_distance_run: double (nullable = true)\n",
      " |-- ground_loss: double (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/05 22:20:33 ERROR Executor: Exception in task 14.0 in stage 29.0 (TID 86)]\n",
      "java.sql.BatchUpdateException: Batch entry 0 INSERT INTO gps_aggregated_results_with_gates (\"course_cd\",\"race_date\",\"race_number\",\"saddle_cloth_number\",\"gate_name\",\"avg_speed\",\"avg_acceleration\",\"max_speed\",\"min_speed\",\"fatigue_factor\",\"is_fastest_gate\",\"is_slowest_gate\",\"total_distance_run\",\"ground_loss\") VALUES (('SAR'),('2023-07-13 -05'::date),('10'::int4),('5  '),('0.5f'),('0.12'::double precision),('0.0'::double precision),('0.12'::double precision),('0.12'::double precision),('0.0'::double precision),('1'::int4),('1'::int4),('1945.9310951890839'::double precision),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(SAR, 2023-07-13, 10, 5  , 0.5f) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.ResultHandlerDelegate.handleError(ResultHandlerDelegate.java:52)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2421)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2153)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.flushIfDeadlockRisk(QueryExecutorImpl.java:1503)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.sendQuery(QueryExecutorImpl.java:1528)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:566)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:888)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1739)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:740)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:896)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:895)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1012)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1012)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2298)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(SAR, 2023-07-13, 10, 5  , 0.5f) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2733)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2420)\n",
      "\t... 22 more\n",
      "24/12/05 22:20:33 ERROR Executor: Exception in task 25.0 in stage 29.0 (TID 97)\n",
      "java.sql.BatchUpdateException: Batch entry 0 INSERT INTO gps_aggregated_results_with_gates (\"course_cd\",\"race_date\",\"race_number\",\"saddle_cloth_number\",\"gate_name\",\"avg_speed\",\"avg_acceleration\",\"max_speed\",\"min_speed\",\"fatigue_factor\",\"is_fastest_gate\",\"is_slowest_gate\",\"total_distance_run\",\"ground_loss\") VALUES (('SAR'),('2023-07-13 -05'::date),('6'::int4),('9  '),('0.5f'),('16.5'::double precision),('0.0'::double precision),('16.5'::double precision),('16.5'::double precision),('0.0'::double precision),('1'::int4),('1'::int4),('1294.1670950266748'::double precision),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(SAR, 2023-07-13, 6, 9  , 0.5f) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.ResultHandlerDelegate.handleError(ResultHandlerDelegate.java:52)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2421)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2153)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.flushIfDeadlockRisk(QueryExecutorImpl.java:1503)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.sendQuery(QueryExecutorImpl.java:1528)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:566)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:888)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1739)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:740)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:896)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:895)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1012)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1012)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2298)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(SAR, 2023-07-13, 6, 9  , 0.5f) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2733)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2420)\n",
      "\t... 22 more\n",
      "24/12/05 22:20:33 ERROR TaskSetManager: Task 14 in stage 29.0 failed 1 times; aborting job\n",
      "ERROR:root:Error processing course SAR: An error occurred while calling o881.jdbc.\n",
      ": org.apache.spark.SparkException: Job aborted due to stage failure: Task 14 in stage 29.0 failed 1 times, most recent failure: Lost task 14.0 in stage 29.0 (TID 86) (mail.relufox.ai executor driver): java.sql.BatchUpdateException: Batch entry 0 INSERT INTO gps_aggregated_results_with_gates (\"course_cd\",\"race_date\",\"race_number\",\"saddle_cloth_number\",\"gate_name\",\"avg_speed\",\"avg_acceleration\",\"max_speed\",\"min_speed\",\"fatigue_factor\",\"is_fastest_gate\",\"is_slowest_gate\",\"total_distance_run\",\"ground_loss\") VALUES (('SAR'),('2023-07-13 -05'::date),('10'::int4),('5  '),('0.5f'),('0.12'::double precision),('0.0'::double precision),('0.12'::double precision),('0.12'::double precision),('0.0'::double precision),('1'::int4),('1'::int4),('1945.9310951890839'::double precision),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(SAR, 2023-07-13, 10, 5  , 0.5f) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.ResultHandlerDelegate.handleError(ResultHandlerDelegate.java:52)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2421)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2153)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.flushIfDeadlockRisk(QueryExecutorImpl.java:1503)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.sendQuery(QueryExecutorImpl.java:1528)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:566)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:888)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1739)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:740)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:896)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:895)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1012)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1012)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2298)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(SAR, 2023-07-13, 10, 5  , 0.5f) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2733)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2420)\n",
      "\t... 22 more\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2790)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2726)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2725)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2725)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1211)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1211)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1211)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2989)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2928)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2917)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:976)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2258)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2279)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2298)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2323)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$1(RDD.scala:1012)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n",
      "\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:408)\n",
      "\tat org.apache.spark.rdd.RDD.foreachPartition(RDD.scala:1010)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.saveTable(JdbcUtils.scala:895)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:70)\n",
      "\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:47)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:118)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:195)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:827)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:65)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:94)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:512)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:104)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:512)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:31)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:31)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:31)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:488)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:94)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:81)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:79)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:133)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:856)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:387)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:360)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:247)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.jdbc(DataFrameWriter.scala:753)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: java.sql.BatchUpdateException: Batch entry 0 INSERT INTO gps_aggregated_results_with_gates (\"course_cd\",\"race_date\",\"race_number\",\"saddle_cloth_number\",\"gate_name\",\"avg_speed\",\"avg_acceleration\",\"max_speed\",\"min_speed\",\"fatigue_factor\",\"is_fastest_gate\",\"is_slowest_gate\",\"total_distance_run\",\"ground_loss\") VALUES (('SAR'),('2023-07-13 -05'::date),('10'::int4),('5  '),('0.5f'),('0.12'::double precision),('0.0'::double precision),('0.12'::double precision),('0.12'::double precision),('0.0'::double precision),('1'::int4),('1'::int4),('1945.9310951890839'::double precision),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(SAR, 2023-07-13, 10, 5  , 0.5f) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.ResultHandlerDelegate.handleError(ResultHandlerDelegate.java:52)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2421)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2153)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.flushIfDeadlockRisk(QueryExecutorImpl.java:1503)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.sendQuery(QueryExecutorImpl.java:1528)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:566)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:888)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1739)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:740)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:896)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:895)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1012)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1012)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2298)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\t... 1 more\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(SAR, 2023-07-13, 10, 5  , 0.5f) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2733)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2420)\n",
      "\t... 22 more\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Loading data from database for course: PIM\n",
      "INFO:root:None\n",
      "INFO:root:None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing course: PIM\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- gate_name: string (nullable = true)\n",
      " |-- avg_speed: double (nullable = true)\n",
      " |-- avg_acceleration: double (nullable = true)\n",
      " |-- max_speed: double (nullable = true)\n",
      " |-- min_speed: double (nullable = true)\n",
      " |-- fatigue_factor: double (nullable = true)\n",
      " |-- is_fastest_gate: integer (nullable = true)\n",
      " |-- is_slowest_gate: integer (nullable = true)\n",
      "\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- gate_name: string (nullable = true)\n",
      " |-- avg_speed: double (nullable = true)\n",
      " |-- avg_acceleration: double (nullable = true)\n",
      " |-- max_speed: double (nullable = true)\n",
      " |-- min_speed: double (nullable = true)\n",
      " |-- fatigue_factor: double (nullable = true)\n",
      " |-- is_fastest_gate: integer (nullable = true)\n",
      " |-- is_slowest_gate: integer (nullable = true)\n",
      "\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- total_distance_run: double (nullable = true)\n",
      " |-- ground_loss: double (nullable = true)\n",
      "\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- total_distance_run: double (nullable = true)\n",
      " |-- ground_loss: double (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:None\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- gate_name: string (nullable = true)\n",
      " |-- avg_speed: double (nullable = true)\n",
      " |-- avg_acceleration: double (nullable = true)\n",
      " |-- max_speed: double (nullable = true)\n",
      " |-- min_speed: double (nullable = true)\n",
      " |-- fatigue_factor: double (nullable = true)\n",
      " |-- is_fastest_gate: integer (nullable = true)\n",
      " |-- is_slowest_gate: integer (nullable = true)\n",
      " |-- total_distance_run: double (nullable = true)\n",
      " |-- ground_loss: double (nullable = true)\n",
      "\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- gate_name: string (nullable = true)\n",
      " |-- avg_speed: double (nullable = true)\n",
      " |-- avg_acceleration: double (nullable = true)\n",
      " |-- max_speed: double (nullable = true)\n",
      " |-- min_speed: double (nullable = true)\n",
      " |-- fatigue_factor: double (nullable = true)\n",
      " |-- is_fastest_gate: integer (nullable = true)\n",
      " |-- is_slowest_gate: integer (nullable = true)\n",
      " |-- total_distance_run: double (nullable = true)\n",
      " |-- ground_loss: double (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/05 22:20:34 ERROR Executor: Exception in task 9.0 in stage 44.0 (TID 125)\n",
      "java.sql.BatchUpdateException: Batch entry 0 INSERT INTO gps_aggregated_results_with_gates (\"course_cd\",\"race_date\",\"race_number\",\"saddle_cloth_number\",\"gate_name\",\"avg_speed\",\"avg_acceleration\",\"max_speed\",\"min_speed\",\"fatigue_factor\",\"is_fastest_gate\",\"is_slowest_gate\",\"total_distance_run\",\"ground_loss\") VALUES (('PIM'),('2022-05-12 -05'::date),('1'::int4),('5  '),('0.5f'),('17.31'::double precision),('0.0'::double precision),('17.31'::double precision),('17.31'::double precision),('0.11228460255697599'::double precision),('0'::int4),('0'::int4),('1124.3971816924275'::double precision),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(PIM, 2022-05-12, 1, 5  , 0.5f) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.ResultHandlerDelegate.handleError(ResultHandlerDelegate.java:52)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2421)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2153)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.flushIfDeadlockRisk(QueryExecutorImpl.java:1503)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.sendQuery(QueryExecutorImpl.java:1528)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:566)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:888)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1739)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:740)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:896)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:895)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1012)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1012)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2298)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(PIM, 2022-05-12, 1, 5  , 0.5f) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2733)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2420)\n",
      "\t... 22 more\n",
      "24/12/05 22:20:34 ERROR TaskSetManager: Task 9 in stage 44.0 failed 1 times; aborting job\n",
      "ERROR:root:Error processing course PIM: An error occurred while calling o1298.jdbc.\n",
      ": org.apache.spark.SparkException: Job aborted due to stage failure: Task 9 in stage 44.0 failed 1 times, most recent failure: Lost task 9.0 in stage 44.0 (TID 125) (mail.relufox.ai executor driver): java.sql.BatchUpdateException: Batch entry 0 INSERT INTO gps_aggregated_results_with_gates (\"course_cd\",\"race_date\",\"race_number\",\"saddle_cloth_number\",\"gate_name\",\"avg_speed\",\"avg_acceleration\",\"max_speed\",\"min_speed\",\"fatigue_factor\",\"is_fastest_gate\",\"is_slowest_gate\",\"total_distance_run\",\"ground_loss\") VALUES (('PIM'),('2022-05-12 -05'::date),('1'::int4),('5  '),('0.5f'),('17.31'::double precision),('0.0'::double precision),('17.31'::double precision),('17.31'::double precision),('0.11228460255697599'::double precision),('0'::int4),('0'::int4),('1124.3971816924275'::double precision),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(PIM, 2022-05-12, 1, 5  , 0.5f) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.ResultHandlerDelegate.handleError(ResultHandlerDelegate.java:52)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2421)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2153)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.flushIfDeadlockRisk(QueryExecutorImpl.java:1503)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.sendQuery(QueryExecutorImpl.java:1528)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:566)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:888)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1739)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:740)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:896)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:895)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1012)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1012)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2298)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(PIM, 2022-05-12, 1, 5  , 0.5f) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2733)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2420)\n",
      "\t... 22 more\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2790)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2726)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2725)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2725)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1211)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1211)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1211)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2989)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2928)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2917)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:976)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2258)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2279)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2298)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2323)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$1(RDD.scala:1012)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n",
      "\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:408)\n",
      "\tat org.apache.spark.rdd.RDD.foreachPartition(RDD.scala:1010)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.saveTable(JdbcUtils.scala:895)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:70)\n",
      "\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:47)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:118)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:195)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:827)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:65)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:94)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:512)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:104)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:512)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:31)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:31)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:31)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:488)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:94)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:81)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:79)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:133)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:856)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:387)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:360)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:247)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.jdbc(DataFrameWriter.scala:753)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: java.sql.BatchUpdateException: Batch entry 0 INSERT INTO gps_aggregated_results_with_gates (\"course_cd\",\"race_date\",\"race_number\",\"saddle_cloth_number\",\"gate_name\",\"avg_speed\",\"avg_acceleration\",\"max_speed\",\"min_speed\",\"fatigue_factor\",\"is_fastest_gate\",\"is_slowest_gate\",\"total_distance_run\",\"ground_loss\") VALUES (('PIM'),('2022-05-12 -05'::date),('1'::int4),('5  '),('0.5f'),('17.31'::double precision),('0.0'::double precision),('17.31'::double precision),('17.31'::double precision),('0.11228460255697599'::double precision),('0'::int4),('0'::int4),('1124.3971816924275'::double precision),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(PIM, 2022-05-12, 1, 5  , 0.5f) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.ResultHandlerDelegate.handleError(ResultHandlerDelegate.java:52)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2421)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2153)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.flushIfDeadlockRisk(QueryExecutorImpl.java:1503)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.sendQuery(QueryExecutorImpl.java:1528)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:566)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:888)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1739)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:740)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:896)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:895)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1012)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1012)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2298)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\t... 1 more\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(PIM, 2022-05-12, 1, 5  , 0.5f) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2733)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2420)\n",
      "\t... 22 more\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Loading data from database for course: TSA\n",
      "INFO:root:None\n",
      "INFO:root:None\n",
      "INFO:root:None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing course: TSA\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- gate_name: string (nullable = true)\n",
      " |-- avg_speed: double (nullable = true)\n",
      " |-- avg_acceleration: double (nullable = true)\n",
      " |-- max_speed: double (nullable = true)\n",
      " |-- min_speed: double (nullable = true)\n",
      " |-- fatigue_factor: double (nullable = true)\n",
      " |-- is_fastest_gate: integer (nullable = true)\n",
      " |-- is_slowest_gate: integer (nullable = true)\n",
      "\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- gate_name: string (nullable = true)\n",
      " |-- avg_speed: double (nullable = true)\n",
      " |-- avg_acceleration: double (nullable = true)\n",
      " |-- max_speed: double (nullable = true)\n",
      " |-- min_speed: double (nullable = true)\n",
      " |-- fatigue_factor: double (nullable = true)\n",
      " |-- is_fastest_gate: integer (nullable = true)\n",
      " |-- is_slowest_gate: integer (nullable = true)\n",
      "\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- total_distance_run: double (nullable = true)\n",
      " |-- ground_loss: double (nullable = true)\n",
      "\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- total_distance_run: double (nullable = true)\n",
      " |-- ground_loss: double (nullable = true)\n",
      "\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- gate_name: string (nullable = true)\n",
      " |-- avg_speed: double (nullable = true)\n",
      " |-- avg_acceleration: double (nullable = true)\n",
      " |-- max_speed: double (nullable = true)\n",
      " |-- min_speed: double (nullable = true)\n",
      " |-- fatigue_factor: double (nullable = true)\n",
      " |-- is_fastest_gate: integer (nullable = true)\n",
      " |-- is_slowest_gate: integer (nullable = true)\n",
      " |-- total_distance_run: double (nullable = true)\n",
      " |-- ground_loss: double (nullable = true)\n",
      "\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- gate_name: string (nullable = true)\n",
      " |-- avg_speed: double (nullable = true)\n",
      " |-- avg_acceleration: double (nullable = true)\n",
      " |-- max_speed: double (nullable = true)\n",
      " |-- min_speed: double (nullable = true)\n",
      " |-- fatigue_factor: double (nullable = true)\n",
      " |-- is_fastest_gate: integer (nullable = true)\n",
      " |-- is_slowest_gate: integer (nullable = true)\n",
      " |-- total_distance_run: double (nullable = true)\n",
      " |-- ground_loss: double (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/05 22:20:37 ERROR Executor: Exception in task 19.0 in stage 59.0 (TID 187)\n",
      "java.sql.BatchUpdateException: Batch entry 0 INSERT INTO gps_aggregated_results_with_gates (\"course_cd\",\"race_date\",\"race_number\",\"saddle_cloth_number\",\"gate_name\",\"avg_speed\",\"avg_acceleration\",\"max_speed\",\"min_speed\",\"fatigue_factor\",\"is_fastest_gate\",\"is_slowest_gate\",\"total_distance_run\",\"ground_loss\") VALUES (('TSA'),('2022-10-21 -05'::date),('7'::int4),('5  '),('0.5f'),('14.48'::double precision),('0.0'::double precision),('14.48'::double precision),('14.48'::double precision),('0.2818371607515658'::double precision),('0'::int4),('0'::int4),('1343.0202193956932'::double precision),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(TSA, 2022-10-21, 7, 5  , 0.5f) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.ResultHandlerDelegate.handleError(ResultHandlerDelegate.java:52)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2421)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2153)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.flushIfDeadlockRisk(QueryExecutorImpl.java:1503)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.sendQuery(QueryExecutorImpl.java:1528)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:566)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:888)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1739)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:740)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:896)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:895)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1012)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1012)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2298)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(TSA, 2022-10-21, 7, 5  , 0.5f) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2733)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2420)\n",
      "\t... 22 more\n",
      "24/12/05 22:20:37 ERROR TaskSetManager: Task 19 in stage 59.0 failed 1 times; aborting job\n",
      "ERROR:root:Error processing course TSA: An error occurred while calling o1715.jdbc.\n",
      ": org.apache.spark.SparkException: Job aborted due to stage failure: Task 19 in stage 59.0 failed 1 times, most recent failure: Lost task 19.0 in stage 59.0 (TID 187) (mail.relufox.ai executor driver): java.sql.BatchUpdateException: Batch entry 0 INSERT INTO gps_aggregated_results_with_gates (\"course_cd\",\"race_date\",\"race_number\",\"saddle_cloth_number\",\"gate_name\",\"avg_speed\",\"avg_acceleration\",\"max_speed\",\"min_speed\",\"fatigue_factor\",\"is_fastest_gate\",\"is_slowest_gate\",\"total_distance_run\",\"ground_loss\") VALUES (('TSA'),('2022-10-21 -05'::date),('7'::int4),('5  '),('0.5f'),('14.48'::double precision),('0.0'::double precision),('14.48'::double precision),('14.48'::double precision),('0.2818371607515658'::double precision),('0'::int4),('0'::int4),('1343.0202193956932'::double precision),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(TSA, 2022-10-21, 7, 5  , 0.5f) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.ResultHandlerDelegate.handleError(ResultHandlerDelegate.java:52)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2421)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2153)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.flushIfDeadlockRisk(QueryExecutorImpl.java:1503)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.sendQuery(QueryExecutorImpl.java:1528)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:566)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:888)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1739)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:740)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:896)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:895)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1012)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1012)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2298)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(TSA, 2022-10-21, 7, 5  , 0.5f) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2733)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2420)\n",
      "\t... 22 more\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2790)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2726)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2725)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2725)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1211)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1211)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1211)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2989)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2928)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2917)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:976)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2258)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2279)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2298)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2323)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$1(RDD.scala:1012)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n",
      "\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:408)\n",
      "\tat org.apache.spark.rdd.RDD.foreachPartition(RDD.scala:1010)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.saveTable(JdbcUtils.scala:895)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:70)\n",
      "\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:47)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:118)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:195)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:827)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:65)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:94)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:512)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:104)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:512)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:31)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:31)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:31)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:488)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:94)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:81)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:79)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:133)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:856)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:387)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:360)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:247)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.jdbc(DataFrameWriter.scala:753)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: java.sql.BatchUpdateException: Batch entry 0 INSERT INTO gps_aggregated_results_with_gates (\"course_cd\",\"race_date\",\"race_number\",\"saddle_cloth_number\",\"gate_name\",\"avg_speed\",\"avg_acceleration\",\"max_speed\",\"min_speed\",\"fatigue_factor\",\"is_fastest_gate\",\"is_slowest_gate\",\"total_distance_run\",\"ground_loss\") VALUES (('TSA'),('2022-10-21 -05'::date),('7'::int4),('5  '),('0.5f'),('14.48'::double precision),('0.0'::double precision),('14.48'::double precision),('14.48'::double precision),('0.2818371607515658'::double precision),('0'::int4),('0'::int4),('1343.0202193956932'::double precision),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(TSA, 2022-10-21, 7, 5  , 0.5f) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.ResultHandlerDelegate.handleError(ResultHandlerDelegate.java:52)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2421)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2153)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.flushIfDeadlockRisk(QueryExecutorImpl.java:1503)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.sendQuery(QueryExecutorImpl.java:1528)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:566)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:888)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1739)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:740)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:896)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:895)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1012)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1012)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2298)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\t... 1 more\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(TSA, 2022-10-21, 7, 5  , 0.5f) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2733)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2420)\n",
      "\t... 22 more\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Loading data from database for course: BEL\n",
      "INFO:root:None\n",
      "INFO:root:None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing course: BEL\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- gate_name: string (nullable = true)\n",
      " |-- avg_speed: double (nullable = true)\n",
      " |-- avg_acceleration: double (nullable = true)\n",
      " |-- max_speed: double (nullable = true)\n",
      " |-- min_speed: double (nullable = true)\n",
      " |-- fatigue_factor: double (nullable = true)\n",
      " |-- is_fastest_gate: integer (nullable = true)\n",
      " |-- is_slowest_gate: integer (nullable = true)\n",
      "\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- gate_name: string (nullable = true)\n",
      " |-- avg_speed: double (nullable = true)\n",
      " |-- avg_acceleration: double (nullable = true)\n",
      " |-- max_speed: double (nullable = true)\n",
      " |-- min_speed: double (nullable = true)\n",
      " |-- fatigue_factor: double (nullable = true)\n",
      " |-- is_fastest_gate: integer (nullable = true)\n",
      " |-- is_slowest_gate: integer (nullable = true)\n",
      "\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- total_distance_run: double (nullable = true)\n",
      " |-- ground_loss: double (nullable = true)\n",
      "\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- total_distance_run: double (nullable = true)\n",
      " |-- ground_loss: double (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:None\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- gate_name: string (nullable = true)\n",
      " |-- avg_speed: double (nullable = true)\n",
      " |-- avg_acceleration: double (nullable = true)\n",
      " |-- max_speed: double (nullable = true)\n",
      " |-- min_speed: double (nullable = true)\n",
      " |-- fatigue_factor: double (nullable = true)\n",
      " |-- is_fastest_gate: integer (nullable = true)\n",
      " |-- is_slowest_gate: integer (nullable = true)\n",
      " |-- total_distance_run: double (nullable = true)\n",
      " |-- ground_loss: double (nullable = true)\n",
      "\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- gate_name: string (nullable = true)\n",
      " |-- avg_speed: double (nullable = true)\n",
      " |-- avg_acceleration: double (nullable = true)\n",
      " |-- max_speed: double (nullable = true)\n",
      " |-- min_speed: double (nullable = true)\n",
      " |-- fatigue_factor: double (nullable = true)\n",
      " |-- is_fastest_gate: integer (nullable = true)\n",
      " |-- is_slowest_gate: integer (nullable = true)\n",
      " |-- total_distance_run: double (nullable = true)\n",
      " |-- ground_loss: double (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/05 22:20:38 ERROR Executor: Exception in task 4.0 in stage 74.0 (TID 235)\n",
      "java.sql.BatchUpdateException: Batch entry 0 INSERT INTO gps_aggregated_results_with_gates (\"course_cd\",\"race_date\",\"race_number\",\"saddle_cloth_number\",\"gate_name\",\"avg_speed\",\"avg_acceleration\",\"max_speed\",\"min_speed\",\"fatigue_factor\",\"is_fastest_gate\",\"is_slowest_gate\",\"total_distance_run\",\"ground_loss\") VALUES (('BEL'),('2023-05-04 -05'::date),('2'::int4),('3  '),('0.5f'),('14.24'::double precision),('0.0'::double precision),('14.24'::double precision),('14.24'::double precision),('0.0'::double precision),('1'::int4),('1'::int4),('1359.9760341082974'::double precision),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(BEL, 2023-05-04, 2, 3  , 0.5f) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.ResultHandlerDelegate.handleError(ResultHandlerDelegate.java:52)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2421)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2153)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.flushIfDeadlockRisk(QueryExecutorImpl.java:1503)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.sendQuery(QueryExecutorImpl.java:1528)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:566)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:888)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1739)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:740)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:896)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:895)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1012)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1012)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2298)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(BEL, 2023-05-04, 2, 3  , 0.5f) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2733)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2420)\n",
      "\t... 22 more\n",
      "24/12/05 22:20:38 ERROR Executor: Exception in task 8.0 in stage 74.0 (TID 239)\n",
      "java.sql.BatchUpdateException: Batch entry 0 INSERT INTO gps_aggregated_results_with_gates (\"course_cd\",\"race_date\",\"race_number\",\"saddle_cloth_number\",\"gate_name\",\"avg_speed\",\"avg_acceleration\",\"max_speed\",\"min_speed\",\"fatigue_factor\",\"is_fastest_gate\",\"is_slowest_gate\",\"total_distance_run\",\"ground_loss\") VALUES (('BEL'),('2023-05-04 -05'::date),('2'::int4),('6  '),('0.5f'),('0.05'::double precision),('0.0'::double precision),('0.05'::double precision),('0.05'::double precision),('0.0'::double precision),('1'::int4),('1'::int4),('1384.2293701214408'::double precision),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(BEL, 2023-05-04, 2, 6  , 0.5f) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.ResultHandlerDelegate.handleError(ResultHandlerDelegate.java:52)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2421)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2153)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.flushIfDeadlockRisk(QueryExecutorImpl.java:1503)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.sendQuery(QueryExecutorImpl.java:1528)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:566)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:888)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1739)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:740)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:896)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:895)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1012)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1012)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2298)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(BEL, 2023-05-04, 2, 6  , 0.5f) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2733)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2420)\n",
      "\t... 22 more\n",
      "24/12/05 22:20:38 ERROR TaskSetManager: Task 4 in stage 74.0 failed 1 times; aborting job\n",
      "ERROR:root:Error processing course BEL: An error occurred while calling o2132.jdbc.\n",
      ": org.apache.spark.SparkException: Job aborted due to stage failure: Task 4 in stage 74.0 failed 1 times, most recent failure: Lost task 4.0 in stage 74.0 (TID 235) (mail.relufox.ai executor driver): java.sql.BatchUpdateException: Batch entry 0 INSERT INTO gps_aggregated_results_with_gates (\"course_cd\",\"race_date\",\"race_number\",\"saddle_cloth_number\",\"gate_name\",\"avg_speed\",\"avg_acceleration\",\"max_speed\",\"min_speed\",\"fatigue_factor\",\"is_fastest_gate\",\"is_slowest_gate\",\"total_distance_run\",\"ground_loss\") VALUES (('BEL'),('2023-05-04 -05'::date),('2'::int4),('3  '),('0.5f'),('14.24'::double precision),('0.0'::double precision),('14.24'::double precision),('14.24'::double precision),('0.0'::double precision),('1'::int4),('1'::int4),('1359.9760341082974'::double precision),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(BEL, 2023-05-04, 2, 3  , 0.5f) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.ResultHandlerDelegate.handleError(ResultHandlerDelegate.java:52)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2421)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2153)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.flushIfDeadlockRisk(QueryExecutorImpl.java:1503)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.sendQuery(QueryExecutorImpl.java:1528)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:566)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:888)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1739)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:740)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:896)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:895)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1012)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1012)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2298)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(BEL, 2023-05-04, 2, 3  , 0.5f) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2733)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2420)\n",
      "\t... 22 more\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2790)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2726)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2725)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2725)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1211)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1211)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1211)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2989)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2928)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2917)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:976)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2258)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2279)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2298)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2323)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$1(RDD.scala:1012)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n",
      "\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:408)\n",
      "\tat org.apache.spark.rdd.RDD.foreachPartition(RDD.scala:1010)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.saveTable(JdbcUtils.scala:895)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:70)\n",
      "\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:47)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:118)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:195)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:827)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:65)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:94)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:512)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:104)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:512)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:31)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:31)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:31)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:488)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:94)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:81)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:79)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:133)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:856)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:387)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:360)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:247)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.jdbc(DataFrameWriter.scala:753)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: java.sql.BatchUpdateException: Batch entry 0 INSERT INTO gps_aggregated_results_with_gates (\"course_cd\",\"race_date\",\"race_number\",\"saddle_cloth_number\",\"gate_name\",\"avg_speed\",\"avg_acceleration\",\"max_speed\",\"min_speed\",\"fatigue_factor\",\"is_fastest_gate\",\"is_slowest_gate\",\"total_distance_run\",\"ground_loss\") VALUES (('BEL'),('2023-05-04 -05'::date),('2'::int4),('3  '),('0.5f'),('14.24'::double precision),('0.0'::double precision),('14.24'::double precision),('14.24'::double precision),('0.0'::double precision),('1'::int4),('1'::int4),('1359.9760341082974'::double precision),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(BEL, 2023-05-04, 2, 3  , 0.5f) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.ResultHandlerDelegate.handleError(ResultHandlerDelegate.java:52)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2421)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2153)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.flushIfDeadlockRisk(QueryExecutorImpl.java:1503)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.sendQuery(QueryExecutorImpl.java:1528)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:566)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:888)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1739)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:740)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:896)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:895)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1012)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1012)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2298)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\t... 1 more\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(BEL, 2023-05-04, 2, 3  , 0.5f) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2733)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2420)\n",
      "\t... 22 more\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Loading data from database for course: MVR\n",
      "INFO:root:None\n",
      "INFO:root:None\n",
      "INFO:root:None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing course: MVR\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- gate_name: string (nullable = true)\n",
      " |-- avg_speed: double (nullable = true)\n",
      " |-- avg_acceleration: double (nullable = true)\n",
      " |-- max_speed: double (nullable = true)\n",
      " |-- min_speed: double (nullable = true)\n",
      " |-- fatigue_factor: double (nullable = true)\n",
      " |-- is_fastest_gate: integer (nullable = true)\n",
      " |-- is_slowest_gate: integer (nullable = true)\n",
      "\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- gate_name: string (nullable = true)\n",
      " |-- avg_speed: double (nullable = true)\n",
      " |-- avg_acceleration: double (nullable = true)\n",
      " |-- max_speed: double (nullable = true)\n",
      " |-- min_speed: double (nullable = true)\n",
      " |-- fatigue_factor: double (nullable = true)\n",
      " |-- is_fastest_gate: integer (nullable = true)\n",
      " |-- is_slowest_gate: integer (nullable = true)\n",
      "\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- total_distance_run: double (nullable = true)\n",
      " |-- ground_loss: double (nullable = true)\n",
      "\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- total_distance_run: double (nullable = true)\n",
      " |-- ground_loss: double (nullable = true)\n",
      "\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- gate_name: string (nullable = true)\n",
      " |-- avg_speed: double (nullable = true)\n",
      " |-- avg_acceleration: double (nullable = true)\n",
      " |-- max_speed: double (nullable = true)\n",
      " |-- min_speed: double (nullable = true)\n",
      " |-- fatigue_factor: double (nullable = true)\n",
      " |-- is_fastest_gate: integer (nullable = true)\n",
      " |-- is_slowest_gate: integer (nullable = true)\n",
      " |-- total_distance_run: double (nullable = true)\n",
      " |-- ground_loss: double (nullable = true)\n",
      "\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- gate_name: string (nullable = true)\n",
      " |-- avg_speed: double (nullable = true)\n",
      " |-- avg_acceleration: double (nullable = true)\n",
      " |-- max_speed: double (nullable = true)\n",
      " |-- min_speed: double (nullable = true)\n",
      " |-- fatigue_factor: double (nullable = true)\n",
      " |-- is_fastest_gate: integer (nullable = true)\n",
      " |-- is_slowest_gate: integer (nullable = true)\n",
      " |-- total_distance_run: double (nullable = true)\n",
      " |-- ground_loss: double (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/05 22:20:40 ERROR Executor: Exception in task 6.0 in stage 97.0 (TID 282)]\n",
      "java.sql.BatchUpdateException: Batch entry 0 INSERT INTO gps_aggregated_results_with_gates (\"course_cd\",\"race_date\",\"race_number\",\"saddle_cloth_number\",\"gate_name\",\"avg_speed\",\"avg_acceleration\",\"max_speed\",\"min_speed\",\"fatigue_factor\",\"is_fastest_gate\",\"is_slowest_gate\",\"total_distance_run\",\"ground_loss\") VALUES (('MVR'),('2022-01-01 -06'::date),('3'::int4),('1  '),('0.5f'),('14.33'::double precision),('0.0'::double precision),('14.33'::double precision),('14.33'::double precision),('0.2981333333333333'::double precision),('0'::int4),('0'::int4),('1342.7537205718252'::double precision),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(MVR, 2022-01-01, 3, 1  , 0.5f) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.ResultHandlerDelegate.handleError(ResultHandlerDelegate.java:52)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2421)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2153)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.flushIfDeadlockRisk(QueryExecutorImpl.java:1503)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.sendQuery(QueryExecutorImpl.java:1528)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:566)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:888)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1739)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:740)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:896)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:895)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1012)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1012)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2298)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(MVR, 2022-01-01, 3, 1  , 0.5f) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2733)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2420)\n",
      "\t... 22 more\n",
      "24/12/05 22:20:40 ERROR TaskSetManager: Task 6 in stage 97.0 failed 1 times; aborting job\n",
      "ERROR:root:Error processing course MVR: An error occurred while calling o2549.jdbc.\n",
      ": org.apache.spark.SparkException: Job aborted due to stage failure: Task 6 in stage 97.0 failed 1 times, most recent failure: Lost task 6.0 in stage 97.0 (TID 282) (mail.relufox.ai executor driver): java.sql.BatchUpdateException: Batch entry 0 INSERT INTO gps_aggregated_results_with_gates (\"course_cd\",\"race_date\",\"race_number\",\"saddle_cloth_number\",\"gate_name\",\"avg_speed\",\"avg_acceleration\",\"max_speed\",\"min_speed\",\"fatigue_factor\",\"is_fastest_gate\",\"is_slowest_gate\",\"total_distance_run\",\"ground_loss\") VALUES (('MVR'),('2022-01-01 -06'::date),('3'::int4),('1  '),('0.5f'),('14.33'::double precision),('0.0'::double precision),('14.33'::double precision),('14.33'::double precision),('0.2981333333333333'::double precision),('0'::int4),('0'::int4),('1342.7537205718252'::double precision),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(MVR, 2022-01-01, 3, 1  , 0.5f) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.ResultHandlerDelegate.handleError(ResultHandlerDelegate.java:52)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2421)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2153)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.flushIfDeadlockRisk(QueryExecutorImpl.java:1503)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.sendQuery(QueryExecutorImpl.java:1528)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:566)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:888)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1739)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:740)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:896)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:895)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1012)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1012)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2298)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(MVR, 2022-01-01, 3, 1  , 0.5f) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2733)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2420)\n",
      "\t... 22 more\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2790)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2726)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2725)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2725)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1211)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1211)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1211)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2989)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2928)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2917)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:976)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2258)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2279)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2298)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2323)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$1(RDD.scala:1012)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n",
      "\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:408)\n",
      "\tat org.apache.spark.rdd.RDD.foreachPartition(RDD.scala:1010)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.saveTable(JdbcUtils.scala:895)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:70)\n",
      "\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:47)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:118)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:195)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:827)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:65)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:94)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:512)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:104)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:512)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:31)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:31)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:31)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:488)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:94)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:81)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:79)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:133)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:856)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:387)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:360)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:247)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.jdbc(DataFrameWriter.scala:753)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: java.sql.BatchUpdateException: Batch entry 0 INSERT INTO gps_aggregated_results_with_gates (\"course_cd\",\"race_date\",\"race_number\",\"saddle_cloth_number\",\"gate_name\",\"avg_speed\",\"avg_acceleration\",\"max_speed\",\"min_speed\",\"fatigue_factor\",\"is_fastest_gate\",\"is_slowest_gate\",\"total_distance_run\",\"ground_loss\") VALUES (('MVR'),('2022-01-01 -06'::date),('3'::int4),('1  '),('0.5f'),('14.33'::double precision),('0.0'::double precision),('14.33'::double precision),('14.33'::double precision),('0.2981333333333333'::double precision),('0'::int4),('0'::int4),('1342.7537205718252'::double precision),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(MVR, 2022-01-01, 3, 1  , 0.5f) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.ResultHandlerDelegate.handleError(ResultHandlerDelegate.java:52)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2421)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2153)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.flushIfDeadlockRisk(QueryExecutorImpl.java:1503)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.sendQuery(QueryExecutorImpl.java:1528)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:566)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:888)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1739)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:740)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:896)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:895)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1012)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1012)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2298)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\t... 1 more\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(MVR, 2022-01-01, 3, 1  , 0.5f) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2733)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2420)\n",
      "\t... 22 more\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Loading data from database for course: TWO\n",
      "INFO:root:None\n",
      "INFO:root:None\n",
      "INFO:root:None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing course: TWO\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- gate_name: string (nullable = true)\n",
      " |-- avg_speed: double (nullable = true)\n",
      " |-- avg_acceleration: double (nullable = true)\n",
      " |-- max_speed: double (nullable = true)\n",
      " |-- min_speed: double (nullable = true)\n",
      " |-- fatigue_factor: double (nullable = true)\n",
      " |-- is_fastest_gate: integer (nullable = true)\n",
      " |-- is_slowest_gate: integer (nullable = true)\n",
      "\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- gate_name: string (nullable = true)\n",
      " |-- avg_speed: double (nullable = true)\n",
      " |-- avg_acceleration: double (nullable = true)\n",
      " |-- max_speed: double (nullable = true)\n",
      " |-- min_speed: double (nullable = true)\n",
      " |-- fatigue_factor: double (nullable = true)\n",
      " |-- is_fastest_gate: integer (nullable = true)\n",
      " |-- is_slowest_gate: integer (nullable = true)\n",
      "\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- total_distance_run: double (nullable = true)\n",
      " |-- ground_loss: double (nullable = true)\n",
      "\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- total_distance_run: double (nullable = true)\n",
      " |-- ground_loss: double (nullable = true)\n",
      "\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- gate_name: string (nullable = true)\n",
      " |-- avg_speed: double (nullable = true)\n",
      " |-- avg_acceleration: double (nullable = true)\n",
      " |-- max_speed: double (nullable = true)\n",
      " |-- min_speed: double (nullable = true)\n",
      " |-- fatigue_factor: double (nullable = true)\n",
      " |-- is_fastest_gate: integer (nullable = true)\n",
      " |-- is_slowest_gate: integer (nullable = true)\n",
      " |-- total_distance_run: double (nullable = true)\n",
      " |-- ground_loss: double (nullable = true)\n",
      "\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- gate_name: string (nullable = true)\n",
      " |-- avg_speed: double (nullable = true)\n",
      " |-- avg_acceleration: double (nullable = true)\n",
      " |-- max_speed: double (nullable = true)\n",
      " |-- min_speed: double (nullable = true)\n",
      " |-- fatigue_factor: double (nullable = true)\n",
      " |-- is_fastest_gate: integer (nullable = true)\n",
      " |-- is_slowest_gate: integer (nullable = true)\n",
      " |-- total_distance_run: double (nullable = true)\n",
      " |-- ground_loss: double (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/05 22:20:45 ERROR Executor: Exception in task 53.0 in stage 112.0 (TID 413)\n",
      "java.sql.BatchUpdateException: Batch entry 0 INSERT INTO gps_aggregated_results_with_gates (\"course_cd\",\"race_date\",\"race_number\",\"saddle_cloth_number\",\"gate_name\",\"avg_speed\",\"avg_acceleration\",\"max_speed\",\"min_speed\",\"fatigue_factor\",\"is_fastest_gate\",\"is_slowest_gate\",\"total_distance_run\",\"ground_loss\") VALUES (('TWO'),('2022-04-16 -05'::date),('2'::int4),('5  '),('0.5f'),('16.94'::double precision),('0.0'::double precision),('16.94'::double precision),('16.94'::double precision),('0.2152514872904272'::double precision),('0'::int4),('0'::int4),('1177.4065558045581'::double precision),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(TWO, 2022-04-16, 2, 5  , 0.5f) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.ResultHandlerDelegate.handleError(ResultHandlerDelegate.java:52)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2421)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2153)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.flushIfDeadlockRisk(QueryExecutorImpl.java:1503)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.sendQuery(QueryExecutorImpl.java:1528)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:566)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:888)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1739)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:740)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:896)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:895)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1012)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1012)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2298)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(TWO, 2022-04-16, 2, 5  , 0.5f) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2733)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2420)\n",
      "\t... 22 more\n",
      "24/12/05 22:20:45 ERROR TaskSetManager: Task 53 in stage 112.0 failed 1 times; aborting job\n",
      "ERROR:root:Error processing course TWO: An error occurred while calling o2966.jdbc.\n",
      ": org.apache.spark.SparkException: Job aborted due to stage failure: Task 53 in stage 112.0 failed 1 times, most recent failure: Lost task 53.0 in stage 112.0 (TID 413) (mail.relufox.ai executor driver): java.sql.BatchUpdateException: Batch entry 0 INSERT INTO gps_aggregated_results_with_gates (\"course_cd\",\"race_date\",\"race_number\",\"saddle_cloth_number\",\"gate_name\",\"avg_speed\",\"avg_acceleration\",\"max_speed\",\"min_speed\",\"fatigue_factor\",\"is_fastest_gate\",\"is_slowest_gate\",\"total_distance_run\",\"ground_loss\") VALUES (('TWO'),('2022-04-16 -05'::date),('2'::int4),('5  '),('0.5f'),('16.94'::double precision),('0.0'::double precision),('16.94'::double precision),('16.94'::double precision),('0.2152514872904272'::double precision),('0'::int4),('0'::int4),('1177.4065558045581'::double precision),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(TWO, 2022-04-16, 2, 5  , 0.5f) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.ResultHandlerDelegate.handleError(ResultHandlerDelegate.java:52)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2421)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2153)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.flushIfDeadlockRisk(QueryExecutorImpl.java:1503)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.sendQuery(QueryExecutorImpl.java:1528)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:566)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:888)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1739)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:740)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:896)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:895)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1012)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1012)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2298)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(TWO, 2022-04-16, 2, 5  , 0.5f) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2733)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2420)\n",
      "\t... 22 more\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2790)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2726)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2725)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2725)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1211)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1211)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1211)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2989)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2928)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2917)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:976)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2258)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2279)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2298)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2323)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$1(RDD.scala:1012)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n",
      "\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:408)\n",
      "\tat org.apache.spark.rdd.RDD.foreachPartition(RDD.scala:1010)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.saveTable(JdbcUtils.scala:895)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:70)\n",
      "\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:47)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:118)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:195)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:827)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:65)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:94)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:512)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:104)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:512)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:31)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:31)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:31)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:488)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:94)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:81)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:79)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:133)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:856)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:387)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:360)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:247)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.jdbc(DataFrameWriter.scala:753)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: java.sql.BatchUpdateException: Batch entry 0 INSERT INTO gps_aggregated_results_with_gates (\"course_cd\",\"race_date\",\"race_number\",\"saddle_cloth_number\",\"gate_name\",\"avg_speed\",\"avg_acceleration\",\"max_speed\",\"min_speed\",\"fatigue_factor\",\"is_fastest_gate\",\"is_slowest_gate\",\"total_distance_run\",\"ground_loss\") VALUES (('TWO'),('2022-04-16 -05'::date),('2'::int4),('5  '),('0.5f'),('16.94'::double precision),('0.0'::double precision),('16.94'::double precision),('16.94'::double precision),('0.2152514872904272'::double precision),('0'::int4),('0'::int4),('1177.4065558045581'::double precision),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(TWO, 2022-04-16, 2, 5  , 0.5f) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.ResultHandlerDelegate.handleError(ResultHandlerDelegate.java:52)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2421)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2153)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.flushIfDeadlockRisk(QueryExecutorImpl.java:1503)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.sendQuery(QueryExecutorImpl.java:1528)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:566)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:888)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1739)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:740)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:896)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:895)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1012)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1012)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2298)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\t... 1 more\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(TWO, 2022-04-16, 2, 5  , 0.5f) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2733)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2420)\n",
      "\t... 22 more\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Loading data from database for course: CLS\n",
      "INFO:root:None\n",
      "INFO:root:None\n",
      "INFO:root:None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing course: CLS\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- gate_name: string (nullable = true)\n",
      " |-- avg_speed: double (nullable = true)\n",
      " |-- avg_acceleration: double (nullable = true)\n",
      " |-- max_speed: double (nullable = true)\n",
      " |-- min_speed: double (nullable = true)\n",
      " |-- fatigue_factor: double (nullable = true)\n",
      " |-- is_fastest_gate: integer (nullable = true)\n",
      " |-- is_slowest_gate: integer (nullable = true)\n",
      "\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- gate_name: string (nullable = true)\n",
      " |-- avg_speed: double (nullable = true)\n",
      " |-- avg_acceleration: double (nullable = true)\n",
      " |-- max_speed: double (nullable = true)\n",
      " |-- min_speed: double (nullable = true)\n",
      " |-- fatigue_factor: double (nullable = true)\n",
      " |-- is_fastest_gate: integer (nullable = true)\n",
      " |-- is_slowest_gate: integer (nullable = true)\n",
      "\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- total_distance_run: double (nullable = true)\n",
      " |-- ground_loss: double (nullable = true)\n",
      "\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- total_distance_run: double (nullable = true)\n",
      " |-- ground_loss: double (nullable = true)\n",
      "\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- gate_name: string (nullable = true)\n",
      " |-- avg_speed: double (nullable = true)\n",
      " |-- avg_acceleration: double (nullable = true)\n",
      " |-- max_speed: double (nullable = true)\n",
      " |-- min_speed: double (nullable = true)\n",
      " |-- fatigue_factor: double (nullable = true)\n",
      " |-- is_fastest_gate: integer (nullable = true)\n",
      " |-- is_slowest_gate: integer (nullable = true)\n",
      " |-- total_distance_run: double (nullable = true)\n",
      " |-- ground_loss: double (nullable = true)\n",
      "\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- gate_name: string (nullable = true)\n",
      " |-- avg_speed: double (nullable = true)\n",
      " |-- avg_acceleration: double (nullable = true)\n",
      " |-- max_speed: double (nullable = true)\n",
      " |-- min_speed: double (nullable = true)\n",
      " |-- fatigue_factor: double (nullable = true)\n",
      " |-- is_fastest_gate: integer (nullable = true)\n",
      " |-- is_slowest_gate: integer (nullable = true)\n",
      " |-- total_distance_run: double (nullable = true)\n",
      " |-- ground_loss: double (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/05 22:20:46 ERROR Executor: Exception in task 0.0 in stage 127.0 (TID 467)\n",
      "java.sql.BatchUpdateException: Batch entry 0 INSERT INTO gps_aggregated_results_with_gates (\"course_cd\",\"race_date\",\"race_number\",\"saddle_cloth_number\",\"gate_name\",\"avg_speed\",\"avg_acceleration\",\"max_speed\",\"min_speed\",\"fatigue_factor\",\"is_fastest_gate\",\"is_slowest_gate\",\"total_distance_run\",\"ground_loss\") VALUES (('CLS'),('2024-08-16 -05'::date),('1'::int4),('1  '),('0.5f'),('0.07'::double precision),('0.0'::double precision),('0.07'::double precision),('0.07'::double precision),('0.0'::double precision),('1'::int4),('1'::int4),('1366.3190584960344'::double precision),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(CLS, 2024-08-16, 1, 1  , 0.5f) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.ResultHandlerDelegate.handleError(ResultHandlerDelegate.java:52)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2421)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2153)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.flushIfDeadlockRisk(QueryExecutorImpl.java:1503)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.sendQuery(QueryExecutorImpl.java:1528)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:566)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:888)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1739)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:740)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:896)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:895)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1012)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1012)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2298)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(CLS, 2024-08-16, 1, 1  , 0.5f) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2733)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2420)\n",
      "\t... 22 more\n",
      "24/12/05 22:20:46 ERROR TaskSetManager: Task 0 in stage 127.0 failed 1 times; aborting job\n",
      "ERROR:root:Error processing course CLS: An error occurred while calling o3383.jdbc.\n",
      ": org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 127.0 failed 1 times, most recent failure: Lost task 0.0 in stage 127.0 (TID 467) (mail.relufox.ai executor driver): java.sql.BatchUpdateException: Batch entry 0 INSERT INTO gps_aggregated_results_with_gates (\"course_cd\",\"race_date\",\"race_number\",\"saddle_cloth_number\",\"gate_name\",\"avg_speed\",\"avg_acceleration\",\"max_speed\",\"min_speed\",\"fatigue_factor\",\"is_fastest_gate\",\"is_slowest_gate\",\"total_distance_run\",\"ground_loss\") VALUES (('CLS'),('2024-08-16 -05'::date),('1'::int4),('1  '),('0.5f'),('0.07'::double precision),('0.0'::double precision),('0.07'::double precision),('0.07'::double precision),('0.0'::double precision),('1'::int4),('1'::int4),('1366.3190584960344'::double precision),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(CLS, 2024-08-16, 1, 1  , 0.5f) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.ResultHandlerDelegate.handleError(ResultHandlerDelegate.java:52)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2421)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2153)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.flushIfDeadlockRisk(QueryExecutorImpl.java:1503)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.sendQuery(QueryExecutorImpl.java:1528)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:566)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:888)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1739)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:740)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:896)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:895)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1012)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1012)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2298)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(CLS, 2024-08-16, 1, 1  , 0.5f) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2733)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2420)\n",
      "\t... 22 more\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2790)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2726)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2725)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2725)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1211)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1211)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1211)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2989)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2928)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2917)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:976)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2258)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2279)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2298)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2323)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$1(RDD.scala:1012)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n",
      "\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:408)\n",
      "\tat org.apache.spark.rdd.RDD.foreachPartition(RDD.scala:1010)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.saveTable(JdbcUtils.scala:895)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:70)\n",
      "\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:47)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:118)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:195)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:827)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:65)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:94)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:512)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:104)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:512)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:31)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:31)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:31)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:488)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:94)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:81)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:79)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:133)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:856)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:387)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:360)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:247)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.jdbc(DataFrameWriter.scala:753)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: java.sql.BatchUpdateException: Batch entry 0 INSERT INTO gps_aggregated_results_with_gates (\"course_cd\",\"race_date\",\"race_number\",\"saddle_cloth_number\",\"gate_name\",\"avg_speed\",\"avg_acceleration\",\"max_speed\",\"min_speed\",\"fatigue_factor\",\"is_fastest_gate\",\"is_slowest_gate\",\"total_distance_run\",\"ground_loss\") VALUES (('CLS'),('2024-08-16 -05'::date),('1'::int4),('1  '),('0.5f'),('0.07'::double precision),('0.0'::double precision),('0.07'::double precision),('0.07'::double precision),('0.0'::double precision),('1'::int4),('1'::int4),('1366.3190584960344'::double precision),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(CLS, 2024-08-16, 1, 1  , 0.5f) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.ResultHandlerDelegate.handleError(ResultHandlerDelegate.java:52)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2421)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2153)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.flushIfDeadlockRisk(QueryExecutorImpl.java:1503)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.sendQuery(QueryExecutorImpl.java:1528)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:566)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:888)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1739)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:740)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:896)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:895)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1012)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1012)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2298)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\t... 1 more\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(CLS, 2024-08-16, 1, 1  , 0.5f) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2733)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2420)\n",
      "\t... 22 more\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Loading data from database for course: KEE\n",
      "INFO:root:None\n",
      "INFO:root:None\n",
      "INFO:root:None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing course: KEE\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- gate_name: string (nullable = true)\n",
      " |-- avg_speed: double (nullable = true)\n",
      " |-- avg_acceleration: double (nullable = true)\n",
      " |-- max_speed: double (nullable = true)\n",
      " |-- min_speed: double (nullable = true)\n",
      " |-- fatigue_factor: double (nullable = true)\n",
      " |-- is_fastest_gate: integer (nullable = true)\n",
      " |-- is_slowest_gate: integer (nullable = true)\n",
      "\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- gate_name: string (nullable = true)\n",
      " |-- avg_speed: double (nullable = true)\n",
      " |-- avg_acceleration: double (nullable = true)\n",
      " |-- max_speed: double (nullable = true)\n",
      " |-- min_speed: double (nullable = true)\n",
      " |-- fatigue_factor: double (nullable = true)\n",
      " |-- is_fastest_gate: integer (nullable = true)\n",
      " |-- is_slowest_gate: integer (nullable = true)\n",
      "\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- total_distance_run: double (nullable = true)\n",
      " |-- ground_loss: double (nullable = true)\n",
      "\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- total_distance_run: double (nullable = true)\n",
      " |-- ground_loss: double (nullable = true)\n",
      "\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- gate_name: string (nullable = true)\n",
      " |-- avg_speed: double (nullable = true)\n",
      " |-- avg_acceleration: double (nullable = true)\n",
      " |-- max_speed: double (nullable = true)\n",
      " |-- min_speed: double (nullable = true)\n",
      " |-- fatigue_factor: double (nullable = true)\n",
      " |-- is_fastest_gate: integer (nullable = true)\n",
      " |-- is_slowest_gate: integer (nullable = true)\n",
      " |-- total_distance_run: double (nullable = true)\n",
      " |-- ground_loss: double (nullable = true)\n",
      "\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- gate_name: string (nullable = true)\n",
      " |-- avg_speed: double (nullable = true)\n",
      " |-- avg_acceleration: double (nullable = true)\n",
      " |-- max_speed: double (nullable = true)\n",
      " |-- min_speed: double (nullable = true)\n",
      " |-- fatigue_factor: double (nullable = true)\n",
      " |-- is_fastest_gate: integer (nullable = true)\n",
      " |-- is_slowest_gate: integer (nullable = true)\n",
      " |-- total_distance_run: double (nullable = true)\n",
      " |-- ground_loss: double (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/05 22:20:47 ERROR Executor: Exception in task 17.0 in stage 142.0 (TID 505)\n",
      "java.sql.BatchUpdateException: Batch entry 0 INSERT INTO gps_aggregated_results_with_gates (\"course_cd\",\"race_date\",\"race_number\",\"saddle_cloth_number\",\"gate_name\",\"avg_speed\",\"avg_acceleration\",\"max_speed\",\"min_speed\",\"fatigue_factor\",\"is_fastest_gate\",\"is_slowest_gate\",\"total_distance_run\",\"ground_loss\") VALUES (('KEE'),('2023-04-07 -05'::date),('3'::int4),('3  '),('0.5f'),('16.59'::double precision),('0.0'::double precision),('16.59'::double precision),('16.59'::double precision),('0.14416475972540044'::double precision),('0'::int4),('0'::int4),('1919.1166139411962'::double precision),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(KEE, 2023-04-07, 3, 3  , 0.5f) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.ResultHandlerDelegate.handleError(ResultHandlerDelegate.java:52)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2421)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2153)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.flushIfDeadlockRisk(QueryExecutorImpl.java:1503)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.sendQuery(QueryExecutorImpl.java:1528)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:566)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:888)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1739)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:740)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:896)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:895)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1012)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1012)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2298)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(KEE, 2023-04-07, 3, 3  , 0.5f) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2733)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2420)\n",
      "\t... 22 more\n",
      "24/12/05 22:20:47 ERROR TaskSetManager: Task 17 in stage 142.0 failed 1 times; aborting job\n",
      "ERROR:root:Error processing course KEE: An error occurred while calling o3800.jdbc.\n",
      ": org.apache.spark.SparkException: Job aborted due to stage failure: Task 17 in stage 142.0 failed 1 times, most recent failure: Lost task 17.0 in stage 142.0 (TID 505) (mail.relufox.ai executor driver): java.sql.BatchUpdateException: Batch entry 0 INSERT INTO gps_aggregated_results_with_gates (\"course_cd\",\"race_date\",\"race_number\",\"saddle_cloth_number\",\"gate_name\",\"avg_speed\",\"avg_acceleration\",\"max_speed\",\"min_speed\",\"fatigue_factor\",\"is_fastest_gate\",\"is_slowest_gate\",\"total_distance_run\",\"ground_loss\") VALUES (('KEE'),('2023-04-07 -05'::date),('3'::int4),('3  '),('0.5f'),('16.59'::double precision),('0.0'::double precision),('16.59'::double precision),('16.59'::double precision),('0.14416475972540044'::double precision),('0'::int4),('0'::int4),('1919.1166139411962'::double precision),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(KEE, 2023-04-07, 3, 3  , 0.5f) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.ResultHandlerDelegate.handleError(ResultHandlerDelegate.java:52)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2421)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2153)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.flushIfDeadlockRisk(QueryExecutorImpl.java:1503)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.sendQuery(QueryExecutorImpl.java:1528)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:566)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:888)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1739)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:740)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:896)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:895)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1012)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1012)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2298)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(KEE, 2023-04-07, 3, 3  , 0.5f) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2733)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2420)\n",
      "\t... 22 more\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2790)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2726)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2725)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2725)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1211)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1211)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1211)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2989)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2928)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2917)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:976)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2258)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2279)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2298)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2323)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$1(RDD.scala:1012)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n",
      "\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:408)\n",
      "\tat org.apache.spark.rdd.RDD.foreachPartition(RDD.scala:1010)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.saveTable(JdbcUtils.scala:895)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:70)\n",
      "\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:47)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:118)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:195)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:827)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:65)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:94)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:512)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:104)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:512)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:31)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:31)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:31)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:488)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:94)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:81)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:79)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:133)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:856)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:387)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:360)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:247)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.jdbc(DataFrameWriter.scala:753)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: java.sql.BatchUpdateException: Batch entry 0 INSERT INTO gps_aggregated_results_with_gates (\"course_cd\",\"race_date\",\"race_number\",\"saddle_cloth_number\",\"gate_name\",\"avg_speed\",\"avg_acceleration\",\"max_speed\",\"min_speed\",\"fatigue_factor\",\"is_fastest_gate\",\"is_slowest_gate\",\"total_distance_run\",\"ground_loss\") VALUES (('KEE'),('2023-04-07 -05'::date),('3'::int4),('3  '),('0.5f'),('16.59'::double precision),('0.0'::double precision),('16.59'::double precision),('16.59'::double precision),('0.14416475972540044'::double precision),('0'::int4),('0'::int4),('1919.1166139411962'::double precision),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(KEE, 2023-04-07, 3, 3  , 0.5f) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.ResultHandlerDelegate.handleError(ResultHandlerDelegate.java:52)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2421)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2153)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.flushIfDeadlockRisk(QueryExecutorImpl.java:1503)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.sendQuery(QueryExecutorImpl.java:1528)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:566)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:888)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1739)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:740)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:896)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:895)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1012)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1012)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2298)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\t... 1 more\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(KEE, 2023-04-07, 3, 3  , 0.5f) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2733)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2420)\n",
      "\t... 22 more\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Loading data from database for course: TAM\n",
      "INFO:root:None\n",
      "INFO:root:None\n",
      "INFO:root:None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing course: TAM\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- gate_name: string (nullable = true)\n",
      " |-- avg_speed: double (nullable = true)\n",
      " |-- avg_acceleration: double (nullable = true)\n",
      " |-- max_speed: double (nullable = true)\n",
      " |-- min_speed: double (nullable = true)\n",
      " |-- fatigue_factor: double (nullable = true)\n",
      " |-- is_fastest_gate: integer (nullable = true)\n",
      " |-- is_slowest_gate: integer (nullable = true)\n",
      "\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- gate_name: string (nullable = true)\n",
      " |-- avg_speed: double (nullable = true)\n",
      " |-- avg_acceleration: double (nullable = true)\n",
      " |-- max_speed: double (nullable = true)\n",
      " |-- min_speed: double (nullable = true)\n",
      " |-- fatigue_factor: double (nullable = true)\n",
      " |-- is_fastest_gate: integer (nullable = true)\n",
      " |-- is_slowest_gate: integer (nullable = true)\n",
      "\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- total_distance_run: double (nullable = true)\n",
      " |-- ground_loss: double (nullable = true)\n",
      "\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- total_distance_run: double (nullable = true)\n",
      " |-- ground_loss: double (nullable = true)\n",
      "\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- gate_name: string (nullable = true)\n",
      " |-- avg_speed: double (nullable = true)\n",
      " |-- avg_acceleration: double (nullable = true)\n",
      " |-- max_speed: double (nullable = true)\n",
      " |-- min_speed: double (nullable = true)\n",
      " |-- fatigue_factor: double (nullable = true)\n",
      " |-- is_fastest_gate: integer (nullable = true)\n",
      " |-- is_slowest_gate: integer (nullable = true)\n",
      " |-- total_distance_run: double (nullable = true)\n",
      " |-- ground_loss: double (nullable = true)\n",
      "\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- gate_name: string (nullable = true)\n",
      " |-- avg_speed: double (nullable = true)\n",
      " |-- avg_acceleration: double (nullable = true)\n",
      " |-- max_speed: double (nullable = true)\n",
      " |-- min_speed: double (nullable = true)\n",
      " |-- fatigue_factor: double (nullable = true)\n",
      " |-- is_fastest_gate: integer (nullable = true)\n",
      " |-- is_slowest_gate: integer (nullable = true)\n",
      " |-- total_distance_run: double (nullable = true)\n",
      " |-- ground_loss: double (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/05 22:20:50 ERROR Executor: Exception in task 51.0 in stage 157.0 (TID 611)\n",
      "java.sql.BatchUpdateException: Batch entry 0 INSERT INTO gps_aggregated_results_with_gates (\"course_cd\",\"race_date\",\"race_number\",\"saddle_cloth_number\",\"gate_name\",\"avg_speed\",\"avg_acceleration\",\"max_speed\",\"min_speed\",\"fatigue_factor\",\"is_fastest_gate\",\"is_slowest_gate\",\"total_distance_run\",\"ground_loss\") VALUES (('TAM'),('2022-01-01 -06'::date),('10'::int4),('1  '),('0.5f'),('16.52'::double precision),('0.0'::double precision),('16.52'::double precision),('16.52'::double precision),('0.13401476433844403'::double precision),('0'::int4),('0'::int4),('1844.2053161973836'::double precision),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(TAM, 2022-01-01, 10, 1  , 0.5f) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.ResultHandlerDelegate.handleError(ResultHandlerDelegate.java:52)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2421)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2153)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.flushIfDeadlockRisk(QueryExecutorImpl.java:1503)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.sendQuery(QueryExecutorImpl.java:1528)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:566)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:888)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1739)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:740)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:896)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:895)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1012)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1012)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2298)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(TAM, 2022-01-01, 10, 1  , 0.5f) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2733)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2420)\n",
      "\t... 22 more\n",
      "24/12/05 22:20:50 ERROR TaskSetManager: Task 51 in stage 157.0 failed 1 times; aborting job\n",
      "ERROR:root:Error processing course TAM: An error occurred while calling o4217.jdbc.\n",
      ": org.apache.spark.SparkException: Job aborted due to stage failure: Task 51 in stage 157.0 failed 1 times, most recent failure: Lost task 51.0 in stage 157.0 (TID 611) (mail.relufox.ai executor driver): java.sql.BatchUpdateException: Batch entry 0 INSERT INTO gps_aggregated_results_with_gates (\"course_cd\",\"race_date\",\"race_number\",\"saddle_cloth_number\",\"gate_name\",\"avg_speed\",\"avg_acceleration\",\"max_speed\",\"min_speed\",\"fatigue_factor\",\"is_fastest_gate\",\"is_slowest_gate\",\"total_distance_run\",\"ground_loss\") VALUES (('TAM'),('2022-01-01 -06'::date),('10'::int4),('1  '),('0.5f'),('16.52'::double precision),('0.0'::double precision),('16.52'::double precision),('16.52'::double precision),('0.13401476433844403'::double precision),('0'::int4),('0'::int4),('1844.2053161973836'::double precision),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(TAM, 2022-01-01, 10, 1  , 0.5f) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.ResultHandlerDelegate.handleError(ResultHandlerDelegate.java:52)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2421)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2153)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.flushIfDeadlockRisk(QueryExecutorImpl.java:1503)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.sendQuery(QueryExecutorImpl.java:1528)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:566)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:888)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1739)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:740)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:896)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:895)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1012)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1012)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2298)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(TAM, 2022-01-01, 10, 1  , 0.5f) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2733)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2420)\n",
      "\t... 22 more\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2790)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2726)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2725)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2725)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1211)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1211)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1211)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2989)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2928)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2917)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:976)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2258)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2279)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2298)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2323)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$1(RDD.scala:1012)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n",
      "\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:408)\n",
      "\tat org.apache.spark.rdd.RDD.foreachPartition(RDD.scala:1010)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.saveTable(JdbcUtils.scala:895)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:70)\n",
      "\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:47)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:118)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:195)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:827)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:65)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:94)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:512)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:104)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:512)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:31)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:31)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:31)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:488)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:94)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:81)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:79)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:133)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:856)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:387)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:360)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:247)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.jdbc(DataFrameWriter.scala:753)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: java.sql.BatchUpdateException: Batch entry 0 INSERT INTO gps_aggregated_results_with_gates (\"course_cd\",\"race_date\",\"race_number\",\"saddle_cloth_number\",\"gate_name\",\"avg_speed\",\"avg_acceleration\",\"max_speed\",\"min_speed\",\"fatigue_factor\",\"is_fastest_gate\",\"is_slowest_gate\",\"total_distance_run\",\"ground_loss\") VALUES (('TAM'),('2022-01-01 -06'::date),('10'::int4),('1  '),('0.5f'),('16.52'::double precision),('0.0'::double precision),('16.52'::double precision),('16.52'::double precision),('0.13401476433844403'::double precision),('0'::int4),('0'::int4),('1844.2053161973836'::double precision),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(TAM, 2022-01-01, 10, 1  , 0.5f) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.ResultHandlerDelegate.handleError(ResultHandlerDelegate.java:52)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2421)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2153)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.flushIfDeadlockRisk(QueryExecutorImpl.java:1503)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.sendQuery(QueryExecutorImpl.java:1528)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:566)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:888)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1739)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:740)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:896)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:895)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1012)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1012)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2298)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\t... 1 more\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(TAM, 2022-01-01, 10, 1  , 0.5f) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2733)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2420)\n",
      "\t... 22 more\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Loading data from database for course: TTP\n",
      "INFO:root:None\n",
      "INFO:root:None\n",
      "INFO:root:None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing course: TTP\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- gate_name: string (nullable = true)\n",
      " |-- avg_speed: double (nullable = true)\n",
      " |-- avg_acceleration: double (nullable = true)\n",
      " |-- max_speed: double (nullable = true)\n",
      " |-- min_speed: double (nullable = true)\n",
      " |-- fatigue_factor: double (nullable = true)\n",
      " |-- is_fastest_gate: integer (nullable = true)\n",
      " |-- is_slowest_gate: integer (nullable = true)\n",
      "\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- gate_name: string (nullable = true)\n",
      " |-- avg_speed: double (nullable = true)\n",
      " |-- avg_acceleration: double (nullable = true)\n",
      " |-- max_speed: double (nullable = true)\n",
      " |-- min_speed: double (nullable = true)\n",
      " |-- fatigue_factor: double (nullable = true)\n",
      " |-- is_fastest_gate: integer (nullable = true)\n",
      " |-- is_slowest_gate: integer (nullable = true)\n",
      "\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- total_distance_run: double (nullable = true)\n",
      " |-- ground_loss: double (nullable = true)\n",
      "\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- total_distance_run: double (nullable = true)\n",
      " |-- ground_loss: double (nullable = true)\n",
      "\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- gate_name: string (nullable = true)\n",
      " |-- avg_speed: double (nullable = true)\n",
      " |-- avg_acceleration: double (nullable = true)\n",
      " |-- max_speed: double (nullable = true)\n",
      " |-- min_speed: double (nullable = true)\n",
      " |-- fatigue_factor: double (nullable = true)\n",
      " |-- is_fastest_gate: integer (nullable = true)\n",
      " |-- is_slowest_gate: integer (nullable = true)\n",
      " |-- total_distance_run: double (nullable = true)\n",
      " |-- ground_loss: double (nullable = true)\n",
      "\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- gate_name: string (nullable = true)\n",
      " |-- avg_speed: double (nullable = true)\n",
      " |-- avg_acceleration: double (nullable = true)\n",
      " |-- max_speed: double (nullable = true)\n",
      " |-- min_speed: double (nullable = true)\n",
      " |-- fatigue_factor: double (nullable = true)\n",
      " |-- is_fastest_gate: integer (nullable = true)\n",
      " |-- is_slowest_gate: integer (nullable = true)\n",
      " |-- total_distance_run: double (nullable = true)\n",
      " |-- ground_loss: double (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/05 22:20:53 ERROR Executor: Exception in task 5.0 in stage 172.0 (TID 668)\n",
      "java.sql.BatchUpdateException: Batch entry 0 INSERT INTO gps_aggregated_results_with_gates (\"course_cd\",\"race_date\",\"race_number\",\"saddle_cloth_number\",\"gate_name\",\"avg_speed\",\"avg_acceleration\",\"max_speed\",\"min_speed\",\"fatigue_factor\",\"is_fastest_gate\",\"is_slowest_gate\",\"total_distance_run\",\"ground_loss\") VALUES (('TTP'),('2022-12-02 -06'::date),('1'::int4),('6  '),('0.5f'),('14.46'::double precision),('0.0'::double precision),('14.46'::double precision),('14.46'::double precision),('0.3400725764644893'::double precision),('0'::int4),('0'::int4),('1451.388434019811'::double precision),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(TTP, 2022-12-02, 1, 6  , 0.5f) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.ResultHandlerDelegate.handleError(ResultHandlerDelegate.java:52)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2421)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2153)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.flushIfDeadlockRisk(QueryExecutorImpl.java:1503)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.sendQuery(QueryExecutorImpl.java:1528)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:566)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:888)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1739)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:740)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:896)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:895)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1012)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1012)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2298)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(TTP, 2022-12-02, 1, 6  , 0.5f) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2733)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2420)\n",
      "\t... 22 more\n",
      "24/12/05 22:20:53 ERROR TaskSetManager: Task 5 in stage 172.0 failed 1 times; aborting job\n",
      "ERROR:root:Error processing course TTP: An error occurred while calling o4634.jdbc.\n",
      ": org.apache.spark.SparkException: Job aborted due to stage failure: Task 5 in stage 172.0 failed 1 times, most recent failure: Lost task 5.0 in stage 172.0 (TID 668) (mail.relufox.ai executor driver): java.sql.BatchUpdateException: Batch entry 0 INSERT INTO gps_aggregated_results_with_gates (\"course_cd\",\"race_date\",\"race_number\",\"saddle_cloth_number\",\"gate_name\",\"avg_speed\",\"avg_acceleration\",\"max_speed\",\"min_speed\",\"fatigue_factor\",\"is_fastest_gate\",\"is_slowest_gate\",\"total_distance_run\",\"ground_loss\") VALUES (('TTP'),('2022-12-02 -06'::date),('1'::int4),('6  '),('0.5f'),('14.46'::double precision),('0.0'::double precision),('14.46'::double precision),('14.46'::double precision),('0.3400725764644893'::double precision),('0'::int4),('0'::int4),('1451.388434019811'::double precision),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(TTP, 2022-12-02, 1, 6  , 0.5f) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.ResultHandlerDelegate.handleError(ResultHandlerDelegate.java:52)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2421)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2153)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.flushIfDeadlockRisk(QueryExecutorImpl.java:1503)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.sendQuery(QueryExecutorImpl.java:1528)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:566)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:888)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1739)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:740)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:896)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:895)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1012)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1012)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2298)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(TTP, 2022-12-02, 1, 6  , 0.5f) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2733)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2420)\n",
      "\t... 22 more\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2790)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2726)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2725)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2725)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1211)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1211)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1211)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2989)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2928)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2917)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:976)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2258)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2279)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2298)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2323)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$1(RDD.scala:1012)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n",
      "\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:408)\n",
      "\tat org.apache.spark.rdd.RDD.foreachPartition(RDD.scala:1010)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.saveTable(JdbcUtils.scala:895)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:70)\n",
      "\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:47)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:118)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:195)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:827)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:65)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:94)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:512)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:104)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:512)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:31)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:31)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:31)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:488)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:94)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:81)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:79)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:133)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:856)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:387)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:360)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:247)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.jdbc(DataFrameWriter.scala:753)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: java.sql.BatchUpdateException: Batch entry 0 INSERT INTO gps_aggregated_results_with_gates (\"course_cd\",\"race_date\",\"race_number\",\"saddle_cloth_number\",\"gate_name\",\"avg_speed\",\"avg_acceleration\",\"max_speed\",\"min_speed\",\"fatigue_factor\",\"is_fastest_gate\",\"is_slowest_gate\",\"total_distance_run\",\"ground_loss\") VALUES (('TTP'),('2022-12-02 -06'::date),('1'::int4),('6  '),('0.5f'),('14.46'::double precision),('0.0'::double precision),('14.46'::double precision),('14.46'::double precision),('0.3400725764644893'::double precision),('0'::int4),('0'::int4),('1451.388434019811'::double precision),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(TTP, 2022-12-02, 1, 6  , 0.5f) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.ResultHandlerDelegate.handleError(ResultHandlerDelegate.java:52)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2421)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2153)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.flushIfDeadlockRisk(QueryExecutorImpl.java:1503)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.sendQuery(QueryExecutorImpl.java:1528)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:566)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:888)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1739)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:740)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:896)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:895)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1012)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1012)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2298)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\t... 1 more\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(TTP, 2022-12-02, 1, 6  , 0.5f) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2733)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2420)\n",
      "\t... 22 more\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Loading data from database for course: TKD\n",
      "INFO:root:None\n",
      "INFO:root:None\n",
      "INFO:root:None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing course: TKD\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- gate_name: string (nullable = true)\n",
      " |-- avg_speed: double (nullable = true)\n",
      " |-- avg_acceleration: double (nullable = true)\n",
      " |-- max_speed: double (nullable = true)\n",
      " |-- min_speed: double (nullable = true)\n",
      " |-- fatigue_factor: double (nullable = true)\n",
      " |-- is_fastest_gate: integer (nullable = true)\n",
      " |-- is_slowest_gate: integer (nullable = true)\n",
      "\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- gate_name: string (nullable = true)\n",
      " |-- avg_speed: double (nullable = true)\n",
      " |-- avg_acceleration: double (nullable = true)\n",
      " |-- max_speed: double (nullable = true)\n",
      " |-- min_speed: double (nullable = true)\n",
      " |-- fatigue_factor: double (nullable = true)\n",
      " |-- is_fastest_gate: integer (nullable = true)\n",
      " |-- is_slowest_gate: integer (nullable = true)\n",
      "\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- total_distance_run: double (nullable = true)\n",
      " |-- ground_loss: double (nullable = true)\n",
      "\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- total_distance_run: double (nullable = true)\n",
      " |-- ground_loss: double (nullable = true)\n",
      "\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- gate_name: string (nullable = true)\n",
      " |-- avg_speed: double (nullable = true)\n",
      " |-- avg_acceleration: double (nullable = true)\n",
      " |-- max_speed: double (nullable = true)\n",
      " |-- min_speed: double (nullable = true)\n",
      " |-- fatigue_factor: double (nullable = true)\n",
      " |-- is_fastest_gate: integer (nullable = true)\n",
      " |-- is_slowest_gate: integer (nullable = true)\n",
      " |-- total_distance_run: double (nullable = true)\n",
      " |-- ground_loss: double (nullable = true)\n",
      "\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- gate_name: string (nullable = true)\n",
      " |-- avg_speed: double (nullable = true)\n",
      " |-- avg_acceleration: double (nullable = true)\n",
      " |-- max_speed: double (nullable = true)\n",
      " |-- min_speed: double (nullable = true)\n",
      " |-- fatigue_factor: double (nullable = true)\n",
      " |-- is_fastest_gate: integer (nullable = true)\n",
      " |-- is_slowest_gate: integer (nullable = true)\n",
      " |-- total_distance_run: double (nullable = true)\n",
      " |-- ground_loss: double (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/05 22:20:54 ERROR Executor: Exception in task 5.0 in stage 187.0 (TID 728)\n",
      "java.sql.BatchUpdateException: Batch entry 0 INSERT INTO gps_aggregated_results_with_gates (\"course_cd\",\"race_date\",\"race_number\",\"saddle_cloth_number\",\"gate_name\",\"avg_speed\",\"avg_acceleration\",\"max_speed\",\"min_speed\",\"fatigue_factor\",\"is_fastest_gate\",\"is_slowest_gate\",\"total_distance_run\",\"ground_loss\") VALUES (('TKD'),('2022-09-01 -05'::date),('2'::int4),('9  '),('0.5f'),('12.2'::double precision),('0.0'::double precision),('12.2'::double precision),('12.2'::double precision),('0.0'::double precision),('1'::int4),('1'::int4),('1868.777204015089'::double precision),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(TKD, 2022-09-01, 2, 9  , 0.5f) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.ResultHandlerDelegate.handleError(ResultHandlerDelegate.java:52)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2421)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2153)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.flushIfDeadlockRisk(QueryExecutorImpl.java:1503)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.sendQuery(QueryExecutorImpl.java:1528)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:566)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:888)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1739)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:740)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:896)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:895)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1012)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1012)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2298)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(TKD, 2022-09-01, 2, 9  , 0.5f) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2733)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2420)\n",
      "\t... 22 more\n",
      "24/12/05 22:20:54 ERROR TaskSetManager: Task 5 in stage 187.0 failed 1 times; aborting job\n",
      "ERROR:root:Error processing course TKD: An error occurred while calling o5051.jdbc.\n",
      ": org.apache.spark.SparkException: Job aborted due to stage failure: Task 5 in stage 187.0 failed 1 times, most recent failure: Lost task 5.0 in stage 187.0 (TID 728) (mail.relufox.ai executor driver): java.sql.BatchUpdateException: Batch entry 0 INSERT INTO gps_aggregated_results_with_gates (\"course_cd\",\"race_date\",\"race_number\",\"saddle_cloth_number\",\"gate_name\",\"avg_speed\",\"avg_acceleration\",\"max_speed\",\"min_speed\",\"fatigue_factor\",\"is_fastest_gate\",\"is_slowest_gate\",\"total_distance_run\",\"ground_loss\") VALUES (('TKD'),('2022-09-01 -05'::date),('2'::int4),('9  '),('0.5f'),('12.2'::double precision),('0.0'::double precision),('12.2'::double precision),('12.2'::double precision),('0.0'::double precision),('1'::int4),('1'::int4),('1868.777204015089'::double precision),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(TKD, 2022-09-01, 2, 9  , 0.5f) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.ResultHandlerDelegate.handleError(ResultHandlerDelegate.java:52)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2421)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2153)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.flushIfDeadlockRisk(QueryExecutorImpl.java:1503)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.sendQuery(QueryExecutorImpl.java:1528)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:566)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:888)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1739)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:740)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:896)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:895)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1012)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1012)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2298)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(TKD, 2022-09-01, 2, 9  , 0.5f) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2733)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2420)\n",
      "\t... 22 more\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2790)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2726)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2725)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2725)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1211)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1211)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1211)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2989)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2928)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2917)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:976)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2258)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2279)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2298)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2323)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$1(RDD.scala:1012)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n",
      "\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:408)\n",
      "\tat org.apache.spark.rdd.RDD.foreachPartition(RDD.scala:1010)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.saveTable(JdbcUtils.scala:895)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:70)\n",
      "\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:47)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:118)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:195)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:827)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:65)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:94)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:512)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:104)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:512)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:31)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:31)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:31)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:488)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:94)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:81)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:79)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:133)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:856)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:387)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:360)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:247)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.jdbc(DataFrameWriter.scala:753)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: java.sql.BatchUpdateException: Batch entry 0 INSERT INTO gps_aggregated_results_with_gates (\"course_cd\",\"race_date\",\"race_number\",\"saddle_cloth_number\",\"gate_name\",\"avg_speed\",\"avg_acceleration\",\"max_speed\",\"min_speed\",\"fatigue_factor\",\"is_fastest_gate\",\"is_slowest_gate\",\"total_distance_run\",\"ground_loss\") VALUES (('TKD'),('2022-09-01 -05'::date),('2'::int4),('9  '),('0.5f'),('12.2'::double precision),('0.0'::double precision),('12.2'::double precision),('12.2'::double precision),('0.0'::double precision),('1'::int4),('1'::int4),('1868.777204015089'::double precision),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(TKD, 2022-09-01, 2, 9  , 0.5f) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.ResultHandlerDelegate.handleError(ResultHandlerDelegate.java:52)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2421)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2153)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.flushIfDeadlockRisk(QueryExecutorImpl.java:1503)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.sendQuery(QueryExecutorImpl.java:1528)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:566)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:888)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1739)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:740)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:896)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:895)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1012)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1012)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2298)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\t... 1 more\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(TKD, 2022-09-01, 2, 9  , 0.5f) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2733)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2420)\n",
      "\t... 22 more\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Loading data from database for course: ELP\n",
      "INFO:root:None\n",
      "INFO:root:None\n",
      "INFO:root:None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing course: ELP\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- gate_name: string (nullable = true)\n",
      " |-- avg_speed: double (nullable = true)\n",
      " |-- avg_acceleration: double (nullable = true)\n",
      " |-- max_speed: double (nullable = true)\n",
      " |-- min_speed: double (nullable = true)\n",
      " |-- fatigue_factor: double (nullable = true)\n",
      " |-- is_fastest_gate: integer (nullable = true)\n",
      " |-- is_slowest_gate: integer (nullable = true)\n",
      "\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- gate_name: string (nullable = true)\n",
      " |-- avg_speed: double (nullable = true)\n",
      " |-- avg_acceleration: double (nullable = true)\n",
      " |-- max_speed: double (nullable = true)\n",
      " |-- min_speed: double (nullable = true)\n",
      " |-- fatigue_factor: double (nullable = true)\n",
      " |-- is_fastest_gate: integer (nullable = true)\n",
      " |-- is_slowest_gate: integer (nullable = true)\n",
      "\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- total_distance_run: double (nullable = true)\n",
      " |-- ground_loss: double (nullable = true)\n",
      "\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- total_distance_run: double (nullable = true)\n",
      " |-- ground_loss: double (nullable = true)\n",
      "\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- gate_name: string (nullable = true)\n",
      " |-- avg_speed: double (nullable = true)\n",
      " |-- avg_acceleration: double (nullable = true)\n",
      " |-- max_speed: double (nullable = true)\n",
      " |-- min_speed: double (nullable = true)\n",
      " |-- fatigue_factor: double (nullable = true)\n",
      " |-- is_fastest_gate: integer (nullable = true)\n",
      " |-- is_slowest_gate: integer (nullable = true)\n",
      " |-- total_distance_run: double (nullable = true)\n",
      " |-- ground_loss: double (nullable = true)\n",
      "\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- gate_name: string (nullable = true)\n",
      " |-- avg_speed: double (nullable = true)\n",
      " |-- avg_acceleration: double (nullable = true)\n",
      " |-- max_speed: double (nullable = true)\n",
      " |-- min_speed: double (nullable = true)\n",
      " |-- fatigue_factor: double (nullable = true)\n",
      " |-- is_fastest_gate: integer (nullable = true)\n",
      " |-- is_slowest_gate: integer (nullable = true)\n",
      " |-- total_distance_run: double (nullable = true)\n",
      " |-- ground_loss: double (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/05 22:20:55 ERROR Executor: Exception in task 8.0 in stage 202.0 (TID 759)\n",
      "java.sql.BatchUpdateException: Batch entry 0 INSERT INTO gps_aggregated_results_with_gates (\"course_cd\",\"race_date\",\"race_number\",\"saddle_cloth_number\",\"gate_name\",\"avg_speed\",\"avg_acceleration\",\"max_speed\",\"min_speed\",\"fatigue_factor\",\"is_fastest_gate\",\"is_slowest_gate\",\"total_distance_run\",\"ground_loss\") VALUES (('ELP'),('2023-06-10 -05'::date),('1'::int4),('2  '),('0.5f'),('16.43'::double precision),('0.0'::double precision),('16.43'::double precision),('16.43'::double precision),('0.2781837160751566'::double precision),('0'::int4),('0'::int4),('1204.137828220455'::double precision),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(ELP, 2023-06-10, 1, 2  , 0.5f) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.ResultHandlerDelegate.handleError(ResultHandlerDelegate.java:52)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2421)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2153)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.flushIfDeadlockRisk(QueryExecutorImpl.java:1503)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.sendQuery(QueryExecutorImpl.java:1528)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:566)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:888)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1739)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:740)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:896)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:895)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1012)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1012)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2298)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(ELP, 2023-06-10, 1, 2  , 0.5f) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2733)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2420)\n",
      "\t... 22 more\n",
      "24/12/05 22:20:55 ERROR Executor: Exception in task 3.0 in stage 202.0 (TID 754)\n",
      "java.sql.BatchUpdateException: Batch entry 0 INSERT INTO gps_aggregated_results_with_gates (\"course_cd\",\"race_date\",\"race_number\",\"saddle_cloth_number\",\"gate_name\",\"avg_speed\",\"avg_acceleration\",\"max_speed\",\"min_speed\",\"fatigue_factor\",\"is_fastest_gate\",\"is_slowest_gate\",\"total_distance_run\",\"ground_loss\") VALUES (('ELP'),('2023-06-10 -05'::date),('4'::int4),('3  '),('0.5f'),('13.75'::double precision),('0.0'::double precision),('13.75'::double precision),('13.75'::double precision),('0.33117932148626816'::double precision),('0'::int4),('0'::int4),('1435.4019027843008'::double precision),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(ELP, 2023-06-10, 4, 3  , 0.5f) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.ResultHandlerDelegate.handleError(ResultHandlerDelegate.java:52)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2421)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2153)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.flushIfDeadlockRisk(QueryExecutorImpl.java:1503)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.sendQuery(QueryExecutorImpl.java:1528)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:566)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:888)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1739)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:740)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:896)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:895)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1012)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1012)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2298)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(ELP, 2023-06-10, 4, 3  , 0.5f) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2733)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2420)\n",
      "\t... 22 more\n",
      "24/12/05 22:20:55 ERROR Executor: Exception in task 17.0 in stage 202.0 (TID 768)\n",
      "java.sql.BatchUpdateException: Batch entry 0 INSERT INTO gps_aggregated_results_with_gates (\"course_cd\",\"race_date\",\"race_number\",\"saddle_cloth_number\",\"gate_name\",\"avg_speed\",\"avg_acceleration\",\"max_speed\",\"min_speed\",\"fatigue_factor\",\"is_fastest_gate\",\"is_slowest_gate\",\"total_distance_run\",\"ground_loss\") VALUES (('ELP'),('2023-06-10 -05'::date),('1'::int4),('13 '),('0.5f'),('16.16'::double precision),('0.0'::double precision),('16.16'::double precision),('16.16'::double precision),('0.10992108229988723'::double precision),('0'::int4),('0'::int4),('1184.2277317783962'::double precision),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(ELP, 2023-06-10, 1, 13 , 0.5f) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.ResultHandlerDelegate.handleError(ResultHandlerDelegate.java:52)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2421)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2153)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.flushIfDeadlockRisk(QueryExecutorImpl.java:1503)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.sendQuery(QueryExecutorImpl.java:1528)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:566)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:888)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1739)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:740)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:896)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:895)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1012)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1012)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2298)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(ELP, 2023-06-10, 1, 13 , 0.5f) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2733)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2420)\n",
      "\t... 22 more\n",
      "24/12/05 22:20:55 ERROR Executor: Exception in task 16.0 in stage 202.0 (TID 767)\n",
      "java.sql.BatchUpdateException: Batch entry 0 INSERT INTO gps_aggregated_results_with_gates (\"course_cd\",\"race_date\",\"race_number\",\"saddle_cloth_number\",\"gate_name\",\"avg_speed\",\"avg_acceleration\",\"max_speed\",\"min_speed\",\"fatigue_factor\",\"is_fastest_gate\",\"is_slowest_gate\",\"total_distance_run\",\"ground_loss\") VALUES (('ELP'),('2023-06-10 -05'::date),('3'::int4),('3  '),('0.5f'),('11.98'::double precision),('0.0'::double precision),('11.98'::double precision),('11.98'::double precision),('0.5686684073107049'::double precision),('0'::int4),('0'::int4),('1668.1056417522232'::double precision),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(ELP, 2023-06-10, 3, 3  , 0.5f) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.ResultHandlerDelegate.handleError(ResultHandlerDelegate.java:52)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2421)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2153)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.flushIfDeadlockRisk(QueryExecutorImpl.java:1503)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.sendQuery(QueryExecutorImpl.java:1528)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:566)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:888)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1739)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:740)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:896)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:895)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1012)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1012)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2298)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(ELP, 2023-06-10, 3, 3  , 0.5f) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2733)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2420)\n",
      "\t... 22 more\n",
      "24/12/05 22:20:55 ERROR Executor: Exception in task 14.0 in stage 202.0 (TID 765)\n",
      "java.sql.BatchUpdateException: Batch entry 0 INSERT INTO gps_aggregated_results_with_gates (\"course_cd\",\"race_date\",\"race_number\",\"saddle_cloth_number\",\"gate_name\",\"avg_speed\",\"avg_acceleration\",\"max_speed\",\"min_speed\",\"fatigue_factor\",\"is_fastest_gate\",\"is_slowest_gate\",\"total_distance_run\",\"ground_loss\") VALUES (('ELP'),('2023-06-10 -05'::date),('1'::int4),('8  '),('0.5f'),('17.26'::double precision),('0.0'::double precision),('17.26'::double precision),('17.26'::double precision),('0.12127774769897123'::double precision),('0'::int4),('0'::int4),('1227.4320985129546'::double precision),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(ELP, 2023-06-10, 1, 8  , 0.5f) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.ResultHandlerDelegate.handleError(ResultHandlerDelegate.java:52)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2421)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2153)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.flushIfDeadlockRisk(QueryExecutorImpl.java:1503)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.sendQuery(QueryExecutorImpl.java:1528)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:566)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:888)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1739)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:740)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:896)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:895)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1012)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1012)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2298)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(ELP, 2023-06-10, 1, 8  , 0.5f) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2733)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2420)\n",
      "\t... 22 more\n",
      "24/12/05 22:20:55 ERROR TaskSetManager: Task 8 in stage 202.0 failed 1 times; aborting job\n",
      "24/12/05 22:20:55 ERROR Executor: Exception in task 5.0 in stage 202.0 (TID 756)\n",
      "java.sql.BatchUpdateException: Batch entry 0 INSERT INTO gps_aggregated_results_with_gates (\"course_cd\",\"race_date\",\"race_number\",\"saddle_cloth_number\",\"gate_name\",\"avg_speed\",\"avg_acceleration\",\"max_speed\",\"min_speed\",\"fatigue_factor\",\"is_fastest_gate\",\"is_slowest_gate\",\"total_distance_run\",\"ground_loss\") VALUES (('ELP'),('2023-06-10 -05'::date),('4'::int4),('11 '),('0.5f'),('15.3'::double precision),('0.0'::double precision),('15.3'::double precision),('15.3'::double precision),('0.20248380129589633'::double precision),('0'::int4),('0'::int4),('1474.8467456448188'::double precision),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(ELP, 2023-06-10, 4, 11 , 0.5f) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.ResultHandlerDelegate.handleError(ResultHandlerDelegate.java:52)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2421)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2153)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.flushIfDeadlockRisk(QueryExecutorImpl.java:1503)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.sendQuery(QueryExecutorImpl.java:1528)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:566)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:888)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1739)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:740)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:896)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:895)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1012)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1012)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2298)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(ELP, 2023-06-10, 4, 11 , 0.5f) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2733)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2420)\n",
      "\t... 22 more\n",
      "ERROR:root:Error processing course ELP: An error occurred while calling o5468.jdbc.\n",
      ": org.apache.spark.SparkException: Job aborted due to stage failure: Task 8 in stage 202.0 failed 1 times, most recent failure: Lost task 8.0 in stage 202.0 (TID 759) (mail.relufox.ai executor driver): java.sql.BatchUpdateException: Batch entry 0 INSERT INTO gps_aggregated_results_with_gates (\"course_cd\",\"race_date\",\"race_number\",\"saddle_cloth_number\",\"gate_name\",\"avg_speed\",\"avg_acceleration\",\"max_speed\",\"min_speed\",\"fatigue_factor\",\"is_fastest_gate\",\"is_slowest_gate\",\"total_distance_run\",\"ground_loss\") VALUES (('ELP'),('2023-06-10 -05'::date),('1'::int4),('2  '),('0.5f'),('16.43'::double precision),('0.0'::double precision),('16.43'::double precision),('16.43'::double precision),('0.2781837160751566'::double precision),('0'::int4),('0'::int4),('1204.137828220455'::double precision),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(ELP, 2023-06-10, 1, 2  , 0.5f) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.ResultHandlerDelegate.handleError(ResultHandlerDelegate.java:52)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2421)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2153)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.flushIfDeadlockRisk(QueryExecutorImpl.java:1503)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.sendQuery(QueryExecutorImpl.java:1528)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:566)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:888)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1739)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:740)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:896)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:895)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1012)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1012)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2298)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(ELP, 2023-06-10, 1, 2  , 0.5f) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2733)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2420)\n",
      "\t... 22 more\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2790)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2726)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2725)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2725)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1211)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1211)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1211)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2989)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2928)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2917)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:976)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2258)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2279)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2298)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2323)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$1(RDD.scala:1012)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n",
      "\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:408)\n",
      "\tat org.apache.spark.rdd.RDD.foreachPartition(RDD.scala:1010)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.saveTable(JdbcUtils.scala:895)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:70)\n",
      "\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:47)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:118)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:195)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:827)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:65)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:94)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:512)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:104)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:512)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:31)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:31)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:31)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:488)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:94)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:81)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:79)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:133)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:856)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:387)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:360)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:247)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.jdbc(DataFrameWriter.scala:753)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: java.sql.BatchUpdateException: Batch entry 0 INSERT INTO gps_aggregated_results_with_gates (\"course_cd\",\"race_date\",\"race_number\",\"saddle_cloth_number\",\"gate_name\",\"avg_speed\",\"avg_acceleration\",\"max_speed\",\"min_speed\",\"fatigue_factor\",\"is_fastest_gate\",\"is_slowest_gate\",\"total_distance_run\",\"ground_loss\") VALUES (('ELP'),('2023-06-10 -05'::date),('1'::int4),('2  '),('0.5f'),('16.43'::double precision),('0.0'::double precision),('16.43'::double precision),('16.43'::double precision),('0.2781837160751566'::double precision),('0'::int4),('0'::int4),('1204.137828220455'::double precision),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(ELP, 2023-06-10, 1, 2  , 0.5f) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.ResultHandlerDelegate.handleError(ResultHandlerDelegate.java:52)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2421)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2153)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.flushIfDeadlockRisk(QueryExecutorImpl.java:1503)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.sendQuery(QueryExecutorImpl.java:1528)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:566)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:888)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1739)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:740)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:896)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:895)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1012)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1012)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2298)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\t... 1 more\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(ELP, 2023-06-10, 1, 2  , 0.5f) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2733)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2420)\n",
      "\t... 22 more\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Loading data from database for course: PEN\n",
      "INFO:root:None\n",
      "INFO:root:None\n",
      "INFO:root:None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing course: PEN\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- gate_name: string (nullable = true)\n",
      " |-- avg_speed: double (nullable = true)\n",
      " |-- avg_acceleration: double (nullable = true)\n",
      " |-- max_speed: double (nullable = true)\n",
      " |-- min_speed: double (nullable = true)\n",
      " |-- fatigue_factor: double (nullable = true)\n",
      " |-- is_fastest_gate: integer (nullable = true)\n",
      " |-- is_slowest_gate: integer (nullable = true)\n",
      "\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- gate_name: string (nullable = true)\n",
      " |-- avg_speed: double (nullable = true)\n",
      " |-- avg_acceleration: double (nullable = true)\n",
      " |-- max_speed: double (nullable = true)\n",
      " |-- min_speed: double (nullable = true)\n",
      " |-- fatigue_factor: double (nullable = true)\n",
      " |-- is_fastest_gate: integer (nullable = true)\n",
      " |-- is_slowest_gate: integer (nullable = true)\n",
      "\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- total_distance_run: double (nullable = true)\n",
      " |-- ground_loss: double (nullable = true)\n",
      "\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- total_distance_run: double (nullable = true)\n",
      " |-- ground_loss: double (nullable = true)\n",
      "\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- gate_name: string (nullable = true)\n",
      " |-- avg_speed: double (nullable = true)\n",
      " |-- avg_acceleration: double (nullable = true)\n",
      " |-- max_speed: double (nullable = true)\n",
      " |-- min_speed: double (nullable = true)\n",
      " |-- fatigue_factor: double (nullable = true)\n",
      " |-- is_fastest_gate: integer (nullable = true)\n",
      " |-- is_slowest_gate: integer (nullable = true)\n",
      " |-- total_distance_run: double (nullable = true)\n",
      " |-- ground_loss: double (nullable = true)\n",
      "\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- gate_name: string (nullable = true)\n",
      " |-- avg_speed: double (nullable = true)\n",
      " |-- avg_acceleration: double (nullable = true)\n",
      " |-- max_speed: double (nullable = true)\n",
      " |-- min_speed: double (nullable = true)\n",
      " |-- fatigue_factor: double (nullable = true)\n",
      " |-- is_fastest_gate: integer (nullable = true)\n",
      " |-- is_slowest_gate: integer (nullable = true)\n",
      " |-- total_distance_run: double (nullable = true)\n",
      " |-- ground_loss: double (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/05 22:20:57 ERROR Executor: Exception in task 4.0 in stage 225.0 (TID 816)\n",
      "java.sql.BatchUpdateException: Batch entry 0 INSERT INTO gps_aggregated_results_with_gates (\"course_cd\",\"race_date\",\"race_number\",\"saddle_cloth_number\",\"gate_name\",\"avg_speed\",\"avg_acceleration\",\"max_speed\",\"min_speed\",\"fatigue_factor\",\"is_fastest_gate\",\"is_slowest_gate\",\"total_distance_run\",\"ground_loss\") VALUES (('PEN'),('2022-01-07 -06'::date),('4'::int4),('9  '),('0.5f'),('14.16'::double precision),('0.0'::double precision),('14.16'::double precision),('14.16'::double precision),('0.3009764503159104'::double precision),('0'::int4),('0'::int4),('1859.8972532036257'::double precision),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(PEN, 2022-01-07, 4, 9  , 0.5f) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.ResultHandlerDelegate.handleError(ResultHandlerDelegate.java:52)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2421)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2153)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.flushIfDeadlockRisk(QueryExecutorImpl.java:1503)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.sendQuery(QueryExecutorImpl.java:1528)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:566)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:888)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1739)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:740)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:896)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:895)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1012)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1012)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2298)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(PEN, 2022-01-07, 4, 9  , 0.5f) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2733)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2420)\n",
      "\t... 22 more\n",
      "24/12/05 22:20:57 ERROR TaskSetManager: Task 4 in stage 225.0 failed 1 times; aborting job\n",
      "ERROR:root:Error processing course PEN: An error occurred while calling o5885.jdbc.\n",
      ": org.apache.spark.SparkException: Job aborted due to stage failure: Task 4 in stage 225.0 failed 1 times, most recent failure: Lost task 4.0 in stage 225.0 (TID 816) (mail.relufox.ai executor driver): java.sql.BatchUpdateException: Batch entry 0 INSERT INTO gps_aggregated_results_with_gates (\"course_cd\",\"race_date\",\"race_number\",\"saddle_cloth_number\",\"gate_name\",\"avg_speed\",\"avg_acceleration\",\"max_speed\",\"min_speed\",\"fatigue_factor\",\"is_fastest_gate\",\"is_slowest_gate\",\"total_distance_run\",\"ground_loss\") VALUES (('PEN'),('2022-01-07 -06'::date),('4'::int4),('9  '),('0.5f'),('14.16'::double precision),('0.0'::double precision),('14.16'::double precision),('14.16'::double precision),('0.3009764503159104'::double precision),('0'::int4),('0'::int4),('1859.8972532036257'::double precision),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(PEN, 2022-01-07, 4, 9  , 0.5f) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.ResultHandlerDelegate.handleError(ResultHandlerDelegate.java:52)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2421)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2153)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.flushIfDeadlockRisk(QueryExecutorImpl.java:1503)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.sendQuery(QueryExecutorImpl.java:1528)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:566)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:888)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1739)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:740)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:896)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:895)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1012)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1012)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2298)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(PEN, 2022-01-07, 4, 9  , 0.5f) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2733)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2420)\n",
      "\t... 22 more\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2790)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2726)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2725)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2725)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1211)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1211)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1211)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2989)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2928)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2917)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:976)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2258)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2279)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2298)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2323)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$1(RDD.scala:1012)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n",
      "\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:408)\n",
      "\tat org.apache.spark.rdd.RDD.foreachPartition(RDD.scala:1010)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.saveTable(JdbcUtils.scala:895)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:70)\n",
      "\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:47)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:118)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:195)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:827)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:65)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:94)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:512)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:104)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:512)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:31)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:31)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:31)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:488)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:94)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:81)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:79)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:133)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:856)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:387)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:360)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:247)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.jdbc(DataFrameWriter.scala:753)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: java.sql.BatchUpdateException: Batch entry 0 INSERT INTO gps_aggregated_results_with_gates (\"course_cd\",\"race_date\",\"race_number\",\"saddle_cloth_number\",\"gate_name\",\"avg_speed\",\"avg_acceleration\",\"max_speed\",\"min_speed\",\"fatigue_factor\",\"is_fastest_gate\",\"is_slowest_gate\",\"total_distance_run\",\"ground_loss\") VALUES (('PEN'),('2022-01-07 -06'::date),('4'::int4),('9  '),('0.5f'),('14.16'::double precision),('0.0'::double precision),('14.16'::double precision),('14.16'::double precision),('0.3009764503159104'::double precision),('0'::int4),('0'::int4),('1859.8972532036257'::double precision),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(PEN, 2022-01-07, 4, 9  , 0.5f) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.ResultHandlerDelegate.handleError(ResultHandlerDelegate.java:52)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2421)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2153)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.flushIfDeadlockRisk(QueryExecutorImpl.java:1503)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.sendQuery(QueryExecutorImpl.java:1528)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:566)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:888)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1739)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:740)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:896)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:895)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1012)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1012)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2298)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\t... 1 more\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(PEN, 2022-01-07, 4, 9  , 0.5f) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2733)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2420)\n",
      "\t... 22 more\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Loading data from database for course: HOU\n",
      "INFO:root:None\n",
      "INFO:root:None\n",
      "INFO:root:None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing course: HOU\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- gate_name: string (nullable = true)\n",
      " |-- avg_speed: double (nullable = true)\n",
      " |-- avg_acceleration: double (nullable = true)\n",
      " |-- max_speed: double (nullable = true)\n",
      " |-- min_speed: double (nullable = true)\n",
      " |-- fatigue_factor: double (nullable = true)\n",
      " |-- is_fastest_gate: integer (nullable = true)\n",
      " |-- is_slowest_gate: integer (nullable = true)\n",
      "\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- gate_name: string (nullable = true)\n",
      " |-- avg_speed: double (nullable = true)\n",
      " |-- avg_acceleration: double (nullable = true)\n",
      " |-- max_speed: double (nullable = true)\n",
      " |-- min_speed: double (nullable = true)\n",
      " |-- fatigue_factor: double (nullable = true)\n",
      " |-- is_fastest_gate: integer (nullable = true)\n",
      " |-- is_slowest_gate: integer (nullable = true)\n",
      "\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- total_distance_run: double (nullable = true)\n",
      " |-- ground_loss: double (nullable = true)\n",
      "\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- total_distance_run: double (nullable = true)\n",
      " |-- ground_loss: double (nullable = true)\n",
      "\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- gate_name: string (nullable = true)\n",
      " |-- avg_speed: double (nullable = true)\n",
      " |-- avg_acceleration: double (nullable = true)\n",
      " |-- max_speed: double (nullable = true)\n",
      " |-- min_speed: double (nullable = true)\n",
      " |-- fatigue_factor: double (nullable = true)\n",
      " |-- is_fastest_gate: integer (nullable = true)\n",
      " |-- is_slowest_gate: integer (nullable = true)\n",
      " |-- total_distance_run: double (nullable = true)\n",
      " |-- ground_loss: double (nullable = true)\n",
      "\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- gate_name: string (nullable = true)\n",
      " |-- avg_speed: double (nullable = true)\n",
      " |-- avg_acceleration: double (nullable = true)\n",
      " |-- max_speed: double (nullable = true)\n",
      " |-- min_speed: double (nullable = true)\n",
      " |-- fatigue_factor: double (nullable = true)\n",
      " |-- is_fastest_gate: integer (nullable = true)\n",
      " |-- is_slowest_gate: integer (nullable = true)\n",
      " |-- total_distance_run: double (nullable = true)\n",
      " |-- ground_loss: double (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/05 22:20:59 ERROR Executor: Exception in task 6.0 in stage 240.0 (TID 867)\n",
      "java.sql.BatchUpdateException: Batch entry 0 INSERT INTO gps_aggregated_results_with_gates (\"course_cd\",\"race_date\",\"race_number\",\"saddle_cloth_number\",\"gate_name\",\"avg_speed\",\"avg_acceleration\",\"max_speed\",\"min_speed\",\"fatigue_factor\",\"is_fastest_gate\",\"is_slowest_gate\",\"total_distance_run\",\"ground_loss\") VALUES (('HOU'),('2022-01-07 -06'::date),('1'::int4),('7  '),('0.5f'),('11.93'::double precision),('0.0'::double precision),('11.93'::double precision),('11.93'::double precision),('0.2780847145488029'::double precision),('0'::int4),('0'::int4),('1356.672313385443'::double precision),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(HOU, 2022-01-07, 1, 7  , 0.5f) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.ResultHandlerDelegate.handleError(ResultHandlerDelegate.java:52)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2421)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2153)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.flushIfDeadlockRisk(QueryExecutorImpl.java:1503)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.sendQuery(QueryExecutorImpl.java:1528)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:566)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:888)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1739)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:740)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:896)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:895)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1012)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1012)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2298)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(HOU, 2022-01-07, 1, 7  , 0.5f) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2733)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2420)\n",
      "\t... 22 more\n",
      "24/12/05 22:20:59 ERROR Executor: Exception in task 19.0 in stage 240.0 (TID 880)\n",
      "java.sql.BatchUpdateException: Batch entry 0 INSERT INTO gps_aggregated_results_with_gates (\"course_cd\",\"race_date\",\"race_number\",\"saddle_cloth_number\",\"gate_name\",\"avg_speed\",\"avg_acceleration\",\"max_speed\",\"min_speed\",\"fatigue_factor\",\"is_fastest_gate\",\"is_slowest_gate\",\"total_distance_run\",\"ground_loss\") VALUES (('HOU'),('2022-01-06 -06'::date),('2'::int4),('8  '),('0.5f'),('13.7'::double precision),('0.0'::double precision),('13.7'::double precision),('13.7'::double precision),('0.30283224400871456'::double precision),('0'::int4),('0'::int4),('1269.7210078805754'::double precision),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(HOU, 2022-01-06, 2, 8  , 0.5f) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.ResultHandlerDelegate.handleError(ResultHandlerDelegate.java:52)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2421)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2153)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.flushIfDeadlockRisk(QueryExecutorImpl.java:1503)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.sendQuery(QueryExecutorImpl.java:1528)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:566)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:888)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1739)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:740)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:896)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:895)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1012)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1012)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2298)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(HOU, 2022-01-06, 2, 8  , 0.5f) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2733)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2420)\n",
      "\t... 22 more\n",
      "24/12/05 22:20:59 ERROR Executor: Exception in task 35.0 in stage 240.0 (TID 896)\n",
      "java.sql.BatchUpdateException: Batch entry 0 INSERT INTO gps_aggregated_results_with_gates (\"course_cd\",\"race_date\",\"race_number\",\"saddle_cloth_number\",\"gate_name\",\"avg_speed\",\"avg_acceleration\",\"max_speed\",\"min_speed\",\"fatigue_factor\",\"is_fastest_gate\",\"is_slowest_gate\",\"total_distance_run\",\"ground_loss\") VALUES (('HOU'),('2022-01-06 -06'::date),('10'::int4),('2  '),('0.5f'),('11.99'::double precision),('0.0'::double precision),('11.99'::double precision),('11.99'::double precision),('0.5777777777777777'::double precision),('0'::int4),('0'::int4),('1179.3464392094997'::double precision),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(HOU, 2022-01-06, 10, 2  , 0.5f) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.ResultHandlerDelegate.handleError(ResultHandlerDelegate.java:52)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2421)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2153)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.flushIfDeadlockRisk(QueryExecutorImpl.java:1503)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.sendQuery(QueryExecutorImpl.java:1528)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:566)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:888)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1739)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:740)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:896)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:895)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1012)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1012)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2298)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(HOU, 2022-01-06, 10, 2  , 0.5f) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2733)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2420)\n",
      "\t... 22 more\n",
      "24/12/05 22:20:59 ERROR Executor: Exception in task 1.0 in stage 240.0 (TID 862)\n",
      "java.sql.BatchUpdateException: Batch entry 0 INSERT INTO gps_aggregated_results_with_gates (\"course_cd\",\"race_date\",\"race_number\",\"saddle_cloth_number\",\"gate_name\",\"avg_speed\",\"avg_acceleration\",\"max_speed\",\"min_speed\",\"fatigue_factor\",\"is_fastest_gate\",\"is_slowest_gate\",\"total_distance_run\",\"ground_loss\") VALUES (('HOU'),('2022-01-06 -06'::date),('4'::int4),('3  '),('0.5f'),('14.46'::double precision),('0.0'::double precision),('14.46'::double precision),('14.46'::double precision),('0.27471910112359554'::double precision),('0'::int4),('0'::int4),('1568.1611523183128'::double precision),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(HOU, 2022-01-06, 4, 3  , 0.5f) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.ResultHandlerDelegate.handleError(ResultHandlerDelegate.java:52)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2421)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2153)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.flushIfDeadlockRisk(QueryExecutorImpl.java:1503)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.sendQuery(QueryExecutorImpl.java:1528)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:566)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:888)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1739)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:740)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:896)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:895)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1012)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1012)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2298)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(HOU, 2022-01-06, 4, 3  , 0.5f) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2733)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2420)\n",
      "\t... 22 more\n",
      "24/12/05 22:20:59 ERROR Executor: Exception in task 2.0 in stage 240.0 (TID 863)\n",
      "java.sql.BatchUpdateException: Batch entry 0 INSERT INTO gps_aggregated_results_with_gates (\"course_cd\",\"race_date\",\"race_number\",\"saddle_cloth_number\",\"gate_name\",\"avg_speed\",\"avg_acceleration\",\"max_speed\",\"min_speed\",\"fatigue_factor\",\"is_fastest_gate\",\"is_slowest_gate\",\"total_distance_run\",\"ground_loss\") VALUES (('HOU'),('2022-01-07 -06'::date),('9'::int4),('6  '),('0.5f'),('13.61'::double precision),('0.0'::double precision),('13.61'::double precision),('13.61'::double precision),('0.4108991825613079'::double precision),('0'::int4),('0'::int4),('1553.2272743433477'::double precision),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(HOU, 2022-01-07, 9, 6  , 0.5f) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.ResultHandlerDelegate.handleError(ResultHandlerDelegate.java:52)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2421)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2153)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.flushIfDeadlockRisk(QueryExecutorImpl.java:1503)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.sendQuery(QueryExecutorImpl.java:1528)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:566)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:888)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1739)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:740)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:896)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:895)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1012)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1012)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2298)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(HOU, 2022-01-07, 9, 6  , 0.5f) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2733)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2420)\n",
      "\t... 22 more\n",
      "24/12/05 22:20:59 ERROR TaskSetManager: Task 19 in stage 240.0 failed 1 times; aborting job\n",
      "ERROR:root:Error processing course HOU: An error occurred while calling o6302.jdbc.\n",
      ": org.apache.spark.SparkException: Job aborted due to stage failure: Task 19 in stage 240.0 failed 1 times, most recent failure: Lost task 19.0 in stage 240.0 (TID 880) (mail.relufox.ai executor driver): java.sql.BatchUpdateException: Batch entry 0 INSERT INTO gps_aggregated_results_with_gates (\"course_cd\",\"race_date\",\"race_number\",\"saddle_cloth_number\",\"gate_name\",\"avg_speed\",\"avg_acceleration\",\"max_speed\",\"min_speed\",\"fatigue_factor\",\"is_fastest_gate\",\"is_slowest_gate\",\"total_distance_run\",\"ground_loss\") VALUES (('HOU'),('2022-01-06 -06'::date),('2'::int4),('8  '),('0.5f'),('13.7'::double precision),('0.0'::double precision),('13.7'::double precision),('13.7'::double precision),('0.30283224400871456'::double precision),('0'::int4),('0'::int4),('1269.7210078805754'::double precision),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(HOU, 2022-01-06, 2, 8  , 0.5f) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.ResultHandlerDelegate.handleError(ResultHandlerDelegate.java:52)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2421)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2153)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.flushIfDeadlockRisk(QueryExecutorImpl.java:1503)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.sendQuery(QueryExecutorImpl.java:1528)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:566)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:888)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1739)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:740)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:896)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:895)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1012)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1012)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2298)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(HOU, 2022-01-06, 2, 8  , 0.5f) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2733)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2420)\n",
      "\t... 22 more\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2790)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2726)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2725)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2725)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1211)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1211)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1211)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2989)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2928)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2917)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:976)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2258)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2279)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2298)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2323)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$1(RDD.scala:1012)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n",
      "\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:408)\n",
      "\tat org.apache.spark.rdd.RDD.foreachPartition(RDD.scala:1010)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.saveTable(JdbcUtils.scala:895)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:70)\n",
      "\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:47)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:118)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:195)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:827)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:65)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:94)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:512)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:104)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:512)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:31)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:31)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:31)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:488)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:94)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:81)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:79)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:133)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:856)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:387)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:360)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:247)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.jdbc(DataFrameWriter.scala:753)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: java.sql.BatchUpdateException: Batch entry 0 INSERT INTO gps_aggregated_results_with_gates (\"course_cd\",\"race_date\",\"race_number\",\"saddle_cloth_number\",\"gate_name\",\"avg_speed\",\"avg_acceleration\",\"max_speed\",\"min_speed\",\"fatigue_factor\",\"is_fastest_gate\",\"is_slowest_gate\",\"total_distance_run\",\"ground_loss\") VALUES (('HOU'),('2022-01-06 -06'::date),('2'::int4),('8  '),('0.5f'),('13.7'::double precision),('0.0'::double precision),('13.7'::double precision),('13.7'::double precision),('0.30283224400871456'::double precision),('0'::int4),('0'::int4),('1269.7210078805754'::double precision),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(HOU, 2022-01-06, 2, 8  , 0.5f) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.ResultHandlerDelegate.handleError(ResultHandlerDelegate.java:52)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2421)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2153)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.flushIfDeadlockRisk(QueryExecutorImpl.java:1503)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.sendQuery(QueryExecutorImpl.java:1528)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:566)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:888)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1739)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:740)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:896)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:895)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1012)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1012)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2298)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\t... 1 more\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(HOU, 2022-01-06, 2, 8  , 0.5f) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2733)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2420)\n",
      "\t... 22 more\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Loading data from database for course: DMR\n",
      "INFO:root:None\n",
      "INFO:root:None\n",
      "INFO:root:None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing course: DMR\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- gate_name: string (nullable = true)\n",
      " |-- avg_speed: double (nullable = true)\n",
      " |-- avg_acceleration: double (nullable = true)\n",
      " |-- max_speed: double (nullable = true)\n",
      " |-- min_speed: double (nullable = true)\n",
      " |-- fatigue_factor: double (nullable = true)\n",
      " |-- is_fastest_gate: integer (nullable = true)\n",
      " |-- is_slowest_gate: integer (nullable = true)\n",
      "\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- gate_name: string (nullable = true)\n",
      " |-- avg_speed: double (nullable = true)\n",
      " |-- avg_acceleration: double (nullable = true)\n",
      " |-- max_speed: double (nullable = true)\n",
      " |-- min_speed: double (nullable = true)\n",
      " |-- fatigue_factor: double (nullable = true)\n",
      " |-- is_fastest_gate: integer (nullable = true)\n",
      " |-- is_slowest_gate: integer (nullable = true)\n",
      "\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- total_distance_run: double (nullable = true)\n",
      " |-- ground_loss: double (nullable = true)\n",
      "\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- total_distance_run: double (nullable = true)\n",
      " |-- ground_loss: double (nullable = true)\n",
      "\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- gate_name: string (nullable = true)\n",
      " |-- avg_speed: double (nullable = true)\n",
      " |-- avg_acceleration: double (nullable = true)\n",
      " |-- max_speed: double (nullable = true)\n",
      " |-- min_speed: double (nullable = true)\n",
      " |-- fatigue_factor: double (nullable = true)\n",
      " |-- is_fastest_gate: integer (nullable = true)\n",
      " |-- is_slowest_gate: integer (nullable = true)\n",
      " |-- total_distance_run: double (nullable = true)\n",
      " |-- ground_loss: double (nullable = true)\n",
      "\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- gate_name: string (nullable = true)\n",
      " |-- avg_speed: double (nullable = true)\n",
      " |-- avg_acceleration: double (nullable = true)\n",
      " |-- max_speed: double (nullable = true)\n",
      " |-- min_speed: double (nullable = true)\n",
      " |-- fatigue_factor: double (nullable = true)\n",
      " |-- is_fastest_gate: integer (nullable = true)\n",
      " |-- is_slowest_gate: integer (nullable = true)\n",
      " |-- total_distance_run: double (nullable = true)\n",
      " |-- ground_loss: double (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/05 22:21:01 ERROR Executor: Exception in task 37.0 in stage 255.0 (TID 967)\n",
      "java.sql.BatchUpdateException: Batch entry 0 INSERT INTO gps_aggregated_results_with_gates (\"course_cd\",\"race_date\",\"race_number\",\"saddle_cloth_number\",\"gate_name\",\"avg_speed\",\"avg_acceleration\",\"max_speed\",\"min_speed\",\"fatigue_factor\",\"is_fastest_gate\",\"is_slowest_gate\",\"total_distance_run\",\"ground_loss\") VALUES (('DMR'),('2022-07-22 -05'::date),('6'::int4),('4  '),('0.5f'),('16.71'::double precision),('0.0'::double precision),('16.71'::double precision),('16.71'::double precision),('0.0909604519774011'::double precision),('0'::int4),('0'::int4),('1990.7761398016607'::double precision),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(DMR, 2022-07-22, 6, 4  , 0.5f) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.ResultHandlerDelegate.handleError(ResultHandlerDelegate.java:52)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2421)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2153)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.flushIfDeadlockRisk(QueryExecutorImpl.java:1503)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.sendQuery(QueryExecutorImpl.java:1528)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:566)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:888)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1739)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:740)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:896)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:895)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1012)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1012)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2298)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(DMR, 2022-07-22, 6, 4  , 0.5f) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2733)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2420)\n",
      "\t... 22 more\n",
      "24/12/05 22:21:01 ERROR Executor: Exception in task 3.0 in stage 255.0 (TID 933)\n",
      "java.sql.BatchUpdateException: Batch entry 0 INSERT INTO gps_aggregated_results_with_gates (\"course_cd\",\"race_date\",\"race_number\",\"saddle_cloth_number\",\"gate_name\",\"avg_speed\",\"avg_acceleration\",\"max_speed\",\"min_speed\",\"fatigue_factor\",\"is_fastest_gate\",\"is_slowest_gate\",\"total_distance_run\",\"ground_loss\") VALUES (('DMR'),('2022-07-23 -05'::date),('5'::int4),('8  '),('0.5f'),('16.48'::double precision),('0.0'::double precision),('16.48'::double precision),('16.48'::double precision),('0.19473978735310576'::double precision),('0'::int4),('0'::int4),('1866.9792306280513'::double precision),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(DMR, 2022-07-23, 5, 8  , 0.5f) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.ResultHandlerDelegate.handleError(ResultHandlerDelegate.java:52)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2421)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2153)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.flushIfDeadlockRisk(QueryExecutorImpl.java:1503)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.sendQuery(QueryExecutorImpl.java:1528)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:566)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:888)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1739)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:740)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:896)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:895)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1012)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1012)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2298)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(DMR, 2022-07-23, 5, 8  , 0.5f) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2733)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2420)\n",
      "\t... 22 more\n",
      "24/12/05 22:21:01 ERROR TaskSetManager: Task 37 in stage 255.0 failed 1 times; aborting job\n",
      "24/12/05 22:21:01 ERROR Executor: Exception in task 18.0 in stage 255.0 (TID 948)\n",
      "java.sql.BatchUpdateException: Batch entry 0 INSERT INTO gps_aggregated_results_with_gates (\"course_cd\",\"race_date\",\"race_number\",\"saddle_cloth_number\",\"gate_name\",\"avg_speed\",\"avg_acceleration\",\"max_speed\",\"min_speed\",\"fatigue_factor\",\"is_fastest_gate\",\"is_slowest_gate\",\"total_distance_run\",\"ground_loss\") VALUES (('DMR'),('2022-07-22 -05'::date),('6'::int4),('8  '),('0.5f'),('16.39'::double precision),('0.0'::double precision),('16.39'::double precision),('16.39'::double precision),('0.23346303501945523'::double precision),('0'::int4),('0'::int4),('1990.6212775266993'::double precision),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(DMR, 2022-07-22, 6, 8  , 0.5f) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.ResultHandlerDelegate.handleError(ResultHandlerDelegate.java:52)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2421)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2153)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.flushIfDeadlockRisk(QueryExecutorImpl.java:1503)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.sendQuery(QueryExecutorImpl.java:1528)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:566)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:888)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1739)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:740)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:896)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:895)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1012)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1012)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2298)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(DMR, 2022-07-22, 6, 8  , 0.5f) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2733)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2420)\n",
      "\t... 22 more\n",
      "ERROR:root:Error processing course DMR: An error occurred while calling o6719.jdbc.\n",
      ": org.apache.spark.SparkException: Job aborted due to stage failure: Task 37 in stage 255.0 failed 1 times, most recent failure: Lost task 37.0 in stage 255.0 (TID 967) (mail.relufox.ai executor driver): java.sql.BatchUpdateException: Batch entry 0 INSERT INTO gps_aggregated_results_with_gates (\"course_cd\",\"race_date\",\"race_number\",\"saddle_cloth_number\",\"gate_name\",\"avg_speed\",\"avg_acceleration\",\"max_speed\",\"min_speed\",\"fatigue_factor\",\"is_fastest_gate\",\"is_slowest_gate\",\"total_distance_run\",\"ground_loss\") VALUES (('DMR'),('2022-07-22 -05'::date),('6'::int4),('4  '),('0.5f'),('16.71'::double precision),('0.0'::double precision),('16.71'::double precision),('16.71'::double precision),('0.0909604519774011'::double precision),('0'::int4),('0'::int4),('1990.7761398016607'::double precision),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(DMR, 2022-07-22, 6, 4  , 0.5f) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.ResultHandlerDelegate.handleError(ResultHandlerDelegate.java:52)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2421)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2153)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.flushIfDeadlockRisk(QueryExecutorImpl.java:1503)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.sendQuery(QueryExecutorImpl.java:1528)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:566)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:888)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1739)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:740)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:896)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:895)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1012)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1012)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2298)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(DMR, 2022-07-22, 6, 4  , 0.5f) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2733)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2420)\n",
      "\t... 22 more\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2790)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2726)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2725)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2725)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1211)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1211)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1211)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2989)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2928)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2917)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:976)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2258)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2279)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2298)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2323)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$1(RDD.scala:1012)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n",
      "\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:408)\n",
      "\tat org.apache.spark.rdd.RDD.foreachPartition(RDD.scala:1010)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.saveTable(JdbcUtils.scala:895)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:70)\n",
      "\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:47)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:118)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:195)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:827)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:65)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:94)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:512)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:104)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:512)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:31)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:31)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:31)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:488)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:94)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:81)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:79)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:133)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:856)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:387)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:360)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:247)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.jdbc(DataFrameWriter.scala:753)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: java.sql.BatchUpdateException: Batch entry 0 INSERT INTO gps_aggregated_results_with_gates (\"course_cd\",\"race_date\",\"race_number\",\"saddle_cloth_number\",\"gate_name\",\"avg_speed\",\"avg_acceleration\",\"max_speed\",\"min_speed\",\"fatigue_factor\",\"is_fastest_gate\",\"is_slowest_gate\",\"total_distance_run\",\"ground_loss\") VALUES (('DMR'),('2022-07-22 -05'::date),('6'::int4),('4  '),('0.5f'),('16.71'::double precision),('0.0'::double precision),('16.71'::double precision),('16.71'::double precision),('0.0909604519774011'::double precision),('0'::int4),('0'::int4),('1990.7761398016607'::double precision),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(DMR, 2022-07-22, 6, 4  , 0.5f) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.ResultHandlerDelegate.handleError(ResultHandlerDelegate.java:52)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2421)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2153)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.flushIfDeadlockRisk(QueryExecutorImpl.java:1503)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.sendQuery(QueryExecutorImpl.java:1528)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:566)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:888)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1739)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:740)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:896)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:895)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1012)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1012)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2298)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\t... 1 more\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(DMR, 2022-07-22, 6, 4  , 0.5f) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2733)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2420)\n",
      "\t... 22 more\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Loading data from database for course: TLS\n",
      "INFO:root:None\n",
      "INFO:root:None\n",
      "INFO:root:None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing course: TLS\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- gate_name: string (nullable = true)\n",
      " |-- avg_speed: double (nullable = true)\n",
      " |-- avg_acceleration: double (nullable = true)\n",
      " |-- max_speed: double (nullable = true)\n",
      " |-- min_speed: double (nullable = true)\n",
      " |-- fatigue_factor: double (nullable = true)\n",
      " |-- is_fastest_gate: integer (nullable = true)\n",
      " |-- is_slowest_gate: integer (nullable = true)\n",
      "\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- gate_name: string (nullable = true)\n",
      " |-- avg_speed: double (nullable = true)\n",
      " |-- avg_acceleration: double (nullable = true)\n",
      " |-- max_speed: double (nullable = true)\n",
      " |-- min_speed: double (nullable = true)\n",
      " |-- fatigue_factor: double (nullable = true)\n",
      " |-- is_fastest_gate: integer (nullable = true)\n",
      " |-- is_slowest_gate: integer (nullable = true)\n",
      "\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- total_distance_run: double (nullable = true)\n",
      " |-- ground_loss: double (nullable = true)\n",
      "\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- total_distance_run: double (nullable = true)\n",
      " |-- ground_loss: double (nullable = true)\n",
      "\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- gate_name: string (nullable = true)\n",
      " |-- avg_speed: double (nullable = true)\n",
      " |-- avg_acceleration: double (nullable = true)\n",
      " |-- max_speed: double (nullable = true)\n",
      " |-- min_speed: double (nullable = true)\n",
      " |-- fatigue_factor: double (nullable = true)\n",
      " |-- is_fastest_gate: integer (nullable = true)\n",
      " |-- is_slowest_gate: integer (nullable = true)\n",
      " |-- total_distance_run: double (nullable = true)\n",
      " |-- ground_loss: double (nullable = true)\n",
      "\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- gate_name: string (nullable = true)\n",
      " |-- avg_speed: double (nullable = true)\n",
      " |-- avg_acceleration: double (nullable = true)\n",
      " |-- max_speed: double (nullable = true)\n",
      " |-- min_speed: double (nullable = true)\n",
      " |-- fatigue_factor: double (nullable = true)\n",
      " |-- is_fastest_gate: integer (nullable = true)\n",
      " |-- is_slowest_gate: integer (nullable = true)\n",
      " |-- total_distance_run: double (nullable = true)\n",
      " |-- ground_loss: double (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/05 22:21:03 ERROR Executor: Exception in task 34.0 in stage 270.0 (TID 1034)\n",
      "java.sql.BatchUpdateException: Batch entry 0 INSERT INTO gps_aggregated_results_with_gates (\"course_cd\",\"race_date\",\"race_number\",\"saddle_cloth_number\",\"gate_name\",\"avg_speed\",\"avg_acceleration\",\"max_speed\",\"min_speed\",\"fatigue_factor\",\"is_fastest_gate\",\"is_slowest_gate\",\"total_distance_run\",\"ground_loss\") VALUES (('TLS'),('2022-04-28 -05'::date),('1'::int4),('10 '),('0.5f'),('15.21'::double precision),('0.0'::double precision),('15.21'::double precision),('15.21'::double precision),('0.26077700904736556'::double precision),('0'::int4),('0'::int4),('1454.8408062219423'::double precision),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(TLS, 2022-04-28, 1, 10 , 0.5f) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.ResultHandlerDelegate.handleError(ResultHandlerDelegate.java:52)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2421)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2153)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.flushIfDeadlockRisk(QueryExecutorImpl.java:1503)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.sendQuery(QueryExecutorImpl.java:1528)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:566)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:888)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1739)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:740)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:896)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:895)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1012)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1012)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2298)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(TLS, 2022-04-28, 1, 10 , 0.5f) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2733)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2420)\n",
      "\t... 22 more\n",
      "24/12/05 22:21:03 ERROR Executor: Exception in task 6.0 in stage 270.0 (TID 1006)\n",
      "java.sql.BatchUpdateException: Batch entry 0 INSERT INTO gps_aggregated_results_with_gates (\"course_cd\",\"race_date\",\"race_number\",\"saddle_cloth_number\",\"gate_name\",\"avg_speed\",\"avg_acceleration\",\"max_speed\",\"min_speed\",\"fatigue_factor\",\"is_fastest_gate\",\"is_slowest_gate\",\"total_distance_run\",\"ground_loss\") VALUES (('TLS'),('2022-04-28 -05'::date),('4'::int4),('5  '),('0.5f'),('14.39'::double precision),('0.0'::double precision),('14.39'::double precision),('14.39'::double precision),('0.4009169638308711'::double precision),('0'::int4),('0'::int4),('1262.198430930444'::double precision),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(TLS, 2022-04-28, 4, 5  , 0.5f) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.ResultHandlerDelegate.handleError(ResultHandlerDelegate.java:52)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2421)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2153)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.flushIfDeadlockRisk(QueryExecutorImpl.java:1503)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.sendQuery(QueryExecutorImpl.java:1528)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:566)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:888)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1739)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:740)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:896)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:895)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1012)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1012)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2298)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(TLS, 2022-04-28, 4, 5  , 0.5f) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2733)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2420)\n",
      "\t... 22 more\n",
      "24/12/05 22:21:03 ERROR TaskSetManager: Task 34 in stage 270.0 failed 1 times; aborting job\n",
      "ERROR:root:Error processing course TLS: An error occurred while calling o7136.jdbc.\n",
      ": org.apache.spark.SparkException: Job aborted due to stage failure: Task 34 in stage 270.0 failed 1 times, most recent failure: Lost task 34.0 in stage 270.0 (TID 1034) (mail.relufox.ai executor driver): java.sql.BatchUpdateException: Batch entry 0 INSERT INTO gps_aggregated_results_with_gates (\"course_cd\",\"race_date\",\"race_number\",\"saddle_cloth_number\",\"gate_name\",\"avg_speed\",\"avg_acceleration\",\"max_speed\",\"min_speed\",\"fatigue_factor\",\"is_fastest_gate\",\"is_slowest_gate\",\"total_distance_run\",\"ground_loss\") VALUES (('TLS'),('2022-04-28 -05'::date),('1'::int4),('10 '),('0.5f'),('15.21'::double precision),('0.0'::double precision),('15.21'::double precision),('15.21'::double precision),('0.26077700904736556'::double precision),('0'::int4),('0'::int4),('1454.8408062219423'::double precision),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(TLS, 2022-04-28, 1, 10 , 0.5f) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.ResultHandlerDelegate.handleError(ResultHandlerDelegate.java:52)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2421)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2153)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.flushIfDeadlockRisk(QueryExecutorImpl.java:1503)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.sendQuery(QueryExecutorImpl.java:1528)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:566)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:888)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1739)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:740)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:896)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:895)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1012)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1012)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2298)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(TLS, 2022-04-28, 1, 10 , 0.5f) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2733)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2420)\n",
      "\t... 22 more\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2790)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2726)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2725)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2725)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1211)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1211)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1211)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2989)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2928)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2917)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:976)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2258)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2279)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2298)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2323)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$1(RDD.scala:1012)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n",
      "\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:408)\n",
      "\tat org.apache.spark.rdd.RDD.foreachPartition(RDD.scala:1010)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.saveTable(JdbcUtils.scala:895)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:70)\n",
      "\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:47)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:118)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:195)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:827)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:65)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:94)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:512)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:104)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:512)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:31)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:31)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:31)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:488)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:94)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:81)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:79)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:133)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:856)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:387)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:360)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:247)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.jdbc(DataFrameWriter.scala:753)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor265.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: java.sql.BatchUpdateException: Batch entry 0 INSERT INTO gps_aggregated_results_with_gates (\"course_cd\",\"race_date\",\"race_number\",\"saddle_cloth_number\",\"gate_name\",\"avg_speed\",\"avg_acceleration\",\"max_speed\",\"min_speed\",\"fatigue_factor\",\"is_fastest_gate\",\"is_slowest_gate\",\"total_distance_run\",\"ground_loss\") VALUES (('TLS'),('2022-04-28 -05'::date),('1'::int4),('10 '),('0.5f'),('15.21'::double precision),('0.0'::double precision),('15.21'::double precision),('15.21'::double precision),('0.26077700904736556'::double precision),('0'::int4),('0'::int4),('1454.8408062219423'::double precision),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(TLS, 2022-04-28, 1, 10 , 0.5f) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.ResultHandlerDelegate.handleError(ResultHandlerDelegate.java:52)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2421)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2153)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.flushIfDeadlockRisk(QueryExecutorImpl.java:1503)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.sendQuery(QueryExecutorImpl.java:1528)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:566)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:888)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1739)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:740)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:896)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:895)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1012)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1012)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2298)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\t... 1 more\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(TLS, 2022-04-28, 1, 10 , 0.5f) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2733)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2420)\n",
      "\t... 22 more\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Loading data from database for course: AQU\n",
      "INFO:root:None\n",
      "INFO:root:None\n",
      "INFO:root:None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing course: AQU\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- gate_name: string (nullable = true)\n",
      " |-- avg_speed: double (nullable = true)\n",
      " |-- avg_acceleration: double (nullable = true)\n",
      " |-- max_speed: double (nullable = true)\n",
      " |-- min_speed: double (nullable = true)\n",
      " |-- fatigue_factor: double (nullable = true)\n",
      " |-- is_fastest_gate: integer (nullable = true)\n",
      " |-- is_slowest_gate: integer (nullable = true)\n",
      "\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- gate_name: string (nullable = true)\n",
      " |-- avg_speed: double (nullable = true)\n",
      " |-- avg_acceleration: double (nullable = true)\n",
      " |-- max_speed: double (nullable = true)\n",
      " |-- min_speed: double (nullable = true)\n",
      " |-- fatigue_factor: double (nullable = true)\n",
      " |-- is_fastest_gate: integer (nullable = true)\n",
      " |-- is_slowest_gate: integer (nullable = true)\n",
      "\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- total_distance_run: double (nullable = true)\n",
      " |-- ground_loss: double (nullable = true)\n",
      "\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- total_distance_run: double (nullable = true)\n",
      " |-- ground_loss: double (nullable = true)\n",
      "\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- gate_name: string (nullable = true)\n",
      " |-- avg_speed: double (nullable = true)\n",
      " |-- avg_acceleration: double (nullable = true)\n",
      " |-- max_speed: double (nullable = true)\n",
      " |-- min_speed: double (nullable = true)\n",
      " |-- fatigue_factor: double (nullable = true)\n",
      " |-- is_fastest_gate: integer (nullable = true)\n",
      " |-- is_slowest_gate: integer (nullable = true)\n",
      " |-- total_distance_run: double (nullable = true)\n",
      " |-- ground_loss: double (nullable = true)\n",
      "\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- gate_name: string (nullable = true)\n",
      " |-- avg_speed: double (nullable = true)\n",
      " |-- avg_acceleration: double (nullable = true)\n",
      " |-- max_speed: double (nullable = true)\n",
      " |-- min_speed: double (nullable = true)\n",
      " |-- fatigue_factor: double (nullable = true)\n",
      " |-- is_fastest_gate: integer (nullable = true)\n",
      " |-- is_slowest_gate: integer (nullable = true)\n",
      " |-- total_distance_run: double (nullable = true)\n",
      " |-- ground_loss: double (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/05 22:21:06 ERROR Executor: Exception in task 39.0 in stage 285.0 (TID 1123)\n",
      "java.sql.BatchUpdateException: Batch entry 0 INSERT INTO gps_aggregated_results_with_gates (\"course_cd\",\"race_date\",\"race_number\",\"saddle_cloth_number\",\"gate_name\",\"avg_speed\",\"avg_acceleration\",\"max_speed\",\"min_speed\",\"fatigue_factor\",\"is_fastest_gate\",\"is_slowest_gate\",\"total_distance_run\",\"ground_loss\") VALUES (('AQU'),('2022-12-29 -06'::date),('5'::int4),('9  '),('0.5f'),('14.38'::double precision),('0.0'::double precision),('14.38'::double precision),('14.38'::double precision),('0.22623679822123396'::double precision),('0'::int4),('0'::int4),('1371.243112492651'::double precision),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(AQU, 2022-12-29, 5, 9  , 0.5f) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.ResultHandlerDelegate.handleError(ResultHandlerDelegate.java:52)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2421)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2153)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.flushIfDeadlockRisk(QueryExecutorImpl.java:1503)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.sendQuery(QueryExecutorImpl.java:1528)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:566)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:888)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1739)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:740)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:896)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:895)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1012)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1012)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2298)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(AQU, 2022-12-29, 5, 9  , 0.5f) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2733)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2420)\n",
      "\t... 22 more\n",
      "24/12/05 22:21:06 ERROR TaskSetManager: Task 39 in stage 285.0 failed 1 times; aborting job\n",
      "ERROR:root:Error processing course AQU: An error occurred while calling o7553.jdbc.\n",
      ": org.apache.spark.SparkException: Job aborted due to stage failure: Task 39 in stage 285.0 failed 1 times, most recent failure: Lost task 39.0 in stage 285.0 (TID 1123) (mail.relufox.ai executor driver): java.sql.BatchUpdateException: Batch entry 0 INSERT INTO gps_aggregated_results_with_gates (\"course_cd\",\"race_date\",\"race_number\",\"saddle_cloth_number\",\"gate_name\",\"avg_speed\",\"avg_acceleration\",\"max_speed\",\"min_speed\",\"fatigue_factor\",\"is_fastest_gate\",\"is_slowest_gate\",\"total_distance_run\",\"ground_loss\") VALUES (('AQU'),('2022-12-29 -06'::date),('5'::int4),('9  '),('0.5f'),('14.38'::double precision),('0.0'::double precision),('14.38'::double precision),('14.38'::double precision),('0.22623679822123396'::double precision),('0'::int4),('0'::int4),('1371.243112492651'::double precision),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(AQU, 2022-12-29, 5, 9  , 0.5f) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.ResultHandlerDelegate.handleError(ResultHandlerDelegate.java:52)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2421)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2153)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.flushIfDeadlockRisk(QueryExecutorImpl.java:1503)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.sendQuery(QueryExecutorImpl.java:1528)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:566)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:888)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1739)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:740)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:896)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:895)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1012)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1012)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2298)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(AQU, 2022-12-29, 5, 9  , 0.5f) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2733)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2420)\n",
      "\t... 22 more\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2790)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2726)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2725)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2725)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1211)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1211)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1211)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2989)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2928)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2917)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:976)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2258)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2279)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2298)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2323)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$1(RDD.scala:1012)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n",
      "\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:408)\n",
      "\tat org.apache.spark.rdd.RDD.foreachPartition(RDD.scala:1010)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.saveTable(JdbcUtils.scala:895)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:70)\n",
      "\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:47)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:118)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:195)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:827)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:65)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:94)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:512)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:104)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:512)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:31)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:31)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:31)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:488)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:94)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:81)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:79)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:133)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:856)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:387)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:360)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:247)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.jdbc(DataFrameWriter.scala:753)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor265.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: java.sql.BatchUpdateException: Batch entry 0 INSERT INTO gps_aggregated_results_with_gates (\"course_cd\",\"race_date\",\"race_number\",\"saddle_cloth_number\",\"gate_name\",\"avg_speed\",\"avg_acceleration\",\"max_speed\",\"min_speed\",\"fatigue_factor\",\"is_fastest_gate\",\"is_slowest_gate\",\"total_distance_run\",\"ground_loss\") VALUES (('AQU'),('2022-12-29 -06'::date),('5'::int4),('9  '),('0.5f'),('14.38'::double precision),('0.0'::double precision),('14.38'::double precision),('14.38'::double precision),('0.22623679822123396'::double precision),('0'::int4),('0'::int4),('1371.243112492651'::double precision),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(AQU, 2022-12-29, 5, 9  , 0.5f) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.ResultHandlerDelegate.handleError(ResultHandlerDelegate.java:52)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2421)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2153)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.flushIfDeadlockRisk(QueryExecutorImpl.java:1503)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.sendQuery(QueryExecutorImpl.java:1528)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:566)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:888)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1739)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:740)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:896)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:895)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1012)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1012)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2298)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\t... 1 more\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(AQU, 2022-12-29, 5, 9  , 0.5f) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2733)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2420)\n",
      "\t... 22 more\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Loading data from database for course: MTH\n",
      "INFO:root:None\n",
      "INFO:root:None\n",
      "INFO:root:None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing course: MTH\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- gate_name: string (nullable = true)\n",
      " |-- avg_speed: double (nullable = true)\n",
      " |-- avg_acceleration: double (nullable = true)\n",
      " |-- max_speed: double (nullable = true)\n",
      " |-- min_speed: double (nullable = true)\n",
      " |-- fatigue_factor: double (nullable = true)\n",
      " |-- is_fastest_gate: integer (nullable = true)\n",
      " |-- is_slowest_gate: integer (nullable = true)\n",
      "\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- gate_name: string (nullable = true)\n",
      " |-- avg_speed: double (nullable = true)\n",
      " |-- avg_acceleration: double (nullable = true)\n",
      " |-- max_speed: double (nullable = true)\n",
      " |-- min_speed: double (nullable = true)\n",
      " |-- fatigue_factor: double (nullable = true)\n",
      " |-- is_fastest_gate: integer (nullable = true)\n",
      " |-- is_slowest_gate: integer (nullable = true)\n",
      "\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- total_distance_run: double (nullable = true)\n",
      " |-- ground_loss: double (nullable = true)\n",
      "\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- total_distance_run: double (nullable = true)\n",
      " |-- ground_loss: double (nullable = true)\n",
      "\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- gate_name: string (nullable = true)\n",
      " |-- avg_speed: double (nullable = true)\n",
      " |-- avg_acceleration: double (nullable = true)\n",
      " |-- max_speed: double (nullable = true)\n",
      " |-- min_speed: double (nullable = true)\n",
      " |-- fatigue_factor: double (nullable = true)\n",
      " |-- is_fastest_gate: integer (nullable = true)\n",
      " |-- is_slowest_gate: integer (nullable = true)\n",
      " |-- total_distance_run: double (nullable = true)\n",
      " |-- ground_loss: double (nullable = true)\n",
      "\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- gate_name: string (nullable = true)\n",
      " |-- avg_speed: double (nullable = true)\n",
      " |-- avg_acceleration: double (nullable = true)\n",
      " |-- max_speed: double (nullable = true)\n",
      " |-- min_speed: double (nullable = true)\n",
      " |-- fatigue_factor: double (nullable = true)\n",
      " |-- is_fastest_gate: integer (nullable = true)\n",
      " |-- is_slowest_gate: integer (nullable = true)\n",
      " |-- total_distance_run: double (nullable = true)\n",
      " |-- ground_loss: double (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/05 22:21:08 ERROR Executor: Exception in task 47.0 in stage 300.0 (TID 1230)\n",
      "java.sql.BatchUpdateException: Batch entry 0 INSERT INTO gps_aggregated_results_with_gates (\"course_cd\",\"race_date\",\"race_number\",\"saddle_cloth_number\",\"gate_name\",\"avg_speed\",\"avg_acceleration\",\"max_speed\",\"min_speed\",\"fatigue_factor\",\"is_fastest_gate\",\"is_slowest_gate\",\"total_distance_run\",\"ground_loss\") VALUES (('MTH'),('2022-05-08 -05'::date),('2'::int4),('5  '),('0.5f'),('14.94'::double precision),('0.0'::double precision),('14.94'::double precision),('14.94'::double precision),('0.29896907216494845'::double precision),('0'::int4),('0'::int4),('1383.1085624488444'::double precision),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(MTH, 2022-05-08, 2, 5  , 0.5f) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.ResultHandlerDelegate.handleError(ResultHandlerDelegate.java:52)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2421)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2153)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.flushIfDeadlockRisk(QueryExecutorImpl.java:1503)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.sendQuery(QueryExecutorImpl.java:1528)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:566)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:888)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1739)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:740)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:896)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:895)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1012)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1012)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2298)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(MTH, 2022-05-08, 2, 5  , 0.5f) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2733)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2420)\n",
      "\t... 22 more\n",
      "24/12/05 22:21:08 ERROR Executor: Exception in task 20.0 in stage 300.0 (TID 1203)\n",
      "java.sql.BatchUpdateException: Batch entry 0 INSERT INTO gps_aggregated_results_with_gates (\"course_cd\",\"race_date\",\"race_number\",\"saddle_cloth_number\",\"gate_name\",\"avg_speed\",\"avg_acceleration\",\"max_speed\",\"min_speed\",\"fatigue_factor\",\"is_fastest_gate\",\"is_slowest_gate\",\"total_distance_run\",\"ground_loss\") VALUES (('MTH'),('2022-05-08 -05'::date),('5'::int4),('3  '),('0.5f'),('14.53'::double precision),('0.0'::double precision),('14.53'::double precision),('14.53'::double precision),('0.3442708333333333'::double precision),('0'::int4),('0'::int4),('1328.5506377786655'::double precision),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(MTH, 2022-05-08, 5, 3  , 0.5f) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.ResultHandlerDelegate.handleError(ResultHandlerDelegate.java:52)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2421)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2153)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.flushIfDeadlockRisk(QueryExecutorImpl.java:1503)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.sendQuery(QueryExecutorImpl.java:1528)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:566)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:888)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1739)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:740)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:896)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:895)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1012)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1012)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2298)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(MTH, 2022-05-08, 5, 3  , 0.5f) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2733)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2420)\n",
      "\t... 22 more\n",
      "24/12/05 22:21:08 ERROR Executor: Exception in task 30.0 in stage 300.0 (TID 1213)\n",
      "java.sql.BatchUpdateException: Batch entry 0 INSERT INTO gps_aggregated_results_with_gates (\"course_cd\",\"race_date\",\"race_number\",\"saddle_cloth_number\",\"gate_name\",\"avg_speed\",\"avg_acceleration\",\"max_speed\",\"min_speed\",\"fatigue_factor\",\"is_fastest_gate\",\"is_slowest_gate\",\"total_distance_run\",\"ground_loss\") VALUES (('MTH'),('2022-05-15 -05'::date),('8'::int4),('10 '),('0.5f'),('14.74'::double precision),('0.0'::double precision),('14.74'::double precision),('14.74'::double precision),('0.3474663908996898'::double precision),('0'::int4),('0'::int4),('1321.386996362937'::double precision),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(MTH, 2022-05-15, 8, 10 , 0.5f) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.ResultHandlerDelegate.handleError(ResultHandlerDelegate.java:52)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2421)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2153)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.flushIfDeadlockRisk(QueryExecutorImpl.java:1503)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.sendQuery(QueryExecutorImpl.java:1528)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:566)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:888)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1739)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:740)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:896)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:895)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1012)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1012)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2298)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(MTH, 2022-05-15, 8, 10 , 0.5f) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2733)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2420)\n",
      "\t... 22 more\n",
      "24/12/05 22:21:08 ERROR TaskSetManager: Task 30 in stage 300.0 failed 1 times; aborting job\n",
      "ERROR:root:Error processing course MTH: An error occurred while calling o7970.jdbc.\n",
      ": org.apache.spark.SparkException: Job aborted due to stage failure: Task 30 in stage 300.0 failed 1 times, most recent failure: Lost task 30.0 in stage 300.0 (TID 1213) (mail.relufox.ai executor driver): java.sql.BatchUpdateException: Batch entry 0 INSERT INTO gps_aggregated_results_with_gates (\"course_cd\",\"race_date\",\"race_number\",\"saddle_cloth_number\",\"gate_name\",\"avg_speed\",\"avg_acceleration\",\"max_speed\",\"min_speed\",\"fatigue_factor\",\"is_fastest_gate\",\"is_slowest_gate\",\"total_distance_run\",\"ground_loss\") VALUES (('MTH'),('2022-05-15 -05'::date),('8'::int4),('10 '),('0.5f'),('14.74'::double precision),('0.0'::double precision),('14.74'::double precision),('14.74'::double precision),('0.3474663908996898'::double precision),('0'::int4),('0'::int4),('1321.386996362937'::double precision),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(MTH, 2022-05-15, 8, 10 , 0.5f) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.ResultHandlerDelegate.handleError(ResultHandlerDelegate.java:52)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2421)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2153)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.flushIfDeadlockRisk(QueryExecutorImpl.java:1503)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.sendQuery(QueryExecutorImpl.java:1528)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:566)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:888)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1739)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:740)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:896)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:895)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1012)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1012)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2298)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(MTH, 2022-05-15, 8, 10 , 0.5f) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2733)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2420)\n",
      "\t... 22 more\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2790)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2726)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2725)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2725)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1211)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1211)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1211)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2989)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2928)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2917)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:976)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2258)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2279)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2298)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2323)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$1(RDD.scala:1012)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n",
      "\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:408)\n",
      "\tat org.apache.spark.rdd.RDD.foreachPartition(RDD.scala:1010)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.saveTable(JdbcUtils.scala:895)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:70)\n",
      "\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:47)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:118)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:195)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:827)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:65)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:94)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:512)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:104)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:512)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:31)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:31)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:31)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:488)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:94)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:81)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:79)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:133)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:856)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:387)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:360)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:247)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.jdbc(DataFrameWriter.scala:753)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor265.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: java.sql.BatchUpdateException: Batch entry 0 INSERT INTO gps_aggregated_results_with_gates (\"course_cd\",\"race_date\",\"race_number\",\"saddle_cloth_number\",\"gate_name\",\"avg_speed\",\"avg_acceleration\",\"max_speed\",\"min_speed\",\"fatigue_factor\",\"is_fastest_gate\",\"is_slowest_gate\",\"total_distance_run\",\"ground_loss\") VALUES (('MTH'),('2022-05-15 -05'::date),('8'::int4),('10 '),('0.5f'),('14.74'::double precision),('0.0'::double precision),('14.74'::double precision),('14.74'::double precision),('0.3474663908996898'::double precision),('0'::int4),('0'::int4),('1321.386996362937'::double precision),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(MTH, 2022-05-15, 8, 10 , 0.5f) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.ResultHandlerDelegate.handleError(ResultHandlerDelegate.java:52)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2421)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2153)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.flushIfDeadlockRisk(QueryExecutorImpl.java:1503)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.sendQuery(QueryExecutorImpl.java:1528)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:566)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:888)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1739)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:740)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:896)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:895)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1012)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1012)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2298)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\t... 1 more\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(MTH, 2022-05-15, 8, 10 , 0.5f) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2733)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2420)\n",
      "\t... 22 more\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Loading data from database for course: TGP\n",
      "INFO:root:None\n",
      "INFO:root:None\n",
      "INFO:root:None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing course: TGP\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- gate_name: string (nullable = true)\n",
      " |-- avg_speed: double (nullable = true)\n",
      " |-- avg_acceleration: double (nullable = true)\n",
      " |-- max_speed: double (nullable = true)\n",
      " |-- min_speed: double (nullable = true)\n",
      " |-- fatigue_factor: double (nullable = true)\n",
      " |-- is_fastest_gate: integer (nullable = true)\n",
      " |-- is_slowest_gate: integer (nullable = true)\n",
      "\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- gate_name: string (nullable = true)\n",
      " |-- avg_speed: double (nullable = true)\n",
      " |-- avg_acceleration: double (nullable = true)\n",
      " |-- max_speed: double (nullable = true)\n",
      " |-- min_speed: double (nullable = true)\n",
      " |-- fatigue_factor: double (nullable = true)\n",
      " |-- is_fastest_gate: integer (nullable = true)\n",
      " |-- is_slowest_gate: integer (nullable = true)\n",
      "\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- total_distance_run: double (nullable = true)\n",
      " |-- ground_loss: double (nullable = true)\n",
      "\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- total_distance_run: double (nullable = true)\n",
      " |-- ground_loss: double (nullable = true)\n",
      "\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- gate_name: string (nullable = true)\n",
      " |-- avg_speed: double (nullable = true)\n",
      " |-- avg_acceleration: double (nullable = true)\n",
      " |-- max_speed: double (nullable = true)\n",
      " |-- min_speed: double (nullable = true)\n",
      " |-- fatigue_factor: double (nullable = true)\n",
      " |-- is_fastest_gate: integer (nullable = true)\n",
      " |-- is_slowest_gate: integer (nullable = true)\n",
      " |-- total_distance_run: double (nullable = true)\n",
      " |-- ground_loss: double (nullable = true)\n",
      "\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- gate_name: string (nullable = true)\n",
      " |-- avg_speed: double (nullable = true)\n",
      " |-- avg_acceleration: double (nullable = true)\n",
      " |-- max_speed: double (nullable = true)\n",
      " |-- min_speed: double (nullable = true)\n",
      " |-- fatigue_factor: double (nullable = true)\n",
      " |-- is_fastest_gate: integer (nullable = true)\n",
      " |-- is_slowest_gate: integer (nullable = true)\n",
      " |-- total_distance_run: double (nullable = true)\n",
      " |-- ground_loss: double (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/05 22:21:14 ERROR Executor: Exception in task 44.0 in stage 315.0 (TID 1350)\n",
      "java.sql.BatchUpdateException: Batch entry 0 INSERT INTO gps_aggregated_results_with_gates (\"course_cd\",\"race_date\",\"race_number\",\"saddle_cloth_number\",\"gate_name\",\"avg_speed\",\"avg_acceleration\",\"max_speed\",\"min_speed\",\"fatigue_factor\",\"is_fastest_gate\",\"is_slowest_gate\",\"total_distance_run\",\"ground_loss\") VALUES (('TGP'),('2022-04-01 -05'::date),('1'::int4),('6  '),('0.32f'),('15.94'::double precision),('0.0'::double precision),('15.94'::double precision),('15.94'::double precision),('0.05599036724864538'::double precision),('0'::int4),('0'::int4),('1840.528624716823'::double precision),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(TGP, 2022-04-01, 1, 6  , 0.32f) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.ResultHandlerDelegate.handleError(ResultHandlerDelegate.java:52)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2421)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2153)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.flushIfDeadlockRisk(QueryExecutorImpl.java:1503)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.sendQuery(QueryExecutorImpl.java:1528)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:566)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:888)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1739)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:740)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:896)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:895)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1012)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1012)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2298)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(TGP, 2022-04-01, 1, 6  , 0.32f) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2733)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2420)\n",
      "\t... 22 more\n",
      "24/12/05 22:21:14 ERROR TaskSetManager: Task 44 in stage 315.0 failed 1 times; aborting job\n",
      "ERROR:root:Error processing course TGP: An error occurred while calling o8387.jdbc.\n",
      ": org.apache.spark.SparkException: Job aborted due to stage failure: Task 44 in stage 315.0 failed 1 times, most recent failure: Lost task 44.0 in stage 315.0 (TID 1350) (mail.relufox.ai executor driver): java.sql.BatchUpdateException: Batch entry 0 INSERT INTO gps_aggregated_results_with_gates (\"course_cd\",\"race_date\",\"race_number\",\"saddle_cloth_number\",\"gate_name\",\"avg_speed\",\"avg_acceleration\",\"max_speed\",\"min_speed\",\"fatigue_factor\",\"is_fastest_gate\",\"is_slowest_gate\",\"total_distance_run\",\"ground_loss\") VALUES (('TGP'),('2022-04-01 -05'::date),('1'::int4),('6  '),('0.32f'),('15.94'::double precision),('0.0'::double precision),('15.94'::double precision),('15.94'::double precision),('0.05599036724864538'::double precision),('0'::int4),('0'::int4),('1840.528624716823'::double precision),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(TGP, 2022-04-01, 1, 6  , 0.32f) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.ResultHandlerDelegate.handleError(ResultHandlerDelegate.java:52)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2421)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2153)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.flushIfDeadlockRisk(QueryExecutorImpl.java:1503)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.sendQuery(QueryExecutorImpl.java:1528)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:566)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:888)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1739)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:740)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:896)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:895)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1012)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1012)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2298)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(TGP, 2022-04-01, 1, 6  , 0.32f) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2733)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2420)\n",
      "\t... 22 more\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2790)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2726)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2725)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2725)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1211)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1211)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1211)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2989)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2928)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2917)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:976)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2258)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2279)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2298)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2323)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$1(RDD.scala:1012)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n",
      "\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:408)\n",
      "\tat org.apache.spark.rdd.RDD.foreachPartition(RDD.scala:1010)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.saveTable(JdbcUtils.scala:895)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:70)\n",
      "\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:47)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:118)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:195)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:827)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:65)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:94)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:512)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:104)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:512)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:31)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:31)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:31)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:488)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:94)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:81)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:79)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:133)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:856)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:387)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:360)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:247)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.jdbc(DataFrameWriter.scala:753)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor265.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: java.sql.BatchUpdateException: Batch entry 0 INSERT INTO gps_aggregated_results_with_gates (\"course_cd\",\"race_date\",\"race_number\",\"saddle_cloth_number\",\"gate_name\",\"avg_speed\",\"avg_acceleration\",\"max_speed\",\"min_speed\",\"fatigue_factor\",\"is_fastest_gate\",\"is_slowest_gate\",\"total_distance_run\",\"ground_loss\") VALUES (('TGP'),('2022-04-01 -05'::date),('1'::int4),('6  '),('0.32f'),('15.94'::double precision),('0.0'::double precision),('15.94'::double precision),('15.94'::double precision),('0.05599036724864538'::double precision),('0'::int4),('0'::int4),('1840.528624716823'::double precision),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(TGP, 2022-04-01, 1, 6  , 0.32f) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.ResultHandlerDelegate.handleError(ResultHandlerDelegate.java:52)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2421)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2153)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.flushIfDeadlockRisk(QueryExecutorImpl.java:1503)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.sendQuery(QueryExecutorImpl.java:1528)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:566)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:888)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1739)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:740)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:896)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:895)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1012)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1012)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2298)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\t... 1 more\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(TGP, 2022-04-01, 1, 6  , 0.32f) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2733)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2420)\n",
      "\t... 22 more\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Loading data from database for course: TGG\n",
      "INFO:root:None\n",
      "INFO:root:None\n",
      "INFO:root:None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing course: TGG\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- gate_name: string (nullable = true)\n",
      " |-- avg_speed: double (nullable = true)\n",
      " |-- avg_acceleration: double (nullable = true)\n",
      " |-- max_speed: double (nullable = true)\n",
      " |-- min_speed: double (nullable = true)\n",
      " |-- fatigue_factor: double (nullable = true)\n",
      " |-- is_fastest_gate: integer (nullable = true)\n",
      " |-- is_slowest_gate: integer (nullable = true)\n",
      "\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- gate_name: string (nullable = true)\n",
      " |-- avg_speed: double (nullable = true)\n",
      " |-- avg_acceleration: double (nullable = true)\n",
      " |-- max_speed: double (nullable = true)\n",
      " |-- min_speed: double (nullable = true)\n",
      " |-- fatigue_factor: double (nullable = true)\n",
      " |-- is_fastest_gate: integer (nullable = true)\n",
      " |-- is_slowest_gate: integer (nullable = true)\n",
      "\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- total_distance_run: double (nullable = true)\n",
      " |-- ground_loss: double (nullable = true)\n",
      "\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- total_distance_run: double (nullable = true)\n",
      " |-- ground_loss: double (nullable = true)\n",
      "\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- gate_name: string (nullable = true)\n",
      " |-- avg_speed: double (nullable = true)\n",
      " |-- avg_acceleration: double (nullable = true)\n",
      " |-- max_speed: double (nullable = true)\n",
      " |-- min_speed: double (nullable = true)\n",
      " |-- fatigue_factor: double (nullable = true)\n",
      " |-- is_fastest_gate: integer (nullable = true)\n",
      " |-- is_slowest_gate: integer (nullable = true)\n",
      " |-- total_distance_run: double (nullable = true)\n",
      " |-- ground_loss: double (nullable = true)\n",
      "\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- gate_name: string (nullable = true)\n",
      " |-- avg_speed: double (nullable = true)\n",
      " |-- avg_acceleration: double (nullable = true)\n",
      " |-- max_speed: double (nullable = true)\n",
      " |-- min_speed: double (nullable = true)\n",
      " |-- fatigue_factor: double (nullable = true)\n",
      " |-- is_fastest_gate: integer (nullable = true)\n",
      " |-- is_slowest_gate: integer (nullable = true)\n",
      " |-- total_distance_run: double (nullable = true)\n",
      " |-- ground_loss: double (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/05 22:21:17 ERROR Executor: Exception in task 41.0 in stage 330.0 (TID 1493)\n",
      "java.sql.BatchUpdateException: Batch entry 0 INSERT INTO gps_aggregated_results_with_gates (\"course_cd\",\"race_date\",\"race_number\",\"saddle_cloth_number\",\"gate_name\",\"avg_speed\",\"avg_acceleration\",\"max_speed\",\"min_speed\",\"fatigue_factor\",\"is_fastest_gate\",\"is_slowest_gate\",\"total_distance_run\",\"ground_loss\") VALUES (('TGG'),('2022-01-08 -06'::date),('6'::int4),('2  '),('0.5f'),('15.06'::double precision),('0.0'::double precision),('15.06'::double precision),('15.06'::double precision),('0.2829190904283448'::double precision),('0'::int4),('0'::int4),('1343.1517549390358'::double precision),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(TGG, 2022-01-08, 6, 2  , 0.5f) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.ResultHandlerDelegate.handleError(ResultHandlerDelegate.java:52)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2421)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2153)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.flushIfDeadlockRisk(QueryExecutorImpl.java:1503)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.sendQuery(QueryExecutorImpl.java:1528)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:566)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:888)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1739)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:740)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:896)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:895)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1012)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1012)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2298)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(TGG, 2022-01-08, 6, 2  , 0.5f) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2733)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2420)\n",
      "\t... 22 more\n",
      "24/12/05 22:21:17 ERROR TaskSetManager: Task 41 in stage 330.0 failed 1 times; aborting job\n",
      "ERROR:root:Error processing course TGG: An error occurred while calling o8804.jdbc.\n",
      ": org.apache.spark.SparkException: Job aborted due to stage failure: Task 41 in stage 330.0 failed 1 times, most recent failure: Lost task 41.0 in stage 330.0 (TID 1493) (mail.relufox.ai executor driver): java.sql.BatchUpdateException: Batch entry 0 INSERT INTO gps_aggregated_results_with_gates (\"course_cd\",\"race_date\",\"race_number\",\"saddle_cloth_number\",\"gate_name\",\"avg_speed\",\"avg_acceleration\",\"max_speed\",\"min_speed\",\"fatigue_factor\",\"is_fastest_gate\",\"is_slowest_gate\",\"total_distance_run\",\"ground_loss\") VALUES (('TGG'),('2022-01-08 -06'::date),('6'::int4),('2  '),('0.5f'),('15.06'::double precision),('0.0'::double precision),('15.06'::double precision),('15.06'::double precision),('0.2829190904283448'::double precision),('0'::int4),('0'::int4),('1343.1517549390358'::double precision),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(TGG, 2022-01-08, 6, 2  , 0.5f) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.ResultHandlerDelegate.handleError(ResultHandlerDelegate.java:52)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2421)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2153)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.flushIfDeadlockRisk(QueryExecutorImpl.java:1503)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.sendQuery(QueryExecutorImpl.java:1528)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:566)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:888)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1739)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:740)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:896)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:895)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1012)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1012)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2298)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(TGG, 2022-01-08, 6, 2  , 0.5f) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2733)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2420)\n",
      "\t... 22 more\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2790)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2726)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2725)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2725)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1211)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1211)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1211)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2989)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2928)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2917)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:976)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2258)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2279)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2298)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2323)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$1(RDD.scala:1012)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n",
      "\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:408)\n",
      "\tat org.apache.spark.rdd.RDD.foreachPartition(RDD.scala:1010)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.saveTable(JdbcUtils.scala:895)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:70)\n",
      "\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:47)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:118)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:195)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:827)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:65)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:94)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:512)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:104)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:512)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:31)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:31)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:31)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:488)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:94)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:81)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:79)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:133)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:856)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:387)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:360)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:247)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.jdbc(DataFrameWriter.scala:753)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor265.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: java.sql.BatchUpdateException: Batch entry 0 INSERT INTO gps_aggregated_results_with_gates (\"course_cd\",\"race_date\",\"race_number\",\"saddle_cloth_number\",\"gate_name\",\"avg_speed\",\"avg_acceleration\",\"max_speed\",\"min_speed\",\"fatigue_factor\",\"is_fastest_gate\",\"is_slowest_gate\",\"total_distance_run\",\"ground_loss\") VALUES (('TGG'),('2022-01-08 -06'::date),('6'::int4),('2  '),('0.5f'),('15.06'::double precision),('0.0'::double precision),('15.06'::double precision),('15.06'::double precision),('0.2829190904283448'::double precision),('0'::int4),('0'::int4),('1343.1517549390358'::double precision),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(TGG, 2022-01-08, 6, 2  , 0.5f) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.ResultHandlerDelegate.handleError(ResultHandlerDelegate.java:52)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2421)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2153)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.flushIfDeadlockRisk(QueryExecutorImpl.java:1503)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.sendQuery(QueryExecutorImpl.java:1528)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:566)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:888)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1739)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:740)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:896)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:895)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1012)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1012)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2298)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\t... 1 more\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(TGG, 2022-01-08, 6, 2  , 0.5f) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2733)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2420)\n",
      "\t... 22 more\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Loading data from database for course: CBY\n",
      "INFO:root:None\n",
      "INFO:root:None\n",
      "INFO:root:None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing course: CBY\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- gate_name: string (nullable = true)\n",
      " |-- avg_speed: double (nullable = true)\n",
      " |-- avg_acceleration: double (nullable = true)\n",
      " |-- max_speed: double (nullable = true)\n",
      " |-- min_speed: double (nullable = true)\n",
      " |-- fatigue_factor: double (nullable = true)\n",
      " |-- is_fastest_gate: integer (nullable = true)\n",
      " |-- is_slowest_gate: integer (nullable = true)\n",
      "\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- gate_name: string (nullable = true)\n",
      " |-- avg_speed: double (nullable = true)\n",
      " |-- avg_acceleration: double (nullable = true)\n",
      " |-- max_speed: double (nullable = true)\n",
      " |-- min_speed: double (nullable = true)\n",
      " |-- fatigue_factor: double (nullable = true)\n",
      " |-- is_fastest_gate: integer (nullable = true)\n",
      " |-- is_slowest_gate: integer (nullable = true)\n",
      "\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- total_distance_run: double (nullable = true)\n",
      " |-- ground_loss: double (nullable = true)\n",
      "\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- total_distance_run: double (nullable = true)\n",
      " |-- ground_loss: double (nullable = true)\n",
      "\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- gate_name: string (nullable = true)\n",
      " |-- avg_speed: double (nullable = true)\n",
      " |-- avg_acceleration: double (nullable = true)\n",
      " |-- max_speed: double (nullable = true)\n",
      " |-- min_speed: double (nullable = true)\n",
      " |-- fatigue_factor: double (nullable = true)\n",
      " |-- is_fastest_gate: integer (nullable = true)\n",
      " |-- is_slowest_gate: integer (nullable = true)\n",
      " |-- total_distance_run: double (nullable = true)\n",
      " |-- ground_loss: double (nullable = true)\n",
      "\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- gate_name: string (nullable = true)\n",
      " |-- avg_speed: double (nullable = true)\n",
      " |-- avg_acceleration: double (nullable = true)\n",
      " |-- max_speed: double (nullable = true)\n",
      " |-- min_speed: double (nullable = true)\n",
      " |-- fatigue_factor: double (nullable = true)\n",
      " |-- is_fastest_gate: integer (nullable = true)\n",
      " |-- is_slowest_gate: integer (nullable = true)\n",
      " |-- total_distance_run: double (nullable = true)\n",
      " |-- ground_loss: double (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/05 22:21:19 ERROR Executor: Exception in task 0.0 in stage 345.0 (TID 1546)\n",
      "java.sql.BatchUpdateException: Batch entry 0 INSERT INTO gps_aggregated_results_with_gates (\"course_cd\",\"race_date\",\"race_number\",\"saddle_cloth_number\",\"gate_name\",\"avg_speed\",\"avg_acceleration\",\"max_speed\",\"min_speed\",\"fatigue_factor\",\"is_fastest_gate\",\"is_slowest_gate\",\"total_distance_run\",\"ground_loss\") VALUES (('CBY'),('2022-05-18 -05'::date),('6'::int4),('1  '),('0.5f'),('0.11'::double precision),('0.0'::double precision),('0.11'::double precision),('0.11'::double precision),('0.0'::double precision),('1'::int4),('1'::int4),('1162.252082678121'::double precision),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(CBY, 2022-05-18, 6, 1  , 0.5f) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.ResultHandlerDelegate.handleError(ResultHandlerDelegate.java:52)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2421)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2153)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.flushIfDeadlockRisk(QueryExecutorImpl.java:1503)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.sendQuery(QueryExecutorImpl.java:1528)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:566)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:888)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1739)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:740)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:896)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:895)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1012)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1012)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2298)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(CBY, 2022-05-18, 6, 1  , 0.5f) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2733)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2420)\n",
      "\t... 22 more\n",
      "24/12/05 22:21:19 ERROR Executor: Exception in task 17.0 in stage 345.0 (TID 1563)\n",
      "java.sql.BatchUpdateException: Batch entry 0 INSERT INTO gps_aggregated_results_with_gates (\"course_cd\",\"race_date\",\"race_number\",\"saddle_cloth_number\",\"gate_name\",\"avg_speed\",\"avg_acceleration\",\"max_speed\",\"min_speed\",\"fatigue_factor\",\"is_fastest_gate\",\"is_slowest_gate\",\"total_distance_run\",\"ground_loss\") VALUES (('CBY'),('2022-05-18 -05'::date),('4'::int4),('7  '),('0.5f'),('1.98'::double precision),('0.0'::double precision),('1.98'::double precision),('1.98'::double precision),('0.0'::double precision),('1'::int4),('1'::int4),('1635.8240465624613'::double precision),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(CBY, 2022-05-18, 4, 7  , 0.5f) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.ResultHandlerDelegate.handleError(ResultHandlerDelegate.java:52)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2421)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2153)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.flushIfDeadlockRisk(QueryExecutorImpl.java:1503)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.sendQuery(QueryExecutorImpl.java:1528)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:566)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:888)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1739)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:740)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:896)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:895)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1012)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1012)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2298)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(CBY, 2022-05-18, 4, 7  , 0.5f) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2733)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2420)\n",
      "\t... 22 more\n",
      "24/12/05 22:21:19 ERROR Executor: Exception in task 12.0 in stage 345.0 (TID 1558)\n",
      "java.sql.BatchUpdateException: Batch entry 0 INSERT INTO gps_aggregated_results_with_gates (\"course_cd\",\"race_date\",\"race_number\",\"saddle_cloth_number\",\"gate_name\",\"avg_speed\",\"avg_acceleration\",\"max_speed\",\"min_speed\",\"fatigue_factor\",\"is_fastest_gate\",\"is_slowest_gate\",\"total_distance_run\",\"ground_loss\") VALUES (('CBY'),('2022-05-19 -05'::date),('8'::int4),('1  '),('0.5f'),('13.16'::double precision),('0.0'::double precision),('13.16'::double precision),('13.16'::double precision),('0.40427751695357333'::double precision),('0'::int4),('0'::int4),('1211.0920433819297'::double precision),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(CBY, 2022-05-19, 8, 1  , 0.5f) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.ResultHandlerDelegate.handleError(ResultHandlerDelegate.java:52)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2421)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2153)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.flushIfDeadlockRisk(QueryExecutorImpl.java:1503)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.sendQuery(QueryExecutorImpl.java:1528)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:566)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:888)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1739)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:740)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:896)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:895)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1012)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1012)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2298)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(CBY, 2022-05-19, 8, 1  , 0.5f) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2733)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2420)\n",
      "\t... 22 more\n",
      "24/12/05 22:21:19 ERROR TaskSetManager: Task 0 in stage 345.0 failed 1 times; aborting job\n",
      "ERROR:root:Error processing course CBY: An error occurred while calling o9221.jdbc.\n",
      ": org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 345.0 failed 1 times, most recent failure: Lost task 0.0 in stage 345.0 (TID 1546) (mail.relufox.ai executor driver): java.sql.BatchUpdateException: Batch entry 0 INSERT INTO gps_aggregated_results_with_gates (\"course_cd\",\"race_date\",\"race_number\",\"saddle_cloth_number\",\"gate_name\",\"avg_speed\",\"avg_acceleration\",\"max_speed\",\"min_speed\",\"fatigue_factor\",\"is_fastest_gate\",\"is_slowest_gate\",\"total_distance_run\",\"ground_loss\") VALUES (('CBY'),('2022-05-18 -05'::date),('6'::int4),('1  '),('0.5f'),('0.11'::double precision),('0.0'::double precision),('0.11'::double precision),('0.11'::double precision),('0.0'::double precision),('1'::int4),('1'::int4),('1162.252082678121'::double precision),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(CBY, 2022-05-18, 6, 1  , 0.5f) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.ResultHandlerDelegate.handleError(ResultHandlerDelegate.java:52)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2421)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2153)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.flushIfDeadlockRisk(QueryExecutorImpl.java:1503)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.sendQuery(QueryExecutorImpl.java:1528)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:566)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:888)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1739)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:740)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:896)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:895)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1012)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1012)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2298)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(CBY, 2022-05-18, 6, 1  , 0.5f) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2733)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2420)\n",
      "\t... 22 more\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2790)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2726)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2725)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2725)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1211)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1211)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1211)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2989)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2928)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2917)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:976)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2258)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2279)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2298)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2323)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$1(RDD.scala:1012)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n",
      "\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:408)\n",
      "\tat org.apache.spark.rdd.RDD.foreachPartition(RDD.scala:1010)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.saveTable(JdbcUtils.scala:895)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:70)\n",
      "\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:47)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:118)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:195)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:827)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:65)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:94)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:512)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:104)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:512)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:31)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:31)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:31)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:488)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:94)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:81)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:79)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:133)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:856)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:387)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:360)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:247)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.jdbc(DataFrameWriter.scala:753)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor265.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: java.sql.BatchUpdateException: Batch entry 0 INSERT INTO gps_aggregated_results_with_gates (\"course_cd\",\"race_date\",\"race_number\",\"saddle_cloth_number\",\"gate_name\",\"avg_speed\",\"avg_acceleration\",\"max_speed\",\"min_speed\",\"fatigue_factor\",\"is_fastest_gate\",\"is_slowest_gate\",\"total_distance_run\",\"ground_loss\") VALUES (('CBY'),('2022-05-18 -05'::date),('6'::int4),('1  '),('0.5f'),('0.11'::double precision),('0.0'::double precision),('0.11'::double precision),('0.11'::double precision),('0.0'::double precision),('1'::int4),('1'::int4),('1162.252082678121'::double precision),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(CBY, 2022-05-18, 6, 1  , 0.5f) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.ResultHandlerDelegate.handleError(ResultHandlerDelegate.java:52)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2421)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2153)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.flushIfDeadlockRisk(QueryExecutorImpl.java:1503)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.sendQuery(QueryExecutorImpl.java:1528)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:566)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:888)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1739)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:740)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:896)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:895)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1012)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1012)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2298)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\t... 1 more\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(CBY, 2022-05-18, 6, 1  , 0.5f) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2733)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2420)\n",
      "\t... 22 more\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Loading data from database for course: LRL\n",
      "INFO:root:None\n",
      "INFO:root:None\n",
      "INFO:root:None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing course: LRL\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- gate_name: string (nullable = true)\n",
      " |-- avg_speed: double (nullable = true)\n",
      " |-- avg_acceleration: double (nullable = true)\n",
      " |-- max_speed: double (nullable = true)\n",
      " |-- min_speed: double (nullable = true)\n",
      " |-- fatigue_factor: double (nullable = true)\n",
      " |-- is_fastest_gate: integer (nullable = true)\n",
      " |-- is_slowest_gate: integer (nullable = true)\n",
      "\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- gate_name: string (nullable = true)\n",
      " |-- avg_speed: double (nullable = true)\n",
      " |-- avg_acceleration: double (nullable = true)\n",
      " |-- max_speed: double (nullable = true)\n",
      " |-- min_speed: double (nullable = true)\n",
      " |-- fatigue_factor: double (nullable = true)\n",
      " |-- is_fastest_gate: integer (nullable = true)\n",
      " |-- is_slowest_gate: integer (nullable = true)\n",
      "\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- total_distance_run: double (nullable = true)\n",
      " |-- ground_loss: double (nullable = true)\n",
      "\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- total_distance_run: double (nullable = true)\n",
      " |-- ground_loss: double (nullable = true)\n",
      "\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- gate_name: string (nullable = true)\n",
      " |-- avg_speed: double (nullable = true)\n",
      " |-- avg_acceleration: double (nullable = true)\n",
      " |-- max_speed: double (nullable = true)\n",
      " |-- min_speed: double (nullable = true)\n",
      " |-- fatigue_factor: double (nullable = true)\n",
      " |-- is_fastest_gate: integer (nullable = true)\n",
      " |-- is_slowest_gate: integer (nullable = true)\n",
      " |-- total_distance_run: double (nullable = true)\n",
      " |-- ground_loss: double (nullable = true)\n",
      "\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- gate_name: string (nullable = true)\n",
      " |-- avg_speed: double (nullable = true)\n",
      " |-- avg_acceleration: double (nullable = true)\n",
      " |-- max_speed: double (nullable = true)\n",
      " |-- min_speed: double (nullable = true)\n",
      " |-- fatigue_factor: double (nullable = true)\n",
      " |-- is_fastest_gate: integer (nullable = true)\n",
      " |-- is_slowest_gate: integer (nullable = true)\n",
      " |-- total_distance_run: double (nullable = true)\n",
      " |-- ground_loss: double (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/05 22:21:24 ERROR Executor: Exception in task 37.0 in stage 360.0 (TID 1689)\n",
      "java.sql.BatchUpdateException: Batch entry 0 INSERT INTO gps_aggregated_results_with_gates (\"course_cd\",\"race_date\",\"race_number\",\"saddle_cloth_number\",\"gate_name\",\"avg_speed\",\"avg_acceleration\",\"max_speed\",\"min_speed\",\"fatigue_factor\",\"is_fastest_gate\",\"is_slowest_gate\",\"total_distance_run\",\"ground_loss\") VALUES (('LRL'),('2022-01-01 -06'::date),('4'::int4),('6  '),('0.5F'),('15.25'::double precision),('0.0'::double precision),('15.25'::double precision),('15.25'::double precision),('0.33438155136268344'::double precision),('0'::int4),('0'::int4),('1343.5662009368332'::double precision),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(LRL, 2022-01-01, 4, 6  , 0.5F) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.ResultHandlerDelegate.handleError(ResultHandlerDelegate.java:52)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2421)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2153)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.flushIfDeadlockRisk(QueryExecutorImpl.java:1503)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.sendQuery(QueryExecutorImpl.java:1528)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:566)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:888)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1739)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:740)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:896)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:895)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1012)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1012)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2298)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(LRL, 2022-01-01, 4, 6  , 0.5F) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2733)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2420)\n",
      "\t... 22 more\n",
      "24/12/05 22:21:24 ERROR TaskSetManager: Task 37 in stage 360.0 failed 1 times; aborting job\n",
      "ERROR:root:Error processing course LRL: An error occurred while calling o9638.jdbc.\n",
      ": org.apache.spark.SparkException: Job aborted due to stage failure: Task 37 in stage 360.0 failed 1 times, most recent failure: Lost task 37.0 in stage 360.0 (TID 1689) (mail.relufox.ai executor driver): java.sql.BatchUpdateException: Batch entry 0 INSERT INTO gps_aggregated_results_with_gates (\"course_cd\",\"race_date\",\"race_number\",\"saddle_cloth_number\",\"gate_name\",\"avg_speed\",\"avg_acceleration\",\"max_speed\",\"min_speed\",\"fatigue_factor\",\"is_fastest_gate\",\"is_slowest_gate\",\"total_distance_run\",\"ground_loss\") VALUES (('LRL'),('2022-01-01 -06'::date),('4'::int4),('6  '),('0.5F'),('15.25'::double precision),('0.0'::double precision),('15.25'::double precision),('15.25'::double precision),('0.33438155136268344'::double precision),('0'::int4),('0'::int4),('1343.5662009368332'::double precision),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(LRL, 2022-01-01, 4, 6  , 0.5F) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.ResultHandlerDelegate.handleError(ResultHandlerDelegate.java:52)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2421)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2153)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.flushIfDeadlockRisk(QueryExecutorImpl.java:1503)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.sendQuery(QueryExecutorImpl.java:1528)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:566)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:888)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1739)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:740)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:896)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:895)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1012)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1012)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2298)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(LRL, 2022-01-01, 4, 6  , 0.5F) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2733)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2420)\n",
      "\t... 22 more\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2790)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2726)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2725)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2725)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1211)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1211)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1211)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2989)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2928)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2917)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:976)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2258)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2279)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2298)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2323)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$1(RDD.scala:1012)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n",
      "\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:408)\n",
      "\tat org.apache.spark.rdd.RDD.foreachPartition(RDD.scala:1010)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.saveTable(JdbcUtils.scala:895)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:70)\n",
      "\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:47)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:118)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:195)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:827)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:65)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:94)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:512)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:104)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:512)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:31)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:31)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:31)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:488)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:94)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:81)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:79)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:133)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:856)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:387)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:360)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:247)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.jdbc(DataFrameWriter.scala:753)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor265.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: java.sql.BatchUpdateException: Batch entry 0 INSERT INTO gps_aggregated_results_with_gates (\"course_cd\",\"race_date\",\"race_number\",\"saddle_cloth_number\",\"gate_name\",\"avg_speed\",\"avg_acceleration\",\"max_speed\",\"min_speed\",\"fatigue_factor\",\"is_fastest_gate\",\"is_slowest_gate\",\"total_distance_run\",\"ground_loss\") VALUES (('LRL'),('2022-01-01 -06'::date),('4'::int4),('6  '),('0.5F'),('15.25'::double precision),('0.0'::double precision),('15.25'::double precision),('15.25'::double precision),('0.33438155136268344'::double precision),('0'::int4),('0'::int4),('1343.5662009368332'::double precision),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(LRL, 2022-01-01, 4, 6  , 0.5F) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.ResultHandlerDelegate.handleError(ResultHandlerDelegate.java:52)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2421)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2153)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.flushIfDeadlockRisk(QueryExecutorImpl.java:1503)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.sendQuery(QueryExecutorImpl.java:1528)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:566)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:888)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1739)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:740)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:896)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:895)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1012)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1012)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2298)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\t... 1 more\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(LRL, 2022-01-01, 4, 6  , 0.5F) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2733)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2420)\n",
      "\t... 22 more\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Loading data from database for course: TED\n",
      "INFO:root:None\n",
      "INFO:root:None\n",
      "INFO:root:None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing course: TED\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- gate_name: string (nullable = true)\n",
      " |-- avg_speed: double (nullable = true)\n",
      " |-- avg_acceleration: double (nullable = true)\n",
      " |-- max_speed: double (nullable = true)\n",
      " |-- min_speed: double (nullable = true)\n",
      " |-- fatigue_factor: double (nullable = true)\n",
      " |-- is_fastest_gate: integer (nullable = true)\n",
      " |-- is_slowest_gate: integer (nullable = true)\n",
      "\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- gate_name: string (nullable = true)\n",
      " |-- avg_speed: double (nullable = true)\n",
      " |-- avg_acceleration: double (nullable = true)\n",
      " |-- max_speed: double (nullable = true)\n",
      " |-- min_speed: double (nullable = true)\n",
      " |-- fatigue_factor: double (nullable = true)\n",
      " |-- is_fastest_gate: integer (nullable = true)\n",
      " |-- is_slowest_gate: integer (nullable = true)\n",
      "\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- total_distance_run: double (nullable = true)\n",
      " |-- ground_loss: double (nullable = true)\n",
      "\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- total_distance_run: double (nullable = true)\n",
      " |-- ground_loss: double (nullable = true)\n",
      "\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- gate_name: string (nullable = true)\n",
      " |-- avg_speed: double (nullable = true)\n",
      " |-- avg_acceleration: double (nullable = true)\n",
      " |-- max_speed: double (nullable = true)\n",
      " |-- min_speed: double (nullable = true)\n",
      " |-- fatigue_factor: double (nullable = true)\n",
      " |-- is_fastest_gate: integer (nullable = true)\n",
      " |-- is_slowest_gate: integer (nullable = true)\n",
      " |-- total_distance_run: double (nullable = true)\n",
      " |-- ground_loss: double (nullable = true)\n",
      "\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- gate_name: string (nullable = true)\n",
      " |-- avg_speed: double (nullable = true)\n",
      " |-- avg_acceleration: double (nullable = true)\n",
      " |-- max_speed: double (nullable = true)\n",
      " |-- min_speed: double (nullable = true)\n",
      " |-- fatigue_factor: double (nullable = true)\n",
      " |-- is_fastest_gate: integer (nullable = true)\n",
      " |-- is_slowest_gate: integer (nullable = true)\n",
      " |-- total_distance_run: double (nullable = true)\n",
      " |-- ground_loss: double (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/05 22:21:25 ERROR Executor: Exception in task 4.0 in stage 375.0 (TID 1770)\n",
      "java.sql.BatchUpdateException: Batch entry 0 INSERT INTO gps_aggregated_results_with_gates (\"course_cd\",\"race_date\",\"race_number\",\"saddle_cloth_number\",\"gate_name\",\"avg_speed\",\"avg_acceleration\",\"max_speed\",\"min_speed\",\"fatigue_factor\",\"is_fastest_gate\",\"is_slowest_gate\",\"total_distance_run\",\"ground_loss\") VALUES (('TED'),('2024-05-04 -05'::date),('2'::int4),('2  '),('0.5f'),('16.34'::double precision),('0.0'::double precision),('16.34'::double precision),('16.34'::double precision),('0.18373983739837393'::double precision),('0'::int4),('0'::int4),('1158.3294908074358'::double precision),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(TED, 2024-05-04, 2, 2  , 0.5f) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.ResultHandlerDelegate.handleError(ResultHandlerDelegate.java:52)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2421)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2153)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.flushIfDeadlockRisk(QueryExecutorImpl.java:1503)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.sendQuery(QueryExecutorImpl.java:1528)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:566)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:888)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1739)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:740)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:896)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:895)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1012)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1012)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2298)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(TED, 2024-05-04, 2, 2  , 0.5f) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2733)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2420)\n",
      "\t... 22 more\n",
      "24/12/05 22:21:25 ERROR TaskSetManager: Task 4 in stage 375.0 failed 1 times; aborting job\n",
      "ERROR:root:Error processing course TED: An error occurred while calling o10055.jdbc.\n",
      ": org.apache.spark.SparkException: Job aborted due to stage failure: Task 4 in stage 375.0 failed 1 times, most recent failure: Lost task 4.0 in stage 375.0 (TID 1770) (mail.relufox.ai executor driver): java.sql.BatchUpdateException: Batch entry 0 INSERT INTO gps_aggregated_results_with_gates (\"course_cd\",\"race_date\",\"race_number\",\"saddle_cloth_number\",\"gate_name\",\"avg_speed\",\"avg_acceleration\",\"max_speed\",\"min_speed\",\"fatigue_factor\",\"is_fastest_gate\",\"is_slowest_gate\",\"total_distance_run\",\"ground_loss\") VALUES (('TED'),('2024-05-04 -05'::date),('2'::int4),('2  '),('0.5f'),('16.34'::double precision),('0.0'::double precision),('16.34'::double precision),('16.34'::double precision),('0.18373983739837393'::double precision),('0'::int4),('0'::int4),('1158.3294908074358'::double precision),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(TED, 2024-05-04, 2, 2  , 0.5f) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.ResultHandlerDelegate.handleError(ResultHandlerDelegate.java:52)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2421)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2153)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.flushIfDeadlockRisk(QueryExecutorImpl.java:1503)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.sendQuery(QueryExecutorImpl.java:1528)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:566)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:888)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1739)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:740)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:896)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:895)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1012)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1012)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2298)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(TED, 2024-05-04, 2, 2  , 0.5f) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2733)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2420)\n",
      "\t... 22 more\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2790)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2726)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2725)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2725)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1211)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1211)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1211)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2989)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2928)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2917)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:976)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2258)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2279)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2298)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2323)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$1(RDD.scala:1012)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n",
      "\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:408)\n",
      "\tat org.apache.spark.rdd.RDD.foreachPartition(RDD.scala:1010)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.saveTable(JdbcUtils.scala:895)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:70)\n",
      "\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:47)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:118)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:195)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:827)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:65)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:94)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:512)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:104)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:512)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:31)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:31)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:31)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:488)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:94)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:81)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:79)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:133)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:856)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:387)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:360)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:247)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.jdbc(DataFrameWriter.scala:753)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor265.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: java.sql.BatchUpdateException: Batch entry 0 INSERT INTO gps_aggregated_results_with_gates (\"course_cd\",\"race_date\",\"race_number\",\"saddle_cloth_number\",\"gate_name\",\"avg_speed\",\"avg_acceleration\",\"max_speed\",\"min_speed\",\"fatigue_factor\",\"is_fastest_gate\",\"is_slowest_gate\",\"total_distance_run\",\"ground_loss\") VALUES (('TED'),('2024-05-04 -05'::date),('2'::int4),('2  '),('0.5f'),('16.34'::double precision),('0.0'::double precision),('16.34'::double precision),('16.34'::double precision),('0.18373983739837393'::double precision),('0'::int4),('0'::int4),('1158.3294908074358'::double precision),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(TED, 2024-05-04, 2, 2  , 0.5f) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.ResultHandlerDelegate.handleError(ResultHandlerDelegate.java:52)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2421)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2153)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.flushIfDeadlockRisk(QueryExecutorImpl.java:1503)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.sendQuery(QueryExecutorImpl.java:1528)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:566)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:888)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1739)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:740)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:896)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:895)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1012)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1012)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2298)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\t... 1 more\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(TED, 2024-05-04, 2, 2  , 0.5f) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2733)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2420)\n",
      "\t... 22 more\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Loading data from database for course: IND\n",
      "INFO:root:None\n",
      "INFO:root:None\n",
      "INFO:root:None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing course: IND\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- gate_name: string (nullable = true)\n",
      " |-- avg_speed: double (nullable = true)\n",
      " |-- avg_acceleration: double (nullable = true)\n",
      " |-- max_speed: double (nullable = true)\n",
      " |-- min_speed: double (nullable = true)\n",
      " |-- fatigue_factor: double (nullable = true)\n",
      " |-- is_fastest_gate: integer (nullable = true)\n",
      " |-- is_slowest_gate: integer (nullable = true)\n",
      "\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- gate_name: string (nullable = true)\n",
      " |-- avg_speed: double (nullable = true)\n",
      " |-- avg_acceleration: double (nullable = true)\n",
      " |-- max_speed: double (nullable = true)\n",
      " |-- min_speed: double (nullable = true)\n",
      " |-- fatigue_factor: double (nullable = true)\n",
      " |-- is_fastest_gate: integer (nullable = true)\n",
      " |-- is_slowest_gate: integer (nullable = true)\n",
      "\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- total_distance_run: double (nullable = true)\n",
      " |-- ground_loss: double (nullable = true)\n",
      "\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- total_distance_run: double (nullable = true)\n",
      " |-- ground_loss: double (nullable = true)\n",
      "\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- gate_name: string (nullable = true)\n",
      " |-- avg_speed: double (nullable = true)\n",
      " |-- avg_acceleration: double (nullable = true)\n",
      " |-- max_speed: double (nullable = true)\n",
      " |-- min_speed: double (nullable = true)\n",
      " |-- fatigue_factor: double (nullable = true)\n",
      " |-- is_fastest_gate: integer (nullable = true)\n",
      " |-- is_slowest_gate: integer (nullable = true)\n",
      " |-- total_distance_run: double (nullable = true)\n",
      " |-- ground_loss: double (nullable = true)\n",
      "\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- gate_name: string (nullable = true)\n",
      " |-- avg_speed: double (nullable = true)\n",
      " |-- avg_acceleration: double (nullable = true)\n",
      " |-- max_speed: double (nullable = true)\n",
      " |-- min_speed: double (nullable = true)\n",
      " |-- fatigue_factor: double (nullable = true)\n",
      " |-- is_fastest_gate: integer (nullable = true)\n",
      " |-- is_slowest_gate: integer (nullable = true)\n",
      " |-- total_distance_run: double (nullable = true)\n",
      " |-- ground_loss: double (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/05 22:21:29 ERROR Executor: Exception in task 11.0 in stage 390.0 (TID 1848)\n",
      "java.sql.BatchUpdateException: Batch entry 0 INSERT INTO gps_aggregated_results_with_gates (\"course_cd\",\"race_date\",\"race_number\",\"saddle_cloth_number\",\"gate_name\",\"avg_speed\",\"avg_acceleration\",\"max_speed\",\"min_speed\",\"fatigue_factor\",\"is_fastest_gate\",\"is_slowest_gate\",\"total_distance_run\",\"ground_loss\") VALUES (('IND'),('2022-04-19 -05'::date),('4'::int4),('4  '),('0.5f'),('14.77'::double precision),('0.0'::double precision),('14.77'::double precision),('14.77'::double precision),('0.26843501326259955'::double precision),('0'::int4),('0'::int4),('1246.9690081284307'::double precision),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(IND, 2022-04-19, 4, 4  , 0.5f) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.ResultHandlerDelegate.handleError(ResultHandlerDelegate.java:52)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2421)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2153)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.flushIfDeadlockRisk(QueryExecutorImpl.java:1503)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.sendQuery(QueryExecutorImpl.java:1528)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:566)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:888)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1739)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:740)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:896)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:895)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1012)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1012)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2298)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(IND, 2022-04-19, 4, 4  , 0.5f) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2733)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2420)\n",
      "\t... 22 more\n",
      "24/12/05 22:21:29 ERROR Executor: Exception in task 72.0 in stage 390.0 (TID 1909)\n",
      "java.sql.BatchUpdateException: Batch entry 0 INSERT INTO gps_aggregated_results_with_gates (\"course_cd\",\"race_date\",\"race_number\",\"saddle_cloth_number\",\"gate_name\",\"avg_speed\",\"avg_acceleration\",\"max_speed\",\"min_speed\",\"fatigue_factor\",\"is_fastest_gate\",\"is_slowest_gate\",\"total_distance_run\",\"ground_loss\") VALUES (('IND'),('2022-04-27 -05'::date),('9'::int4),('7  '),('0.5f'),('15.82'::double precision),('0.0'::double precision),('15.82'::double precision),('15.82'::double precision),('0.30728616684266113'::double precision),('0'::int4),('0'::int4),('1160.4490883049446'::double precision),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(IND, 2022-04-27, 9, 7  , 0.5f) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.ResultHandlerDelegate.handleError(ResultHandlerDelegate.java:52)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2421)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2153)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.flushIfDeadlockRisk(QueryExecutorImpl.java:1503)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.sendQuery(QueryExecutorImpl.java:1528)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:566)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:888)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1739)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:740)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:896)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:895)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1012)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1012)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2298)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(IND, 2022-04-27, 9, 7  , 0.5f) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2733)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2420)\n",
      "\t... 22 more\n",
      "24/12/05 22:21:29 ERROR TaskSetManager: Task 11 in stage 390.0 failed 1 times; aborting job\n",
      "ERROR:root:Error processing course IND: An error occurred while calling o10472.jdbc.\n",
      ": org.apache.spark.SparkException: Job aborted due to stage failure: Task 11 in stage 390.0 failed 1 times, most recent failure: Lost task 11.0 in stage 390.0 (TID 1848) (mail.relufox.ai executor driver): java.sql.BatchUpdateException: Batch entry 0 INSERT INTO gps_aggregated_results_with_gates (\"course_cd\",\"race_date\",\"race_number\",\"saddle_cloth_number\",\"gate_name\",\"avg_speed\",\"avg_acceleration\",\"max_speed\",\"min_speed\",\"fatigue_factor\",\"is_fastest_gate\",\"is_slowest_gate\",\"total_distance_run\",\"ground_loss\") VALUES (('IND'),('2022-04-19 -05'::date),('4'::int4),('4  '),('0.5f'),('14.77'::double precision),('0.0'::double precision),('14.77'::double precision),('14.77'::double precision),('0.26843501326259955'::double precision),('0'::int4),('0'::int4),('1246.9690081284307'::double precision),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(IND, 2022-04-19, 4, 4  , 0.5f) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.ResultHandlerDelegate.handleError(ResultHandlerDelegate.java:52)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2421)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2153)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.flushIfDeadlockRisk(QueryExecutorImpl.java:1503)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.sendQuery(QueryExecutorImpl.java:1528)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:566)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:888)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1739)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:740)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:896)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:895)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1012)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1012)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2298)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(IND, 2022-04-19, 4, 4  , 0.5f) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2733)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2420)\n",
      "\t... 22 more\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2790)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2726)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2725)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2725)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1211)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1211)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1211)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2989)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2928)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2917)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:976)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2258)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2279)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2298)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2323)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$1(RDD.scala:1012)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n",
      "\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:408)\n",
      "\tat org.apache.spark.rdd.RDD.foreachPartition(RDD.scala:1010)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.saveTable(JdbcUtils.scala:895)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:70)\n",
      "\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:47)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:118)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:195)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:827)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:65)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:94)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:512)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:104)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:512)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:31)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:31)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:31)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:488)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:94)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:81)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:79)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:133)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:856)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:387)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:360)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:247)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.jdbc(DataFrameWriter.scala:753)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor265.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: java.sql.BatchUpdateException: Batch entry 0 INSERT INTO gps_aggregated_results_with_gates (\"course_cd\",\"race_date\",\"race_number\",\"saddle_cloth_number\",\"gate_name\",\"avg_speed\",\"avg_acceleration\",\"max_speed\",\"min_speed\",\"fatigue_factor\",\"is_fastest_gate\",\"is_slowest_gate\",\"total_distance_run\",\"ground_loss\") VALUES (('IND'),('2022-04-19 -05'::date),('4'::int4),('4  '),('0.5f'),('14.77'::double precision),('0.0'::double precision),('14.77'::double precision),('14.77'::double precision),('0.26843501326259955'::double precision),('0'::int4),('0'::int4),('1246.9690081284307'::double precision),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(IND, 2022-04-19, 4, 4  , 0.5f) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.ResultHandlerDelegate.handleError(ResultHandlerDelegate.java:52)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2421)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2153)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.flushIfDeadlockRisk(QueryExecutorImpl.java:1503)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.sendQuery(QueryExecutorImpl.java:1528)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:566)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:888)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1739)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:740)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:896)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:895)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1012)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1012)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2298)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\t... 1 more\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(IND, 2022-04-19, 4, 4  , 0.5f) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2733)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2420)\n",
      "\t... 22 more\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Loading data from database for course: CTD\n",
      "INFO:root:None\n",
      "INFO:root:None\n",
      "INFO:root:None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing course: CTD\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- gate_name: string (nullable = true)\n",
      " |-- avg_speed: double (nullable = true)\n",
      " |-- avg_acceleration: double (nullable = true)\n",
      " |-- max_speed: double (nullable = true)\n",
      " |-- min_speed: double (nullable = true)\n",
      " |-- fatigue_factor: double (nullable = true)\n",
      " |-- is_fastest_gate: integer (nullable = true)\n",
      " |-- is_slowest_gate: integer (nullable = true)\n",
      "\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- gate_name: string (nullable = true)\n",
      " |-- avg_speed: double (nullable = true)\n",
      " |-- avg_acceleration: double (nullable = true)\n",
      " |-- max_speed: double (nullable = true)\n",
      " |-- min_speed: double (nullable = true)\n",
      " |-- fatigue_factor: double (nullable = true)\n",
      " |-- is_fastest_gate: integer (nullable = true)\n",
      " |-- is_slowest_gate: integer (nullable = true)\n",
      "\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- total_distance_run: double (nullable = true)\n",
      " |-- ground_loss: double (nullable = true)\n",
      "\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- total_distance_run: double (nullable = true)\n",
      " |-- ground_loss: double (nullable = true)\n",
      "\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- gate_name: string (nullable = true)\n",
      " |-- avg_speed: double (nullable = true)\n",
      " |-- avg_acceleration: double (nullable = true)\n",
      " |-- max_speed: double (nullable = true)\n",
      " |-- min_speed: double (nullable = true)\n",
      " |-- fatigue_factor: double (nullable = true)\n",
      " |-- is_fastest_gate: integer (nullable = true)\n",
      " |-- is_slowest_gate: integer (nullable = true)\n",
      " |-- total_distance_run: double (nullable = true)\n",
      " |-- ground_loss: double (nullable = true)\n",
      "\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- gate_name: string (nullable = true)\n",
      " |-- avg_speed: double (nullable = true)\n",
      " |-- avg_acceleration: double (nullable = true)\n",
      " |-- max_speed: double (nullable = true)\n",
      " |-- min_speed: double (nullable = true)\n",
      " |-- fatigue_factor: double (nullable = true)\n",
      " |-- is_fastest_gate: integer (nullable = true)\n",
      " |-- is_slowest_gate: integer (nullable = true)\n",
      " |-- total_distance_run: double (nullable = true)\n",
      " |-- ground_loss: double (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/05 22:21:30 ERROR Executor: Exception in task 11.0 in stage 405.0 (TID 1965)\n",
      "java.sql.BatchUpdateException: Batch entry 0 INSERT INTO gps_aggregated_results_with_gates (\"course_cd\",\"race_date\",\"race_number\",\"saddle_cloth_number\",\"gate_name\",\"avg_speed\",\"avg_acceleration\",\"max_speed\",\"min_speed\",\"fatigue_factor\",\"is_fastest_gate\",\"is_slowest_gate\",\"total_distance_run\",\"ground_loss\") VALUES (('CTD'),('2024-03-16 -05'::date),('4'::int4),('5  '),('0.5f'),('14.01'::double precision),('0.0'::double precision),('14.01'::double precision),('14.01'::double precision),('0.11225895316804402'::double precision),('0'::int4),('0'::int4),('1879.9927529610707'::double precision),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(CTD, 2024-03-16, 4, 5  , 0.5f) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.ResultHandlerDelegate.handleError(ResultHandlerDelegate.java:52)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2421)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2153)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.flushIfDeadlockRisk(QueryExecutorImpl.java:1503)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.sendQuery(QueryExecutorImpl.java:1528)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:566)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:888)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1739)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:740)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:896)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:895)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1012)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1012)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2298)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(CTD, 2024-03-16, 4, 5  , 0.5f) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2733)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2420)\n",
      "\t... 22 more\n",
      "24/12/05 22:21:30 ERROR TaskSetManager: Task 11 in stage 405.0 failed 1 times; aborting job\n",
      "ERROR:root:Error processing course CTD: An error occurred while calling o10889.jdbc.\n",
      ": org.apache.spark.SparkException: Job aborted due to stage failure: Task 11 in stage 405.0 failed 1 times, most recent failure: Lost task 11.0 in stage 405.0 (TID 1965) (mail.relufox.ai executor driver): java.sql.BatchUpdateException: Batch entry 0 INSERT INTO gps_aggregated_results_with_gates (\"course_cd\",\"race_date\",\"race_number\",\"saddle_cloth_number\",\"gate_name\",\"avg_speed\",\"avg_acceleration\",\"max_speed\",\"min_speed\",\"fatigue_factor\",\"is_fastest_gate\",\"is_slowest_gate\",\"total_distance_run\",\"ground_loss\") VALUES (('CTD'),('2024-03-16 -05'::date),('4'::int4),('5  '),('0.5f'),('14.01'::double precision),('0.0'::double precision),('14.01'::double precision),('14.01'::double precision),('0.11225895316804402'::double precision),('0'::int4),('0'::int4),('1879.9927529610707'::double precision),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(CTD, 2024-03-16, 4, 5  , 0.5f) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.ResultHandlerDelegate.handleError(ResultHandlerDelegate.java:52)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2421)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2153)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.flushIfDeadlockRisk(QueryExecutorImpl.java:1503)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.sendQuery(QueryExecutorImpl.java:1528)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:566)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:888)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1739)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:740)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:896)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:895)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1012)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1012)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2298)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(CTD, 2024-03-16, 4, 5  , 0.5f) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2733)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2420)\n",
      "\t... 22 more\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2790)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2726)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2725)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2725)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1211)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1211)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1211)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2989)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2928)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2917)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:976)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2258)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2279)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2298)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2323)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$1(RDD.scala:1012)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n",
      "\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:408)\n",
      "\tat org.apache.spark.rdd.RDD.foreachPartition(RDD.scala:1010)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.saveTable(JdbcUtils.scala:895)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:70)\n",
      "\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:47)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:118)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:195)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:827)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:65)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:94)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:512)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:104)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:512)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:31)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:31)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:31)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:488)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:94)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:81)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:79)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:133)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:856)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:387)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:360)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:247)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.jdbc(DataFrameWriter.scala:753)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor265.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: java.sql.BatchUpdateException: Batch entry 0 INSERT INTO gps_aggregated_results_with_gates (\"course_cd\",\"race_date\",\"race_number\",\"saddle_cloth_number\",\"gate_name\",\"avg_speed\",\"avg_acceleration\",\"max_speed\",\"min_speed\",\"fatigue_factor\",\"is_fastest_gate\",\"is_slowest_gate\",\"total_distance_run\",\"ground_loss\") VALUES (('CTD'),('2024-03-16 -05'::date),('4'::int4),('5  '),('0.5f'),('14.01'::double precision),('0.0'::double precision),('14.01'::double precision),('14.01'::double precision),('0.11225895316804402'::double precision),('0'::int4),('0'::int4),('1879.9927529610707'::double precision),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(CTD, 2024-03-16, 4, 5  , 0.5f) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.ResultHandlerDelegate.handleError(ResultHandlerDelegate.java:52)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2421)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2153)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.flushIfDeadlockRisk(QueryExecutorImpl.java:1503)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.sendQuery(QueryExecutorImpl.java:1528)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:566)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:888)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1739)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:740)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:896)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:895)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1012)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1012)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2298)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\t... 1 more\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(CTD, 2024-03-16, 4, 5  , 0.5f) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2733)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2420)\n",
      "\t... 22 more\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Loading data from database for course: ASD\n",
      "INFO:root:None\n",
      "INFO:root:None\n",
      "INFO:root:None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing course: ASD\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- gate_name: string (nullable = true)\n",
      " |-- avg_speed: double (nullable = true)\n",
      " |-- avg_acceleration: double (nullable = true)\n",
      " |-- max_speed: double (nullable = true)\n",
      " |-- min_speed: double (nullable = true)\n",
      " |-- fatigue_factor: double (nullable = true)\n",
      " |-- is_fastest_gate: integer (nullable = true)\n",
      " |-- is_slowest_gate: integer (nullable = true)\n",
      "\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- gate_name: string (nullable = true)\n",
      " |-- avg_speed: double (nullable = true)\n",
      " |-- avg_acceleration: double (nullable = true)\n",
      " |-- max_speed: double (nullable = true)\n",
      " |-- min_speed: double (nullable = true)\n",
      " |-- fatigue_factor: double (nullable = true)\n",
      " |-- is_fastest_gate: integer (nullable = true)\n",
      " |-- is_slowest_gate: integer (nullable = true)\n",
      "\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- total_distance_run: double (nullable = true)\n",
      " |-- ground_loss: double (nullable = true)\n",
      "\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- total_distance_run: double (nullable = true)\n",
      " |-- ground_loss: double (nullable = true)\n",
      "\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- gate_name: string (nullable = true)\n",
      " |-- avg_speed: double (nullable = true)\n",
      " |-- avg_acceleration: double (nullable = true)\n",
      " |-- max_speed: double (nullable = true)\n",
      " |-- min_speed: double (nullable = true)\n",
      " |-- fatigue_factor: double (nullable = true)\n",
      " |-- is_fastest_gate: integer (nullable = true)\n",
      " |-- is_slowest_gate: integer (nullable = true)\n",
      " |-- total_distance_run: double (nullable = true)\n",
      " |-- ground_loss: double (nullable = true)\n",
      "\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- gate_name: string (nullable = true)\n",
      " |-- avg_speed: double (nullable = true)\n",
      " |-- avg_acceleration: double (nullable = true)\n",
      " |-- max_speed: double (nullable = true)\n",
      " |-- min_speed: double (nullable = true)\n",
      " |-- fatigue_factor: double (nullable = true)\n",
      " |-- is_fastest_gate: integer (nullable = true)\n",
      " |-- is_slowest_gate: integer (nullable = true)\n",
      " |-- total_distance_run: double (nullable = true)\n",
      " |-- ground_loss: double (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/05 22:21:31 ERROR Executor: Exception in task 8.0 in stage 420.0 (TID 1999)\n",
      "java.sql.BatchUpdateException: Batch entry 0 INSERT INTO gps_aggregated_results_with_gates (\"course_cd\",\"race_date\",\"race_number\",\"saddle_cloth_number\",\"gate_name\",\"avg_speed\",\"avg_acceleration\",\"max_speed\",\"min_speed\",\"fatigue_factor\",\"is_fastest_gate\",\"is_slowest_gate\",\"total_distance_run\",\"ground_loss\") VALUES (('ASD'),('2023-05-22 -05'::date),('1'::int4),('4  '),('0.5f'),('14.92'::double precision),('0.0'::double precision),('14.92'::double precision),('14.92'::double precision),('0.29287190082644626'::double precision),('0'::int4),('0'::int4),('1138.978170822401'::double precision),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(ASD, 2023-05-22, 1, 4  , 0.5f) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.ResultHandlerDelegate.handleError(ResultHandlerDelegate.java:52)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2421)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2153)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.flushIfDeadlockRisk(QueryExecutorImpl.java:1503)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.sendQuery(QueryExecutorImpl.java:1528)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:566)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:888)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1739)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:740)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:896)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:895)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1012)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1012)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2298)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(ASD, 2023-05-22, 1, 4  , 0.5f) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2733)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2420)\n",
      "\t... 22 more\n",
      "24/12/05 22:21:31 ERROR TaskSetManager: Task 8 in stage 420.0 failed 1 times; aborting job\n",
      "ERROR:root:Error processing course ASD: An error occurred while calling o11306.jdbc.\n",
      ": org.apache.spark.SparkException: Job aborted due to stage failure: Task 8 in stage 420.0 failed 1 times, most recent failure: Lost task 8.0 in stage 420.0 (TID 1999) (mail.relufox.ai executor driver): java.sql.BatchUpdateException: Batch entry 0 INSERT INTO gps_aggregated_results_with_gates (\"course_cd\",\"race_date\",\"race_number\",\"saddle_cloth_number\",\"gate_name\",\"avg_speed\",\"avg_acceleration\",\"max_speed\",\"min_speed\",\"fatigue_factor\",\"is_fastest_gate\",\"is_slowest_gate\",\"total_distance_run\",\"ground_loss\") VALUES (('ASD'),('2023-05-22 -05'::date),('1'::int4),('4  '),('0.5f'),('14.92'::double precision),('0.0'::double precision),('14.92'::double precision),('14.92'::double precision),('0.29287190082644626'::double precision),('0'::int4),('0'::int4),('1138.978170822401'::double precision),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(ASD, 2023-05-22, 1, 4  , 0.5f) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.ResultHandlerDelegate.handleError(ResultHandlerDelegate.java:52)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2421)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2153)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.flushIfDeadlockRisk(QueryExecutorImpl.java:1503)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.sendQuery(QueryExecutorImpl.java:1528)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:566)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:888)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1739)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:740)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:896)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:895)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1012)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1012)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2298)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(ASD, 2023-05-22, 1, 4  , 0.5f) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2733)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2420)\n",
      "\t... 22 more\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2790)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2726)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2725)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2725)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1211)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1211)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1211)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2989)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2928)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2917)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:976)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2258)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2279)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2298)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2323)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$1(RDD.scala:1012)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n",
      "\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:408)\n",
      "\tat org.apache.spark.rdd.RDD.foreachPartition(RDD.scala:1010)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.saveTable(JdbcUtils.scala:895)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:70)\n",
      "\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:47)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:118)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:195)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:827)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:65)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:94)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:512)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:104)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:512)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:31)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:31)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:31)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:488)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:94)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:81)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:79)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:133)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:856)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:387)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:360)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:247)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.jdbc(DataFrameWriter.scala:753)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor265.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: java.sql.BatchUpdateException: Batch entry 0 INSERT INTO gps_aggregated_results_with_gates (\"course_cd\",\"race_date\",\"race_number\",\"saddle_cloth_number\",\"gate_name\",\"avg_speed\",\"avg_acceleration\",\"max_speed\",\"min_speed\",\"fatigue_factor\",\"is_fastest_gate\",\"is_slowest_gate\",\"total_distance_run\",\"ground_loss\") VALUES (('ASD'),('2023-05-22 -05'::date),('1'::int4),('4  '),('0.5f'),('14.92'::double precision),('0.0'::double precision),('14.92'::double precision),('14.92'::double precision),('0.29287190082644626'::double precision),('0'::int4),('0'::int4),('1138.978170822401'::double precision),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(ASD, 2023-05-22, 1, 4  , 0.5f) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.ResultHandlerDelegate.handleError(ResultHandlerDelegate.java:52)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2421)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2153)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.flushIfDeadlockRisk(QueryExecutorImpl.java:1503)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.sendQuery(QueryExecutorImpl.java:1528)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:566)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:888)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1739)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:740)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:896)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:895)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1012)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1012)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2298)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\t... 1 more\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(ASD, 2023-05-22, 1, 4  , 0.5f) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2733)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2420)\n",
      "\t... 22 more\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Loading data from database for course: TCD\n",
      "INFO:root:None\n",
      "INFO:root:None\n",
      "INFO:root:None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing course: TCD\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- gate_name: string (nullable = true)\n",
      " |-- avg_speed: double (nullable = true)\n",
      " |-- avg_acceleration: double (nullable = true)\n",
      " |-- max_speed: double (nullable = true)\n",
      " |-- min_speed: double (nullable = true)\n",
      " |-- fatigue_factor: double (nullable = true)\n",
      " |-- is_fastest_gate: integer (nullable = true)\n",
      " |-- is_slowest_gate: integer (nullable = true)\n",
      "\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- gate_name: string (nullable = true)\n",
      " |-- avg_speed: double (nullable = true)\n",
      " |-- avg_acceleration: double (nullable = true)\n",
      " |-- max_speed: double (nullable = true)\n",
      " |-- min_speed: double (nullable = true)\n",
      " |-- fatigue_factor: double (nullable = true)\n",
      " |-- is_fastest_gate: integer (nullable = true)\n",
      " |-- is_slowest_gate: integer (nullable = true)\n",
      "\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- total_distance_run: double (nullable = true)\n",
      " |-- ground_loss: double (nullable = true)\n",
      "\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- total_distance_run: double (nullable = true)\n",
      " |-- ground_loss: double (nullable = true)\n",
      "\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- gate_name: string (nullable = true)\n",
      " |-- avg_speed: double (nullable = true)\n",
      " |-- avg_acceleration: double (nullable = true)\n",
      " |-- max_speed: double (nullable = true)\n",
      " |-- min_speed: double (nullable = true)\n",
      " |-- fatigue_factor: double (nullable = true)\n",
      " |-- is_fastest_gate: integer (nullable = true)\n",
      " |-- is_slowest_gate: integer (nullable = true)\n",
      " |-- total_distance_run: double (nullable = true)\n",
      " |-- ground_loss: double (nullable = true)\n",
      "\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- gate_name: string (nullable = true)\n",
      " |-- avg_speed: double (nullable = true)\n",
      " |-- avg_acceleration: double (nullable = true)\n",
      " |-- max_speed: double (nullable = true)\n",
      " |-- min_speed: double (nullable = true)\n",
      " |-- fatigue_factor: double (nullable = true)\n",
      " |-- is_fastest_gate: integer (nullable = true)\n",
      " |-- is_slowest_gate: integer (nullable = true)\n",
      " |-- total_distance_run: double (nullable = true)\n",
      " |-- ground_loss: double (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/05 22:21:34 ERROR Executor: Exception in task 7.0 in stage 435.0 (TID 2050)\n",
      "java.sql.BatchUpdateException: Batch entry 0 INSERT INTO gps_aggregated_results_with_gates (\"course_cd\",\"race_date\",\"race_number\",\"saddle_cloth_number\",\"gate_name\",\"avg_speed\",\"avg_acceleration\",\"max_speed\",\"min_speed\",\"fatigue_factor\",\"is_fastest_gate\",\"is_slowest_gate\",\"total_distance_run\",\"ground_loss\") VALUES (('TCD'),('2023-04-29 -05'::date),('1'::int4),('5  '),('0.5f'),('15.09'::double precision),('0.0'::double precision),('15.09'::double precision),('15.09'::double precision),('0.22524483133841125'::double precision),('0'::int4),('0'::int4),('1565.2591502130028'::double precision),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(TCD, 2023-04-29, 1, 5  , 0.5f) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.ResultHandlerDelegate.handleError(ResultHandlerDelegate.java:52)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2421)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2153)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.flushIfDeadlockRisk(QueryExecutorImpl.java:1503)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.sendQuery(QueryExecutorImpl.java:1528)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:566)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:888)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1739)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:740)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:896)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:895)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1012)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1012)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2298)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(TCD, 2023-04-29, 1, 5  , 0.5f) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2733)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2420)\n",
      "\t... 22 more\n",
      "24/12/05 22:21:34 ERROR Executor: Exception in task 13.0 in stage 435.0 (TID 2056)\n",
      "java.sql.BatchUpdateException: Batch entry 0 INSERT INTO gps_aggregated_results_with_gates (\"course_cd\",\"race_date\",\"race_number\",\"saddle_cloth_number\",\"gate_name\",\"avg_speed\",\"avg_acceleration\",\"max_speed\",\"min_speed\",\"fatigue_factor\",\"is_fastest_gate\",\"is_slowest_gate\",\"total_distance_run\",\"ground_loss\") VALUES (('TCD'),('2023-05-02 -05'::date),('9'::int4),('4  '),('0.5f'),('16.1'::double precision),('0.0'::double precision),('16.1'::double precision),('16.1'::double precision),('0.11621315192743768'::double precision),('0'::int4),('0'::int4),('2187.1037685783904'::double precision),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(TCD, 2023-05-02, 9, 4  , 0.5f) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.ResultHandlerDelegate.handleError(ResultHandlerDelegate.java:52)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2421)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2153)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.flushIfDeadlockRisk(QueryExecutorImpl.java:1503)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.sendQuery(QueryExecutorImpl.java:1528)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:566)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:888)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1739)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:740)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:896)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:895)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1012)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1012)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2298)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(TCD, 2023-05-02, 9, 4  , 0.5f) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2733)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2420)\n",
      "\t... 22 more\n",
      "24/12/05 22:21:34 ERROR TaskSetManager: Task 7 in stage 435.0 failed 1 times; aborting job\n",
      "ERROR:root:Error processing course TCD: An error occurred while calling o11723.jdbc.\n",
      ": org.apache.spark.SparkException: Job aborted due to stage failure: Task 7 in stage 435.0 failed 1 times, most recent failure: Lost task 7.0 in stage 435.0 (TID 2050) (mail.relufox.ai executor driver): java.sql.BatchUpdateException: Batch entry 0 INSERT INTO gps_aggregated_results_with_gates (\"course_cd\",\"race_date\",\"race_number\",\"saddle_cloth_number\",\"gate_name\",\"avg_speed\",\"avg_acceleration\",\"max_speed\",\"min_speed\",\"fatigue_factor\",\"is_fastest_gate\",\"is_slowest_gate\",\"total_distance_run\",\"ground_loss\") VALUES (('TCD'),('2023-04-29 -05'::date),('1'::int4),('5  '),('0.5f'),('15.09'::double precision),('0.0'::double precision),('15.09'::double precision),('15.09'::double precision),('0.22524483133841125'::double precision),('0'::int4),('0'::int4),('1565.2591502130028'::double precision),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(TCD, 2023-04-29, 1, 5  , 0.5f) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.ResultHandlerDelegate.handleError(ResultHandlerDelegate.java:52)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2421)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2153)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.flushIfDeadlockRisk(QueryExecutorImpl.java:1503)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.sendQuery(QueryExecutorImpl.java:1528)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:566)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:888)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1739)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:740)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:896)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:895)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1012)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1012)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2298)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(TCD, 2023-04-29, 1, 5  , 0.5f) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2733)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2420)\n",
      "\t... 22 more\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2790)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2726)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2725)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2725)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1211)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1211)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1211)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2989)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2928)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2917)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:976)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2258)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2279)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2298)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2323)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$1(RDD.scala:1012)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n",
      "\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:408)\n",
      "\tat org.apache.spark.rdd.RDD.foreachPartition(RDD.scala:1010)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.saveTable(JdbcUtils.scala:895)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:70)\n",
      "\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:47)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:118)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:195)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:827)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:65)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:94)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:512)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:104)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:512)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:31)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:31)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:31)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:488)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:94)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:81)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:79)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:133)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:856)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:387)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:360)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:247)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.jdbc(DataFrameWriter.scala:753)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor265.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: java.sql.BatchUpdateException: Batch entry 0 INSERT INTO gps_aggregated_results_with_gates (\"course_cd\",\"race_date\",\"race_number\",\"saddle_cloth_number\",\"gate_name\",\"avg_speed\",\"avg_acceleration\",\"max_speed\",\"min_speed\",\"fatigue_factor\",\"is_fastest_gate\",\"is_slowest_gate\",\"total_distance_run\",\"ground_loss\") VALUES (('TCD'),('2023-04-29 -05'::date),('1'::int4),('5  '),('0.5f'),('15.09'::double precision),('0.0'::double precision),('15.09'::double precision),('15.09'::double precision),('0.22524483133841125'::double precision),('0'::int4),('0'::int4),('1565.2591502130028'::double precision),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(TCD, 2023-04-29, 1, 5  , 0.5f) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.ResultHandlerDelegate.handleError(ResultHandlerDelegate.java:52)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2421)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2153)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.flushIfDeadlockRisk(QueryExecutorImpl.java:1503)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.sendQuery(QueryExecutorImpl.java:1528)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:566)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:888)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1739)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:740)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:896)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:895)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1012)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1012)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2298)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\t... 1 more\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(TCD, 2023-04-29, 1, 5  , 0.5f) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2733)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2420)\n",
      "\t... 22 more\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Loading data from database for course: LAD\n",
      "INFO:root:None\n",
      "INFO:root:None\n",
      "INFO:root:None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing course: LAD\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- gate_name: string (nullable = true)\n",
      " |-- avg_speed: double (nullable = true)\n",
      " |-- avg_acceleration: double (nullable = true)\n",
      " |-- max_speed: double (nullable = true)\n",
      " |-- min_speed: double (nullable = true)\n",
      " |-- fatigue_factor: double (nullable = true)\n",
      " |-- is_fastest_gate: integer (nullable = true)\n",
      " |-- is_slowest_gate: integer (nullable = true)\n",
      "\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- gate_name: string (nullable = true)\n",
      " |-- avg_speed: double (nullable = true)\n",
      " |-- avg_acceleration: double (nullable = true)\n",
      " |-- max_speed: double (nullable = true)\n",
      " |-- min_speed: double (nullable = true)\n",
      " |-- fatigue_factor: double (nullable = true)\n",
      " |-- is_fastest_gate: integer (nullable = true)\n",
      " |-- is_slowest_gate: integer (nullable = true)\n",
      "\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- total_distance_run: double (nullable = true)\n",
      " |-- ground_loss: double (nullable = true)\n",
      "\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- total_distance_run: double (nullable = true)\n",
      " |-- ground_loss: double (nullable = true)\n",
      "\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- gate_name: string (nullable = true)\n",
      " |-- avg_speed: double (nullable = true)\n",
      " |-- avg_acceleration: double (nullable = true)\n",
      " |-- max_speed: double (nullable = true)\n",
      " |-- min_speed: double (nullable = true)\n",
      " |-- fatigue_factor: double (nullable = true)\n",
      " |-- is_fastest_gate: integer (nullable = true)\n",
      " |-- is_slowest_gate: integer (nullable = true)\n",
      " |-- total_distance_run: double (nullable = true)\n",
      " |-- ground_loss: double (nullable = true)\n",
      "\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- gate_name: string (nullable = true)\n",
      " |-- avg_speed: double (nullable = true)\n",
      " |-- avg_acceleration: double (nullable = true)\n",
      " |-- max_speed: double (nullable = true)\n",
      " |-- min_speed: double (nullable = true)\n",
      " |-- fatigue_factor: double (nullable = true)\n",
      " |-- is_fastest_gate: integer (nullable = true)\n",
      " |-- is_slowest_gate: integer (nullable = true)\n",
      " |-- total_distance_run: double (nullable = true)\n",
      " |-- ground_loss: double (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/05 22:21:35 ERROR Executor: Exception in task 11.0 in stage 450.0 (TID 2125)\n",
      "java.sql.BatchUpdateException: Batch entry 0 INSERT INTO gps_aggregated_results_with_gates (\"course_cd\",\"race_date\",\"race_number\",\"saddle_cloth_number\",\"gate_name\",\"avg_speed\",\"avg_acceleration\",\"max_speed\",\"min_speed\",\"fatigue_factor\",\"is_fastest_gate\",\"is_slowest_gate\",\"total_distance_run\",\"ground_loss\") VALUES (('LAD'),('2023-05-06 -05'::date),('2'::int4),('3  '),('0.5f'),('15.52'::double precision),('0.0'::double precision),('15.52'::double precision),('15.52'::double precision),('0.302713987473904'::double precision),('0'::int4),('0'::int4),('1302.2251403110654'::double precision),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(LAD, 2023-05-06, 2, 3  , 0.5f) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.ResultHandlerDelegate.handleError(ResultHandlerDelegate.java:52)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2421)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2153)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.flushIfDeadlockRisk(QueryExecutorImpl.java:1503)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.sendQuery(QueryExecutorImpl.java:1528)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:566)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:888)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1739)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:740)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:896)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:895)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1012)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1012)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2298)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(LAD, 2023-05-06, 2, 3  , 0.5f) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2733)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2420)\n",
      "\t... 22 more\n",
      "24/12/05 22:21:35 ERROR Executor: Exception in task 0.0 in stage 450.0 (TID 2114)\n",
      "java.sql.BatchUpdateException: Batch entry 0 INSERT INTO gps_aggregated_results_with_gates (\"course_cd\",\"race_date\",\"race_number\",\"saddle_cloth_number\",\"gate_name\",\"avg_speed\",\"avg_acceleration\",\"max_speed\",\"min_speed\",\"fatigue_factor\",\"is_fastest_gate\",\"is_slowest_gate\",\"total_distance_run\",\"ground_loss\") VALUES (('LAD'),('2023-05-06 -05'::date),('1'::int4),('2  '),('0.5f'),('13.67'::double precision),('0.0'::double precision),('13.67'::double precision),('13.67'::double precision),('0.30185676392572947'::double precision),('0'::int4),('0'::int4),('1448.8550090671224'::double precision),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(LAD, 2023-05-06, 1, 2  , 0.5f) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.ResultHandlerDelegate.handleError(ResultHandlerDelegate.java:52)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2421)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2153)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.flushIfDeadlockRisk(QueryExecutorImpl.java:1503)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.sendQuery(QueryExecutorImpl.java:1528)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:566)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:888)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1739)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:740)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:896)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:895)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1012)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1012)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2298)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(LAD, 2023-05-06, 1, 2  , 0.5f) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2733)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2420)\n",
      "\t... 22 more\n",
      "24/12/05 22:21:35 ERROR TaskSetManager: Task 0 in stage 450.0 failed 1 times; aborting job\n",
      "ERROR:root:Error processing course LAD: An error occurred while calling o12140.jdbc.\n",
      ": org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 450.0 failed 1 times, most recent failure: Lost task 0.0 in stage 450.0 (TID 2114) (mail.relufox.ai executor driver): java.sql.BatchUpdateException: Batch entry 0 INSERT INTO gps_aggregated_results_with_gates (\"course_cd\",\"race_date\",\"race_number\",\"saddle_cloth_number\",\"gate_name\",\"avg_speed\",\"avg_acceleration\",\"max_speed\",\"min_speed\",\"fatigue_factor\",\"is_fastest_gate\",\"is_slowest_gate\",\"total_distance_run\",\"ground_loss\") VALUES (('LAD'),('2023-05-06 -05'::date),('1'::int4),('2  '),('0.5f'),('13.67'::double precision),('0.0'::double precision),('13.67'::double precision),('13.67'::double precision),('0.30185676392572947'::double precision),('0'::int4),('0'::int4),('1448.8550090671224'::double precision),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(LAD, 2023-05-06, 1, 2  , 0.5f) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.ResultHandlerDelegate.handleError(ResultHandlerDelegate.java:52)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2421)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2153)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.flushIfDeadlockRisk(QueryExecutorImpl.java:1503)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.sendQuery(QueryExecutorImpl.java:1528)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:566)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:888)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1739)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:740)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:896)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:895)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1012)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1012)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2298)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(LAD, 2023-05-06, 1, 2  , 0.5f) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2733)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2420)\n",
      "\t... 22 more\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2790)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2726)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2725)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2725)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1211)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1211)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1211)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2989)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2928)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2917)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:976)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2258)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2279)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2298)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2323)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$1(RDD.scala:1012)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n",
      "\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:408)\n",
      "\tat org.apache.spark.rdd.RDD.foreachPartition(RDD.scala:1010)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.saveTable(JdbcUtils.scala:895)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:70)\n",
      "\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:47)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:118)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:195)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:827)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:65)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:94)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:512)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:104)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:512)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:31)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:31)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:31)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:488)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:94)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:81)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:79)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:133)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:856)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:387)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:360)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:247)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.jdbc(DataFrameWriter.scala:753)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor265.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: java.sql.BatchUpdateException: Batch entry 0 INSERT INTO gps_aggregated_results_with_gates (\"course_cd\",\"race_date\",\"race_number\",\"saddle_cloth_number\",\"gate_name\",\"avg_speed\",\"avg_acceleration\",\"max_speed\",\"min_speed\",\"fatigue_factor\",\"is_fastest_gate\",\"is_slowest_gate\",\"total_distance_run\",\"ground_loss\") VALUES (('LAD'),('2023-05-06 -05'::date),('1'::int4),('2  '),('0.5f'),('13.67'::double precision),('0.0'::double precision),('13.67'::double precision),('13.67'::double precision),('0.30185676392572947'::double precision),('0'::int4),('0'::int4),('1448.8550090671224'::double precision),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(LAD, 2023-05-06, 1, 2  , 0.5f) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.ResultHandlerDelegate.handleError(ResultHandlerDelegate.java:52)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2421)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2153)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.flushIfDeadlockRisk(QueryExecutorImpl.java:1503)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.sendQuery(QueryExecutorImpl.java:1528)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:566)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:888)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1739)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:740)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:896)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:895)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1012)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1012)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2298)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\t... 1 more\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(LAD, 2023-05-06, 1, 2  , 0.5f) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2733)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2420)\n",
      "\t... 22 more\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Loading data from database for course: MED\n",
      "INFO:root:None\n",
      "INFO:root:None\n",
      "INFO:root:None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing course: MED\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- gate_name: string (nullable = true)\n",
      " |-- avg_speed: double (nullable = true)\n",
      " |-- avg_acceleration: double (nullable = true)\n",
      " |-- max_speed: double (nullable = true)\n",
      " |-- min_speed: double (nullable = true)\n",
      " |-- fatigue_factor: double (nullable = true)\n",
      " |-- is_fastest_gate: integer (nullable = true)\n",
      " |-- is_slowest_gate: integer (nullable = true)\n",
      "\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- gate_name: string (nullable = true)\n",
      " |-- avg_speed: double (nullable = true)\n",
      " |-- avg_acceleration: double (nullable = true)\n",
      " |-- max_speed: double (nullable = true)\n",
      " |-- min_speed: double (nullable = true)\n",
      " |-- fatigue_factor: double (nullable = true)\n",
      " |-- is_fastest_gate: integer (nullable = true)\n",
      " |-- is_slowest_gate: integer (nullable = true)\n",
      "\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- total_distance_run: double (nullable = true)\n",
      " |-- ground_loss: double (nullable = true)\n",
      "\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- total_distance_run: double (nullable = true)\n",
      " |-- ground_loss: double (nullable = true)\n",
      "\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- gate_name: string (nullable = true)\n",
      " |-- avg_speed: double (nullable = true)\n",
      " |-- avg_acceleration: double (nullable = true)\n",
      " |-- max_speed: double (nullable = true)\n",
      " |-- min_speed: double (nullable = true)\n",
      " |-- fatigue_factor: double (nullable = true)\n",
      " |-- is_fastest_gate: integer (nullable = true)\n",
      " |-- is_slowest_gate: integer (nullable = true)\n",
      " |-- total_distance_run: double (nullable = true)\n",
      " |-- ground_loss: double (nullable = true)\n",
      "\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- gate_name: string (nullable = true)\n",
      " |-- avg_speed: double (nullable = true)\n",
      " |-- avg_acceleration: double (nullable = true)\n",
      " |-- max_speed: double (nullable = true)\n",
      " |-- min_speed: double (nullable = true)\n",
      " |-- fatigue_factor: double (nullable = true)\n",
      " |-- is_fastest_gate: integer (nullable = true)\n",
      " |-- is_slowest_gate: integer (nullable = true)\n",
      " |-- total_distance_run: double (nullable = true)\n",
      " |-- ground_loss: double (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Loading data from database for course: TOP                            \n",
      "INFO:root:None\n",
      "INFO:root:None\n",
      "INFO:root:None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed processing for course: MED\n",
      "Processing course: TOP\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- gate_name: string (nullable = true)\n",
      " |-- avg_speed: double (nullable = true)\n",
      " |-- avg_acceleration: double (nullable = true)\n",
      " |-- max_speed: double (nullable = true)\n",
      " |-- min_speed: double (nullable = true)\n",
      " |-- fatigue_factor: double (nullable = true)\n",
      " |-- is_fastest_gate: integer (nullable = true)\n",
      " |-- is_slowest_gate: integer (nullable = true)\n",
      "\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- gate_name: string (nullable = true)\n",
      " |-- avg_speed: double (nullable = true)\n",
      " |-- avg_acceleration: double (nullable = true)\n",
      " |-- max_speed: double (nullable = true)\n",
      " |-- min_speed: double (nullable = true)\n",
      " |-- fatigue_factor: double (nullable = true)\n",
      " |-- is_fastest_gate: integer (nullable = true)\n",
      " |-- is_slowest_gate: integer (nullable = true)\n",
      "\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- total_distance_run: double (nullable = true)\n",
      " |-- ground_loss: double (nullable = true)\n",
      "\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- total_distance_run: double (nullable = true)\n",
      " |-- ground_loss: double (nullable = true)\n",
      "\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- gate_name: string (nullable = true)\n",
      " |-- avg_speed: double (nullable = true)\n",
      " |-- avg_acceleration: double (nullable = true)\n",
      " |-- max_speed: double (nullable = true)\n",
      " |-- min_speed: double (nullable = true)\n",
      " |-- fatigue_factor: double (nullable = true)\n",
      " |-- is_fastest_gate: integer (nullable = true)\n",
      " |-- is_slowest_gate: integer (nullable = true)\n",
      " |-- total_distance_run: double (nullable = true)\n",
      " |-- ground_loss: double (nullable = true)\n",
      "\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- gate_name: string (nullable = true)\n",
      " |-- avg_speed: double (nullable = true)\n",
      " |-- avg_acceleration: double (nullable = true)\n",
      " |-- max_speed: double (nullable = true)\n",
      " |-- min_speed: double (nullable = true)\n",
      " |-- fatigue_factor: double (nullable = true)\n",
      " |-- is_fastest_gate: integer (nullable = true)\n",
      " |-- is_slowest_gate: integer (nullable = true)\n",
      " |-- total_distance_run: double (nullable = true)\n",
      " |-- ground_loss: double (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/05 22:21:39 ERROR Executor: Exception in task 25.0 in stage 470.0 (TID 2216)\n",
      "java.sql.BatchUpdateException: Batch entry 0 INSERT INTO gps_aggregated_results_with_gates (\"course_cd\",\"race_date\",\"race_number\",\"saddle_cloth_number\",\"gate_name\",\"avg_speed\",\"avg_acceleration\",\"max_speed\",\"min_speed\",\"fatigue_factor\",\"is_fastest_gate\",\"is_slowest_gate\",\"total_distance_run\",\"ground_loss\") VALUES (('TOP'),('2022-01-02 -06'::date),('2'::int4),('10 '),('0.5f'),('15.27'::double precision),('0.0'::double precision),('15.27'::double precision),('15.27'::double precision),('0.28031496062992123'::double precision),('0'::int4),('0'::int4),('1249.1233091901004'::double precision),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(TOP, 2022-01-02, 2, 10 , 0.5f) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.ResultHandlerDelegate.handleError(ResultHandlerDelegate.java:52)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2421)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2153)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.flushIfDeadlockRisk(QueryExecutorImpl.java:1503)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.sendQuery(QueryExecutorImpl.java:1528)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:566)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:888)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1739)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:740)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:896)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:895)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1012)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1012)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2298)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(TOP, 2022-01-02, 2, 10 , 0.5f) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2733)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2420)\n",
      "\t... 22 more\n",
      "24/12/05 22:21:39 ERROR TaskSetManager: Task 25 in stage 470.0 failed 1 times; aborting job\n",
      "ERROR:root:Error processing course TOP: An error occurred while calling o12971.jdbc.\n",
      ": org.apache.spark.SparkException: Job aborted due to stage failure: Task 25 in stage 470.0 failed 1 times, most recent failure: Lost task 25.0 in stage 470.0 (TID 2216) (mail.relufox.ai executor driver): java.sql.BatchUpdateException: Batch entry 0 INSERT INTO gps_aggregated_results_with_gates (\"course_cd\",\"race_date\",\"race_number\",\"saddle_cloth_number\",\"gate_name\",\"avg_speed\",\"avg_acceleration\",\"max_speed\",\"min_speed\",\"fatigue_factor\",\"is_fastest_gate\",\"is_slowest_gate\",\"total_distance_run\",\"ground_loss\") VALUES (('TOP'),('2022-01-02 -06'::date),('2'::int4),('10 '),('0.5f'),('15.27'::double precision),('0.0'::double precision),('15.27'::double precision),('15.27'::double precision),('0.28031496062992123'::double precision),('0'::int4),('0'::int4),('1249.1233091901004'::double precision),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(TOP, 2022-01-02, 2, 10 , 0.5f) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.ResultHandlerDelegate.handleError(ResultHandlerDelegate.java:52)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2421)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2153)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.flushIfDeadlockRisk(QueryExecutorImpl.java:1503)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.sendQuery(QueryExecutorImpl.java:1528)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:566)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:888)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1739)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:740)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:896)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:895)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1012)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1012)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2298)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(TOP, 2022-01-02, 2, 10 , 0.5f) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2733)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2420)\n",
      "\t... 22 more\n",
      "\n",
      "Driver stacktrace:\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2790)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2726)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2725)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
      "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
      "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2725)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1211)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1211)\n",
      "\tat scala.Option.foreach(Option.scala:407)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1211)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2989)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2928)\n",
      "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2917)\n",
      "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n",
      "\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:976)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2258)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2279)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2298)\n",
      "\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2323)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$1(RDD.scala:1012)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n",
      "\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\n",
      "\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:408)\n",
      "\tat org.apache.spark.rdd.RDD.foreachPartition(RDD.scala:1010)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.saveTable(JdbcUtils.scala:895)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcRelationProvider.createRelation(JdbcRelationProvider.scala:70)\n",
      "\tat org.apache.spark.sql.execution.datasources.SaveIntoDataSourceCommand.run(SaveIntoDataSourceCommand.scala:47)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:75)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:73)\n",
      "\tat org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:84)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.$anonfun$applyOrElse$1(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$6(SQLExecution.scala:118)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:195)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:103)\n",
      "\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:827)\n",
      "\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:65)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:98)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution$$anonfun$eagerlyExecuteCommands$1.applyOrElse(QueryExecution.scala:94)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:512)\n",
      "\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:104)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:512)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:31)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:267)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:263)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:31)\n",
      "\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:31)\n",
      "\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:488)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:94)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted$lzycompute(QueryExecution.scala:81)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:79)\n",
      "\tat org.apache.spark.sql.execution.QueryExecution.assertCommandExecuted(QueryExecution.scala:133)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:856)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:387)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.saveInternal(DataFrameWriter.scala:360)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:247)\n",
      "\tat org.apache.spark.sql.DataFrameWriter.jdbc(DataFrameWriter.scala:753)\n",
      "\tat jdk.internal.reflect.GeneratedMethodAccessor265.invoke(Unknown Source)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "Caused by: java.sql.BatchUpdateException: Batch entry 0 INSERT INTO gps_aggregated_results_with_gates (\"course_cd\",\"race_date\",\"race_number\",\"saddle_cloth_number\",\"gate_name\",\"avg_speed\",\"avg_acceleration\",\"max_speed\",\"min_speed\",\"fatigue_factor\",\"is_fastest_gate\",\"is_slowest_gate\",\"total_distance_run\",\"ground_loss\") VALUES (('TOP'),('2022-01-02 -06'::date),('2'::int4),('10 '),('0.5f'),('15.27'::double precision),('0.0'::double precision),('15.27'::double precision),('15.27'::double precision),('0.28031496062992123'::double precision),('0'::int4),('0'::int4),('1249.1233091901004'::double precision),(NULL)) was aborted: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(TOP, 2022-01-02, 2, 10 , 0.5f) already exists.  Call getNextException to see other errors in the batch.\n",
      "\tat org.postgresql.jdbc.BatchResultHandler.handleError(BatchResultHandler.java:165)\n",
      "\tat org.postgresql.core.ResultHandlerDelegate.handleError(ResultHandlerDelegate.java:52)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2421)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2153)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.flushIfDeadlockRisk(QueryExecutorImpl.java:1503)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.sendQuery(QueryExecutorImpl.java:1528)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:566)\n",
      "\tat org.postgresql.jdbc.PgStatement.internalExecuteBatch(PgStatement.java:888)\n",
      "\tat org.postgresql.jdbc.PgStatement.executeBatch(PgStatement.java:912)\n",
      "\tat org.postgresql.jdbc.PgPreparedStatement.executeBatch(PgPreparedStatement.java:1739)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.savePartition(JdbcUtils.scala:740)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1(JdbcUtils.scala:896)\n",
      "\tat org.apache.spark.sql.execution.datasources.jdbc.JdbcUtils$.$anonfun$saveTable$1$adapted(JdbcUtils.scala:895)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2(RDD.scala:1012)\n",
      "\tat org.apache.spark.rdd.RDD.$anonfun$foreachPartition$2$adapted(RDD.scala:1012)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2298)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\t... 1 more\n",
      "Caused by: org.postgresql.util.PSQLException: ERROR: duplicate key value violates unique constraint \"gps_aggregated_results_with_gates_pkey\"\n",
      "  Detail: Key (course_cd, race_date, race_number, saddle_cloth_number, gate_name)=(TOP, 2022-01-02, 2, 10 , 0.5f) already exists.\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2733)\n",
      "\tat org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2420)\n",
      "\t... 22 more\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Loading data from database for course: HOO\n",
      "INFO:root:None\n",
      "INFO:root:None\n",
      "INFO:root:None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing course: HOO\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- gate_name: string (nullable = true)\n",
      " |-- avg_speed: double (nullable = true)\n",
      " |-- avg_acceleration: double (nullable = true)\n",
      " |-- max_speed: double (nullable = true)\n",
      " |-- min_speed: double (nullable = true)\n",
      " |-- fatigue_factor: double (nullable = true)\n",
      " |-- is_fastest_gate: integer (nullable = true)\n",
      " |-- is_slowest_gate: integer (nullable = true)\n",
      "\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- gate_name: string (nullable = true)\n",
      " |-- avg_speed: double (nullable = true)\n",
      " |-- avg_acceleration: double (nullable = true)\n",
      " |-- max_speed: double (nullable = true)\n",
      " |-- min_speed: double (nullable = true)\n",
      " |-- fatigue_factor: double (nullable = true)\n",
      " |-- is_fastest_gate: integer (nullable = true)\n",
      " |-- is_slowest_gate: integer (nullable = true)\n",
      "\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- total_distance_run: double (nullable = true)\n",
      " |-- ground_loss: double (nullable = true)\n",
      "\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- total_distance_run: double (nullable = true)\n",
      " |-- ground_loss: double (nullable = true)\n",
      "\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- gate_name: string (nullable = true)\n",
      " |-- avg_speed: double (nullable = true)\n",
      " |-- avg_acceleration: double (nullable = true)\n",
      " |-- max_speed: double (nullable = true)\n",
      " |-- min_speed: double (nullable = true)\n",
      " |-- fatigue_factor: double (nullable = true)\n",
      " |-- is_fastest_gate: integer (nullable = true)\n",
      " |-- is_slowest_gate: integer (nullable = true)\n",
      " |-- total_distance_run: double (nullable = true)\n",
      " |-- ground_loss: double (nullable = true)\n",
      "\n",
      "root\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- saddle_cloth_number: string (nullable = true)\n",
      " |-- gate_name: string (nullable = true)\n",
      " |-- avg_speed: double (nullable = true)\n",
      " |-- avg_acceleration: double (nullable = true)\n",
      " |-- max_speed: double (nullable = true)\n",
      " |-- min_speed: double (nullable = true)\n",
      " |-- fatigue_factor: double (nullable = true)\n",
      " |-- is_fastest_gate: integer (nullable = true)\n",
      " |-- is_slowest_gate: integer (nullable = true)\n",
      " |-- total_distance_run: double (nullable = true)\n",
      " |-- ground_loss: double (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/05 22:21:39 ERROR TaskSchedulerImpl: Exception in statusUpdate            \n",
      "java.util.concurrent.RejectedExecutionException: Task org.apache.spark.scheduler.TaskResultGetter$$anon$3@20e51ce5 rejected from java.util.concurrent.ThreadPoolExecutor@58336d97[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 2260]\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2055)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:825)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1355)\n",
      "\tat org.apache.spark.scheduler.TaskResultGetter.enqueueSuccessfulTask(TaskResultGetter.scala:61)\n",
      "\tat org.apache.spark.scheduler.TaskSchedulerImpl.liftedTree2$1(TaskSchedulerImpl.scala:833)\n",
      "\tat org.apache.spark.scheduler.TaskSchedulerImpl.statusUpdate(TaskSchedulerImpl.scala:808)\n",
      "\tat org.apache.spark.scheduler.local.LocalEndpoint$$anonfun$receive$1.applyOrElse(LocalSchedulerBackend.scala:71)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:115)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\n",
      "\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed processing for course: HOO\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession, Window\n",
    "from pyspark.sql.functions import (\n",
    "    col, avg, max as F_max, min as F_min, count, stddev, row_number, lag, lead,\n",
    "    when, lit, first, last, abs, sum as F_sum, udf\n",
    ")\n",
    "from pyspark.sql.types import DoubleType\n",
    "import math\n",
    "import logging\n",
    "\n",
    "# Initialize Spark session\n",
    "def initialize_spark():\n",
    "    jdbc_driver_path = \"/home/exx/myCode/horse-racing/FoxRiverAIRacing/jdbc/postgresql-42.7.4.jar\"\n",
    "    extra_class_path = jdbc_driver_path  # Ensure this is the correct path to your JDBC JAR\n",
    "    spark = SparkSession.builder \\\n",
    "        .appName(\"GPS Sectionals Analysis - Enhanced Aggregation\") \\\n",
    "        .config(\"spark.driver.extraClassPath\", extra_class_path) \\\n",
    "        .config(\"spark.executor.extraClassPath\", extra_class_path) \\\n",
    "        .config(\"spark.driver.memory\", \"64g\") \\\n",
    "        .config(\"spark.executor.memory\", \"32g\") \\\n",
    "        .config(\"spark.executor.memoryOverhead\", \"8g\") \\\n",
    "        .config(\"spark.sql.debug.maxToStringFields\", \"1000\") \\\n",
    "        .config(\"spark.sql.adaptive.enabled\", \"true\") \\\n",
    "        .getOrCreate()\n",
    "    spark.sparkContext.setLogLevel(\"ERROR\")\n",
    "    logging.info(\"Spark session created successfully.\")\n",
    "    return spark\n",
    "\n",
    "# Define the haversine function and UDF\n",
    "def define_haversine_udf():\n",
    "    def haversine(lat1, lon1, lat2, lon2):\n",
    "        # Check for None values\n",
    "        if None in (lat1, lon1, lat2, lon2):\n",
    "            return 0.0\n",
    "        # Convert decimal degrees to radians\n",
    "        lon1, lat1, lon2, lat2 = map(\n",
    "            lambda x: math.radians(float(x)), [lon1, lat1, lon2, lat2]\n",
    "        )\n",
    "        # Haversine formula\n",
    "        dlon = lon2 - lon1\n",
    "        dlat = lat2 - lat1\n",
    "        a = math.sin(dlat / 2) ** 2 + \\\n",
    "            math.cos(lat1) * math.cos(lat2) * math.sin(dlon / 2) ** 2\n",
    "        c = 2 * math.asin(math.sqrt(a))\n",
    "        # Radius of earth in meters\n",
    "        r = 6371000\n",
    "        return c * r\n",
    "    return udf(haversine, DoubleType())\n",
    "\n",
    "# Load data from the database\n",
    "def load_data(spark, course):\n",
    "    # Load sectionals data\n",
    "    sectionals_df = spark.read.jdbc(\n",
    "        url=jdbc_url,\n",
    "        table=\"sectionals\",\n",
    "        properties=jdbc_properties\n",
    "    ).filter(col(\"course_cd\") == course).select(\n",
    "        col(\"course_cd\"),\n",
    "        col(\"race_date\"),\n",
    "        col(\"race_number\"),\n",
    "        col(\"saddle_cloth_number\"),\n",
    "        col(\"gate_name\"),\n",
    "        col(\"length_to_finish\"),\n",
    "        col(\"sectional_time\"),\n",
    "        col(\"running_time\"),\n",
    "        col(\"distance_back\"),\n",
    "        col(\"distance_ran\"),\n",
    "        col(\"number_of_strides\")\n",
    "    )\n",
    "\n",
    "    # Load gpspoint data\n",
    "    gps_df = spark.read.jdbc(\n",
    "        url=jdbc_url,\n",
    "        table=\"gpspoint\",\n",
    "        properties=jdbc_properties\n",
    "    ).filter(col(\"course_cd\") == course).select(\n",
    "        col(\"course_cd\"),\n",
    "        col(\"race_date\"),\n",
    "        col(\"race_number\"),\n",
    "        col(\"saddle_cloth_number\"),\n",
    "        \"time_stamp\",\n",
    "        \"longitude\",\n",
    "        \"latitude\",\n",
    "        \"progress\",\n",
    "        \"speed\",\n",
    "        \"stride_frequency\"\n",
    "    )\n",
    "\n",
    "    # Load races data to get nominal race distance\n",
    "    races_df = spark.read.jdbc(\n",
    "        url=jdbc_url,\n",
    "        table=\"races\",\n",
    "        properties=jdbc_properties\n",
    "    ).filter(col(\"course_cd\") == course).select(\n",
    "        \"course_cd\",\n",
    "        \"race_date\",\n",
    "        \"race_number\",\n",
    "        col(\"distance\").alias(\"nominal_distance\"),\n",
    "        col(\"dist_unit\").alias(\"nominal_dist_unit\")\n",
    "    )\n",
    "    return sectionals_df, gps_df, races_df\n",
    "\n",
    "# Rename columns for clarity\n",
    "def rename_columns(sectionals_df, gps_df, races_df):\n",
    "    sectionals_df = sectionals_df.select(\n",
    "        col(\"course_cd\").alias(\"s_course_cd\"),\n",
    "        col(\"race_date\").alias(\"s_race_date\"),\n",
    "        col(\"race_number\").alias(\"s_race_number\"),\n",
    "        col(\"saddle_cloth_number\").alias(\"s_saddle_cloth_number\"),\n",
    "        \"gate_name\",\n",
    "        \"length_to_finish\",\n",
    "        \"sectional_time\",\n",
    "        \"running_time\",\n",
    "        \"distance_back\",\n",
    "        \"distance_ran\",\n",
    "        \"number_of_strides\"\n",
    "    )\n",
    "\n",
    "    gps_df = gps_df.select(\n",
    "        col(\"course_cd\").alias(\"g_course_cd\"),\n",
    "        col(\"race_date\").alias(\"g_race_date\"),\n",
    "        col(\"race_number\").alias(\"g_race_number\"),\n",
    "        col(\"saddle_cloth_number\").alias(\"g_saddle_cloth_number\"),\n",
    "        \"time_stamp\",\n",
    "        \"longitude\",\n",
    "        \"latitude\",\n",
    "        \"progress\",\n",
    "        \"speed\",\n",
    "        \"stride_frequency\"\n",
    "    )\n",
    "\n",
    "    races_df = races_df.select(\n",
    "        col(\"course_cd\").alias(\"r_course_cd\"),\n",
    "        col(\"race_date\").alias(\"r_race_date\"),\n",
    "        col(\"race_number\").alias(\"r_race_number\"),\n",
    "        col(\"nominal_distance\"),\n",
    "        col(\"nominal_dist_unit\")\n",
    "    )\n",
    "    return sectionals_df, gps_df, races_df\n",
    "\n",
    "# Join sectionals and GPS data\n",
    "def join_sectionals_gps(sectionals_df, gps_df):\n",
    "    gps_with_gates = sectionals_df.alias(\"s\").join(\n",
    "        gps_df.alias(\"g\"),\n",
    "        (col(\"s.s_course_cd\") == col(\"g.g_course_cd\")) &\n",
    "        (col(\"s.s_race_date\") == col(\"g.g_race_date\")) &\n",
    "        (col(\"s.s_race_number\") == col(\"g.g_race_number\")) &\n",
    "        (col(\"s.s_saddle_cloth_number\") == col(\"g.g_saddle_cloth_number\")),\n",
    "        how=\"inner\"\n",
    "    )\n",
    "    return gps_with_gates\n",
    "\n",
    "# Find the closest GPS point to each gate\n",
    "def find_closest_gps_points(gps_with_gates):\n",
    "    gps_with_gates = gps_with_gates.withColumn(\n",
    "        \"progress_diff\",\n",
    "        abs(col(\"g.progress\") - col(\"s.length_to_finish\"))\n",
    "    )\n",
    "\n",
    "    window_spec_gate = Window.partitionBy(\n",
    "        \"s.s_course_cd\",\n",
    "        \"s.s_race_date\",\n",
    "        \"s.s_race_number\",\n",
    "        \"s.s_saddle_cloth_number\",\n",
    "        \"gate_name\"\n",
    "    ).orderBy(\"progress_diff\")\n",
    "\n",
    "    gps_at_gates = gps_with_gates.withColumn(\n",
    "        \"row_number\",\n",
    "        row_number().over(window_spec_gate)\n",
    "    ).filter(col(\"row_number\") == 1).drop(\"row_number\", \"progress_diff\")\n",
    "    return gps_at_gates\n",
    "\n",
    "# Calculate speed changes and acceleration\n",
    "def calculate_speed_acceleration(gps_at_gates):\n",
    "    gate_order_window = Window.partitionBy(\n",
    "        \"s.s_course_cd\",\n",
    "        \"s.s_race_date\",\n",
    "        \"s.s_race_number\",\n",
    "        \"s.s_saddle_cloth_number\"\n",
    "    ).orderBy(\"gate_name\")  # Modify if gate_name is not sortable\n",
    "\n",
    "    gps_at_gates = gps_at_gates.withColumn(\n",
    "        \"previous_speed\",\n",
    "        lag(\"g.speed\").over(gate_order_window)\n",
    "    ).withColumn(\n",
    "        \"speed_change\",\n",
    "        col(\"g.speed\") - col(\"previous_speed\")\n",
    "    ).withColumn(\n",
    "        \"acceleration\",\n",
    "        when(col(\"previous_speed\").isNotNull(),\n",
    "             col(\"speed_change\") / col(\"previous_speed\")\n",
    "             ).otherwise(lit(0))\n",
    "    )\n",
    "    return gps_at_gates\n",
    "\n",
    "# Identify fastest and slowest gates\n",
    "def identify_fastest_slowest_gates(gps_at_gates):\n",
    "    speed_window = Window.partitionBy(\n",
    "        \"s.s_course_cd\",\n",
    "        \"s.s_race_date\",\n",
    "        \"s.s_race_number\",\n",
    "        \"s.s_saddle_cloth_number\"\n",
    "    )\n",
    "\n",
    "    gps_at_gates = gps_at_gates.withColumn(\n",
    "        \"max_speed\",\n",
    "        F_max(\"g.speed\").over(speed_window)\n",
    "    ).withColumn(\n",
    "        \"min_speed\",\n",
    "        F_min(\"g.speed\").over(speed_window)\n",
    "    ).withColumn(\n",
    "        \"is_fastest_gate\",\n",
    "        when(col(\"g.speed\") == col(\"max_speed\"), lit(1)).otherwise(lit(0))\n",
    "    ).withColumn(\n",
    "        \"is_slowest_gate\",\n",
    "        when(col(\"g.speed\") == col(\"min_speed\"), lit(1)).otherwise(lit(0))\n",
    "    )\n",
    "    return gps_at_gates\n",
    "\n",
    "# Calculate fatigue factor\n",
    "def calculate_fatigue_factor(gps_at_gates):\n",
    "    # Extract finish speed\n",
    "    finish_speed = gps_at_gates.filter(col(\"gate_name\") == \"Finish\").select(\n",
    "        col(\"s.s_course_cd\").alias(\"course_cd\"),\n",
    "        col(\"s.s_race_date\").alias(\"race_date\"),\n",
    "        col(\"s.s_race_number\").alias(\"race_number\"),\n",
    "        col(\"s.s_saddle_cloth_number\").alias(\"saddle_cloth_number\"),\n",
    "        col(\"g.speed\").alias(\"finish_speed\")\n",
    "    )\n",
    "\n",
    "    # Join finish speed back to gps_at_gates\n",
    "    gps_at_gates = gps_at_gates.join(\n",
    "        finish_speed,\n",
    "        on=[\n",
    "            gps_at_gates[\"s.s_course_cd\"] == finish_speed[\"course_cd\"],\n",
    "            gps_at_gates[\"s.s_race_date\"] == finish_speed[\"race_date\"],\n",
    "            gps_at_gates[\"s.s_race_number\"] == finish_speed[\"race_number\"],\n",
    "            gps_at_gates[\"s.s_saddle_cloth_number\"] == finish_speed[\"saddle_cloth_number\"]\n",
    "        ],\n",
    "        how=\"left\"\n",
    "    )\n",
    "\n",
    "    # Calculate fatigue factor\n",
    "    gps_at_gates = gps_at_gates.withColumn(\n",
    "        \"fatigue_factor\",\n",
    "        (col(\"max_speed\") - col(\"finish_speed\")) / col(\"max_speed\")\n",
    "    )\n",
    "    return gps_at_gates\n",
    "\n",
    "# Prepare aggregated metrics per gate\n",
    "def prepare_aggregated_metrics(gps_at_gates):\n",
    "    aggregated_metrics = gps_at_gates.select(\n",
    "        col(\"s.s_course_cd\").alias(\"course_cd\"),\n",
    "        col(\"s.s_race_date\").alias(\"race_date\"),\n",
    "        col(\"s.s_race_number\").alias(\"race_number\"),\n",
    "        col(\"s.s_saddle_cloth_number\").alias(\"saddle_cloth_number\"),\n",
    "        \"gate_name\",\n",
    "        col(\"g.speed\").alias(\"speed\"),\n",
    "        \"acceleration\",\n",
    "        \"fatigue_factor\",\n",
    "        \"is_fastest_gate\",\n",
    "        \"is_slowest_gate\"\n",
    "    )\n",
    "\n",
    "    per_gate_metrics = aggregated_metrics.groupBy(\n",
    "        \"course_cd\",\n",
    "        \"race_date\",\n",
    "        \"race_number\",\n",
    "        \"saddle_cloth_number\",\n",
    "        \"gate_name\"\n",
    "    ).agg(\n",
    "        avg(\"speed\").alias(\"avg_speed\"),\n",
    "        avg(\"acceleration\").alias(\"avg_acceleration\"),\n",
    "        F_max(\"speed\").alias(\"max_speed\"),\n",
    "        F_min(\"speed\").alias(\"min_speed\"),\n",
    "        F_max(\"fatigue_factor\").alias(\"fatigue_factor\"),\n",
    "        F_max(\"is_fastest_gate\").alias(\"is_fastest_gate\"),\n",
    "        F_max(\"is_slowest_gate\").alias(\"is_slowest_gate\")\n",
    "    )\n",
    "    return per_gate_metrics\n",
    "\n",
    "# Calculate actual distance run and ground loss\n",
    "def calculate_ground_loss(gps_df, races_df, haversine_udf):\n",
    "    # Define window specification\n",
    "    window_spec_time = Window.partitionBy(\n",
    "        \"g_course_cd\", \"g_race_date\", \"g_race_number\", \"g_saddle_cloth_number\"\n",
    "    ).orderBy(\"time_stamp\")\n",
    "\n",
    "    # Get previous latitude and longitude\n",
    "    gps_df = gps_df.withColumn(\"prev_latitude\", lag(\"latitude\").over(window_spec_time))\n",
    "    gps_df = gps_df.withColumn(\"prev_longitude\", lag(\"longitude\").over(window_spec_time))\n",
    "\n",
    "    # Calculate segment distance using haversine formula\n",
    "    gps_df = gps_df.withColumn(\n",
    "        \"segment_distance\",\n",
    "        haversine_udf(\n",
    "            col(\"prev_latitude\"),\n",
    "            col(\"prev_longitude\"),\n",
    "            col(\"latitude\"),\n",
    "            col(\"longitude\")\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Fill null values\n",
    "    gps_df = gps_df.fillna({\"segment_distance\": 0})\n",
    "\n",
    "    # Calculate cumulative distance\n",
    "    gps_df = gps_df.withColumn(\n",
    "        \"cumulative_distance\",\n",
    "        F_sum(\"segment_distance\").over(window_spec_time)\n",
    "    )\n",
    "\n",
    "    # Get total distance per horse\n",
    "    total_distance_df = gps_df.groupBy(\n",
    "        \"g_course_cd\", \"g_race_date\", \"g_race_number\", \"g_saddle_cloth_number\"\n",
    "    ).agg(\n",
    "        F_max(\"cumulative_distance\").alias(\"total_distance_run\")\n",
    "    )\n",
    "\n",
    "    # Convert nominal distance to meters with proper scaling\n",
    "    races_df = races_df.withColumn(\n",
    "        \"nominal_distance_meters\",\n",
    "        when(col(\"nominal_dist_unit\") == 'F', (col(\"nominal_distance\") / 100) * 201.168)\n",
    "        .when(col(\"nominal_dist_unit\") == 'Y', col(\"nominal_distance\") * 0.9144)\n",
    "        .otherwise(lit(None))\n",
    "    )\n",
    "\n",
    "\n",
    "    # Join total_distance_df with races_df\n",
    "    distance_comparison_df = total_distance_df.join(\n",
    "        races_df,\n",
    "        (total_distance_df[\"g_course_cd\"] == races_df[\"r_course_cd\"]) &\n",
    "        (total_distance_df[\"g_race_date\"] == races_df[\"r_race_date\"]) &\n",
    "        (total_distance_df[\"g_race_number\"] == races_df[\"r_race_number\"]),\n",
    "        how=\"left\"\n",
    "    )\n",
    "\n",
    "    # Calculate ground loss\n",
    "    distance_comparison_df = distance_comparison_df.withColumn(\n",
    "        \"ground_loss\",\n",
    "        col(\"total_distance_run\") - col(\"nominal_distance_meters\")\n",
    "    )\n",
    "\n",
    "    # Join and select required columns\n",
    "    distance_comparison_df = total_distance_df.join(\n",
    "        races_df,\n",
    "        (total_distance_df[\"g_course_cd\"] == races_df[\"r_course_cd\"]) &\n",
    "        (total_distance_df[\"g_race_date\"] == races_df[\"r_race_date\"]) &\n",
    "        (total_distance_df[\"g_race_number\"] == races_df[\"r_race_number\"]),\n",
    "        how=\"left\"\n",
    "    ).withColumn(\n",
    "        \"ground_loss\",\n",
    "        col(\"total_distance_run\") - col(\"nominal_distance_meters\")\n",
    "    ).select(\n",
    "        col(\"g_course_cd\").alias(\"course_cd\"),\n",
    "        col(\"g_race_date\").alias(\"race_date\"),\n",
    "        col(\"g_race_number\").alias(\"race_number\"),\n",
    "        col(\"g_saddle_cloth_number\").alias(\"saddle_cloth_number\"),\n",
    "        \"total_distance_run\",\n",
    "        \"ground_loss\"\n",
    "    )\n",
    "\n",
    "    return distance_comparison_df\n",
    "\n",
    "# Integrate ground loss into final metrics\n",
    "def integrate_ground_loss(per_gate_metrics, distance_comparison_df):\n",
    "    final_metrics = per_gate_metrics.join(\n",
    "        distance_comparison_df,\n",
    "        on=[\"course_cd\", \"race_date\", \"race_number\", \"saddle_cloth_number\"],\n",
    "        how=\"left\"\n",
    "    )\n",
    "    return final_metrics\n",
    "    \n",
    "# Write final metrics to the database\n",
    "def write_to_database(final_metrics):\n",
    "    # Ensure all necessary columns are included\n",
    "    required_columns = [\n",
    "        'course_cd', 'race_date', 'race_number', 'saddle_cloth_number',\n",
    "        'gate_name', 'avg_speed', 'avg_acceleration', 'max_speed', 'min_speed',\n",
    "        'fatigue_factor', 'is_fastest_gate', 'is_slowest_gate',\n",
    "        'total_distance_run', 'ground_loss'\n",
    "    ]\n",
    "\n",
    "    # Check if all required columns are present\n",
    "    missing_columns = [col for col in required_columns if col not in final_metrics.columns]\n",
    "    if missing_columns:\n",
    "        logging.error(f\"Missing columns in final_metrics: {missing_columns}\")\n",
    "        return\n",
    "\n",
    "    # Write final metrics to the database\n",
    "    final_metrics.write.jdbc(\n",
    "        url=jdbc_url,\n",
    "        table=\"gps_aggregated_results_with_gates\",\n",
    "        mode=\"append\",\n",
    "        properties=jdbc_properties\n",
    "    )\n",
    "    \n",
    "# Main processing function for each course\n",
    "def process_course(course, spark, haversine_udf):\n",
    "    print(f\"Processing course: {course}\")\n",
    "\n",
    "    # Load data\n",
    "    sectionals_df, gps_df, races_df = load_data(spark, course)\n",
    "    logging.info(f\"Loading data from database for course: {course}\")\n",
    "    # Rename columns\n",
    "    sectionals_df, gps_df, races_df = rename_columns(sectionals_df, gps_df, races_df)\n",
    "\n",
    "    # Join sectionals and GPS data\n",
    "    gps_with_gates = join_sectionals_gps(sectionals_df, gps_df)\n",
    "\n",
    "    # Find closest GPS points to gates\n",
    "    gps_at_gates = find_closest_gps_points(gps_with_gates)\n",
    "\n",
    "    # Calculate speed changes and acceleration\n",
    "    gps_at_gates = calculate_speed_acceleration(gps_at_gates)\n",
    "\n",
    "    # Identify fastest and slowest gates\n",
    "    gps_at_gates = identify_fastest_slowest_gates(gps_at_gates)\n",
    "\n",
    "    # Calculate fatigue factor\n",
    "    gps_at_gates = calculate_fatigue_factor(gps_at_gates)\n",
    "\n",
    "    # Prepare aggregated metrics\n",
    "    per_gate_metrics = prepare_aggregated_metrics(gps_at_gates)\n",
    "\n",
    "    # Calculate ground loss\n",
    "    distance_comparison_df = calculate_ground_loss(gps_df, races_df, haversine_udf)\n",
    "\n",
    "    per_gate_metrics.printSchema()\n",
    "    logging.info(per_gate_metrics.printSchema())\n",
    "    distance_comparison_df.printSchema()\n",
    "    logging.info(distance_comparison_df.printSchema())\n",
    "    # Integrate ground loss into final metrics\n",
    "    final_metrics = integrate_ground_loss(per_gate_metrics, distance_comparison_df)\n",
    "    \n",
    "    final_metrics = integrate_ground_loss(per_gate_metrics, distance_comparison_df)\n",
    "    final_metrics.printSchema()\n",
    "    logging.info(final_metrics.printSchema())\n",
    "\n",
    "    # Write final metrics to database\n",
    "    write_to_database(final_metrics)\n",
    "\n",
    "    print(f\"Completed processing for course: {course}\")\n",
    "\n",
    "def main():\n",
    "    # Initialize Spark session\n",
    "    spark = initialize_spark()\n",
    "    spark.sparkContext.setLogLevel(\"ERROR\")\n",
    "    # Define haversine UDF\n",
    "    haversine_udf = define_haversine_udf()\n",
    "\n",
    "    # List of courses\n",
    "    courses = ['CNL', 'SAR', 'PIM', 'TSA', 'BEL', 'MVR', 'TWO', 'CLS', 'KEE', 'TAM',\n",
    "               'TTP', 'TKD', 'ELP', 'PEN', 'HOU', 'DMR', 'TLS', 'AQU', 'MTH', 'TGP',\n",
    "               'TGG', 'CBY', 'LRL', 'TED', 'IND', 'CTD', 'ASD', 'TCD', 'LAD', 'MED',\n",
    "               'TOP', 'HOO']\n",
    "\n",
    "    # Process each course\n",
    "    for course in courses:\n",
    "        try:\n",
    "            process_course(course, spark, haversine_udf)\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error processing course {course}: {e}\")\n",
    "\n",
    "    # Stop Spark session\n",
    "    spark.stop()\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f75611-2333-4205-8bce-0d9280c55440",
   "metadata": {},
   "source": [
    "1. Modular Functions\n",
    "\n",
    ">    •\tinitialize_spark(): Sets up the Spark session with the necessary configurations.\n",
    "> \n",
    ">    •\tdefine_haversine_udf(): Defines the Haversine function to calculate distances between GPS points and registers it as a UDF.\n",
    "> \n",
    ">\t•\t**load_data()**: Loads the sectionals, gpspoint, and races data from the database for a given course.\n",
    "> \n",
    "> \t•\trename_columns(): Aliases columns in the DataFrames for clarity and to avoid naming conflicts.\n",
    "> \n",
    "> \t•\tjoin_sectionals_gps(): Joins the sectionals and gpspoint DataFrames on the race and horse identifiers.\n",
    "> \n",
    ">\t•\tfind_closest_gps_points(): Finds the closest GPS point to each gate for each horse.\n",
    "> \n",
    "> \t•\tcalculate_speed_acceleration(): Calculates speed changes and acceleration between gates.\n",
    "> \n",
    ">\t•\tidentify_fastest_slowest_gates(): Identifies the fastest and slowest gates for each horse.\n",
    "> \n",
    ">\t•\tcalculate_fatigue_factor(): Computes the fatigue factor for each horse based on their maximum speed and finish speed.\n",
    "> \n",
    ">\t•\tprepare_aggregated_metrics(): Aggregates the metrics per gate and per horse.\n",
    "> \n",
    ">\t•\tcalculate_ground_loss(): Calculates the actual distance run by each horse and computes the ground loss compared to the nominal race distance.\n",
    "> \n",
    ">\t•\tintegrate_ground_loss(): Integrates the ground loss metric into the final aggregated metrics.\n",
    ">\t•\twrite_to_database(): Writes the final metrics to the database.\n",
    "> \n",
    ">\t•\tprocess_course(): Orchestrates the processing steps for a single course.\n",
    "> \n",
    ">\t•\tmain(): The main function that initializes the Spark session, processes each course, and stops the Spark session.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4714c416-49e6-4ab7-899e-8a36276825dd",
   "metadata": {},
   "source": [
    "Next Steps\n",
    "\n",
    "\t1.\tVisualization:\n",
    "\t•\tPlot speed and stride frequency trends across gates for specific horses to validate the analysis.\n",
    "\t2.\tTesting:\n",
    "\t•\tApply this to a few more courses to confirm that the calculations are meaningful and robust across different races.\n",
    "\t3.\tAnalysis:\n",
    "\t•\tCompare fatigue factors or speed trends between winners and non-winners to derive insights about race dynamics.\n",
    "\n",
    "These enhancements should provide valuable insights and improve the predictive capabilities of your analysis!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ffe146d-1e27-4d44-a282-06623496d1f0",
   "metadata": {},
   "source": [
    "\n",
    "# Additional steps to derive fatigue factors, sectional efficiency, etc.\n",
    "\n",
    "Innovative Applications\n",
    "\n",
    "\t1.\tPredictive Fatigue Model: Train a model using TPD data to predict fatigue thresholds for horses.\n",
    "\t2.\tRace Simulation: Use historical TPD data to simulate how horses might perform in upcoming races.\n",
    "\t3.\tDynamic Betting Insights: Provide real-time insights into how race conditions or competitor performance might influence outcomes.\n",
    "\n",
    "Spark’s distributed computing will allow you to process the large dataset efficiently and scale as needed. By creatively combining TPD and EQB data, you can uncover insights that traditional analysis might overlook.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
