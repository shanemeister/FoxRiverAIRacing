{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b13d3cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Setup Environment\n",
    "import time\n",
    "from optuna.importance import MeanDecreaseImpurityImportanceEvaluator\n",
    "import os\n",
    "import io\n",
    "import logging\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib # Used for encoding horse_id\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.utils import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "import optuna\n",
    "import optuna.visualization as viz\n",
    "from optuna.pruners import MedianPruner\n",
    "from catboost import CatBoostRanker, CatBoostRegressor, CatBoostClassifier, Pool\n",
    "import catboost as cb\n",
    "import numpy as np\n",
    "import itertools\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.functions import (col, count, row_number, abs, unix_timestamp, mean, \n",
    "                                   when, lit, min as F_min, max as F_max , upper, trim,\n",
    "                                   row_number, mean as F_mean, countDistinct, last, first, when)\n",
    "from src.data_preprocessing.data_prep1.data_utils import initialize_environment \n",
    "# Set global references to None\n",
    "spark = None\n",
    "master_results_df = None\n",
    "race_df = None\n",
    "df = None\n",
    "training_data = None\n",
    "train_df = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef1b02ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark session created successfully.\n"
     ]
    }
   ],
   "source": [
    "spark, jdbc_url, jdbc_properties, parquet_dir, log_file = initialize_environment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4fff6c10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- axciskey: string (nullable = true)\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: double (nullable = true)\n",
      " |-- horse_id: double (nullable = true)\n",
      " |-- horse_name: string (nullable = true)\n",
      " |-- official_fin: long (nullable = true)\n",
      " |-- time_behind: double (nullable = true)\n",
      " |-- pace_delta_time: double (nullable = true)\n",
      " |-- speed_rating: long (nullable = true)\n",
      " |-- prev_speed_rating: double (nullable = true)\n",
      " |-- previous_class: double (nullable = true)\n",
      " |-- purse: double (nullable = true)\n",
      " |-- weight: double (nullable = true)\n",
      " |-- sex: string (nullable = true)\n",
      " |-- equip: string (nullable = true)\n",
      " |-- claimprice: double (nullable = true)\n",
      " |-- surface: string (nullable = true)\n",
      " |-- distance_meters: double (nullable = true)\n",
      " |-- class_rating: double (nullable = true)\n",
      " |-- previous_distance: double (nullable = true)\n",
      " |-- previous_surface: string (nullable = true)\n",
      " |-- off_finish_last_race: long (nullable = true)\n",
      " |-- power: double (nullable = true)\n",
      " |-- trk_cond: string (nullable = true)\n",
      " |-- med: string (nullable = true)\n",
      " |-- morn_odds: double (nullable = true)\n",
      " |-- avgspd: double (nullable = true)\n",
      " |-- starts: long (nullable = true)\n",
      " |-- race_type: string (nullable = true)\n",
      " |-- net_sentiment: double (nullable = true)\n",
      " |-- stk_clm_md: string (nullable = true)\n",
      " |-- turf_mud_mark: string (nullable = true)\n",
      " |-- avg_spd_sd: double (nullable = true)\n",
      " |-- ave_cl_sd: double (nullable = true)\n",
      " |-- hi_spd_sd: double (nullable = true)\n",
      " |-- pstyerl: double (nullable = true)\n",
      " |-- all_starts: double (nullable = true)\n",
      " |-- all_win: double (nullable = true)\n",
      " |-- all_place: double (nullable = true)\n",
      " |-- all_show: double (nullable = true)\n",
      " |-- all_fourth: double (nullable = true)\n",
      " |-- all_earnings: double (nullable = true)\n",
      " |-- horse_itm_percentage: double (nullable = true)\n",
      " |-- cond_starts: double (nullable = true)\n",
      " |-- cond_win: double (nullable = true)\n",
      " |-- cond_place: double (nullable = true)\n",
      " |-- cond_show: double (nullable = true)\n",
      " |-- cond_fourth: double (nullable = true)\n",
      " |-- cond_earnings: double (nullable = true)\n",
      " |-- jock_win_percent: double (nullable = true)\n",
      " |-- jock_itm_percent: double (nullable = true)\n",
      " |-- trainer_win_percent: double (nullable = true)\n",
      " |-- trainer_itm_percent: double (nullable = true)\n",
      " |-- jt_win_percent: double (nullable = true)\n",
      " |-- jt_itm_percent: double (nullable = true)\n",
      " |-- jock_win_track: double (nullable = true)\n",
      " |-- jock_itm_track: double (nullable = true)\n",
      " |-- trainer_win_track: double (nullable = true)\n",
      " |-- trainer_itm_track: double (nullable = true)\n",
      " |-- jt_win_track: double (nullable = true)\n",
      " |-- jt_itm_track: double (nullable = true)\n",
      " |-- sire_itm_percentage: double (nullable = true)\n",
      " |-- sire_roi: double (nullable = true)\n",
      " |-- dam_itm_percentage: double (nullable = true)\n",
      " |-- dam_roi: double (nullable = true)\n",
      " |-- total_races_5: double (nullable = true)\n",
      " |-- avg_fin_5: double (nullable = true)\n",
      " |-- avg_speed_5: double (nullable = true)\n",
      " |-- best_speed: double (nullable = true)\n",
      " |-- avg_beaten_len_5: double (nullable = true)\n",
      " |-- first_race_date_5: date (nullable = true)\n",
      " |-- most_recent_race_5: date (nullable = true)\n",
      " |-- avg_dist_bk_gate1_5: double (nullable = true)\n",
      " |-- avg_dist_bk_gate2_5: double (nullable = true)\n",
      " |-- avg_dist_bk_gate3_5: double (nullable = true)\n",
      " |-- avg_dist_bk_gate4_5: double (nullable = true)\n",
      " |-- avg_speed_fullrace_5: double (nullable = true)\n",
      " |-- avg_stride_length_5: double (nullable = true)\n",
      " |-- avg_strfreq_q1_5: double (nullable = true)\n",
      " |-- avg_strfreq_q2_5: double (nullable = true)\n",
      " |-- avg_strfreq_q3_5: double (nullable = true)\n",
      " |-- avg_strfreq_q4_5: double (nullable = true)\n",
      " |-- prev_speed: double (nullable = true)\n",
      " |-- speed_improvement: double (nullable = true)\n",
      " |-- prev_race_date: date (nullable = true)\n",
      " |-- days_off: double (nullable = true)\n",
      " |-- layoff_cat: string (nullable = true)\n",
      " |-- avg_workout_rank_3: double (nullable = true)\n",
      " |-- count_workouts_3: double (nullable = true)\n",
      " |-- race_count: double (nullable = true)\n",
      " |-- track_name: string (nullable = true)\n",
      " |-- age_at_race_day: double (nullable = true)\n",
      " |-- gps_present: long (nullable = true)\n",
      " |-- race_id: string (nullable = true)\n",
      " |-- group_id: long (nullable = true)\n",
      " |-- perf_target: long (nullable = true)\n",
      " |-- custom_speed_figure: double (nullable = true)\n",
      " |-- horse_idx: long (nullable = true)\n",
      " |-- embed_0: double (nullable = true)\n",
      " |-- embed_1: double (nullable = true)\n",
      " |-- embed_2: double (nullable = true)\n",
      " |-- embed_3: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "    full_path = f\"/home/exx/myCode/horse-racing/FoxRiverAIRacing/data/parquet/horse_embedding_data-2025-01-25-2309.parquet\" #os.path.join(parquet_dir, model_filename)\n",
    "\n",
    "    horse_embedding_sdf = spark.read.parquet(full_path)\n",
    "    logging.info(\"Schema of horse_embedding_sdf:\")\n",
    "    horse_embedding_sdf.printSchema()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ad16341",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = horse_embedding_sdf.toPandas()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6402833b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=[\"official_fin\"], errors=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7302846d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['axciskey', 'course_cd', 'race_date', 'race_number', 'horse_id',\n",
       "       'horse_name', 'time_behind', 'pace_delta_time', 'speed_rating',\n",
       "       'prev_speed_rating',\n",
       "       ...\n",
       "       'gps_present', 'race_id', 'group_id', 'perf_target',\n",
       "       'custom_speed_figure', 'horse_idx', 'embed_0', 'embed_1', 'embed_2',\n",
       "       'embed_3'],\n",
       "      dtype='object', length=102)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d4930551",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 328184, Columns: 102\n"
     ]
    }
   ],
   "source": [
    "    # Show basic info\n",
    "rows, cols = df.shape\n",
    "print(f\"Rows: {rows}, Columns: {cols}\")\n",
    "#print(f\"Columns: {df.columns.tolist()}\")\n",
    "#print(f\"Dtypes:\\n{df.dtypes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c67aa1ec",
   "metadata": {},
   "source": [
    "###############################################################################\n",
    "# 1) Handle certain datetime columns\n",
    "###############################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e6ed4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime_columns = [\"first_race_date_5\", \"most_recent_race_5\", \"prev_race_date\"]\n",
    "# Convert each datetime column, but store the \"numeric\" versions in a dict of new columns\n",
    "new_numeric_cols = {}\n",
    "for col in datetime_columns:\n",
    "    df[col] = pd.to_datetime(df[col])\n",
    "    new_numeric_cols[col + \"_numeric\"] = (df[col] - pd.Timestamp(\"1970-01-01\")).dt.days\n",
    "\n",
    "# Drop all original datetime columns at once:\n",
    "df.drop(columns=datetime_columns, inplace=True, errors=\"ignore\")\n",
    "\n",
    "# Now concat all new numeric columns in a single step\n",
    "df = pd.concat([df, pd.DataFrame(new_numeric_cols, index=df.index)], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8fb0e81",
   "metadata": {},
   "source": [
    "###############################################################################\n",
    "# 2) Split Data Chronologically (Train up to 2023-12-31, etc.)\n",
    "###############################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468545e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"race_date\"] = pd.to_datetime(df[\"race_date\"])\n",
    "\n",
    "train_end_date = pd.to_datetime(\"2023-12-31\")\n",
    "valid_data_end_date = pd.to_datetime(\"2024-06-30\")\n",
    "holdout_start = pd.to_datetime(\"2024-07-01\")\n",
    "\n",
    "# Note: check your date logic carefully. \n",
    "train_data = df[df[\"race_date\"] <= train_end_date].copy()\n",
    "valid_data = df[(df[\"race_date\"] > train_end_date) & (df[\"race_date\"] <= valid_data_end_date)].copy()\n",
    "holdout_data = df[df[\"race_date\"] >= holdout_start].copy()\n",
    "\n",
    "print(f\"Train shape: {train_data.shape}\")\n",
    "print(f\"Valid shape: {valid_data.shape}\")\n",
    "print(f\"Holdout shape: {holdout_data.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36ec55b",
   "metadata": {},
   "source": [
    "###############################################################################\n",
    "# 3) Identify Categorical, Embed and Numeric Columns\n",
    "###############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78745e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = [\n",
    "        \"course_cd\", \"trk_cond\", \"sex\", \"equip\", \"surface\", \"med\",\n",
    "        \"race_type\", \"stk_clm_md\", \"turf_mud_mark\", \"layoff_cat\",\n",
    "        \"previous_surface\"\n",
    "    ]\n",
    "    # Removed duplicate \"surface\" from that list if it was repeated.\n",
    "\n",
    "label_col = \"perf_target\"\n",
    "\n",
    "# We'll add the embed_0..embed_63 columns if they exist\n",
    "embed_cols = [f\"embed_{i}\" for i in range(64)]\n",
    "\n",
    "# numeric_cols: all float64/int64 except label_col\n",
    "# We'll define them for each sub-data because they differ after merges/drops\n",
    "# For now, let's define them from train_data\n",
    "def get_numeric_cols(df_):\n",
    "    # Potential numeric\n",
    "    cand = [c for c in df_.columns if df_[c].dtype in [np.float64, np.int64]]\n",
    "    # Exclude the label col\n",
    "    cand = [c for c in cand if c != label_col]\n",
    "    return cand\n",
    "\n",
    "numeric_cols_train = get_numeric_cols(train_data)\n",
    "# add embed columns if they're not already included \n",
    "for ec in embed_cols:\n",
    "    if ec not in numeric_cols_train and ec in train_data.columns:\n",
    "        numeric_cols_train.append(ec)\n",
    "\n",
    "# We'll do the same or similar for valid_data, holdout_data if needed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b57dcadf",
   "metadata": {},
   "source": [
    "###############################################################################\n",
    "# 4) Sort by group_id if it exists, then create X,y,group\n",
    "###############################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ff35ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"group_id\" in train_data.columns:\n",
    "    train_data.sort_values(\"group_id\", ascending=True, inplace=True)\n",
    "if \"group_id\" in valid_data.columns:\n",
    "    valid_data.sort_values(\"group_id\", ascending=True, inplace=True)\n",
    "if \"group_id\" in holdout_data.columns:\n",
    "    holdout_data.sort_values(\"group_id\", ascending=True, inplace=True)\n",
    "    \n",
    "all_training_cols = numeric_cols_train + cat_cols\n",
    "# remove duplicates\n",
    "all_training_cols = list(set(all_training_cols))\n",
    "\n",
    "# Build X,y for train\n",
    "X_train = train_data.drop(columns=[label_col], errors=\"ignore\")\n",
    "X_train = train_data[all_training_cols].copy()\n",
    "y_train = train_data[label_col]\n",
    "if \"group_id\" in train_data.columns:\n",
    "    train_group_id = train_data[\"group_id\"]\n",
    "else:\n",
    "    train_group_id = pd.Series(np.zeros(len(train_data)), index=train_data.index)\n",
    "\n",
    "# Build X,y for valid\n",
    "X_valid = valid_data.drop(columns=[label_col], errors=\"ignore\")\n",
    "X_valid = valid_data[all_training_cols].copy()\n",
    "y_valid = valid_data[label_col]\n",
    "if \"group_id\" in valid_data.columns:\n",
    "    valid_group_id = valid_data[\"group_id\"]\n",
    "else:\n",
    "    valid_group_id = pd.Series(np.zeros(len(valid_data)), index=valid_data.index)\n",
    "\n",
    "# Build X,y for holdout\n",
    "X_holdout = holdout_data.drop(columns=[label_col], errors=\"ignore\")\n",
    "X_holdout = holdout_data[all_training_cols].copy()\n",
    "y_holdout = holdout_data[label_col]\n",
    "if \"group_id\" in holdout_data.columns:\n",
    "    holdout_group_id = holdout_data[\"group_id\"]\n",
    "else:\n",
    "    holdout_group_id = pd.Series(np.zeros(len(holdout_data)), index=holdout_data.index)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83743e9a",
   "metadata": {},
   "source": [
    "###############################################################################\n",
    "# 5) Create CatBoost Pools\n",
    "###############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a71987",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# cat_features_idx: indices in X_train that match cat_cols\n",
    "# We only do it for the columns that truly exist in X_train\n",
    "train_col_list = X_train.columns.tolist()\n",
    "cat_features_idx = [train_col_list.index(c) for c in cat_cols if c in train_col_list]\n",
    "\n",
    "train_pool = Pool(\n",
    "    data=X_train,\n",
    "    label=y_train,\n",
    "    group_id=train_group_id,\n",
    "    cat_features=cat_features_idx\n",
    ")\n",
    "\n",
    "valid_pool = Pool(\n",
    "    data=X_valid,\n",
    "    label=y_valid,\n",
    "    group_id=valid_group_id,\n",
    "    cat_features=cat_features_idx\n",
    ")\n",
    "\n",
    "holdout_pool = Pool(\n",
    "    data=X_holdout,\n",
    "    label=y_holdout,\n",
    "    group_id=holdout_group_id,\n",
    "    cat_features=cat_features_idx\n",
    ")\n",
    "\n",
    "print(f\"X_train shape: {X_train.shape}, y_train length: {len(y_train)}\")\n",
    "print(f\"X_valid shape: {X_valid.shape}, y_valid length: {len(y_valid)}\")\n",
    "print(f\"X_holdout shape: {X_holdout.shape}, y_holdout length: {len(y_holdout)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b864a1e",
   "metadata": {},
   "source": [
    "###############################################################################\n",
    "# 6) Define Utility for get_timestamp\n",
    "###############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97d4681",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_timestamp():\n",
    "    return datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04c24a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train.columns"
   ]
  },
  {
   "cell_type": "raw",
   "id": "05193738",
   "metadata": {},
   "source": [
    "Index(['avg_fin_5', 'all_show', 'all_starts', 'first_race_date_5_numeric',\n",
    "       'embed_3', 'jock_itm_track', 'cond_show', 'sire_roi', 'race_count',\n",
    "       'avg_dist_bk_gate3_5', 'embed_1', 'race_type', 'cond_fourth',\n",
    "       'turf_mud_mark', 'avg_dist_bk_gate1_5', 'dam_roi', 'class_rating',\n",
    "       'avg_beaten_len_5', 'starts', 'avg_strfreq_q2_5', 'all_place',\n",
    "       'stk_clm_md', 'avg_strfreq_q3_5', 'morn_odds', 'trainer_itm_percent',\n",
    "       'best_speed', 'pace_delta_time', 'trainer_itm_track', 'cond_earnings',\n",
    "       'race_number', 'sex', 'cond_place', 'jock_win_track', 'previous_class',\n",
    "       'med', 'prev_speed_rating', 'equip', 'prev_race_date_numeric',\n",
    "       'gps_present', 'embed_2', 'dam_itm_percentage', 'surface',\n",
    "       'most_recent_race_5_numeric', 'horse_idx', 'trainer_win_percent',\n",
    "       'off_finish_last_race', 'trk_cond', 'all_earnings', 'avg_spd_sd',\n",
    "       'ave_cl_sd', 'avg_workout_rank_3', 'days_off', 'pstyerl',\n",
    "       'avg_stride_length_5', 'purse', 'trainer_win_track', 'distance_meters',\n",
    "       'prev_speed', 'avg_dist_bk_gate4_5', 'horse_itm_percentage',\n",
    "       'course_cd', 'age_at_race_day', 'avg_dist_bk_gate2_5',\n",
    "       'custom_speed_figure', 'weight', 'embed_0', 'count_workouts_3',\n",
    "       'avg_speed_5', 'speed_rating', 'power', 'jt_itm_track', 'cond_win',\n",
    "       'avg_speed_fullrace_5', 'all_fourth', 'hi_spd_sd', 'jock_win_percent',\n",
    "       'jock_itm_percent', 'avgspd', 'avg_strfreq_q4_5', 'total_races_5',\n",
    "       'speed_improvement', 'layoff_cat', 'net_sentiment', 'official_fin',\n",
    "       'jt_win_percent', 'all_win', 'horse_id', 'jt_itm_percent',\n",
    "       'sire_itm_percentage', 'previous_distance', 'jt_win_track', 'group_id',\n",
    "       'avg_strfreq_q1_5', 'claimprice', 'cond_starts', 'previous_surface',\n",
    "       'time_behind'],\n",
    "      dtype='object')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f08326",
   "metadata": {},
   "source": [
    "###############################################################################\n",
    "# 7) Define the objective, run_optuna, final training\n",
    "###############################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6da02a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def objective(trial):\n",
    "        params = {\n",
    "            \"loss_function\": \"YetiRank:top=3\",    # or pass in as an argument\n",
    "            \"eval_metric\": \"NDCG:top=3\",\n",
    "            \"task_type\": \"GPU\",\n",
    "            \"iterations\": trial.suggest_int(\"iterations\", 500, 3000, step=500),\n",
    "            \"depth\": trial.suggest_int(\"depth\", 4, 12),\n",
    "            \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-3, 0.3, log=True),\n",
    "            \"l2_leaf_reg\": trial.suggest_float(\"l2_leaf_reg\", 1.0, 20.0),\n",
    "            \"random_seed\": 42,\n",
    "            \"verbose\": 100,\n",
    "        }\n",
    "\n",
    "        # Grow policy\n",
    "        grow_policy = trial.suggest_categorical(\"grow_policy\", [\"SymmetricTree\", \"Depthwise\", \"Lossguide\"])\n",
    "        params[\"grow_policy\"] = grow_policy\n",
    "        if grow_policy == \"Lossguide\":\n",
    "            params[\"max_leaves\"] = trial.suggest_int(\"max_leaves\", 32, 256, step=32)\n",
    "\n",
    "        # Bootstrap type\n",
    "        bootstrap_type = trial.suggest_categorical(\"bootstrap_type\", [\"Bayesian\", \"Bernoulli\", \"Poisson\", \"MVS\"])\n",
    "        params[\"bootstrap_type\"] = bootstrap_type\n",
    "\n",
    "        if bootstrap_type == \"Bernoulli\":\n",
    "            params[\"subsample\"] = trial.suggest_float(\"subsample\", 0.5, 1.0)\n",
    "        elif bootstrap_type == \"Bayesian\":\n",
    "            params[\"bagging_temperature\"] = trial.suggest_float(\"bagging_temperature\", 0.0, 2.0)\n",
    "\n",
    "        # random_strength\n",
    "        params[\"random_strength\"] = trial.suggest_float(\"random_strength\", 0.0, 20.0)\n",
    "\n",
    "        # border_count\n",
    "        params[\"border_count\"] = trial.suggest_int(\"border_count\", 32, 512, step=32)\n",
    "\n",
    "        # early stopping\n",
    "        params[\"od_type\"] = \"Iter\"\n",
    "        params[\"od_wait\"] = trial.suggest_int(\"od_wait\", 20, 100, step=10)\n",
    "\n",
    "        model = CatBoostRanker(**params)\n",
    "        model.fit(train_pool, eval_set=valid_pool)\n",
    "\n",
    "        score_dict = model.get_best_score()\n",
    "        print(\"Model Best Scores:\", score_dict)\n",
    "\n",
    "        # We'll assume we can read \"NDCG:top=3\" from score_dict\n",
    "        valid_ndcg = 0.0\n",
    "        if \"validation\" in score_dict:\n",
    "            metric_key = \"NDCG:top=3;type=Base\"\n",
    "            valid_ndcg = score_dict[\"validation\"].get(metric_key, 0.0)\n",
    "        else:\n",
    "            # fallback to manual ndcg\n",
    "            val_preds = model.predict(valid_pool)\n",
    "            true_labels = y_valid.values.reshape(1, -1)\n",
    "            predicted_scores = val_preds.reshape(1, -1)\n",
    "            valid_ndcg = ndcg_score(true_labels, predicted_scores, k=3)\n",
    "\n",
    "        return valid_ndcg\n",
    "\n",
    "    def run_optuna_search(n_trials=100):\n",
    "        \"\"\"Simple function to create an Optuna study and run the objective above.\"\"\"\n",
    "        study = optuna.create_study(\n",
    "            direction=\"maximize\",\n",
    "            pruner=MedianPruner(n_warmup_steps=3)\n",
    "        )\n",
    "        study.optimize(objective, n_trials=n_trials)\n",
    "        return study\n",
    "\n",
    "    def train_and_save_model(best_params, model_save_dir):\n",
    "        \"\"\"Train final model with best_params, then save to .cbm.\"\"\"\n",
    "        recognized_params = dict(best_params)\n",
    "        recognized_params[\"loss_function\"] = \"YetiRank:top=3\"\n",
    "        recognized_params[\"eval_metric\"] = \"NDCG:top=3\"\n",
    "        recognized_params[\"random_seed\"] = 42\n",
    "        recognized_params[\"task_type\"] = \"GPU\"\n",
    "\n",
    "        final_model = CatBoostRanker(**recognized_params)\n",
    "        final_model.fit(\n",
    "            train_pool,\n",
    "            eval_set=valid_pool,\n",
    "            early_stopping_rounds=100,\n",
    "            verbose=100\n",
    "        )\n",
    "\n",
    "        os.makedirs(model_save_dir, exist_ok=True)\n",
    "        timestamp = get_timestamp()\n",
    "        model_filename = f\"catboost_YetiRank_top3_{timestamp}.cbm\"\n",
    "        model_path = os.path.join(model_save_dir, model_filename)\n",
    "        final_model.save_model(model_path)\n",
    "        logging.info(f\"Final model saved to: {model_path}\")\n",
    "        return final_model, model_path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2de865d",
   "metadata": {},
   "source": [
    "###############################################################################\n",
    "# 8) Run the hyperparameter search\n",
    "###############################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2dca9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(\"=== Starting Optuna search for YetiRank:top=3 / NDCG:top=3 ===\")\n",
    "study = run_optuna_search(n_trials=300)  # or 500 if you want bigger search\n",
    "\n",
    "best_score = study.best_value\n",
    "best_params = study.best_params\n",
    "logging.info(f\"Best NDCG@3: {best_score}, Best params: {best_params}\")\n",
    "\n",
    "# Save the best params to a JSON\n",
    "with open(\"./data/training/best_params.json\", \"w\") as f:\n",
    "    json.dump(best_params, f, indent=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f5a56d",
   "metadata": {},
   "source": [
    "###############################################################################\n",
    "# 9) Train final model with best params\n",
    "###############################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc379e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model, model_path = train_and_save_model(best_params, \"/home/exx/myCode/horse-racing/FoxRiverAIRacing/data/models/catboost\")\n",
    "logging.info(f\"Saved final model to: {model_path}\")\n",
    "\n",
    "# Evaluate on holdout if you want\n",
    "holdout_preds = final_model.predict(holdout_pool)\n",
    "holdout_true = y_holdout.values.reshape(1, -1)\n",
    "holdout_scores = holdout_preds.reshape(1, -1)\n",
    "holdout_ndcg = ndcg_score(holdout_true, holdout_scores, k=3)\n",
    "logging.info(f\"Holdout NDCG@3: {holdout_ndcg:.4f}\")\n",
    "\n",
    "logging.info(\"=== Done training CatBoost model ===\")\n",
    "\n",
    "return model_path  # or whatever you want to return"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
