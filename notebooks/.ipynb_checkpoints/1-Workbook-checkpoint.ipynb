{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b13d3cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Setup Environment\n",
    "import time\n",
    "from optuna.importance import MeanDecreaseImpurityImportanceEvaluator\n",
    "import os\n",
    "import io\n",
    "import logging\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib # Used for encoding horse_id\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.utils import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "import optuna\n",
    "import optuna.visualization as viz\n",
    "from optuna.pruners import MedianPruner\n",
    "from catboost import CatBoostRanker, CatBoostRegressor, CatBoostClassifier, Pool\n",
    "import catboost as cb\n",
    "import numpy as np\n",
    "import itertools\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.functions import (col, count, row_number, abs, unix_timestamp, mean, \n",
    "                                   when, lit, min as F_min, max as F_max , upper, trim,\n",
    "                                   row_number, mean as F_mean, countDistinct, last, first, when)\n",
    "from src.data_preprocessing.data_prep1.data_utils import initialize_environment \n",
    "# Set global references to None\n",
    "spark = None\n",
    "master_results_df = None\n",
    "race_df = None\n",
    "df = None\n",
    "training_data = None\n",
    "train_df = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef1b02ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark session created successfully.\n"
     ]
    }
   ],
   "source": [
    "spark, jdbc_url, jdbc_properties, parquet_dir, log_file = initialize_environment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4fff6c10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- axciskey: string (nullable = true)\n",
      " |-- course_cd: string (nullable = true)\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: double (nullable = true)\n",
      " |-- horse_id: double (nullable = true)\n",
      " |-- horse_name: string (nullable = true)\n",
      " |-- official_fin: long (nullable = true)\n",
      " |-- time_behind: double (nullable = true)\n",
      " |-- pace_delta_time: double (nullable = true)\n",
      " |-- speed_rating: long (nullable = true)\n",
      " |-- prev_speed_rating: double (nullable = true)\n",
      " |-- previous_class: double (nullable = true)\n",
      " |-- purse: double (nullable = true)\n",
      " |-- weight: double (nullable = true)\n",
      " |-- sex: string (nullable = true)\n",
      " |-- equip: string (nullable = true)\n",
      " |-- claimprice: double (nullable = true)\n",
      " |-- surface: string (nullable = true)\n",
      " |-- distance_meters: double (nullable = true)\n",
      " |-- class_rating: double (nullable = true)\n",
      " |-- previous_distance: double (nullable = true)\n",
      " |-- previous_surface: string (nullable = true)\n",
      " |-- off_finish_last_race: long (nullable = true)\n",
      " |-- power: double (nullable = true)\n",
      " |-- trk_cond: string (nullable = true)\n",
      " |-- med: string (nullable = true)\n",
      " |-- morn_odds: double (nullable = true)\n",
      " |-- avgspd: double (nullable = true)\n",
      " |-- starts: long (nullable = true)\n",
      " |-- race_type: string (nullable = true)\n",
      " |-- net_sentiment: double (nullable = true)\n",
      " |-- stk_clm_md: string (nullable = true)\n",
      " |-- turf_mud_mark: string (nullable = true)\n",
      " |-- avg_spd_sd: double (nullable = true)\n",
      " |-- ave_cl_sd: double (nullable = true)\n",
      " |-- hi_spd_sd: double (nullable = true)\n",
      " |-- pstyerl: double (nullable = true)\n",
      " |-- all_starts: double (nullable = true)\n",
      " |-- all_win: double (nullable = true)\n",
      " |-- all_place: double (nullable = true)\n",
      " |-- all_show: double (nullable = true)\n",
      " |-- all_fourth: double (nullable = true)\n",
      " |-- all_earnings: double (nullable = true)\n",
      " |-- horse_itm_percentage: double (nullable = true)\n",
      " |-- cond_starts: double (nullable = true)\n",
      " |-- cond_win: double (nullable = true)\n",
      " |-- cond_place: double (nullable = true)\n",
      " |-- cond_show: double (nullable = true)\n",
      " |-- cond_fourth: double (nullable = true)\n",
      " |-- cond_earnings: double (nullable = true)\n",
      " |-- jock_win_percent: double (nullable = true)\n",
      " |-- jock_itm_percent: double (nullable = true)\n",
      " |-- trainer_win_percent: double (nullable = true)\n",
      " |-- trainer_itm_percent: double (nullable = true)\n",
      " |-- jt_win_percent: double (nullable = true)\n",
      " |-- jt_itm_percent: double (nullable = true)\n",
      " |-- jock_win_track: double (nullable = true)\n",
      " |-- jock_itm_track: double (nullable = true)\n",
      " |-- trainer_win_track: double (nullable = true)\n",
      " |-- trainer_itm_track: double (nullable = true)\n",
      " |-- jt_win_track: double (nullable = true)\n",
      " |-- jt_itm_track: double (nullable = true)\n",
      " |-- sire_itm_percentage: double (nullable = true)\n",
      " |-- sire_roi: double (nullable = true)\n",
      " |-- dam_itm_percentage: double (nullable = true)\n",
      " |-- dam_roi: double (nullable = true)\n",
      " |-- total_races_5: double (nullable = true)\n",
      " |-- avg_fin_5: double (nullable = true)\n",
      " |-- avg_speed_5: double (nullable = true)\n",
      " |-- best_speed: double (nullable = true)\n",
      " |-- avg_beaten_len_5: double (nullable = true)\n",
      " |-- first_race_date_5: date (nullable = true)\n",
      " |-- most_recent_race_5: date (nullable = true)\n",
      " |-- avg_dist_bk_gate1_5: double (nullable = true)\n",
      " |-- avg_dist_bk_gate2_5: double (nullable = true)\n",
      " |-- avg_dist_bk_gate3_5: double (nullable = true)\n",
      " |-- avg_dist_bk_gate4_5: double (nullable = true)\n",
      " |-- avg_speed_fullrace_5: double (nullable = true)\n",
      " |-- avg_stride_length_5: double (nullable = true)\n",
      " |-- avg_strfreq_q1_5: double (nullable = true)\n",
      " |-- avg_strfreq_q2_5: double (nullable = true)\n",
      " |-- avg_strfreq_q3_5: double (nullable = true)\n",
      " |-- avg_strfreq_q4_5: double (nullable = true)\n",
      " |-- prev_speed: double (nullable = true)\n",
      " |-- speed_improvement: double (nullable = true)\n",
      " |-- prev_race_date: date (nullable = true)\n",
      " |-- days_off: double (nullable = true)\n",
      " |-- layoff_cat: string (nullable = true)\n",
      " |-- avg_workout_rank_3: double (nullable = true)\n",
      " |-- count_workouts_3: double (nullable = true)\n",
      " |-- race_count: double (nullable = true)\n",
      " |-- track_name: string (nullable = true)\n",
      " |-- age_at_race_day: double (nullable = true)\n",
      " |-- gps_present: long (nullable = true)\n",
      " |-- race_id: string (nullable = true)\n",
      " |-- group_id: long (nullable = true)\n",
      " |-- perf_target: long (nullable = true)\n",
      " |-- custom_speed_figure: double (nullable = true)\n",
      " |-- horse_idx: long (nullable = true)\n",
      " |-- embed_0: double (nullable = true)\n",
      " |-- embed_1: double (nullable = true)\n",
      " |-- embed_2: double (nullable = true)\n",
      " |-- embed_3: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "    full_path = f\"/home/exx/myCode/horse-racing/FoxRiverAIRacing/data/parquet/horse_embedding_data-2025-01-25-2309.parquet\" #os.path.join(parquet_dir, model_filename)\n",
    "\n",
    "    horse_embedding_sdf = spark.read.parquet(full_path)\n",
    "    logging.info(\"Schema of horse_embedding_sdf:\")\n",
    "    horse_embedding_sdf.printSchema()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1ad16341",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = horse_embedding_sdf.toPandas()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7302846d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['axciskey', 'course_cd', 'race_date', 'race_number', 'horse_id',\n",
       "       'horse_name', 'official_fin', 'time_behind', 'pace_delta_time',\n",
       "       'speed_rating',\n",
       "       ...\n",
       "       'gps_present', 'race_id', 'group_id', 'perf_target',\n",
       "       'custom_speed_figure', 'horse_idx', 'embed_0', 'embed_1', 'embed_2',\n",
       "       'embed_3'],\n",
       "      dtype='object', length=103)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d4930551",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 328184, Columns: 103\n"
     ]
    }
   ],
   "source": [
    "    # Show basic info\n",
    "rows, cols = df.shape\n",
    "print(f\"Rows: {rows}, Columns: {cols}\")\n",
    "#print(f\"Columns: {df.columns.tolist()}\")\n",
    "#print(f\"Dtypes:\\n{df.dtypes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "80ea2ae8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['axciskey', 'course_cd', 'race_date', 'race_number', 'horse_id',\n",
       "       'horse_name', 'official_fin', 'time_behind', 'pace_delta_time',\n",
       "       'speed_rating',\n",
       "       ...\n",
       "       'gps_present', 'race_id', 'group_id', 'perf_target',\n",
       "       'custom_speed_figure', 'horse_idx', 'embed_0', 'embed_1', 'embed_2',\n",
       "       'embed_3'],\n",
       "      dtype='object', length=103)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c67aa1ec",
   "metadata": {},
   "source": [
    "###############################################################################\n",
    "# 1) Handle certain datetime columns\n",
    "###############################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f6e6ed4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime_columns = [\"first_race_date_5\", \"most_recent_race_5\", \"prev_race_date\"]\n",
    "# Convert each datetime column, but store the \"numeric\" versions in a dict of new columns\n",
    "new_numeric_cols = {}\n",
    "for col in datetime_columns:\n",
    "    df[col] = pd.to_datetime(df[col])\n",
    "    new_numeric_cols[col + \"_numeric\"] = (df[col] - pd.Timestamp(\"1970-01-01\")).dt.days\n",
    "\n",
    "# Drop all original datetime columns at once:\n",
    "df.drop(columns=datetime_columns, inplace=True, errors=\"ignore\")\n",
    "\n",
    "# Now concat all new numeric columns in a single step\n",
    "df = pd.concat([df, pd.DataFrame(new_numeric_cols, index=df.index)], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8fb0e81",
   "metadata": {},
   "source": [
    "###############################################################################\n",
    "# 2) Split Data Chronologically (Train up to 2023-12-31, etc.)\n",
    "###############################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "468545e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (214541, 103)\n",
      "Valid shape: (58646, 103)\n",
      "Holdout shape: (54997, 103)\n"
     ]
    }
   ],
   "source": [
    "df[\"race_date\"] = pd.to_datetime(df[\"race_date\"])\n",
    "\n",
    "train_end_date = pd.to_datetime(\"2023-12-31\")\n",
    "valid_data_end_date = pd.to_datetime(\"2024-06-30\")\n",
    "holdout_start = pd.to_datetime(\"2024-07-01\")\n",
    "\n",
    "# Note: check your date logic carefully. \n",
    "train_data = df[df[\"race_date\"] <= train_end_date].copy()\n",
    "valid_data = df[(df[\"race_date\"] > train_end_date) & (df[\"race_date\"] <= valid_data_end_date)].copy()\n",
    "holdout_data = df[df[\"race_date\"] >= holdout_start].copy()\n",
    "\n",
    "print(f\"Train shape: {train_data.shape}\")\n",
    "print(f\"Valid shape: {valid_data.shape}\")\n",
    "print(f\"Holdout shape: {holdout_data.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36ec55b",
   "metadata": {},
   "source": [
    "###############################################################################\n",
    "# 3) Identify Categorical, Embed and Numeric Columns\n",
    "###############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "78745e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = [\n",
    "        \"course_cd\", \"trk_cond\", \"sex\", \"equip\", \"surface\", \"med\",\n",
    "        \"race_type\", \"stk_clm_md\", \"turf_mud_mark\", \"layoff_cat\",\n",
    "        \"previous_surface\"\n",
    "    ]\n",
    "    # Removed duplicate \"surface\" from that list if it was repeated.\n",
    "\n",
    "label_col = \"perf_target\"\n",
    "\n",
    "# We'll add the embed_0..embed_63 columns if they exist\n",
    "embed_cols = [f\"embed_{i}\" for i in range(64)]\n",
    "\n",
    "# numeric_cols: all float64/int64 except label_col\n",
    "# We'll define them for each sub-data because they differ after merges/drops\n",
    "# For now, let's define them from train_data\n",
    "def get_numeric_cols(df_):\n",
    "    # Potential numeric\n",
    "    cand = [c for c in df_.columns if df_[c].dtype in [np.float64, np.int64]]\n",
    "    # Exclude the label col\n",
    "    cand = [c for c in cand if c != label_col]\n",
    "    return cand\n",
    "\n",
    "numeric_cols_train = get_numeric_cols(train_data)\n",
    "# add embed columns if they're not already included \n",
    "for ec in embed_cols:\n",
    "    if ec not in numeric_cols_train and ec in train_data.columns:\n",
    "        numeric_cols_train.append(ec)\n",
    "\n",
    "# We'll do the same or similar for valid_data, holdout_data if needed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b57dcadf",
   "metadata": {},
   "source": [
    "###############################################################################\n",
    "# 4) Sort by group_id if it exists, then create X,y,group\n",
    "###############################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "09ff35ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"group_id\" in train_data.columns:\n",
    "    train_data.sort_values(\"group_id\", ascending=True, inplace=True)\n",
    "if \"group_id\" in valid_data.columns:\n",
    "    valid_data.sort_values(\"group_id\", ascending=True, inplace=True)\n",
    "if \"group_id\" in holdout_data.columns:\n",
    "    holdout_data.sort_values(\"group_id\", ascending=True, inplace=True)\n",
    "    \n",
    "all_training_cols = numeric_cols_train + cat_cols\n",
    "# remove duplicates\n",
    "all_training_cols = list(set(all_training_cols))\n",
    "\n",
    "# Build X,y for train\n",
    "X_train = train_data.drop(columns=[label_col], errors=\"ignore\")\n",
    "X_train = train_data[all_training_cols].copy()\n",
    "y_train = train_data[label_col]\n",
    "if \"group_id\" in train_data.columns:\n",
    "    train_group_id = train_data[\"group_id\"]\n",
    "else:\n",
    "    train_group_id = pd.Series(np.zeros(len(train_data)), index=train_data.index)\n",
    "\n",
    "# Build X,y for valid\n",
    "X_valid = valid_data.drop(columns=[label_col], errors=\"ignore\")\n",
    "X_valid = valid_data[all_training_cols].copy()\n",
    "y_valid = valid_data[label_col]\n",
    "if \"group_id\" in valid_data.columns:\n",
    "    valid_group_id = valid_data[\"group_id\"]\n",
    "else:\n",
    "    valid_group_id = pd.Series(np.zeros(len(valid_data)), index=valid_data.index)\n",
    "\n",
    "# Build X,y for holdout\n",
    "X_holdout = holdout_data.drop(columns=[label_col], errors=\"ignore\")\n",
    "X_holdout = holdout_data[all_training_cols].copy()\n",
    "y_holdout = holdout_data[label_col]\n",
    "if \"group_id\" in holdout_data.columns:\n",
    "    holdout_group_id = holdout_data[\"group_id\"]\n",
    "else:\n",
    "    holdout_group_id = pd.Series(np.zeros(len(holdout_data)), index=holdout_data.index)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83743e9a",
   "metadata": {},
   "source": [
    "###############################################################################\n",
    "# 5) Create CatBoost Pools\n",
    "###############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "07a71987",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (214541, 97), y_train length: 214541\n",
      "X_valid shape: (58646, 97), y_valid length: 58646\n",
      "X_holdout shape: (54997, 97), y_holdout length: 54997\n"
     ]
    }
   ],
   "source": [
    "# cat_features_idx: indices in X_train that match cat_cols\n",
    "# We only do it for the columns that truly exist in X_train\n",
    "train_col_list = X_train.columns.tolist()\n",
    "cat_features_idx = [train_col_list.index(c) for c in cat_cols if c in train_col_list]\n",
    "\n",
    "train_pool = Pool(\n",
    "    data=X_train,\n",
    "    label=y_train,\n",
    "    group_id=train_group_id,\n",
    "    cat_features=cat_features_idx\n",
    ")\n",
    "\n",
    "valid_pool = Pool(\n",
    "    data=X_valid,\n",
    "    label=y_valid,\n",
    "    group_id=valid_group_id,\n",
    "    cat_features=cat_features_idx\n",
    ")\n",
    "\n",
    "holdout_pool = Pool(\n",
    "    data=X_holdout,\n",
    "    label=y_holdout,\n",
    "    group_id=holdout_group_id,\n",
    "    cat_features=cat_features_idx\n",
    ")\n",
    "\n",
    "print(f\"X_train shape: {X_train.shape}, y_train length: {len(y_train)}\")\n",
    "print(f\"X_valid shape: {X_valid.shape}, y_valid length: {len(y_valid)}\")\n",
    "print(f\"X_holdout shape: {X_holdout.shape}, y_holdout length: {len(y_holdout)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b864a1e",
   "metadata": {},
   "source": [
    "###############################################################################\n",
    "# 6) Define Utility for get_timestamp\n",
    "###############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f97d4681",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_timestamp():\n",
    "    return datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f08326",
   "metadata": {},
   "source": [
    "###############################################################################\n",
    "# 7) Define the objective, run_optuna, final training\n",
    "###############################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f6da02a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "    def objective(trial):\n",
    "        params = {\n",
    "            \"loss_function\": \"YetiRank:top=3\",    # or pass in as an argument\n",
    "            \"eval_metric\": \"NDCG:top=3\",\n",
    "            \"task_type\": \"GPU\",\n",
    "            \"iterations\": trial.suggest_int(\"iterations\", 500, 3000, step=500),\n",
    "            \"depth\": trial.suggest_int(\"depth\", 4, 12),\n",
    "            \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-3, 0.3, log=True),\n",
    "            \"l2_leaf_reg\": trial.suggest_float(\"l2_leaf_reg\", 1.0, 20.0),\n",
    "            \"random_seed\": 42,\n",
    "            \"verbose\": 100,\n",
    "        }\n",
    "\n",
    "        # Grow policy\n",
    "        grow_policy = trial.suggest_categorical(\"grow_policy\", [\"SymmetricTree\", \"Depthwise\", \"Lossguide\"])\n",
    "        params[\"grow_policy\"] = grow_policy\n",
    "        if grow_policy == \"Lossguide\":\n",
    "            params[\"max_leaves\"] = trial.suggest_int(\"max_leaves\", 32, 256, step=32)\n",
    "\n",
    "        # Bootstrap type\n",
    "        bootstrap_type = trial.suggest_categorical(\"bootstrap_type\", [\"Bayesian\", \"Bernoulli\", \"Poisson\", \"MVS\"])\n",
    "        params[\"bootstrap_type\"] = bootstrap_type\n",
    "\n",
    "        if bootstrap_type == \"Bernoulli\":\n",
    "            params[\"subsample\"] = trial.suggest_float(\"subsample\", 0.5, 1.0)\n",
    "        elif bootstrap_type == \"Bayesian\":\n",
    "            params[\"bagging_temperature\"] = trial.suggest_float(\"bagging_temperature\", 0.0, 2.0)\n",
    "\n",
    "        # random_strength\n",
    "        params[\"random_strength\"] = trial.suggest_float(\"random_strength\", 0.0, 20.0)\n",
    "\n",
    "        # border_count\n",
    "        params[\"border_count\"] = trial.suggest_int(\"border_count\", 32, 512, step=32)\n",
    "\n",
    "        # early stopping\n",
    "        params[\"od_type\"] = \"Iter\"\n",
    "        params[\"od_wait\"] = trial.suggest_int(\"od_wait\", 20, 100, step=10)\n",
    "\n",
    "        model = CatBoostRanker(**params)\n",
    "        model.fit(train_pool, eval_set=valid_pool)\n",
    "\n",
    "        score_dict = model.get_best_score()\n",
    "        print(\"Model Best Scores:\", score_dict)\n",
    "\n",
    "        # We'll assume we can read \"NDCG:top=3\" from score_dict\n",
    "        valid_ndcg = 0.0\n",
    "        if \"validation\" in score_dict:\n",
    "            metric_key = \"NDCG:top=3;type=Base\"\n",
    "            valid_ndcg = score_dict[\"validation\"].get(metric_key, 0.0)\n",
    "        else:\n",
    "            # fallback to manual ndcg\n",
    "            val_preds = model.predict(valid_pool)\n",
    "            true_labels = y_valid.values.reshape(1, -1)\n",
    "            predicted_scores = val_preds.reshape(1, -1)\n",
    "            valid_ndcg = ndcg_score(true_labels, predicted_scores, k=3)\n",
    "\n",
    "        return valid_ndcg\n",
    "\n",
    "    def run_optuna_search(n_trials=100):\n",
    "        \"\"\"Simple function to create an Optuna study and run the objective above.\"\"\"\n",
    "        study = optuna.create_study(\n",
    "            direction=\"maximize\",\n",
    "            pruner=MedianPruner(n_warmup_steps=3)\n",
    "        )\n",
    "        study.optimize(objective, n_trials=n_trials)\n",
    "        return study\n",
    "\n",
    "    def train_and_save_model(best_params, model_save_dir):\n",
    "        \"\"\"Train final model with best_params, then save to .cbm.\"\"\"\n",
    "        recognized_params = dict(best_params)\n",
    "        recognized_params[\"loss_function\"] = \"YetiRank:top=3\"\n",
    "        recognized_params[\"eval_metric\"] = \"NDCG:top=3\"\n",
    "        recognized_params[\"random_seed\"] = 42\n",
    "        recognized_params[\"task_type\"] = \"GPU\"\n",
    "\n",
    "        final_model = CatBoostRanker(**recognized_params)\n",
    "        final_model.fit(\n",
    "            train_pool,\n",
    "            eval_set=valid_pool,\n",
    "            early_stopping_rounds=100,\n",
    "            verbose=100\n",
    "        )\n",
    "\n",
    "        os.makedirs(model_save_dir, exist_ok=True)\n",
    "        timestamp = get_timestamp()\n",
    "        model_filename = f\"catboost_YetiRank_top3_{timestamp}.cbm\"\n",
    "        model_path = os.path.join(model_save_dir, model_filename)\n",
    "        final_model.save_model(model_path)\n",
    "        logging.info(f\"Final model saved to: {model_path}\")\n",
    "        return final_model, model_path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2de865d",
   "metadata": {},
   "source": [
    "###############################################################################\n",
    "# 8) Run the hyperparameter search\n",
    "###############################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3f2dca9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2025-01-26 11:44:23,658]\u001b[0m A new study created in memory with name: no-name-e353ccf2-ea1f-40c9-960d-f16ddde4a44f\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Groupwise loss function. OneHotMaxSize set to 10\n",
      "0:\ttest: 0.9943149\tbest: 0.9943149 (0)\ttotal: 24.5ms\tremaining: 1m 1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because NDCG is/are not implemented for GPU\n",
      "Metric NDCG:type=Base is not implemented on GPU. Will use CPU for metric computation, this could significantly affect learning time\n",
      "Metric NDCG:top=3;type=Base is not implemented on GPU. Will use CPU for metric computation, this could significantly affect learning time\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100:\ttest: 0.9971575\tbest: 0.9971741 (99)\ttotal: 1.65s\tremaining: 39.1s\n",
      "200:\ttest: 0.9999870\tbest: 0.9999870 (198)\ttotal: 3.27s\tremaining: 37.4s\n",
      "300:\ttest: 1.0000000\tbest: 1.0000000 (256)\ttotal: 4.93s\tremaining: 36s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m[W 2025-01-26 11:44:30,031]\u001b[0m Trial 0 failed with parameters: {'iterations': 2500, 'depth': 9, 'learning_rate': 0.017360732585914446, 'l2_leaf_reg': 3.3685349704741245, 'grow_policy': 'SymmetricTree', 'bootstrap_type': 'Bernoulli', 'subsample': 0.7738108574232709, 'random_strength': 15.475520262556199, 'border_count': 32, 'od_wait': 90} because of the following error: NameError(\"name 'ndcg_score' is not defined\").\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/exx/anaconda3/envs/mamba_env/envs/tf_310/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_4091756/3840013914.py\", line 55, in objective\n",
      "    valid_ndcg = ndcg_score(true_labels, predicted_scores, k=3)\n",
      "NameError: name 'ndcg_score' is not defined\n",
      "\u001b[33m[W 2025-01-26 11:44:30,034]\u001b[0m Trial 0 failed with value None.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bestTest = 1\n",
      "bestIteration = 256\n",
      "Shrink model to first 257 iterations.\n",
      "Model Best Scores: {}\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'ndcg_score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[72], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=== Starting Optuna search for YetiRank:top=3 / NDCG:top=3 ===\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m study \u001b[38;5;241m=\u001b[39m \u001b[43mrun_optuna_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m300\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# or 500 if you want bigger search\u001b[39;00m\n\u001b[1;32m      4\u001b[0m best_score \u001b[38;5;241m=\u001b[39m study\u001b[38;5;241m.\u001b[39mbest_value\n\u001b[1;32m      5\u001b[0m best_params \u001b[38;5;241m=\u001b[39m study\u001b[38;5;241m.\u001b[39mbest_params\n",
      "Cell \u001b[0;32mIn[69], line 65\u001b[0m, in \u001b[0;36mrun_optuna_search\u001b[0;34m(n_trials)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Simple function to create an Optuna study and run the objective above.\"\"\"\u001b[39;00m\n\u001b[1;32m     61\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(\n\u001b[1;32m     62\u001b[0m     direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     63\u001b[0m     pruner\u001b[38;5;241m=\u001b[39mMedianPruner(n_warmup_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m     64\u001b[0m )\n\u001b[0;32m---> 65\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m study\n",
      "File \u001b[0;32m~/anaconda3/envs/mamba_env/envs/tf_310/lib/python3.10/site-packages/optuna/study/study.py:425\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    321\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    323\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    330\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    331\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    332\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    333\u001b[0m \n\u001b[1;32m    334\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    423\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 425\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    426\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    427\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    428\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    429\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    430\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    431\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    432\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    433\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    434\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    435\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/mamba_env/envs/tf_310/lib/python3.10/site-packages/optuna/study/_optimize.py:66\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 66\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     79\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/mamba_env/envs/tf_310/lib/python3.10/site-packages/optuna/study/_optimize.py:163\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 163\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    167\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m~/anaconda3/envs/mamba_env/envs/tf_310/lib/python3.10/site-packages/optuna/study/_optimize.py:251\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    246\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    247\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[1;32m    248\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    250\u001b[0m ):\n\u001b[0;32m--> 251\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[0;32m~/anaconda3/envs/mamba_env/envs/tf_310/lib/python3.10/site-packages/optuna/study/_optimize.py:200\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[1;32m    199\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 200\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    202\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    203\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[0;32mIn[69], line 55\u001b[0m, in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     53\u001b[0m     true_labels \u001b[38;5;241m=\u001b[39m y_valid\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     54\u001b[0m     predicted_scores \u001b[38;5;241m=\u001b[39m val_preds\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 55\u001b[0m     valid_ndcg \u001b[38;5;241m=\u001b[39m \u001b[43mndcg_score\u001b[49m(true_labels, predicted_scores, k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m valid_ndcg\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ndcg_score' is not defined"
     ]
    }
   ],
   "source": [
    "logging.info(\"=== Starting Optuna search for YetiRank:top=3 / NDCG:top=3 ===\")\n",
    "study = run_optuna_search(n_trials=300)  # or 500 if you want bigger search\n",
    "\n",
    "best_score = study.best_value\n",
    "best_params = study.best_params\n",
    "logging.info(f\"Best NDCG@3: {best_score}, Best params: {best_params}\")\n",
    "\n",
    "# Save the best params to a JSON\n",
    "with open(\"./data/training/best_params.json\", \"w\") as f:\n",
    "    json.dump(best_params, f, indent=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f5a56d",
   "metadata": {},
   "source": [
    "###############################################################################\n",
    "# 9) Train final model with best params\n",
    "###############################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc379e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model, model_path = train_and_save_model(best_params, \"/home/exx/myCode/horse-racing/FoxRiverAIRacing/data/models/catboost\")\n",
    "logging.info(f\"Saved final model to: {model_path}\")\n",
    "\n",
    "# Evaluate on holdout if you want\n",
    "holdout_preds = final_model.predict(holdout_pool)\n",
    "holdout_true = y_holdout.values.reshape(1, -1)\n",
    "holdout_scores = holdout_preds.reshape(1, -1)\n",
    "holdout_ndcg = ndcg_score(holdout_true, holdout_scores, k=3)\n",
    "logging.info(f\"Holdout NDCG@3: {holdout_ndcg:.4f}\")\n",
    "\n",
    "logging.info(\"=== Done training CatBoost model ===\")\n",
    "\n",
    "return model_path  # or whatever you want to return"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
