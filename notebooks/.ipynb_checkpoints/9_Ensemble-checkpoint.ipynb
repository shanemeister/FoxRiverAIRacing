{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a43fc8b",
   "metadata": {},
   "source": [
    "# Ensemble Model Preparation\n",
    "\n",
    "A lot of work has gone into compiling the current dataset. I have merged the gps_df, sectionals_df and results_df. I have limited the amount of Equibase data I am using just to keep the focus on the TPD GPS data, and to do some feature engineering.  However, there are some good metrics from the Equibase data that are just basic measures that could be obtained from any racebook sheet. \n",
    "\n",
    "## Get Started\n",
    "\n",
    "1. Going to load the parquet DataFrame from disk and do some imputation, one-hot encoding, string indexing, and scaling. The run it through XBBoost to see how it's looking. At this point I will do the integration of route data, and add the GPS aggregations. I just want to see what I can minimally do and how its working before I go down the wrong path. If the XGBoost doesn't do any better than the LSTM, at least I won't have wasted any more time on it. \n",
    "\n",
    "### Model Additional Requirements\n",
    "\n",
    "#### Logistic Regression:\n",
    "> Ensure features are scaled (e.g., StandardScaler) and that categorical variables are one-hot encoded.\n",
    "\n",
    "#### Random Forest\t\n",
    "> Scaling is unnecessary, and categorical variables should be one-hot encoded.\n",
    "\n",
    "#### XGBoost/LightGBM\t\n",
    "> **Scaling is unnecessary, and categorical variables should be one-hot encoded.**\n",
    "\n",
    "#### Support Vector Machines (SVM)\t\n",
    ">Requires scaling and one-hot encoding.\n",
    "\n",
    "#### k-Nearest Neighbors\t\n",
    ">Requires scaling and one-hot encoding.\n",
    "\n",
    "#### Multi-Layer Perceptron (MLP)\n",
    "> Requires scaling and one-hot encoding.\n",
    "\n",
    "#### CatBoost\t\n",
    "> No need for one-hot encoding; you can specify categorical columns directly using CatBoost’s cat_features parameter.\n",
    "\n",
    "\n",
    "### Load master_results_df.parquet file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c1463424",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Environment\n",
    "\n",
    "import os\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn import set_config\n",
    "\n",
    "import pyspark.sql.functions as F\n",
    "import xgboost as xgb\n",
    "from sklearn import set_config\n",
    "from pyspark.sql.functions import (col, count, row_number, abs, unix_timestamp, mean, \n",
    "                                   when, lit, min as F_min, max as F_max , \n",
    "                                   row_number, mean as F_mean, countDistinct, last, first, when)\n",
    "import configparser\n",
    "from pyspark.sql import SparkSession\n",
    "from src.data_preprocessing.data_prep1.sql_queries import sql_queries\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql import DataFrame, Window\n",
    "from src.data_preprocessing.data_prep1.data_utils import (save_parquet, gather_statistics, \n",
    "                initialize_environment, load_config, initialize_logging, initialize_spark, \n",
    "                identify_and_impute_outliers, \n",
    "                identify_and_remove_outliers, identify_missing_and_outliers)\n",
    "from pyspark.ml.functions import vector_to_array\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Set global references to None\n",
    "spark = None\n",
    "master_results_df = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73671a61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-31 14:19:04,392 - INFO - Environment setup initialized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark session created successfully.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "spark, jdbc_url, jdbc_properties, queries, parquet_dir, log_file = initialize_environment()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c57a596",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.parquet(os.path.join(parquet_dir, \"results_only_clean.parquet\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ccd5955",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "777100"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce2ed82",
   "metadata": {},
   "source": [
    "# Switching to Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e3b985b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Convert Spark DataFrame -> Pandas DataFrame\n",
    "\n",
    "rf_df = df.toPandas()\n",
    "df = None\n",
    "# Quick info about the DataFrame\n",
    "#print(df.info())\n",
    "#print(df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92eb1d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppose the finish position is in a column named 'official_fin'\n",
    "# Create a binary label: 1 = first place, 0 = others\n",
    "#df[\"label\"] = (df[\"official_fin\"] == 1).astype(int)\n",
    "\n",
    "# Check distribution of the label\n",
    "#print(df[\"label\"].value_counts())\n",
    "\n",
    "# Define a function to map official_fin to label\n",
    "def map_official_fin_to_label(official_fin):\n",
    "    if official_fin == 1:\n",
    "        return 0  # Win\n",
    "    elif official_fin == 2:\n",
    "        return 1  # Place\n",
    "    elif official_fin == 3:\n",
    "        return 2  # Show\n",
    "    elif official_fin == 4:\n",
    "        return 3  # Fourth\n",
    "    elif official_fin == 5:\n",
    "        return 4  # Fifth\n",
    "    elif official_fin == 6:\n",
    "        return 5  # Sixth\n",
    "    elif official_fin == 7:\n",
    "        return 6  # Seventh\n",
    "    else:\n",
    "        return 7  # Outside top-7\n",
    "\n",
    "# Apply the function to create the label column\n",
    "rf_df['label'] = rf_df['official_fin'].apply(map_official_fin_to_label)\n",
    "\n",
    "# Check the DataFrame\n",
    "#print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7eb90e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4a) Identify columns with high missingness\n",
    "missing_summary = rf_df.isna().sum().sort_values(ascending=False)\n",
    "#print(\"Missing Value Summary:\\n\", missing_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f3dade4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Descriptive Stats:\\n\", df.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c0d9caaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Quick correlation matrix\n",
    "# corr_matrix = df.corr(numeric_only=True)\n",
    "# print(\"Correlation Matrix:\\n\", corr_matrix[\"label\"].sort_values(ascending=False))\n",
    "\n",
    "# # Possibly visualize\n",
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.figure(figsize=(8, 6))\n",
    "# sns.heatmap(corr_matrix, cmap=\"coolwarm\")\n",
    "# plt.title(\"Correlation Heatmap\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "84383e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Histograms for numeric columns\n",
    "# df.hist(bins=30, figsize=(15,10))\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d071d9a",
   "metadata": {},
   "source": [
    "# OHE\n",
    "\n",
    "> Required for Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0a39d97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6b) Convert categorical columns to numeric dummies\n",
    "categorical_cols = [\"course_cd\", \n",
    "                    \"equip\", \n",
    "                    \"surface\", \n",
    "                    \"trk_cond\", \n",
    "                    \"weather\", \n",
    "                    \"med\", \n",
    "                    \"stk_clm_md\", \n",
    "                    \"turf_mud_mark\", \n",
    "                    \"race_type\"]\n",
    "\n",
    "# Perform one-hot encoding on the categorical columns\n",
    "df_encoded = pd.get_dummies(rf_df, columns=categorical_cols, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f701e552",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = rf_df[[\"race_date\", \"race_number\", \"horse_id\"]]  # Replace with your metadata columns\n",
    "\n",
    "feature_cols = [\"morn_odds\", \"net_sentiment\", \"power\", \"avg_spd_sd\", \"hi_spd_sd\",\n",
    "                \"avgspd\", \"ave_cl_sd\", \"cond_win\", \"cond_place\", \"all_win\", \"all_place\",\n",
    "                \"cond_earnings\", \"all_earnings\", \"weight\", \"cond_show\", \"all_show\", \n",
    "                \"cond_starts\", \"all_starts\", \"class_rating\", \"age_at_race_day\", \"distance\",\n",
    "                \"horse_id\", \"claimprice\", \"wps_pool\", \"cond_fourth\", \"all_fourth\", \n",
    "                \"purse\", \"pstyerl\", \"race_number\", \"start_position\"]\n",
    "\n",
    "# Separate the label from the features\n",
    "y = df_encoded[\"label\"].values\n",
    "\n",
    "X = rf_df[feature_cols].copy()\n",
    "\n",
    "# Combine the encoded features with the numeric features\n",
    "X = df_encoded[feature_cols].copy()\n",
    "\n",
    "# Separate the date columns\n",
    "# date_cols = ['race_date']\n",
    "# X = X.drop(columns=date_cols)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test, metadata_train, metadata_test = train_test_split(\n",
    "    X, y, metadata, test_size=0.20, random_state=42, stratify=y\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d9f7b2",
   "metadata": {},
   "source": [
    "# Scaling\n",
    "\n",
    ">Unnecessary for Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cd8a47c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Scale numeric features\n",
    "# # Not necessary for Random Forest\n",
    "# scaler = StandardScaler()\n",
    "# X_train_scaled = scaler.fit_transform(X_train)\n",
    "# X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Check the scaled features\n",
    "# print(X_train_scaled)\n",
    "# print(X_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2842de6d",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0aced663",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_config(display=\"text\")  # Switch to text-based display\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(\n",
    "    objective=\"multi:softmax\",  # Multi-class classification\n",
    "    num_class=8,               # Number of classes (0 to 7)\n",
    "    max_depth=6,               # Tree depth\n",
    "    learning_rate=0.1,         # Learning rate\n",
    "    n_estimators=100,          # Number of trees\n",
    "    eval_metric=\"mlogloss\",    # Log loss for multi-class\n",
    "    early_stopping_rounds=10   # Specify early stopping rounds here\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "12ba670f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-mlogloss:2.06199\tvalidation_1-mlogloss:2.06233\n",
      "[1]\tvalidation_0-mlogloss:2.04695\tvalidation_1-mlogloss:2.04759\n",
      "[2]\tvalidation_0-mlogloss:2.03382\tvalidation_1-mlogloss:2.03479\n",
      "[3]\tvalidation_0-mlogloss:2.02233\tvalidation_1-mlogloss:2.02360\n",
      "[4]\tvalidation_0-mlogloss:2.01206\tvalidation_1-mlogloss:2.01363\n",
      "[5]\tvalidation_0-mlogloss:2.00295\tvalidation_1-mlogloss:2.00482\n",
      "[6]\tvalidation_0-mlogloss:1.99479\tvalidation_1-mlogloss:1.99699\n",
      "[7]\tvalidation_0-mlogloss:1.98747\tvalidation_1-mlogloss:1.98996\n",
      "[8]\tvalidation_0-mlogloss:1.98084\tvalidation_1-mlogloss:1.98360\n",
      "[9]\tvalidation_0-mlogloss:1.97486\tvalidation_1-mlogloss:1.97792\n",
      "[10]\tvalidation_0-mlogloss:1.96942\tvalidation_1-mlogloss:1.97277\n",
      "[11]\tvalidation_0-mlogloss:1.96444\tvalidation_1-mlogloss:1.96807\n",
      "[12]\tvalidation_0-mlogloss:1.95992\tvalidation_1-mlogloss:1.96384\n",
      "[13]\tvalidation_0-mlogloss:1.95579\tvalidation_1-mlogloss:1.95998\n",
      "[14]\tvalidation_0-mlogloss:1.95200\tvalidation_1-mlogloss:1.95647\n",
      "[15]\tvalidation_0-mlogloss:1.94855\tvalidation_1-mlogloss:1.95329\n",
      "[16]\tvalidation_0-mlogloss:1.94536\tvalidation_1-mlogloss:1.95038\n",
      "[17]\tvalidation_0-mlogloss:1.94242\tvalidation_1-mlogloss:1.94775\n",
      "[18]\tvalidation_0-mlogloss:1.93973\tvalidation_1-mlogloss:1.94534\n",
      "[19]\tvalidation_0-mlogloss:1.93722\tvalidation_1-mlogloss:1.94312\n",
      "[20]\tvalidation_0-mlogloss:1.93489\tvalidation_1-mlogloss:1.94108\n",
      "[21]\tvalidation_0-mlogloss:1.93273\tvalidation_1-mlogloss:1.93921\n",
      "[22]\tvalidation_0-mlogloss:1.93072\tvalidation_1-mlogloss:1.93749\n",
      "[23]\tvalidation_0-mlogloss:1.92884\tvalidation_1-mlogloss:1.93588\n",
      "[24]\tvalidation_0-mlogloss:1.92709\tvalidation_1-mlogloss:1.93439\n",
      "[25]\tvalidation_0-mlogloss:1.92545\tvalidation_1-mlogloss:1.93302\n",
      "[26]\tvalidation_0-mlogloss:1.92388\tvalidation_1-mlogloss:1.93174\n",
      "[27]\tvalidation_0-mlogloss:1.92240\tvalidation_1-mlogloss:1.93052\n",
      "[28]\tvalidation_0-mlogloss:1.92105\tvalidation_1-mlogloss:1.92943\n",
      "[29]\tvalidation_0-mlogloss:1.91972\tvalidation_1-mlogloss:1.92839\n",
      "[30]\tvalidation_0-mlogloss:1.91847\tvalidation_1-mlogloss:1.92742\n",
      "[31]\tvalidation_0-mlogloss:1.91732\tvalidation_1-mlogloss:1.92655\n",
      "[32]\tvalidation_0-mlogloss:1.91620\tvalidation_1-mlogloss:1.92570\n",
      "[33]\tvalidation_0-mlogloss:1.91511\tvalidation_1-mlogloss:1.92490\n",
      "[34]\tvalidation_0-mlogloss:1.91411\tvalidation_1-mlogloss:1.92417\n",
      "[35]\tvalidation_0-mlogloss:1.91315\tvalidation_1-mlogloss:1.92348\n",
      "[36]\tvalidation_0-mlogloss:1.91224\tvalidation_1-mlogloss:1.92283\n",
      "[37]\tvalidation_0-mlogloss:1.91137\tvalidation_1-mlogloss:1.92224\n",
      "[38]\tvalidation_0-mlogloss:1.91053\tvalidation_1-mlogloss:1.92168\n",
      "[39]\tvalidation_0-mlogloss:1.90971\tvalidation_1-mlogloss:1.92115\n",
      "[40]\tvalidation_0-mlogloss:1.90892\tvalidation_1-mlogloss:1.92062\n",
      "[41]\tvalidation_0-mlogloss:1.90817\tvalidation_1-mlogloss:1.92013\n",
      "[42]\tvalidation_0-mlogloss:1.90744\tvalidation_1-mlogloss:1.91971\n",
      "[43]\tvalidation_0-mlogloss:1.90671\tvalidation_1-mlogloss:1.91928\n",
      "[44]\tvalidation_0-mlogloss:1.90602\tvalidation_1-mlogloss:1.91886\n",
      "[45]\tvalidation_0-mlogloss:1.90537\tvalidation_1-mlogloss:1.91850\n",
      "[46]\tvalidation_0-mlogloss:1.90469\tvalidation_1-mlogloss:1.91812\n",
      "[47]\tvalidation_0-mlogloss:1.90404\tvalidation_1-mlogloss:1.91775\n",
      "[48]\tvalidation_0-mlogloss:1.90341\tvalidation_1-mlogloss:1.91740\n",
      "[49]\tvalidation_0-mlogloss:1.90282\tvalidation_1-mlogloss:1.91708\n",
      "[50]\tvalidation_0-mlogloss:1.90222\tvalidation_1-mlogloss:1.91678\n",
      "[51]\tvalidation_0-mlogloss:1.90162\tvalidation_1-mlogloss:1.91648\n",
      "[52]\tvalidation_0-mlogloss:1.90107\tvalidation_1-mlogloss:1.91622\n",
      "[53]\tvalidation_0-mlogloss:1.90051\tvalidation_1-mlogloss:1.91594\n",
      "[54]\tvalidation_0-mlogloss:1.89995\tvalidation_1-mlogloss:1.91569\n",
      "[55]\tvalidation_0-mlogloss:1.89943\tvalidation_1-mlogloss:1.91546\n",
      "[56]\tvalidation_0-mlogloss:1.89892\tvalidation_1-mlogloss:1.91523\n",
      "[57]\tvalidation_0-mlogloss:1.89842\tvalidation_1-mlogloss:1.91501\n",
      "[58]\tvalidation_0-mlogloss:1.89792\tvalidation_1-mlogloss:1.91478\n",
      "[59]\tvalidation_0-mlogloss:1.89742\tvalidation_1-mlogloss:1.91457\n",
      "[60]\tvalidation_0-mlogloss:1.89691\tvalidation_1-mlogloss:1.91435\n",
      "[61]\tvalidation_0-mlogloss:1.89644\tvalidation_1-mlogloss:1.91414\n",
      "[62]\tvalidation_0-mlogloss:1.89596\tvalidation_1-mlogloss:1.91396\n",
      "[63]\tvalidation_0-mlogloss:1.89551\tvalidation_1-mlogloss:1.91378\n",
      "[64]\tvalidation_0-mlogloss:1.89505\tvalidation_1-mlogloss:1.91360\n",
      "[65]\tvalidation_0-mlogloss:1.89458\tvalidation_1-mlogloss:1.91341\n",
      "[66]\tvalidation_0-mlogloss:1.89415\tvalidation_1-mlogloss:1.91321\n",
      "[67]\tvalidation_0-mlogloss:1.89369\tvalidation_1-mlogloss:1.91302\n",
      "[68]\tvalidation_0-mlogloss:1.89325\tvalidation_1-mlogloss:1.91288\n",
      "[69]\tvalidation_0-mlogloss:1.89286\tvalidation_1-mlogloss:1.91274\n",
      "[70]\tvalidation_0-mlogloss:1.89241\tvalidation_1-mlogloss:1.91256\n",
      "[71]\tvalidation_0-mlogloss:1.89199\tvalidation_1-mlogloss:1.91243\n",
      "[72]\tvalidation_0-mlogloss:1.89155\tvalidation_1-mlogloss:1.91227\n",
      "[73]\tvalidation_0-mlogloss:1.89107\tvalidation_1-mlogloss:1.91206\n",
      "[74]\tvalidation_0-mlogloss:1.89070\tvalidation_1-mlogloss:1.91194\n",
      "[75]\tvalidation_0-mlogloss:1.89030\tvalidation_1-mlogloss:1.91179\n",
      "[76]\tvalidation_0-mlogloss:1.88990\tvalidation_1-mlogloss:1.91165\n",
      "[77]\tvalidation_0-mlogloss:1.88949\tvalidation_1-mlogloss:1.91152\n",
      "[78]\tvalidation_0-mlogloss:1.88913\tvalidation_1-mlogloss:1.91140\n",
      "[79]\tvalidation_0-mlogloss:1.88875\tvalidation_1-mlogloss:1.91129\n",
      "[80]\tvalidation_0-mlogloss:1.88835\tvalidation_1-mlogloss:1.91115\n",
      "[81]\tvalidation_0-mlogloss:1.88800\tvalidation_1-mlogloss:1.91105\n",
      "[82]\tvalidation_0-mlogloss:1.88764\tvalidation_1-mlogloss:1.91096\n",
      "[83]\tvalidation_0-mlogloss:1.88728\tvalidation_1-mlogloss:1.91087\n",
      "[84]\tvalidation_0-mlogloss:1.88692\tvalidation_1-mlogloss:1.91074\n",
      "[85]\tvalidation_0-mlogloss:1.88656\tvalidation_1-mlogloss:1.91065\n",
      "[86]\tvalidation_0-mlogloss:1.88624\tvalidation_1-mlogloss:1.91052\n",
      "[87]\tvalidation_0-mlogloss:1.88591\tvalidation_1-mlogloss:1.91045\n",
      "[88]\tvalidation_0-mlogloss:1.88556\tvalidation_1-mlogloss:1.91034\n",
      "[89]\tvalidation_0-mlogloss:1.88521\tvalidation_1-mlogloss:1.91025\n",
      "[90]\tvalidation_0-mlogloss:1.88488\tvalidation_1-mlogloss:1.91016\n",
      "[91]\tvalidation_0-mlogloss:1.88458\tvalidation_1-mlogloss:1.91008\n",
      "[92]\tvalidation_0-mlogloss:1.88428\tvalidation_1-mlogloss:1.91000\n",
      "[93]\tvalidation_0-mlogloss:1.88394\tvalidation_1-mlogloss:1.90992\n",
      "[94]\tvalidation_0-mlogloss:1.88358\tvalidation_1-mlogloss:1.90983\n",
      "[95]\tvalidation_0-mlogloss:1.88324\tvalidation_1-mlogloss:1.90975\n",
      "[96]\tvalidation_0-mlogloss:1.88291\tvalidation_1-mlogloss:1.90969\n",
      "[97]\tvalidation_0-mlogloss:1.88262\tvalidation_1-mlogloss:1.90959\n",
      "[98]\tvalidation_0-mlogloss:1.88234\tvalidation_1-mlogloss:1.90956\n",
      "[99]\tvalidation_0-mlogloss:1.88203\tvalidation_1-mlogloss:1.90951\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=10,\n",
       "              enable_categorical=False, eval_metric='mlogloss',\n",
       "              feature_types=None, gamma=None, gpu_id=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=0.1, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=6,\n",
       "              max_leaves=None, min_child_weight=None, missing=nan,\n",
       "              monotone_constraints=None, n_estimators=100, n_jobs=None,\n",
       "              num_class=8, num_parallel_tree=None, objective='multi:softmax', ...)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "xgb_model.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_train, y_train), (X_test, y_test)],\n",
    "    verbose=True  # Use verbose for training progress\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a326fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# # Assuming y_train contains the labels\n",
    "# class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_train), y=y_train)\n",
    "# class_weights_dict = {i: class_weights[i] for i in range(len(class_weights))}\n",
    "\n",
    "# Use 'balanced' which automatically computes the class weights based on training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7aeff08a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[10995  3068  2111  1205  1207   547     8  2014]\n",
      " [ 8152  3238  2674  1656  1836   836    16  2720]\n",
      " [ 6184  2977  2877  2054  2455  1184    21  3353]\n",
      " [ 4604  2544  2670  2280  3121  1688    28  4086]\n",
      " [ 3433  2061  2374  2265  3347  1966    44  4933]\n",
      " [ 2353  1499  1779  1730  2906  2162    45  5525]\n",
      " [ 1422   897  1034   975  1745  1621    50  5669]\n",
      " [ 1345   831   972   780  1409  1474    29 12336]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.52      0.37     21155\n",
      "           1       0.19      0.15      0.17     21128\n",
      "           2       0.17      0.14      0.15     21105\n",
      "           3       0.18      0.11      0.13     21021\n",
      "           4       0.19      0.16      0.17     20423\n",
      "           5       0.19      0.12      0.15     17999\n",
      "           6       0.21      0.00      0.01     13413\n",
      "           7       0.30      0.64      0.41     19176\n",
      "\n",
      "    accuracy                           0.24    155420\n",
      "   macro avg       0.21      0.23      0.20    155420\n",
      "weighted avg       0.21      0.24      0.20    155420\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predict on test set\n",
    "y_pred = xgb_model.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4b66f9ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "morn_odds: 0.4517\n",
      "net_sentiment: 0.0453\n",
      "power: 0.0157\n",
      "avg_spd_sd: 0.0172\n",
      "hi_spd_sd: 0.0184\n",
      "avgspd: 0.0175\n",
      "ave_cl_sd: 0.0118\n",
      "cond_win: 0.0154\n",
      "cond_place: 0.0095\n",
      "all_win: 0.0197\n",
      "all_place: 0.0129\n",
      "cond_earnings: 0.0124\n",
      "all_earnings: 0.0170\n",
      "weight: 0.0101\n",
      "cond_show: 0.0100\n",
      "all_show: 0.0153\n",
      "cond_starts: 0.0121\n",
      "all_starts: 0.0161\n",
      "class_rating: 0.0171\n",
      "age_at_race_day: 0.0117\n",
      "distance: 0.0117\n",
      "horse_id: 0.0104\n",
      "claimprice: 0.0133\n",
      "wps_pool: 0.0274\n",
      "cond_fourth: 0.0115\n",
      "all_fourth: 0.0141\n",
      "purse: 0.0180\n",
      "pstyerl: 0.0195\n",
      "race_number: 0.0447\n",
      "start_position: 0.0726\n"
     ]
    }
   ],
   "source": [
    "importances = xgb_model.feature_importances_\n",
    "for col, imp in zip(feature_cols, importances):\n",
    "    print(f\"{col}: {imp:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2939f420",
   "metadata": {},
   "source": [
    "# Predicting Probabilities for Ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b9ee05e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/exx/anaconda3/envs/mamba_env/envs/tf_310/lib/python3.10/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Predict Probabilities\n",
    "predicted_probs = rf_model.predict_proba(X_test_scaled)[:, 1]  # Probability for winning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8963293a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         race_date  race_number  horse_id  predicted_probability  rank\n",
      "443968  2022-01-01            1    257862                  0.190   1.0\n",
      "403657  2022-01-01            1     96356                  0.189   2.0\n",
      "557148  2022-01-01            1     14941                  0.188   3.0\n",
      "143143  2022-01-01            1    294126                  0.187   4.0\n",
      "732523  2022-01-01            1    113458                  0.148   5.0\n",
      "241696  2022-01-01            1      9903                  0.143   6.0\n",
      "732524  2022-01-01            1     35560                  0.085   7.0\n",
      "732528  2022-01-01            1    181319                  0.084   8.0\n",
      "403659  2022-01-01            1     96358                  0.084   9.0\n",
      "200286  2022-01-01            1    269764                  0.084  10.0\n",
      "443966  2022-01-01            1     10298                  0.078  11.0\n",
      "200285  2022-01-01            1     62596                  0.078  12.0\n",
      "424227  2022-01-01            1    163465                  0.077  13.0\n",
      "443969  2022-01-01            1    257859                  0.075  14.0\n",
      "409177  2022-01-01            1      4068                  0.071  15.0\n",
      "200284  2022-01-01            1      6236                  0.071  16.0\n",
      "403661  2022-01-01            1      9405                  0.062  17.0\n",
      "443965  2022-01-01            1     15154                  0.062  18.0\n",
      "598473  2022-01-01            2     14951                  0.310   1.0\n",
      "598474  2022-01-01            2     12667                  0.309   2.0\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Combine Metadata with Predictions\n",
    "ranked_df = metadata_test.copy()\n",
    "ranked_df[\"predicted_probability\"] = predicted_probs\n",
    "\n",
    "# Step 3: Rank Horses\n",
    "ranked_df[\"rank\"] = (\n",
    "    ranked_df.groupby([\"race_date\", \"race_number\"])[\"predicted_probability\"]\n",
    "    .rank(method=\"first\", ascending=False)\n",
    ")\n",
    "\n",
    "# Step 4: Sort Ranked DataFrame\n",
    "ranked_df = ranked_df.sort_values(by=[\"race_date\", \"race_number\", \"rank\"])\n",
    "\n",
    "# Step 5: Save or Display Results\n",
    "print(ranked_df.head(20))  # Display top 20 ranked horses\n",
    "ranked_df.to_csv(\"ranked_horses.csv\", index=False)  # Save to CSV if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "270b85ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/exx/anaconda3/envs/mamba_env/envs/tf_310/lib/python3.10/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'race_date' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 14\u001b[0m\n\u001b[1;32m      9\u001b[0m predicted_probs \u001b[38;5;241m=\u001b[39m proba[:, \u001b[38;5;241m1\u001b[39m]  \u001b[38;5;66;03m# Probability for class 1 (winning)\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Step 2: Create a DataFrame for `X_test` with metadata\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Replace with actual metadata (e.g., from original test data before splitting)\u001b[39;00m\n\u001b[1;32m     13\u001b[0m metadata \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\n\u001b[0;32m---> 14\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrace_date\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[43mrace_date\u001b[49m,  \u001b[38;5;66;03m# Replace with actual race dates\u001b[39;00m\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrace_number\u001b[39m\u001b[38;5;124m\"\u001b[39m: race_number,  \u001b[38;5;66;03m# Replace with actual race numbers\u001b[39;00m\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhorse_id\u001b[39m\u001b[38;5;124m\"\u001b[39m: horse_id,  \u001b[38;5;66;03m# Replace with actual horse IDs\u001b[39;00m\n\u001b[1;32m     17\u001b[0m })\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Combine predicted probabilities with metadata\u001b[39;00m\n\u001b[1;32m     20\u001b[0m ranked_df \u001b[38;5;241m=\u001b[39m metadata\u001b[38;5;241m.\u001b[39mcopy()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'race_date' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Assuming X_test corresponds to the feature matrix for your test set\n",
    "# And you have additional columns `race_date`, `race_number`, `horse_id` in the original data.\n",
    "\n",
    "# Step 1: Predict Probabilities\n",
    "proba = rf_model.predict_proba(X_test_scaled)  # Shape: (n_samples, 2)\n",
    "predicted_probs = proba[:, 1]  # Probability for class 1 (winning)\n",
    "\n",
    "# Step 2: Create a DataFrame for `X_test` with metadata\n",
    "# Replace with actual metadata (e.g., from original test data before splitting)\n",
    "metadata = pd.DataFrame({\n",
    "    \"race_date\": race_date,  # Replace with actual race dates\n",
    "    \"race_number\": race_number,  # Replace with actual race numbers\n",
    "    \"horse_id\": horse_id,  # Replace with actual horse IDs\n",
    "})\n",
    "\n",
    "# Combine predicted probabilities with metadata\n",
    "ranked_df = metadata.copy()\n",
    "ranked_df[\"predicted_probability\"] = predicted_probs\n",
    "\n",
    "# Step 3: Rank Horses\n",
    "# Group by race_date and race_number, then rank by predicted_probability\n",
    "ranked_df[\"rank\"] = (\n",
    "    ranked_df.groupby([\"race_date\", \"race_number\"])[\"predicted_probability\"]\n",
    "    .rank(method=\"first\", ascending=False)\n",
    ")\n",
    "\n",
    "# Step 4: Sort Ranked DataFrame\n",
    "ranked_df = ranked_df.sort_values(by=[\"race_date\", \"race_number\", \"rank\"])\n",
    "\n",
    "# Step 5: Save or Display Results\n",
    "print(ranked_df.head(20))  # Display top 20 ranked horses\n",
    "ranked_df.to_csv(\"ranked_horses.csv\", index=False)  # Save to CSV if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca5f385",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranked_df = metadata_test.copy()  # Metadata includes race_date, race_number, horse_id\n",
    "ranked_df[\"predicted_probability\"] = predicted_probs\n",
    "ranked_df[\"actual_label\"] = y_test  # Optional: for evaluation purposes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b920b06",
   "metadata": {},
   "source": [
    "## Predict via Ranking using Test Race from Dataset\n",
    "\n",
    "You can test the model on a race in your dataset by excluding the target variable (official_fin) and making predictions as if it were a new race. Here’s how you can proceed:\n",
    "\n",
    "Step 1: Select a Race for Testing\n",
    "\n",
    "Extract a specific race from your dataset based on race_date and race_number.\n",
    "\n",
    "race_to_test = df[\n",
    "    (df[\"race_date\"] == \"2023-05-15\") & (df[\"race_number\"] == 5)\n",
    "].drop(columns=[\"official_fin\"])  # Drop the target variable\n",
    "\n",
    "Step 2: Prepare the Features\n",
    "\n",
    "Ensure that the extracted race has the same feature processing (scaling, encoding) as was done during training.\n",
    "\n",
    "# Extract features\n",
    "X_race = race_to_test[feature_cols]  # Ensure `feature_cols` matches the training feature set\n",
    "\n",
    "# Scale features\n",
    "X_race_scaled = scaler.transform(X_race)  # Use the scaler fitted during training\n",
    "\n",
    "Step 3: Predict Probabilities\n",
    "\n",
    "Use the model to predict probabilities for this specific race.\n",
    "\n",
    "# Predict probabilities\n",
    "race_probs = rf_model.predict_proba(X_race_scaled)\n",
    "\n",
    "# Attach probabilities back to the metadata\n",
    "race_to_test[\"predicted_probability\"] = race_probs[:, 1]  # Assuming class 1 is 'winning'\n",
    "\n",
    "# Rank horses by predicted probability\n",
    "race_to_test[\"rank\"] = race_to_test[\"predicted_probability\"].rank(ascending=False)\n",
    "race_to_test = race_to_test.sort_values(by=\"rank\")\n",
    "\n",
    "Step 4: Compare to Actual Results\n",
    "\n",
    "If you still have the actual official_fin values in a backup, compare the model’s ranking against the real results.\n",
    "\n",
    "# Add actual finish positions for comparison (if available)\n",
    "actual_results = df[\n",
    "    (df[\"race_date\"] == \"2023-05-15\") & (df[\"race_number\"] == 5)\n",
    "][[\"horse_id\", \"official_fin\"]]\n",
    "\n",
    "race_to_test = race_to_test.merge(actual_results, on=\"horse_id\", how=\"left\")\n",
    "\n",
    "# Display results\n",
    "print(race_to_test[[\"horse_id\", \"predicted_probability\", \"rank\", \"official_fin\"]])\n",
    "\n",
    "Testing Without horse_id, race_date, or race_number\n",
    "\n",
    "If you remove horse_id, race_date, or race_number, the model should still be able to make predictions if those columns are not part of the feature set. However, you won’t be able to group or rank the predictions by race because race_date and race_number are critical for distinguishing horses in the same race.\n",
    "\n",
    "To simulate a future race:\n",
    "\t1.\tSelect a race that the model hasn’t seen during training (e.g., from a holdout set).\n",
    "\t2.\tRemove any identifying metadata (e.g., horse_id, race_date, race_number).\n",
    "\t3.\tProcess the features the same way as during training.\n",
    "\t4.\tUse the model to predict probabilities for the horses in that race.\n",
    "\t5.\tRank the predictions by probability.\n",
    "\n",
    "Testing with a Future Race\n",
    "\n",
    "For a future race:\n",
    "\t1.\tCollect horse features for that race (e.g., from Equibase).\n",
    "\t2.\tProcess the data the same way as the training data.\n",
    "\t3.\tUse the model to make predictions.\n",
    "\t4.\tRank horses by predicted probabilities.\n",
    "\t5.\tWait for the race results and compare the model’s rankings to the actual outcomes.\n",
    "\n",
    "This approach ensures the model is evaluated on unseen data, simulating a real-world scenario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccea8560",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c9d5cf9c",
   "metadata": {},
   "source": [
    "## Hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f69c255",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f05de29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    \"n_estimators\": [50, 100, 200],\n",
    "    \"max_depth\": [None, 10, 20],\n",
    "    \"max_features\": [\"auto\", \"sqrt\", 0.5],\n",
    "    \"class_weight\": [None, \"balanced\"]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=RandomForestClassifier(random_state=42),\n",
    "    param_grid=param_grid,\n",
    "    scoring=\"accuracy\",    # or \"f1\", \"balanced_accuracy\", etc.\n",
    "    cv=3,                  # 3-fold cross-validation\n",
    "    n_jobs=-1             # use all CPU cores\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(\"Best Params:\", grid_search.best_params_)\n",
    "print(\"Best Score:\", grid_search.best_score_)\n",
    "\n",
    "# Then evaluate on the test set:\n",
    "best_rf = grid_search.best_estimator_\n",
    "y_pred_best = best_rf.predict(X_test)\n",
    "print(\"Final Test Accuracy:\", (y_pred_best == y_test).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a0649f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3486d1c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb16452a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
