{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f96c21c8",
   "metadata": {},
   "source": [
    "# Proposed Ensemble Models\n",
    "\n",
    "Given the constraints and objectives, I will consider the following models for the ensemble:\n",
    "\t\n",
    "    1.\tModel 1: LSTM Network on Raw GPS Data\n",
    "    \n",
    ">•\tInput Data: Sequences of raw GPS data (speed, progress, stride_frequency, etc.).\n",
    "\n",
    ">•\tArchitecture: An LSTM network designed to capture temporal dependencies and patterns in the sequential data.\n",
    "\n",
    ">•\tAdvantage: LSTMs are well-suited for time-series data and can learn complex temporal dynamics without the need for hand-engineered features like acceleration.\n",
    "\n",
    "    2.\tModel 2: 1D Convolutional Neural Network (1D-CNN)\n",
    "\t\n",
    ">•\tInput Data: The same raw GPS sequences as in Model 1.\n",
    "\n",
    ">•\tArchitecture: A 1D-CNN that applies convolutional filters across the time dimension to detect local patterns.\n",
    "\n",
    ">•\tAdvantage: CNNs can capture spatial hierarchies and are effective in recognizing patterns in sequences, potentially identifying features like sudden changes in speed or stride frequency.\n",
    "\n",
    "    3.\tModel 3: Transformer-based Model\n",
    "\t\n",
    ">•\tInput Data: Raw GPS sequences and possibly sectionals data.\n",
    "\n",
    ">•\tArchitecture: A Transformer model that uses self-attention mechanisms to weigh the importance of different parts of the sequence.\n",
    "\n",
    ">•\tAdvantage: Transformers can model long-range dependencies and focus on the most relevant parts of the sequence for prediction.\n",
    "\n",
    "## Additional Models (Optional):\n",
    "\n",
    "    4.\tModel 4: Gated Recurrent Unit (GRU) Network\n",
    "\n",
    ">•\tSimilar to LSTMs but with a simpler architecture, GRUs can be more efficient and may perform better on certain datasets.\n",
    "\n",
    ">•\tModel 5: Temporal Convolutional Network (TCN)\n",
    "\n",
    ">•\tTCNs are designed for sequential data and can capture long-term dependencies using causal convolutions and residual connections.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f703df",
   "metadata": {},
   "source": [
    "## Load Parquet Train, Test, and Validaion (VAL) Data:\n",
    "\n",
    "/home/exx/myCode/horse-racing/FoxRiverAIRacing/data/parquet/train_sequences.parquet\n",
    "\n",
    "/home/exx/myCode/horse-racing/FoxRiverAIRacing/data/parquet/test_sequences.parquet\n",
    "\n",
    "/home/exx/myCode/horse-racing/FoxRiverAIRacing/data/parquet/val_sequences.parquet\n",
    "\n",
    "# Set Environment\n",
    "import os\n",
    "import pyspark.sql.functions as F\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pyspark.sql import DataFrame\n",
    "from pyspark.sql.functions import col, size, when, count\n",
    "from src.data_preprocessing.data_prep1.data_utils import (\n",
    "    save_parquet, gather_statistics, initialize_environment,\n",
    "    load_config, initialize_logging, initialize_spark, \n",
    "    identify_and_impute_outliers, identify_and_remove_outliers, process_merged_results_sectionals,\n",
    "    identify_missing_and_outliers\n",
    ")\n",
    "\n",
    "try:\n",
    "    spark, jdbc_url, jdbc_properties, queries, parquet_dir, log_file = initialize_environment()\n",
    "    # input(\"Press Enter to continue...\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during initialization: {e}\")\n",
    "    logging.error(f\"An error occurred during initialization: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1cf56395",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-30 15:38:29,698 - INFO - Environment setup initialized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark session created successfully.\n"
     ]
    }
   ],
   "source": [
    "# Set Environment\n",
    "import os\n",
    "import pyspark.sql.functions as F\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pyspark.sql import DataFrame\n",
    "from pyspark.sql.functions import col, size, when, count\n",
    "from src.data_preprocessing.data_prep1.data_utils import (\n",
    "    save_parquet, gather_statistics, initialize_environment,\n",
    "    load_config, initialize_logging, initialize_spark, \n",
    "    identify_and_impute_outliers, identify_and_remove_outliers, process_merged_results_sectionals,\n",
    "    identify_missing_and_outliers\n",
    ")\n",
    "\n",
    "try:\n",
    "    spark, jdbc_url, jdbc_properties, queries, parquet_dir, log_file = initialize_environment()\n",
    "    # input(\"Press Enter to continue...\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during initialization: {e}\")\n",
    "    logging.error(f\"An error occurred during initialization: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f109da6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_sequences_path = os.path.join(parquet_dir, \"train_sequences.parquet\")\n",
    "val_sequences_path = os.path.join(parquet_dir, \"val_sequences.parquet\")\n",
    "test_sequences_path = os.path.join(parquet_dir, \"test_sequences.parquet\")\n",
    "train_sequences = spark.read.parquet(train_sequences_path)\n",
    "val_sequences = spark.read.parquet(val_sequences_path)\n",
    "test_sequences = spark.read.parquet(test_sequences_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eaecdf4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- horse_id: integer (nullable = true)\n",
      " |-- label: integer (nullable = true)\n",
      " |-- gate_index: integer (nullable = true)\n",
      " |-- course_cd_ohe: array (nullable = true)\n",
      " |    |-- element: double (containsNull = true)\n",
      " |-- equip_ohe: array (nullable = true)\n",
      " |    |-- element: double (containsNull = true)\n",
      " |-- surface_ohe: array (nullable = true)\n",
      " |    |-- element: double (containsNull = true)\n",
      " |-- trk_cond_ohe: array (nullable = true)\n",
      " |    |-- element: double (containsNull = true)\n",
      " |-- weather_ohe: array (nullable = true)\n",
      " |    |-- element: double (containsNull = true)\n",
      " |-- med_ohe: array (nullable = true)\n",
      " |    |-- element: double (containsNull = true)\n",
      " |-- stk_clm_md_ohe: array (nullable = true)\n",
      " |    |-- element: double (containsNull = true)\n",
      " |-- turf_mud_mark_ohe: array (nullable = true)\n",
      " |    |-- element: double (containsNull = true)\n",
      " |-- race_type_ohe: array (nullable = true)\n",
      " |    |-- element: double (containsNull = true)\n",
      " |-- scaled_features: vector (nullable = true)\n",
      " |-- aggregated_struct: struct (nullable = true)\n",
      " |    |-- ohe_flat: array (nullable = true)\n",
      " |    |    |-- element: double (containsNull = true)\n",
      " |    |-- avg_speed_agg: double (nullable = true)\n",
      " |    |-- max_speed_agg: double (nullable = true)\n",
      " |    |-- final_speed_agg: double (nullable = true)\n",
      " |    |-- avg_accel_agg: double (nullable = true)\n",
      " |    |-- fatigue_agg: double (nullable = true)\n",
      " |    |-- sectional_time_agg: double (nullable = true)\n",
      " |    |-- running_time_agg: double (nullable = true)\n",
      " |    |-- distance_back_agg: double (nullable = true)\n",
      " |    |-- distance_ran_agg: double (nullable = true)\n",
      " |    |-- strides_agg: double (nullable = true)\n",
      " |    |-- max_speed_overall: double (nullable = true)\n",
      " |    |-- min_speed_overall: double (nullable = true)\n",
      " |-- past_races_sequence: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- ohe_flat: array (nullable = true)\n",
      " |    |    |    |-- element: double (containsNull = true)\n",
      " |    |    |-- avg_speed_agg: double (nullable = true)\n",
      " |    |    |-- max_speed_agg: double (nullable = true)\n",
      " |    |    |-- final_speed_agg: double (nullable = true)\n",
      " |    |    |-- avg_accel_agg: double (nullable = true)\n",
      " |    |    |-- fatigue_agg: double (nullable = true)\n",
      " |    |    |-- sectional_time_agg: double (nullable = true)\n",
      " |    |    |-- running_time_agg: double (nullable = true)\n",
      " |    |    |-- distance_back_agg: double (nullable = true)\n",
      " |    |    |-- distance_ran_agg: double (nullable = true)\n",
      " |    |    |-- strides_agg: double (nullable = true)\n",
      " |    |    |-- max_speed_overall: double (nullable = true)\n",
      " |    |    |-- min_speed_overall: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_sequences.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "728c1701",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Convert to Pandas DataFrame\n",
    "train_sequences_pd = train_sequences.toPandas()\n",
    "val_sequences_pd = val_sequences.toPandas()\n",
    "test_sequences_pd = test_sequences.toPandas()\n",
    "\n",
    "horse_ids_train = train_sequences_pd[\"horse_id\"].values  # Extract horse_id for training\n",
    "horse_ids_val = val_sequences_pd[\"horse_id\"].values  # Extract horse_id for validation\n",
    "horse_ids_test = test_sequences_pd[\"horse_id\"].values  # Extract horse_id for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0fca647b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------+\n",
      "|size(past_races_sequence)|\n",
      "+-------------------------+\n",
      "|                       10|\n",
      "+-------------------------+\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(train_sequences.select(F.size(\"past_races_sequence\")).distinct().show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e78edfb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Row(label=1, count=5840), Row(label=6, count=3640), Row(label=3, count=5955), Row(label=5, count=4928), Row(label=4, count=5738), Row(label=7, count=5065), Row(label=2, count=5984), Row(label=0, count=5662)]\n"
     ]
    }
   ],
   "source": [
    "label_distribution = train_sequences.groupBy(\"label\").count().collect()\n",
    "print(label_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "779dec92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...\n",
       "1    [([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...\n",
       "2    [([0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...\n",
       "3    [([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0...\n",
       "4    [([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0...\n",
       "Name: past_races_sequence, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sequences_pd[\"past_races_sequence\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04b82223",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def flatten_sequence(sequence):\n",
    "    \"\"\"\n",
    "    Flattens a sequence of race data into a single NumPy array.\n",
    "    Ensures uniform array shapes for each time step in the sequence.\n",
    "    \"\"\"\n",
    "    ohe_length = 43 + 26 + 10 + 2 + 8 + 7 + 5 + 4 + 4 + 14  # Total OHE length\n",
    "    aggregator_length = len(aggregator_cols)  # Length of aggregator columns\n",
    "\n",
    "    flattened_sequence = []\n",
    "    for step in sequence:\n",
    "        # Extract `ohe_flat` or default to zero array\n",
    "        ohe_flat = step[\"ohe_flat\"] if \"ohe_flat\" in step else [0.0] * ohe_length\n",
    "\n",
    "        # Ensure `ohe_flat` has the correct length\n",
    "        if len(ohe_flat) != ohe_length:\n",
    "            ohe_flat = [0.0] * ohe_length\n",
    "\n",
    "        # Extract aggregator values or default to -999.0\n",
    "        aggregator_values = [step[agg] if agg in step else -999.0 for agg in aggregator_cols]\n",
    "\n",
    "        # Concatenate `ohe_flat` and aggregator values\n",
    "        flattened_step = np.array(ohe_flat + aggregator_values)\n",
    "\n",
    "        # Verify the length of the flattened step\n",
    "        if len(flattened_step) != (ohe_length + aggregator_length):\n",
    "            raise ValueError(f\"Flattened step has inconsistent length: {len(flattened_step)}\")\n",
    "\n",
    "        flattened_sequence.append(flattened_step)\n",
    "\n",
    "    return np.array(flattened_sequence)\n",
    "\n",
    "aggregator_cols = [\n",
    "    \"avg_speed_agg\", \"max_speed_agg\", \"final_speed_agg\", \"avg_accel_agg\", \n",
    "    \"fatigue_agg\", \"sectional_time_agg\", \"running_time_agg\", \"distance_back_agg\", \n",
    "    \"distance_ran_agg\", \"strides_agg\", \"max_speed_overall\", \"min_speed_overall\"\n",
    "]\n",
    "\n",
    "X_train = np.array([flatten_sequence(seq) for seq in train_sequences_pd[\"past_races_sequence\"]])\n",
    "y_train = train_sequences_pd[\"label\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c0ee064c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array([flatten_sequence(seq) for seq in train_sequences_pd[\"past_races_sequence\"]])\n",
    "y_train = train_sequences_pd[\"label\"].values\n",
    "\n",
    "X_val = np.array([flatten_sequence(seq) for seq in val_sequences_pd[\"past_races_sequence\"]])\n",
    "y_val = val_sequences_pd[\"label\"].values\n",
    "\n",
    "X_test = np.array([flatten_sequence(seq) for seq in test_sequences_pd[\"past_races_sequence\"]])\n",
    "y_test = test_sequences_pd[\"label\"].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "09a71c0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (42812, 10, 135)\n",
      "y_train shape: (42812,)\n"
     ]
    }
   ],
   "source": [
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9fc17a27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6 7]\n"
     ]
    }
   ],
   "source": [
    " # Label targets\n",
    "print(np.unique(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "10c190a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|label|count|\n",
      "+-----+-----+\n",
      "|    0| 5662|\n",
      "|    1| 5840|\n",
      "|    2| 5984|\n",
      "|    3| 5955|\n",
      "|    4| 5738|\n",
      "|    5| 4928|\n",
      "|    6| 3640|\n",
      "|    7| 5065|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "label_dist = train_sequences.groupBy(\"label\").count().orderBy(\"label\")\n",
    "label_dist.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "382e23df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|label|count|\n",
      "+-----+-----+\n",
      "|    0| 1055|\n",
      "|    1| 1115|\n",
      "|    2| 1130|\n",
      "|    3| 1107|\n",
      "|    4| 1073|\n",
      "|    5|  943|\n",
      "|    6|  821|\n",
      "|    7| 1224|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "label_dist = test_sequences.groupBy(\"label\").count().orderBy(\"label\")\n",
    "label_dist.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "42173d97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (42812, 10, 135), y_train shape: (42812,), horse_ids_train shape: (42812,)\n",
      "X_val shape: (11253, 10, 135), y_val shape: (11253,), horse_ids_val shape: (11253,)\n",
      "X_test shape: (8468, 10, 135), y_test shape: (8468,), horse_ids_test shape: (8468,)\n"
     ]
    }
   ],
   "source": [
    "print(f\"X_train shape: {X_train.shape}, y_train shape: {y_train.shape}, horse_ids_train shape: {horse_ids_train.shape}\")\n",
    "print(f\"X_val shape: {X_val.shape}, y_val shape: {y_val.shape}, horse_ids_val shape: {horse_ids_val.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}, y_test shape: {y_test.shape}, horse_ids_test shape: {horse_ids_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cdb17aa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_features      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">135</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">25,984</span> │ input_features[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">12,352</span> │ dropout_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_horse_id      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_max_pooling… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv1d_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling1…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_2         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">339,072</span> │ input_horse_id[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ global_max_pooli… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embedding_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_2       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ flatten_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">6,208</span> │ concatenate_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">325</span> │ dropout_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_features      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m135\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_4 (\u001b[38;5;33mConv1D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │     \u001b[38;5;34m25,984\u001b[0m │ input_features[\u001b[38;5;34m0\u001b[0m… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ conv1d_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv1d_5 (\u001b[38;5;33mConv1D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │     \u001b[38;5;34m12,352\u001b[0m │ dropout_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_horse_id      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_max_pooling… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ conv1d_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mGlobalMaxPooling1…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_2         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │    \u001b[38;5;34m339,072\u001b[0m │ input_horse_id[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ global_max_pooli… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_2 (\u001b[38;5;33mFlatten\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ embedding_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_2       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m96\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dropout_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ flatten_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m6,208\u001b[0m │ concatenate_2[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_8 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dense_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)         │        \u001b[38;5;34m325\u001b[0m │ dropout_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">383,941</span> (1.46 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m383,941\u001b[0m (1.46 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">383,941</span> (1.46 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m383,941\u001b[0m (1.46 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import (Input, Conv1D, Dropout, GlobalMaxPooling1D, \n",
    "                                     Dense, Embedding, Flatten, Concatenate)\n",
    "\n",
    "# Define the input shapes\n",
    "time_steps = X_train.shape[1]\n",
    "features = X_train.shape[2]\n",
    "num_horses = len(np.unique(horse_ids_train))\n",
    "\n",
    "# 1) Input layers\n",
    "input_features = Input(shape=(time_steps, features), name='input_features')\n",
    "input_horse_id = Input(shape=(1,), name='input_horse_id')\n",
    "\n",
    "# 2) Horse embedding\n",
    "embedding = Embedding(input_dim=num_horses, output_dim=32)(input_horse_id)\n",
    "embedding = Flatten()(embedding)\n",
    "\n",
    "# 3) CNN layers\n",
    "x = Conv1D(filters=64, kernel_size=3, activation='relu')(input_features)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Conv1D(filters=64, kernel_size=3, activation='relu')(x)\n",
    "x = GlobalMaxPooling1D()(x)  # or GlobalAveragePooling1D()\n",
    "x = Dropout(0.2)(x)\n",
    "\n",
    "# 4) Concatenate CNN output with embedding\n",
    "concat = Concatenate()([x, embedding])\n",
    "\n",
    "# 5) Dense layers\n",
    "dense_out = Dense(64, activation='relu')(concat)\n",
    "dense_out = Dropout(0.2)(dense_out)\n",
    "\n",
    "# 6) Output layer (assume 5-class classification example)\n",
    "output = Dense(5, activation='softmax')(dense_out)\n",
    "\n",
    "model_cnn = Model(inputs=[input_features, input_horse_id], outputs=output)\n",
    "model_cnn.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model_cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "787fa0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_scheduler = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss', factor=0.5, patience=5, min_lr=1e-5\n",
    ")\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', patience=10, restore_best_weights=True\n",
    ")\n",
    "\n",
    "model_checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath='best_model.keras',\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "30426d1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 5662, 1: 5840, 2: 5984, 3: 5955, 4: 5738, 5: 4928, 6: 3640, 7: 5065}\n",
      "[0 1 2 3 4 5 6 7]\n",
      "[5662 5840 5984 5955 5738 4928 3640 5065]\n"
     ]
    }
   ],
   "source": [
    "unique, counts = np.unique(y_train, return_counts=True)\n",
    "train_counts = dict(zip(unique, counts))\n",
    "\n",
    "print(train_counts)\n",
    "print(unique)\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7d22444e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 1.4786206896551723, 1: 1.3809983896940419, 2: 1.4198675496688742, 3: 1.4437710437710438, 4: 0.453996823716252}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Train label counts from your distribution\n",
    "train_counts = np.array([580, 621, 604, 594, 1889])\n",
    "total = train_counts.sum()  # 18164\n",
    "n_classes = len(train_counts)  # 5\n",
    "\n",
    "class_weight = {}\n",
    "for i, count_i in enumerate(train_counts):\n",
    "    class_weight[i] = float(total) / (n_classes * count_i)\n",
    "\n",
    "print(class_weight)\n",
    "# Example output:\n",
    "# {0: 1.463870..., 1: 1.416..., 2: 1.426..., 3: 1.446..., 4: 0.45...}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee588f9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1735595250.889758 3092494 service.cc:146] XLA service 0x7f7998001ef0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1735595250.889781 3092494 service.cc:154]   StreamExecutor device (0): NVIDIA RTX A6000, Compute Capability 8.6\n",
      "I0000 00:00:1735595250.889783 3092494 service.cc:154]   StreamExecutor device (1): NVIDIA RTX A6000, Compute Capability 8.6\n",
      "2024-12-30 15:47:30.906599: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-12-30 15:47:30.980392: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 90300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m169/669\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 901us/step - accuracy: 0.1249 - loss: nan"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1735595252.372365 3092494 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m669/669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.1315 - loss: nan - val_accuracy: 0.1277 - val_loss: nan - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m669/669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.1365 - loss: nan - val_accuracy: 0.1277 - val_loss: nan - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m669/669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.1347 - loss: nan - val_accuracy: 0.1277 - val_loss: nan - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m669/669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.1332 - loss: nan - val_accuracy: 0.1277 - val_loss: nan - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m669/669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.1360 - loss: nan - val_accuracy: 0.1277 - val_loss: nan - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m669/669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.1305 - loss: nan - val_accuracy: 0.1277 - val_loss: nan - learning_rate: 5.0000e-04\n",
      "Epoch 7/50\n",
      "\u001b[1m669/669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.1322 - loss: nan - val_accuracy: 0.1277 - val_loss: nan - learning_rate: 5.0000e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m669/669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.1368 - loss: nan - val_accuracy: 0.1277 - val_loss: nan - learning_rate: 5.0000e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m655/669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 847us/step - accuracy: 0.1363 - loss: nan"
     ]
    }
   ],
   "source": [
    "# Then fit your model:\n",
    "history = model_cnn.fit(\n",
    "    [X_train, horse_ids_train],\n",
    "    y_train,\n",
    "    epochs=50,\n",
    "    batch_size=64,\n",
    "    validation_data=([X_val, horse_ids_val], y_val),\n",
    "    callbacks=[lr_scheduler, early_stopping, model_checkpoint],\n",
    "    class_weight=class_weight,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0c647b19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.1295 - loss: nan\n",
      "Validation Loss: nan, Validation Accuracy: 0.13089843094348907\n"
     ]
    }
   ],
   "source": [
    "# Evaluate:\n",
    "val_loss, val_accuracy = model_cnn.evaluate([X_val, horse_ids_val], y_val)\n",
    "print(f'Validation Loss: {val_loss}, Validation Accuracy: {val_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d24823de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m265/265\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "preds = model_gru.predict([X_test, horse_ids_test])\n",
    "print(np.argmax(preds, axis=-1)[:50])  # First 50 predictio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d936d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "#model.save('/path/to/save/model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "686865bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.03624932,  0.01595378, -0.01132381, ...,  0.01218581,\n",
       "          0.03504742,  0.02878574],\n",
       "        [-0.04518082, -0.04061698,  0.01971302, ...,  0.04646026,\n",
       "          0.02600035, -0.00787012],\n",
       "        [-0.00503497, -0.00930778, -0.01403008, ..., -0.02993131,\n",
       "          0.02693386, -0.00233991],\n",
       "        ...,\n",
       "        [-0.03675495,  0.00015531,  0.04402621, ...,  0.00095692,\n",
       "         -0.03980571, -0.02099963],\n",
       "        [-0.04129555, -0.00743706,  0.00836102, ..., -0.0076436 ,\n",
       "          0.00274826, -0.03877602],\n",
       "        [-0.01163303,  0.0312897 , -0.01761264, ..., -0.00316349,\n",
       "         -0.02661247, -0.01493084]], dtype=float32)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_gru.get_layer(\"embedding_1\").get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284c5de2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
