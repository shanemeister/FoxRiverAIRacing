{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "277e9121-0ed4-44f3-b848-ba98dc6ce795",
   "metadata": {},
   "source": [
    "# Proposed Ensemble Models\n",
    "\n",
    "Given the constraints and objectives, I recommend considering the following models for the ensemble:\n",
    "\t\n",
    "    1.\tModel 1: LSTM Network on Raw GPS Data\n",
    "    \n",
    ">•\tInput Data: Sequences of raw GPS data (speed, progress, stride_frequency, etc.).\n",
    "\n",
    ">•\tArchitecture: An LSTM network designed to capture temporal dependencies and patterns in the sequential data.\n",
    "\n",
    ">•\tAdvantage: LSTMs are well-suited for time-series data and can learn complex temporal dynamics without the need for hand-engineered features like acceleration.\n",
    "\n",
    "    2.\tModel 2: 1D Convolutional Neural Network (1D-CNN)\n",
    "\t\n",
    ">•\tInput Data: The same raw GPS sequences as in Model 1.\n",
    "\n",
    ">•\tArchitecture: A 1D-CNN that applies convolutional filters across the time dimension to detect local patterns.\n",
    "\n",
    ">•\tAdvantage: CNNs can capture spatial hierarchies and are effective in recognizing patterns in sequences, potentially identifying features like sudden changes in speed or stride frequency.\n",
    "\n",
    "    3.\tModel 3: Transformer-based Model\n",
    "\t\n",
    ">•\tInput Data: Raw GPS sequences and possibly sectionals data.\n",
    "\n",
    ">•\tArchitecture: A Transformer model that uses self-attention mechanisms to weigh the importance of different parts of the sequence.\n",
    "\n",
    ">•\tAdvantage: Transformers can model long-range dependencies and focus on the most relevant parts of the sequence for prediction.\n",
    "\n",
    "## Additional Models (Optional):\n",
    "\n",
    "    4.\tModel 4: Gated Recurrent Unit (GRU) Network\n",
    "\n",
    ">•\tSimilar to LSTMs but with a simpler architecture, GRUs can be more efficient and may perform better on certain datasets.\n",
    "\n",
    ">•\tModel 5: Temporal Convolutional Network (TCN)\n",
    "\n",
    ">•\tTCNs are designed for sequential data and can capture long-term dependencies using causal convolutions and residual connections.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "144788c4-1601-45af-97bd-2832f1d4d22d",
   "metadata": {},
   "source": [
    "# The LSTM Network on Raw GPS Data\n",
    "\n",
    "Initially I desired to merge the GPS data with Sectionals, but the timestamp and gate_name intervals of each respectively made it difficult to align the data in sequences -- something that is needed for Long-Short Term Memory models. Therefore, it was decided to go with an ensemble approach. There will be additional models that incorporate Equibase data as well, but for the time being, the focus will be on Total Performance GPS data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0647b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment setup\n",
    "\n",
    "import logging\n",
    "import os\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy import text\n",
    "import geopandas as gpd\n",
    "from datetime import datetime\n",
    "import configparser\n",
    "from src.data_ingestion.ingestion_utils import (\n",
    "    get_db_connection, update_tracking, load_processed_files\n",
    ")\n",
    "from src.data_ingestion.eqb_ppData import process_pluspro_data\n",
    "from src.data_ingestion.eqb_resultsCharts import process_resultscharts_data\n",
    "from src.data_ingestion.tpd_datasets import (\n",
    "    process_tpd_sectionals_data,\n",
    "    process_tpd_gpsdata_data\n",
    ")\n",
    "import traceback\n",
    "\n",
    "# Load the configuration file\n",
    "config = configparser.ConfigParser()\n",
    "config.read('/home/exx/myCode/horse-racing/FoxRiverAIRacing/config.ini')\n",
    "\n",
    "# Set up logging for consistent logging behavior in Notebook\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# Retrieve database credentials from config file\n",
    "# Retrieve database credentials from config file\n",
    "db_host = config['database']['host']\n",
    "db_port = config['database']['port']\n",
    "db_name = config['database']['dbname']  # Corrected from 'name' to 'dbname'\n",
    "db_user = config['database']['user']\n",
    "\n",
    "# Establish connection using get_db_connection\n",
    "conn = get_db_connection(config)\n",
    "\n",
    "# Create the SQLAlchemy engine\n",
    "engine = create_engine(f'postgresql+psycopg2://{db_user}@{db_host}:{db_port}/{db_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78392887",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_results = \"\"\"\n",
    "   SELECT *\n",
    "    FROM results_entries\n",
    "    WHERE breed = 'TB';\n",
    "\"\"\"\n",
    "\n",
    "query_sectionals = \"\"\"    \n",
    "    \n",
    "SELECT *\n",
    "FROM sectionals;\n",
    "\"\"\"\n",
    "query_gpspoint = \"\"\"\n",
    "select * from gpspoint;\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8b5e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute the query and load data into a DataFrame\n",
    "gps_df = pd.read_sql_query(query_gpspoint, engine, parse_dates=['time_stamp'])\n",
    "sectionals_df = pd.read_sql_query(query_sectionals, engine)\n",
    "results_df = pd.read_sql_query(query_results, engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51918fe",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "gps_df.to_parquet('/home/exx/myCode/horse-racing/FoxRiverAIRacing/notebooks/data/GPS.parquet', index=False)\n",
    "sectionals_df.to_parquet('/home/exx/myCode/horse-racing/FoxRiverAIRacing/notebooks/data/Sectionals.parquet', index=False)\n",
    "results_df.to_parquet('/home/exx/myCode/horse-racing/FoxRiverAIRacing/notebooks/data/Results.parquet', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20e1766e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               time_stamp saddle_cloth_number  longitude   latitude  speed  \\\n",
      "0 2024-10-25 16:44:39.200                 2   -73.828833  40.670248   0.06   \n",
      "1 2024-10-25 16:44:39.200                 3   -73.828808  40.670240   0.02   \n",
      "2 2024-10-25 16:44:39.200                 4   -73.828802  40.670239   0.07   \n",
      "3 2024-10-25 16:44:39.200                 5   -73.828788  40.670229   0.04   \n",
      "4 2024-10-25 16:44:39.200                 6   -73.828777  40.670236   0.09   \n",
      "\n",
      "   progress  stride_frequency  \\\n",
      "0    1207.0               NaN   \n",
      "1    1207.0               NaN   \n",
      "2    1207.0               NaN   \n",
      "3    1207.0               NaN   \n",
      "4    1207.0               NaN   \n",
      "\n",
      "                                            location course_cd  race_date  \\\n",
      "0  0101000020E61000008976BA980B7552C00FDC37ADCA55...       AQU 2024-10-25   \n",
      "1  0101000020E6100000482B082F0B7552C04B3CA06CCA55...       AQU 2024-10-25   \n",
      "2  0101000020E6100000F415A4190B7552C0E6006663CA55...       AQU 2024-10-25   \n",
      "3  0101000020E6100000245525DB0A7552C081690712CA55...       AQU 2024-10-25   \n",
      "4  0101000020E61000002A2C02AD0A7552C033CCBF4CCA55...       AQU 2024-10-25   \n",
      "\n",
      "   race_number               last_updated  \n",
      "0            1 2024-11-28 09:04:32.159423  \n",
      "1            1 2024-11-28 09:04:32.160063  \n",
      "2            1 2024-11-28 09:04:32.160439  \n",
      "3            1 2024-11-28 09:04:32.160807  \n",
      "4            1 2024-11-28 09:04:32.161174  \n",
      "  saddle_cloth_number course_cd  race_date  race_number gate_name  \\\n",
      "0                 3         AQU 2023-12-14            4      5.5f   \n",
      "1                 1         AQU 2023-12-14            4        5f   \n",
      "2                 5         AQU 2023-12-14            4        5f   \n",
      "3                 7         AQU 2023-12-14            4        5f   \n",
      "4                 2         AQU 2023-12-14            4        5f   \n",
      "\n",
      "   length_to_finish  sectional_time  running_time  distance_back  \\\n",
      "0            1106.4            6.88         6.875            5.6   \n",
      "1            1005.8            5.41        11.978            0.0   \n",
      "2            1005.8            5.44        11.994            0.3   \n",
      "3            1005.8            5.44        12.121            2.7   \n",
      "4            1005.8            5.50        12.173            3.6   \n",
      "\n",
      "   distance_ran  number_of_strides  gate_numeric  \n",
      "0         100.6               17.0           5.5  \n",
      "1         100.6               14.0           5.0  \n",
      "2         100.6               14.1           5.0  \n",
      "3         100.6               13.7           5.0  \n",
      "4         100.6               13.4           5.0  \n",
      "        horse_name breed                                            last_pp  \\\n",
      "0  Optimistic Nate    TB  {'TRACK': {'CODE': 'PRX', 'NAME': 'PARX RACING...   \n",
      "1      Badbadbobby    TB  {'TRACK': {'CODE': 'PRX', 'NAME': 'PARX RACING...   \n",
      "2   Clancy O'Toole    TB  {'TRACK': {'CODE': 'PEN', 'NAME': 'PENN NATION...   \n",
      "3    Bullet Breeze    TB  {'TRACK': {'CODE': 'PRX', 'NAME': 'PARX RACING...   \n",
      "4  Papa Do Papa Do    TB  {'TRACK': {'CODE': 'PRX', 'NAME': 'PARX RACING...   \n",
      "\n",
      "   weight  age meds equip  dollar_odds program_num  post_pos  ...  \\\n",
      "0     122    4    L     b          8.2         1           1  ...   \n",
      "1     117    5    L     b         22.3         2           2  ...   \n",
      "2     119    3    L     f          0.7         3           3  ...   \n",
      "3     122    4    L    bf          2.5         4           4  ...   \n",
      "4     119    3    L  None         81.4         5           5  ...   \n",
      "\n",
      "                   axciskey  \\\n",
      "0  050049050052061056058062   \n",
      "1  049058050051055056061064   \n",
      "2  050050050052052054058060   \n",
      "3  050049050052053061057062   \n",
      "4  050050050052059054060064   \n",
      "\n",
      "                                       point_of_call  jock_key train_key  \\\n",
      "0  [{'WHICH': None, 'LENGTHS': None, 'POSITION': ...    136730    974678   \n",
      "1  [{'WHICH': None, 'LENGTHS': None, 'POSITION': ...    172054      2357   \n",
      "2  [{'WHICH': None, 'LENGTHS': None, 'POSITION': ...    166267    267532   \n",
      "3  [{'WHICH': None, 'LENGTHS': None, 'POSITION': ...    151624    975951   \n",
      "4  [{'WHICH': None, 'LENGTHS': None, 'POSITION': ...    157670    968751   \n",
      "\n",
      "   course_cd  race_date           post_time race_number  sex_code  \\\n",
      "0        PRX 2024-11-27 2024-12-01 12:08:00           1         G   \n",
      "1        PRX 2024-11-27 2024-12-01 12:08:00           1         G   \n",
      "2        PRX 2024-11-27 2024-12-01 12:08:00           1         C   \n",
      "3        PRX 2024-11-27 2024-12-01 12:08:00           1         G   \n",
      "4        PRX 2024-11-27 2024-12-01 12:08:00           1         G   \n",
      "\n",
      "   sex_description  \n",
      "0          Gelding  \n",
      "1          Gelding  \n",
      "2             Colt  \n",
      "3          Gelding  \n",
      "4          Gelding  \n",
      "\n",
      "[5 rows x 32 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the Parquet file into a DataFrame\n",
    "gps_df = pd.read_parquet('/home/exx/myCode/horse-racing/FoxRiverAIRacing/notebooks/data/GPS.parquet')\n",
    "sectionals_df = pd.read_parquet('/home/exx/myCode/horse-racing/FoxRiverAIRacing/notebooks/data/Sectionals.parquet')\n",
    "results_df = pd.read_parquet('/home/exx/myCode/horse-racing/FoxRiverAIRacing/notebooks/data/Results.parquet')\n",
    "\n",
    "# Display the DataFrames\n",
    "print(gps_df.head())\n",
    "print(sectionals_df.head())\n",
    "print(results_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80814863",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete a column using del\n",
    "# del results_df['post_time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f2d314e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gps_df['race_date'] = pd.to_datetime(gps_df['race_date'])\n",
    "sectionals_df['race_date'] = pd.to_datetime(sectionals_df['race_date'])\n",
    "results_df['race_date'] = pd.to_datetime(results_df['race_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7423ba07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join gps_df with results_df\n",
    "merged_df = gps_df.merge(results_df, \n",
    "                          left_on=['course_cd', 'race_date', 'race_number', 'saddle_cloth_number'], \n",
    "                          right_on=['course_cd', 'race_date', 'race_number', 'program_num'], \n",
    "                          how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c1f7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join the result with sectionals_df\n",
    "merged_df = merged_df.merge(sectionals_df, \n",
    "                             left_on=['course_cd', 'race_date', 'race_number', 'saddle_cloth_number'], \n",
    "                             right_on=['course_cd', 'race_date', 'race_number', 'saddle_cloth_number'], \n",
    "                             how='inner')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c815126",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Select the required columns\n",
    "final_df = merged_df[[\n",
    "    'course_cd',\n",
    "    'race_date',\n",
    "    'race_number',\n",
    "    'saddle_cloth_number',\n",
    "    'time_stamp',\n",
    "    'gate_numeric',\n",
    "    'weight', \n",
    "    'age', \n",
    "    'meds', \n",
    "    'equip', \n",
    "    'dollar_odds', \n",
    "    'post_pos', \n",
    "    'finish_time', \n",
    "    'speed_rating', \n",
    "    'official_fin',\n",
    "    'longitude',\n",
    "    'latitude',\n",
    "    'speed',\n",
    "    'stride_frequency',\n",
    "    'number_of_strides',\n",
    "    'sectional_time',\n",
    "    'running_time',\n",
    "    'progress',\n",
    "    'length_to_finish',\n",
    "    'distance_back',\n",
    "    'distance_ran'\n",
    "]]\n",
    "\n",
    "# Optionally, sort the final DataFrame\n",
    "final_df = final_df.sort_values(by=['course_cd', 'race_date', 'race_number', 'saddle_cloth_number', 'time_stamp', 'gate_numeric'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12fe7ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(gps_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b96e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(gps_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006b6e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(merged_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c30501",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calculate correlation matrix\n",
    "corr_matrix = df[['speed', 'progress', 'stride_frequency', 'longitude', 'latitude', 'post_pos', 'official_fin']].corr()\n",
    "\n",
    "# Plot heatmap\n",
    "sns.heatmap(corr_matrix, annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70a5d93-705d-42e3-956a-9cb9dbc4178a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "\n",
    "# Define your variables\n",
    "max_seq_length = 120  # Replace with your maximum sequence length\n",
    "num_features = 5      # Replace with the actual number of features in your data\n",
    "num_classes = 12      # Replace with the actual number of classes\n",
    "\n",
    "# Build your model\n",
    "model_lstm = tf.keras.Sequential()\n",
    "model_lstm.add(tf.keras.layers.Masking(mask_value=0., input_shape=(max_seq_length, num_features)))\n",
    "model_lstm.add(tf.keras.layers.LSTM(128))\n",
    "model_lstm.add(tf.keras.layers.Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model_lstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3dddd20-cbb3-4444-98d7-10f3931ef518",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ce19d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data into dataframe:\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd02ef34-d54b-4619-bf4b-c2128e9bc171",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "\n",
    "history_lstm = model_lstm.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=[early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816d5e01-6b93-41af-af61-7ee2fa5827c7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Combining the Models\n",
    "\n",
    "To create an ensemble, you can combine the predictions of these models in several ways:\n",
    "\t1.\tAveraging Probabilities:\n",
    "\t•\tObtain probability distributions over finishing positions from each model.\n",
    "\t•\tAverage the probabilities across models to get the final prediction.\n",
    "\t2.\tWeighted Averaging:\n",
    "\t•\tAssign weights to each model based on validation performance.\n",
    "\t•\tCompute a weighted average of the probabilities.\n",
    "\t3.\tStacking (Meta-Learner):\n",
    "\t•\tUse the predictions from the individual models as input features to a meta-model (e.g., a logistic regression or another neural network).\n",
    "\t•\tThe meta-model learns how to best combine the individual predictions.\n",
    "\t4.\tVoting (for Classification):\n",
    "\t•\tIf treating the problem as classification into discrete positions, use majority voting among the models.\n",
    "\t•\tNot as suitable if you need probability distributions.\n",
    "\n",
    "Implementation Steps\n",
    "\n",
    "1. Data Preparation\n",
    "\n",
    "\t•\tSequences:\n",
    "\t•\tUse the raw GPS data (gpspoint) to create sequences for each horse in each race.\n",
    "\t•\tEnsure that sequences are properly sorted by time_stamp.\n",
    "\t•\tFeatures:\n",
    "\t•\tInclude raw features such as speed, progress, stride_frequency.\n",
    "\t•\tAvoid hand-engineering features like acceleration to adhere to your objective.\n",
    "\t•\tLabels:\n",
    "\t•\tUse official_fin from results_entries as the target variable.\n",
    "\t•\tSince you want probabilities for each finishing position, consider encoding official_fin as categorical labels.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffdede23-c3ae-4f35-9620-a281a6c599c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
