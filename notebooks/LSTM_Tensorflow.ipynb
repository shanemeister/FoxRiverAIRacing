{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f96c21c8",
   "metadata": {},
   "source": [
    "# Proposed Ensemble Models\n",
    "\n",
    "Given the constraints and objectives, I will consider the following models for the ensemble:\n",
    "\t\n",
    "    1.\tModel 1: LSTM Network on Raw GPS Data\n",
    "    \n",
    ">•\tInput Data: Sequences of raw GPS data (speed, progress, stride_frequency, etc.).\n",
    "\n",
    ">•\tArchitecture: An LSTM network designed to capture temporal dependencies and patterns in the sequential data.\n",
    "\n",
    ">•\tAdvantage: LSTMs are well-suited for time-series data and can learn complex temporal dynamics without the need for hand-engineered features like acceleration.\n",
    "\n",
    "    2.\tModel 2: 1D Convolutional Neural Network (1D-CNN)\n",
    "\t\n",
    ">•\tInput Data: The same raw GPS sequences as in Model 1.\n",
    "\n",
    ">•\tArchitecture: A 1D-CNN that applies convolutional filters across the time dimension to detect local patterns.\n",
    "\n",
    ">•\tAdvantage: CNNs can capture spatial hierarchies and are effective in recognizing patterns in sequences, potentially identifying features like sudden changes in speed or stride frequency.\n",
    "\n",
    "    3.\tModel 3: Transformer-based Model\n",
    "\t\n",
    ">•\tInput Data: Raw GPS sequences and possibly sectionals data.\n",
    "\n",
    ">•\tArchitecture: A Transformer model that uses self-attention mechanisms to weigh the importance of different parts of the sequence.\n",
    "\n",
    ">•\tAdvantage: Transformers can model long-range dependencies and focus on the most relevant parts of the sequence for prediction.\n",
    "\n",
    "## Additional Models (Optional):\n",
    "\n",
    "    4.\tModel 4: Gated Recurrent Unit (GRU) Network\n",
    "\n",
    ">•\tSimilar to LSTMs but with a simpler architecture, GRUs can be more efficient and may perform better on certain datasets.\n",
    "\n",
    ">•\tModel 5: Temporal Convolutional Network (TCN)\n",
    "\n",
    ">•\tTCNs are designed for sequential data and can capture long-term dependencies using causal convolutions and residual connections.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "75b90c3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# packages in environment at /home/exx/anaconda3/envs/mamba_env/envs/tf_310:\r\n",
      "#\r\n",
      "# Name                    Version                   Build  Channel\r\n",
      "_libgcc_mutex             0.1                 conda_forge    conda-forge\r\n",
      "_openmp_mutex             4.5                       2_gnu    conda-forge\r\n",
      "anyio                     4.6.2.post1        pyhd8ed1ab_0    conda-forge\r\n",
      "argon2-cffi               23.1.0             pyhd8ed1ab_0    conda-forge\r\n",
      "argon2-cffi-bindings      21.2.0          py310ha75aee5_5    conda-forge\r\n",
      "arrow                     1.3.0              pyhd8ed1ab_0    conda-forge\r\n",
      "asttokens                 2.4.1              pyhd8ed1ab_0    conda-forge\r\n",
      "async-lru                 2.0.4              pyhd8ed1ab_0    conda-forge\r\n",
      "attrs                     24.2.0             pyh71513ae_0    conda-forge\r\n",
      "aws-c-auth                0.8.0                h56a2c13_4    conda-forge\r\n",
      "aws-c-cal                 0.8.0                hd3f4568_0    conda-forge\r\n",
      "aws-c-common              0.9.31               hb9d3cd8_0    conda-forge\r\n",
      "aws-c-compression         0.3.0                hf20e7d7_0    conda-forge\r\n",
      "aws-c-event-stream        0.5.0                h68c3b0c_2    conda-forge\r\n",
      "aws-c-http                0.9.0                hfad4ed3_3    conda-forge\r\n",
      "aws-c-io                  0.15.0               h17eb868_2    conda-forge\r\n",
      "aws-c-mqtt                0.11.0               h407ecb8_2    conda-forge\r\n",
      "aws-c-s3                  0.7.0                hadeddc1_5    conda-forge\r\n",
      "aws-c-sdkutils            0.2.0                hf20e7d7_0    conda-forge\r\n",
      "aws-checksums             0.2.0                hf20e7d7_0    conda-forge\r\n",
      "aws-crt-cpp               0.29.0               h73f0fd4_6    conda-forge\r\n",
      "aws-sdk-cpp               1.11.407             h6a6dca0_6    conda-forge\r\n",
      "azure-core-cpp            1.14.0               h5cfcd09_0    conda-forge\r\n",
      "azure-identity-cpp        1.10.0               h113e628_0    conda-forge\r\n",
      "azure-storage-blobs-cpp   12.13.0              h3cf044e_1    conda-forge\r\n",
      "azure-storage-common-cpp  12.8.0               h736e048_1    conda-forge\r\n",
      "azure-storage-files-datalake-cpp 12.12.0              ha633028_1    conda-forge\r\n",
      "babel                     2.16.0             pyhd8ed1ab_0    conda-forge\r\n",
      "beautifulsoup4            4.12.3             pyha770c72_0    conda-forge\r\n",
      "bleach                    6.2.0              pyhd8ed1ab_0    conda-forge\r\n",
      "brotli-python             1.1.0           py310hf71b8c6_2    conda-forge\r\n",
      "bzip2                     1.0.8                h4bc722e_7    conda-forge\r\n",
      "c-ares                    1.34.3               hb9d3cd8_1    conda-forge\r\n",
      "ca-certificates           2024.12.14           hbcca054_0    conda-forge\r\n",
      "cached-property           1.5.2                hd8ed1ab_1    conda-forge\r\n",
      "cached_property           1.5.2              pyha770c72_1    conda-forge\r\n",
      "certifi                   2024.12.14         pyhd8ed1ab_0    conda-forge\r\n",
      "cffi                      1.17.1          py310h8deb56e_0    conda-forge\r\n",
      "charset-normalizer        3.4.0              pyhd8ed1ab_0    conda-forge\r\n",
      "comm                      0.2.2              pyhd8ed1ab_0    conda-forge\r\n",
      "configparser              7.1.0              pyhd8ed1ab_0    conda-forge\r\n",
      "cyrus-sasl                2.1.27               h54b06d7_7    conda-forge\r\n",
      "debugpy                   1.8.9           py310hf71b8c6_0    conda-forge\r\n",
      "decorator                 5.1.1              pyhd8ed1ab_0    conda-forge\r\n",
      "defusedxml                0.7.1              pyhd8ed1ab_0    conda-forge\r\n",
      "entrypoints               0.4                pyhd8ed1ab_0    conda-forge\r\n",
      "exceptiongroup            1.2.2              pyhd8ed1ab_0    conda-forge\r\n",
      "executing                 2.1.0              pyhd8ed1ab_0    conda-forge\r\n",
      "fastkml                   0.12               pyhd8ed1ab_0    conda-forge\r\n",
      "fqdn                      1.5.1              pyhd8ed1ab_0    conda-forge\r\n",
      "gflags                    2.2.2             h5888daf_1005    conda-forge\r\n",
      "git                       2.47.1          pl5321h59d505e_0    conda-forge\r\n",
      "git-filter-repo           2.38.0             pyhd8ed1ab_0    conda-forge\r\n",
      "glog                      0.7.1                hbabe93e_0    conda-forge\r\n",
      "greenlet                  3.1.1           py310hf71b8c6_0    conda-forge\r\n",
      "h11                       0.14.0             pyhd8ed1ab_0    conda-forge\r\n",
      "h2                        4.1.0              pyhd8ed1ab_0    conda-forge\r\n",
      "hpack                     4.0.0              pyh9f0ad1d_0    conda-forge\r\n",
      "httpcore                  1.0.7              pyh29332c3_1    conda-forge\r\n",
      "httpx                     0.28.0             pyhd8ed1ab_0    conda-forge\r\n",
      "hyperframe                6.0.1              pyhd8ed1ab_0    conda-forge\r\n",
      "icu                       75.1                 he02047a_0    conda-forge\r\n",
      "idna                      3.10               pyhd8ed1ab_0    conda-forge\r\n",
      "importlib-metadata        8.5.0              pyha770c72_0    conda-forge\r\n",
      "importlib_resources       6.4.5              pyhd8ed1ab_0    conda-forge\r\n",
      "ipykernel                 6.29.5             pyh3099207_0    conda-forge\r\n",
      "ipython                   8.30.0             pyh707e725_0    conda-forge\r\n",
      "ipython_genutils          0.2.0              pyhd8ed1ab_1    conda-forge\r\n",
      "ipywidgets                8.1.5              pyhd8ed1ab_0    conda-forge\r\n",
      "isoduration               20.11.0            pyhd8ed1ab_0    conda-forge\r\n",
      "jedi                      0.19.2             pyhff2d567_0    conda-forge\r\n",
      "jinja2                    3.1.4              pyhd8ed1ab_0    conda-forge\r\n",
      "json5                     0.10.0             pyhd8ed1ab_0    conda-forge\r\n",
      "jsonpointer               3.0.0           py310hff52083_1    conda-forge\r\n",
      "jsonschema                4.23.0             pyhd8ed1ab_0    conda-forge\r\n",
      "jsonschema-specifications 2024.10.1          pyhd8ed1ab_0    conda-forge\r\n",
      "jsonschema-with-format-nongpl 4.23.0               hd8ed1ab_0    conda-forge\r\n",
      "jupyter                   1.1.1              pyhd8ed1ab_0    conda-forge\r\n",
      "jupyter-lsp               2.2.5              pyhd8ed1ab_0    conda-forge\r\n",
      "jupyter_client            7.4.9              pyhd8ed1ab_0    conda-forge\r\n",
      "jupyter_console           6.6.3              pyhd8ed1ab_0    conda-forge\r\n",
      "jupyter_core              5.7.2              pyh31011fe_1    conda-forge\r\n",
      "jupyter_events            0.10.0             pyhd8ed1ab_0    conda-forge\r\n",
      "jupyter_server            2.14.2             pyhd8ed1ab_0    conda-forge\r\n",
      "jupyter_server_terminals  0.5.3              pyhd8ed1ab_0    conda-forge\r\n",
      "jupyterlab                4.3.1              pyhff2d567_0    conda-forge\r\n",
      "jupyterlab_pygments       0.3.0              pyhd8ed1ab_1    conda-forge\r\n",
      "jupyterlab_server         2.27.3             pyhd8ed1ab_0    conda-forge\r\n",
      "jupyterlab_widgets        3.0.13             pyhd8ed1ab_0    conda-forge\r\n",
      "keyutils                  1.6.1                h166bdaf_0    conda-forge\r\n",
      "krb5                      1.21.3               h659f571_0    conda-forge\r\n",
      "ld_impl_linux-64          2.43                 h712a8e2_2    conda-forge\r\n",
      "libabseil                 20240722.0      cxx17_h5888daf_1    conda-forge\r\n",
      "libarrow                  18.0.0          h9c5d0aa_0_cuda    conda-forge\r\n",
      "libarrow-acero            18.0.0          h530483c_0_cuda    conda-forge\r\n",
      "libarrow-dataset          18.0.0          h530483c_0_cuda    conda-forge\r\n",
      "libarrow-substrait        18.0.0          h8ffff87_0_cuda    conda-forge\r\n",
      "libbrotlicommon           1.1.0                hb9d3cd8_2    conda-forge\r\n",
      "libbrotlidec              1.1.0                hb9d3cd8_2    conda-forge\r\n",
      "libbrotlienc              1.1.0                hb9d3cd8_2    conda-forge\r\n",
      "libcrc32c                 1.1.2                h9c3ff4c_0    conda-forge\r\n",
      "libcurl                   8.10.1               hbbe4b11_0    conda-forge\r\n",
      "libedit                   3.1.20191231         he28a2e2_2    conda-forge\r\n",
      "libev                     4.33                 hd590300_2    conda-forge\r\n",
      "libevent                  2.1.12               hf998b51_1    conda-forge\r\n",
      "libexpat                  2.6.4                h5888daf_0    conda-forge\r\n",
      "libffi                    3.4.2                h7f98852_5    conda-forge\r\n",
      "libgcc                    14.2.0               h77fa898_1    conda-forge\r\n",
      "libgcc-ng                 14.2.0               h69a702a_1    conda-forge\r\n",
      "libgomp                   14.2.0               h77fa898_1    conda-forge\r\n",
      "libgoogle-cloud           2.30.0               h438788a_0    conda-forge\r\n",
      "libgoogle-cloud-storage   2.30.0               h0121fbd_0    conda-forge\r\n",
      "libgrpc                   1.65.5               hf5c653b_0    conda-forge\r\n",
      "libiconv                  1.17                 hd590300_2    conda-forge\r\n",
      "libnghttp2                1.64.0               h161d5f1_0    conda-forge\r\n",
      "libnsl                    2.0.1                hd590300_0    conda-forge\r\n",
      "libntlm                   1.4               h7f98852_1002    conda-forge\r\n",
      "libparquet                18.0.0          hdbc8f64_0_cuda    conda-forge\r\n",
      "libpq                     17.2                 h04577a9_0    conda-forge\r\n",
      "libprotobuf               5.27.5               h5b01275_2    conda-forge\r\n",
      "libre2-11                 2024.07.02           hbbce691_1    conda-forge\r\n",
      "libsodium                 1.0.20               h4ab18f5_0    conda-forge\r\n",
      "libsqlite                 3.47.0               hadc24fc_1    conda-forge\r\n",
      "libssh2                   1.11.1               hf672d98_0    conda-forge\r\n",
      "libstdcxx                 14.2.0               hc0a3c3a_1    conda-forge\r\n",
      "libstdcxx-ng              14.2.0               h4852527_1    conda-forge\r\n",
      "libthrift                 0.21.0               h0e7cc3e_0    conda-forge\r\n",
      "libutf8proc               2.8.0                hf23e847_1    conda-forge\r\n",
      "libuuid                   2.38.1               h0b41bf4_0    conda-forge\r\n",
      "libxcrypt                 4.4.36               hd590300_1    conda-forge\r\n",
      "libxml2                   2.13.5               hb346dea_0    conda-forge\r\n",
      "libxslt                   1.1.39               h76b75d6_0    conda-forge\r\n",
      "libzlib                   1.3.1                hb9d3cd8_2    conda-forge\r\n",
      "lxml                      5.3.0           py310h6ee67d5_2    conda-forge\r\n",
      "lz4-c                     1.9.4                hcb278e6_0    conda-forge\r\n",
      "markupsafe                3.0.2           py310h89163eb_0    conda-forge\r\n",
      "matplotlib-inline         0.1.7              pyhd8ed1ab_0    conda-forge\r\n",
      "mistune                   3.0.2              pyhd8ed1ab_0    conda-forge\r\n",
      "nbclassic                 1.1.0              pyhd8ed1ab_0    conda-forge\r\n",
      "nbclient                  0.10.1             pyhd8ed1ab_0    conda-forge\r\n",
      "nbconvert-core            7.16.4             pyhd8ed1ab_1    conda-forge\r\n",
      "nbformat                  5.10.4             pyhd8ed1ab_0    conda-forge\r\n",
      "ncurses                   6.5                  he02047a_1    conda-forge\r\n",
      "nest-asyncio              1.6.0              pyhd8ed1ab_0    conda-forge\r\n",
      "notebook                  6.5.7              pyha770c72_0    conda-forge\r\n",
      "notebook-shim             0.2.4              pyhd8ed1ab_0    conda-forge\r\n",
      "numpy                     2.2.0                    pypi_0    pypi\r\n",
      "openldap                  2.6.9                he970967_0    conda-forge\r\n",
      "openssl                   3.4.0                hb9d3cd8_0    conda-forge\r\n",
      "orc                       2.0.2                h690cf93_1    conda-forge\r\n",
      "overrides                 7.7.0              pyhd8ed1ab_0    conda-forge\r\n",
      "packaging                 24.2               pyhff2d567_1    conda-forge\r\n",
      "pandocfilters             1.5.0              pyhd8ed1ab_0    conda-forge\r\n",
      "parso                     0.8.4              pyhd8ed1ab_0    conda-forge\r\n",
      "pcre2                     10.44                hba22ea6_2    conda-forge\r\n",
      "perl                      5.32.1          7_hd590300_perl5    conda-forge\r\n",
      "pexpect                   4.9.0              pyhd8ed1ab_0    conda-forge\r\n",
      "pickleshare               0.7.5                   py_1003    conda-forge\r\n",
      "pip                       24.3.1             pyh8b19718_0    conda-forge\r\n",
      "pkgutil-resolve-name      1.3.10             pyhd8ed1ab_1    conda-forge\r\n",
      "platformdirs              4.3.6              pyhd8ed1ab_0    conda-forge\r\n",
      "prometheus_client         0.21.0             pyhd8ed1ab_0    conda-forge\r\n",
      "prompt-toolkit            3.0.48             pyha770c72_0    conda-forge\r\n",
      "prompt_toolkit            3.0.48               hd8ed1ab_0    conda-forge\r\n",
      "psutil                    6.1.0           py310ha75aee5_0    conda-forge\r\n",
      "psycopg2                  2.9.9           py310hce86986_2    conda-forge\r\n",
      "ptyprocess                0.7.0              pyhd3deb0d_0    conda-forge\r\n",
      "pure_eval                 0.2.3              pyhd8ed1ab_0    conda-forge\r\n",
      "py4j                      0.10.9.7           pyhd8ed1ab_0    conda-forge\r\n",
      "pyarrow                   18.0.0          py310hff52083_2    conda-forge\r\n",
      "pyarrow-core              18.0.0          py310h23ac199_2_cuda    conda-forge\r\n",
      "pycparser                 2.22               pyhd8ed1ab_0    conda-forge\r\n",
      "pygeoif                   0.7                        py_1    conda-forge\r\n",
      "pygments                  2.18.0             pyhd8ed1ab_0    conda-forge\r\n",
      "pysocks                   1.7.1              pyha2e5f31_6    conda-forge\r\n",
      "pyspark                   3.4.4                    pypi_0    pypi\r\n",
      "python                    3.10.15         h4a871b0_2_cpython    conda-forge\r\n",
      "python-dateutil           2.9.0.post0        pyhff2d567_0    conda-forge\r\n",
      "python-fastjsonschema     2.21.0             pyhd8ed1ab_0    conda-forge\r\n",
      "python-json-logger        2.0.7              pyhd8ed1ab_0    conda-forge\r\n",
      "python_abi                3.10                    5_cp310    conda-forge\r\n",
      "pytz                      2024.1             pyhd8ed1ab_0    conda-forge\r\n",
      "pyyaml                    6.0.2           py310ha75aee5_1    conda-forge\r\n",
      "pyzmq                     26.2.0          py310h71f11fc_3    conda-forge\r\n",
      "re2                       2024.07.02           h77b4e00_1    conda-forge\r\n",
      "readline                  8.2                  h8228510_1    conda-forge\r\n",
      "referencing               0.35.1             pyhd8ed1ab_0    conda-forge\r\n",
      "requests                  2.32.3             pyhd8ed1ab_0    conda-forge\r\n",
      "rfc3339-validator         0.1.4              pyhd8ed1ab_0    conda-forge\r\n",
      "rfc3986-validator         0.1.1              pyh9f0ad1d_0    conda-forge\r\n",
      "rpds-py                   0.21.0          py310h505e2c1_0    conda-forge\r\n",
      "s2n                       1.5.6                h0e56266_0    conda-forge\r\n",
      "send2trash                1.8.3              pyh0d859eb_0    conda-forge\r\n",
      "setuptools                75.6.0             pyhff2d567_1    conda-forge\r\n",
      "six                       1.16.0             pyh6c4a22f_0    conda-forge\r\n",
      "snappy                    1.2.1                ha2e4443_0    conda-forge\r\n",
      "sniffio                   1.3.1              pyhd8ed1ab_0    conda-forge\r\n",
      "soupsieve                 2.5                pyhd8ed1ab_1    conda-forge\r\n",
      "sqlalchemy                2.0.36          py310ha75aee5_0    conda-forge\r\n",
      "stack_data                0.6.2              pyhd8ed1ab_0    conda-forge\r\n",
      "terminado                 0.18.1             pyh0d859eb_0    conda-forge\r\n",
      "tinycss2                  1.4.0              pyhd8ed1ab_0    conda-forge\r\n",
      "tk                        8.6.13          noxft_h4845f30_101    conda-forge\r\n",
      "tomli                     2.2.1              pyhd8ed1ab_0    conda-forge\r\n",
      "tornado                   6.4.2           py310ha75aee5_0    conda-forge\r\n",
      "traitlets                 5.14.3             pyhd8ed1ab_0    conda-forge\r\n",
      "types-python-dateutil     2.9.0.20241003     pyhff2d567_0    conda-forge\r\n",
      "typing-extensions         4.12.2               hd8ed1ab_0    conda-forge\r\n",
      "typing_extensions         4.12.2             pyha770c72_0    conda-forge\r\n",
      "typing_utils              0.1.0              pyhd8ed1ab_0    conda-forge\r\n",
      "tzdata                    2024b                hc8b5060_0    conda-forge\r\n",
      "uri-template              1.3.0              pyhd8ed1ab_0    conda-forge\r\n",
      "urllib3                   2.2.3              pyhd8ed1ab_0    conda-forge\r\n",
      "wcwidth                   0.2.13             pyhd8ed1ab_0    conda-forge\r\n",
      "webcolors                 24.8.0             pyhd8ed1ab_0    conda-forge\r\n",
      "webencodings              0.5.1              pyhd8ed1ab_2    conda-forge\r\n",
      "websocket-client          1.8.0              pyhd8ed1ab_0    conda-forge\r\n",
      "wheel                     0.45.1             pyhd8ed1ab_0    conda-forge\r\n",
      "widgetsnbextension        4.0.13             pyhd8ed1ab_0    conda-forge\r\n",
      "xgboost                   1.7.5                    pypi_0    pypi\r\n",
      "xz                        5.2.6                h166bdaf_0    conda-forge\r\n",
      "yaml                      0.2.5                h7f98852_2    conda-forge\r\n",
      "zeromq                    4.3.5                h3b0a872_7    conda-forge\r\n",
      "zipp                      3.21.0             pyhd8ed1ab_1    conda-forge\r\n",
      "zstandard                 0.23.0          py310ha39cb0e_1    conda-forge\r\n",
      "zstd                      1.5.6                ha6fb4c9_0    conda-forge\r\n"
     ]
    }
   ],
   "source": [
    "!conda list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5676d892",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "58b57899",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "512d9039",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available: 2\n"
     ]
    }
   ],
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "print(\"Num GPUs Available:\", len(physical_devices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ea217710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n",
      "PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')\n"
     ]
    }
   ],
   "source": [
    "for device in physical_devices:\n",
    "    print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1ba4cda9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/lib/jvm/java-11-openjdk\n",
      "openjdk 11.0.25 2024-10-15 LTS\n",
      "OpenJDK Runtime Environment (Red_Hat-11.0.25.0.9-1) (build 11.0.25+9-LTS)\n",
      "OpenJDK 64-Bit Server VM (Red_Hat-11.0.25.0.9-1) (build 11.0.25+9-LTS, mixed mode, sharing)\n"
     ]
    }
   ],
   "source": [
    "!echo $JAVA_HOME\n",
    "!java --version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f703df",
   "metadata": {},
   "source": [
    "## Load Parquet Train, Test, and Validaion (VAL) Data:\n",
    "\n",
    "/home/exx/myCode/horse-racing/FoxRiverAIRacing/data/parquet/train_sequences.parquet\n",
    "\n",
    "/home/exx/myCode/horse-racing/FoxRiverAIRacing/data/parquet/test_sequences.parquet\n",
    "\n",
    "/home/exx/myCode/horse-racing/FoxRiverAIRacing/data/parquet/val_sequences.parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ecee23cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow.parquet as pq\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9e14937c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "#from tensorflow.keras.models import Sequential\n",
    "#from tensorflow.layers import LSTM, Dense\n",
    "#from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f5e7901e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "race_date: date32[day]\n",
      "race_number: int32\n",
      "gate_index: int32\n",
      "horse_id: int32\n",
      "label: int32 not null\n",
      "course_cd_ohe: struct<type: int8 not null, size: int32, indices: list<element: int32 not null>, values: list<element: double not null>>\n",
      "  child 0, type: int8 not null\n",
      "  child 1, size: int32\n",
      "  child 2, indices: list<element: int32 not null>\n",
      "      child 0, element: int32 not null\n",
      "  child 3, values: list<element: double not null>\n",
      "      child 0, element: double not null\n",
      "equip_ohe: struct<type: int8 not null, size: int32, indices: list<element: int32 not null>, values: list<element: double not null>>\n",
      "  child 0, type: int8 not null\n",
      "  child 1, size: int32\n",
      "  child 2, indices: list<element: int32 not null>\n",
      "      child 0, element: int32 not null\n",
      "  child 3, values: list<element: double not null>\n",
      "      child 0, element: double not null\n",
      "surface_ohe: struct<type: int8 not null, size: int32, indices: list<element: int32 not null>, values: list<element: double not null>>\n",
      "  child 0, type: int8 not null\n",
      "  child 1, size: int32\n",
      "  child 2, indices: list<element: int32 not null>\n",
      "      child 0, element: int32 not null\n",
      "  child 3, values: list<element: double not null>\n",
      "      child 0, element: double not null\n",
      "trk_cond_ohe: struct<type: int8 not null, size: int32, indices: list<element: int32 not null>, values: list<element: double not null>>\n",
      "  child 0, type: int8 not null\n",
      "  child 1, size: int32\n",
      "  child 2, indices: list<element: int32 not null>\n",
      "      child 0, element: int32 not null\n",
      "  child 3, values: list<element: double not null>\n",
      "      child 0, element: double not null\n",
      "weather_ohe: struct<type: int8 not null, size: int32, indices: list<element: int32 not null>, values: list<element: double not null>>\n",
      "  child 0, type: int8 not null\n",
      "  child 1, size: int32\n",
      "  child 2, indices: list<element: int32 not null>\n",
      "      child 0, element: int32 not null\n",
      "  child 3, values: list<element: double not null>\n",
      "      child 0, element: double not null\n",
      "med_ohe: struct<type: int8 not null, size: int32, indices: list<element: int32 not null>, values: list<element: double not null>>\n",
      "  child 0, type: int8 not null\n",
      "  child 1, size: int32\n",
      "  child 2, indices: list<element: int32 not null>\n",
      "      child 0, element: int32 not null\n",
      "  child 3, values: list<element: double not null>\n",
      "      child 0, element: double not null\n",
      "stk_clm_md_ohe: struct<type: int8 not null, size: int32, indices: list<element: int32 not null>, values: list<element: double not null>>\n",
      "  child 0, type: int8 not null\n",
      "  child 1, size: int32\n",
      "  child 2, indices: list<element: int32 not null>\n",
      "      child 0, element: int32 not null\n",
      "  child 3, values: list<element: double not null>\n",
      "      child 0, element: double not null\n",
      "turf_mud_mark_ohe: struct<type: int8 not null, size: int32, indices: list<element: int32 not null>, values: list<element: double not null>>\n",
      "  child 0, type: int8 not null\n",
      "  child 1, size: int32\n",
      "  child 2, indices: list<element: int32 not null>\n",
      "      child 0, element: int32 not null\n",
      "  child 3, values: list<element: double not null>\n",
      "      child 0, element: double not null\n",
      "race_type_ohe: struct<type: int8 not null, size: int32, indices: list<element: int32 not null>, values: list<element: double not null>>\n",
      "  child 0, type: int8 not null\n",
      "  child 1, size: int32\n",
      "  child 2, indices: list<element: int32 not null>\n",
      "      child 0, element: int32 not null\n",
      "  child 3, values: list<element: double not null>\n",
      "      child 0, element: double not null\n",
      "scaled_features: struct<type: int8 not null, size: int32, indices: list<element: int32 not null>, values: list<element: double not null>>\n",
      "  child 0, type: int8 not null\n",
      "  child 1, size: int32\n",
      "  child 2, indices: list<element: int32 not null>\n",
      "      child 0, element: int32 not null\n",
      "  child 3, values: list<element: double not null>\n",
      "      child 0, element: double not null\n",
      "sequence: list<element: struct<type: int8 not null, size: int32, indices: list<element: int32 not null>, values: list<element: double not null>> not null> not null\n",
      "  child 0, element: struct<type: int8 not null, size: int32, indices: list<element: int32 not null>, values: list<element: double not null>> not null\n",
      "      child 0, type: int8 not null\n",
      "      child 1, size: int32\n",
      "      child 2, indices: list<element: int32 not null>\n",
      "          child 0, element: int32 not null\n",
      "      child 3, values: list<element: double not null>\n",
      "          child 0, element: double not null\n",
      "-- schema metadata --\n",
      "org.apache.spark.timeZone: 'America/Chicago'\n",
      "org.apache.spark.legacyINT96: ''\n",
      "org.apache.spark.version: '3.4.4'\n",
      "org.apache.spark.sql.parquet.row.metadata: '{\"type\":\"struct\",\"fields\":[{\"' + 9192\n",
      "org.apache.spark.legacyDateTime: ''\n",
      "Error converting column race_date: Cannot convert numpy.ndarray to numpy.ndarray\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Cannot convert numpy.ndarray to numpy.ndarray",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 28\u001b[0m\n\u001b[1;32m     25\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mDataFrame(columns)\n\u001b[0;32m---> 28\u001b[0m train_df \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_table_to_dataframe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_table\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m test_df \u001b[38;5;241m=\u001b[39m convert_table_to_dataframe(test_table)\n\u001b[1;32m     30\u001b[0m validation_df \u001b[38;5;241m=\u001b[39m convert_table_to_dataframe(validation_table)\n",
      "Cell \u001b[0;32mIn[34], line 25\u001b[0m, in \u001b[0;36mconvert_table_to_dataframe\u001b[0;34m(table)\u001b[0m\n\u001b[1;32m     23\u001b[0m             columns[column_name] \u001b[38;5;241m=\u001b[39m column\u001b[38;5;241m.\u001b[39mto_pylist()\n\u001b[1;32m     24\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 25\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mDataFrame(columns)\n",
      "Cell \u001b[0;32mIn[34], line 18\u001b[0m, in \u001b[0;36mconvert_table_to_dataframe\u001b[0;34m(table)\u001b[0m\n\u001b[1;32m     16\u001b[0m column \u001b[38;5;241m=\u001b[39m table[column_name]\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 18\u001b[0m     columns[column_name] \u001b[38;5;241m=\u001b[39m \u001b[43mcolumn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_pandas\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError converting column \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcolumn_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/mamba_env/envs/tf_310/lib/python3.10/site-packages/pyarrow/array.pxi:887\u001b[0m, in \u001b[0;36mpyarrow.lib._PandasConvertible.to_pandas\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/mamba_env/envs/tf_310/lib/python3.10/site-packages/pyarrow/table.pxi:488\u001b[0m, in \u001b[0;36mpyarrow.lib.ChunkedArray._to_pandas\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/mamba_env/envs/tf_310/lib/python3.10/site-packages/pyarrow/array.pxi:2133\u001b[0m, in \u001b[0;36mpyarrow.lib._array_like_to_pandas\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/mamba_env/envs/tf_310/lib/python3.10/site-packages/pyarrow/pandas-shim.pxi:116\u001b[0m, in \u001b[0;36mpyarrow.lib._PandasAPIShim.series\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/mamba_env/envs/tf_310/lib/python3.10/site-packages/pandas/core/series.py:584\u001b[0m, in \u001b[0;36m__init__\u001b[0;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/mamba_env/envs/tf_310/lib/python3.10/site-packages/pandas/core/construction.py:633\u001b[0m, in \u001b[0;36msanitize_array\u001b[0;34m(data, index, dtype, copy, allow_2d)\u001b[0m\n\u001b[1;32m    631\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    632\u001b[0m         data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(data, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[0;32m--> 633\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msanitize_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    634\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    635\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    636\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    637\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    638\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    639\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    641\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    642\u001b[0m     _sanitize_non_ordered(data)\n",
      "File \u001b[0;32m~/anaconda3/envs/mamba_env/envs/tf_310/lib/python3.10/site-packages/pandas/core/construction.py:606\u001b[0m, in \u001b[0;36msanitize_array\u001b[0;34m(data, index, dtype, copy, allow_2d)\u001b[0m\n\u001b[1;32m    604\u001b[0m subarr \u001b[38;5;241m=\u001b[39m data\n\u001b[1;32m    605\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m data\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m:\n\u001b[0;32m--> 606\u001b[0m     subarr \u001b[38;5;241m=\u001b[39m \u001b[43mmaybe_infer_to_datetimelike\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    607\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    608\u001b[0m         object_index\n\u001b[1;32m    609\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m using_pyarrow_string_dtype()\n\u001b[1;32m    610\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m is_string_dtype(subarr)\n\u001b[1;32m    611\u001b[0m     ):\n\u001b[1;32m    612\u001b[0m         \u001b[38;5;66;03m# Avoid inference when string option is set\u001b[39;00m\n\u001b[1;32m    613\u001b[0m         subarr \u001b[38;5;241m=\u001b[39m data\n",
      "File \u001b[0;32m~/anaconda3/envs/mamba_env/envs/tf_310/lib/python3.10/site-packages/pandas/core/dtypes/cast.py:1189\u001b[0m, in \u001b[0;36mmaybe_infer_to_datetimelike\u001b[0;34m(value)\u001b[0m\n\u001b[1;32m   1184\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m value\n\u001b[1;32m   1186\u001b[0m \u001b[38;5;66;03m# error: Incompatible return value type (got \"Union[ExtensionArray,\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[38;5;66;03m# ndarray[Any, Any]]\", expected \"Union[ndarray[Any, Any], DatetimeArray,\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[38;5;66;03m# TimedeltaArray, PeriodArray, IntervalArray]\")\u001b[39;00m\n\u001b[0;32m-> 1189\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmaybe_convert_objects\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[return-value]\u001b[39;49;00m\n\u001b[1;32m   1190\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1191\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Here we do not convert numeric dtypes, as if we wanted that,\u001b[39;49;00m\n\u001b[1;32m   1192\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m#  numpy would have done it for us.\u001b[39;49;00m\n\u001b[1;32m   1193\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconvert_numeric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1194\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconvert_non_numeric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype_if_all_nat\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mM8[ns]\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1196\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32mlib.pyx:2538\u001b[0m, in \u001b[0;36mpandas._libs.lib.maybe_convert_objects\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Cannot convert numpy.ndarray to numpy.ndarray"
     ]
    }
   ],
   "source": [
    "import pyarrow.parquet as pq\n",
    "import pandas as pd\n",
    "\n",
    "# Load the data from Parquet files using PyArrow\n",
    "train_table = pq.read_table('/home/exx/myCode/horse-racing/FoxRiverAIRacing/data/parquet/train_sequences.parquet')\n",
    "test_table = pq.read_table('/home/exx/myCode/horse-racing/FoxRiverAIRacing/data/parquet/test_sequences.parquet')\n",
    "validation_table = pq.read_table('/home/exx/myCode/horse-racing/FoxRiverAIRacing/data/parquet/val_sequences.parquet')\n",
    "\n",
    "# Inspect the schema of the PyArrow table\n",
    "print(train_table.schema)\n",
    "\n",
    "# Convert each column individually and handle complex data types\n",
    "def convert_table_to_dataframe(table):\n",
    "    columns = {}\n",
    "    for column_name in table.column_names:\n",
    "        column = table[column_name]\n",
    "        try:\n",
    "            columns[column_name] = column.to_pandas()\n",
    "        except TypeError as e:\n",
    "            print(f\"Error converting column {column_name}: {e}\")\n",
    "            # Handle complex data types here if needed\n",
    "            if column.type == 'struct' or column.type == 'list':\n",
    "                columns[column_name] = column.to_pylist()\n",
    "            else:\n",
    "                raise e\n",
    "    return pd.DataFrame(columns)\n",
    "\n",
    "train_df = convert_table_to_dataframe(train_table)\n",
    "test_df = convert_table_to_dataframe(test_table)\n",
    "validation_df = convert_table_to_dataframe(validation_table)\n",
    "\n",
    "# Check the schema of the DataFrames\n",
    "print(train_df.head())\n",
    "print(test_df.head())\n",
    "print(validation_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d125517a",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Cannot convert numpy.ndarray to numpy.ndarray",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Load the data from Parquet files\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m train_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_parquet\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/home/exx/myCode/horse-racing/FoxRiverAIRacing/data/parquet/train_sequences.parquet\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m test_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_parquet(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/home/exx/myCode/horse-racing/FoxRiverAIRacing/data/parquet/test_sequences.parquet\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m validation_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_parquet(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/home/exx/myCode/horse-racing/FoxRiverAIRacing/data/parquet/val_sequences.parquet\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/mamba_env/envs/tf_310/lib/python3.10/site-packages/pandas/io/parquet.py:667\u001b[0m, in \u001b[0;36mread_parquet\u001b[0;34m(path, engine, columns, storage_options, use_nullable_dtypes, dtype_backend, filesystem, filters, **kwargs)\u001b[0m\n\u001b[1;32m    664\u001b[0m     use_nullable_dtypes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    665\u001b[0m check_dtype_backend(dtype_backend)\n\u001b[0;32m--> 667\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimpl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    668\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_nullable_dtypes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_nullable_dtypes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilesystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/mamba_env/envs/tf_310/lib/python3.10/site-packages/pandas/io/parquet.py:281\u001b[0m, in \u001b[0;36mPyArrowImpl.read\u001b[0;34m(self, path, columns, filters, use_nullable_dtypes, dtype_backend, storage_options, filesystem, **kwargs)\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    274\u001b[0m     pa_table \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi\u001b[38;5;241m.\u001b[39mparquet\u001b[38;5;241m.\u001b[39mread_table(\n\u001b[1;32m    275\u001b[0m         path_or_handle,\n\u001b[1;32m    276\u001b[0m         columns\u001b[38;5;241m=\u001b[39mcolumns,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    279\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    280\u001b[0m     )\n\u001b[0;32m--> 281\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mpa_table\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_pandas\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mto_pandas_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    283\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m manager \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    284\u001b[0m         result \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39m_as_manager(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m\"\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/mamba_env/envs/tf_310/lib/python3.10/site-packages/pyarrow/array.pxi:887\u001b[0m, in \u001b[0;36mpyarrow.lib._PandasConvertible.to_pandas\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/mamba_env/envs/tf_310/lib/python3.10/site-packages/pyarrow/table.pxi:5132\u001b[0m, in \u001b[0;36mpyarrow.lib.Table._to_pandas\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/mamba_env/envs/tf_310/lib/python3.10/site-packages/pyarrow/pandas_compat.py:790\u001b[0m, in \u001b[0;36mtable_to_dataframe\u001b[0;34m(options, table, categories, ignore_metadata, types_mapper)\u001b[0m\n\u001b[1;32m    787\u001b[0m     ext_columns_dtypes \u001b[38;5;241m=\u001b[39m _get_extension_dtypes(table, [], types_mapper)\n\u001b[1;32m    789\u001b[0m _check_data_column_metadata_consistency(all_columns)\n\u001b[0;32m--> 790\u001b[0m columns \u001b[38;5;241m=\u001b[39m \u001b[43m_deserialize_column_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mall_columns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumn_indexes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    792\u001b[0m column_names \u001b[38;5;241m=\u001b[39m table\u001b[38;5;241m.\u001b[39mcolumn_names\n\u001b[1;32m    793\u001b[0m result \u001b[38;5;241m=\u001b[39m pa\u001b[38;5;241m.\u001b[39mlib\u001b[38;5;241m.\u001b[39mtable_to_blocks(options, table, categories,\n\u001b[1;32m    794\u001b[0m                                 \u001b[38;5;28mlist\u001b[39m(ext_columns_dtypes\u001b[38;5;241m.\u001b[39mkeys()))\n",
      "File \u001b[0;32m~/anaconda3/envs/mamba_env/envs/tf_310/lib/python3.10/site-packages/pyarrow/pandas_compat.py:922\u001b[0m, in \u001b[0;36m_deserialize_column_index\u001b[0;34m(block_table, all_columns, column_indexes)\u001b[0m\n\u001b[1;32m    917\u001b[0m     columns \u001b[38;5;241m=\u001b[39m _pandas_api\u001b[38;5;241m.\u001b[39mpd\u001b[38;5;241m.\u001b[39mMultiIndex\u001b[38;5;241m.\u001b[39mfrom_tuples(\n\u001b[1;32m    918\u001b[0m         \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mmap\u001b[39m(ast\u001b[38;5;241m.\u001b[39mliteral_eval, columns_values)),\n\u001b[1;32m    919\u001b[0m         names\u001b[38;5;241m=\u001b[39m[col_index[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m col_index \u001b[38;5;129;01min\u001b[39;00m column_indexes],\n\u001b[1;32m    920\u001b[0m     )\n\u001b[1;32m    921\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 922\u001b[0m     columns \u001b[38;5;241m=\u001b[39m \u001b[43m_pandas_api\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mIndex\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    923\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumn_indexes\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mname\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcolumn_indexes\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[1;32m    924\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    926\u001b[0m \u001b[38;5;66;03m# if we're reconstructing the index\u001b[39;00m\n\u001b[1;32m    927\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(column_indexes) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/mamba_env/envs/tf_310/lib/python3.10/site-packages/pandas/core/indexes/base.py:565\u001b[0m, in \u001b[0;36mIndex.__new__\u001b[0;34m(cls, data, dtype, copy, name, tupleize_cols)\u001b[0m\n\u001b[1;32m    562\u001b[0m         data \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39masarray_tuplesafe(data, dtype\u001b[38;5;241m=\u001b[39m_dtype_obj)\n\u001b[1;32m    564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 565\u001b[0m     arr \u001b[38;5;241m=\u001b[39m \u001b[43msanitize_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    566\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    567\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex must be specified when data is not list-like\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(err):\n",
      "File \u001b[0;32m~/anaconda3/envs/mamba_env/envs/tf_310/lib/python3.10/site-packages/pandas/core/construction.py:654\u001b[0m, in \u001b[0;36msanitize_array\u001b[0;34m(data, index, dtype, copy, allow_2d)\u001b[0m\n\u001b[1;32m    651\u001b[0m     subarr \u001b[38;5;241m=\u001b[39m _try_cast(data, dtype, copy)\n\u001b[1;32m    653\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 654\u001b[0m     subarr \u001b[38;5;241m=\u001b[39m \u001b[43mmaybe_convert_platform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    655\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m subarr\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m:\n\u001b[1;32m    656\u001b[0m         subarr \u001b[38;5;241m=\u001b[39m cast(np\u001b[38;5;241m.\u001b[39mndarray, subarr)\n",
      "File \u001b[0;32m~/anaconda3/envs/mamba_env/envs/tf_310/lib/python3.10/site-packages/pandas/core/dtypes/cast.py:138\u001b[0m, in \u001b[0;36mmaybe_convert_platform\u001b[0;34m(values)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m _dtype_obj:\n\u001b[1;32m    137\u001b[0m     arr \u001b[38;5;241m=\u001b[39m cast(np\u001b[38;5;241m.\u001b[39mndarray, arr)\n\u001b[0;32m--> 138\u001b[0m     arr \u001b[38;5;241m=\u001b[39m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmaybe_convert_objects\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m arr\n",
      "File \u001b[0;32mlib.pyx:2538\u001b[0m, in \u001b[0;36mpandas._libs.lib.maybe_convert_objects\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Cannot convert numpy.ndarray to numpy.ndarray"
     ]
    }
   ],
   "source": [
    "# Load the data from Parquet files\n",
    "train_df = pd.read_parquet('/home/exx/myCode/horse-racing/FoxRiverAIRacing/data/parquet/train_sequences.parquet')\n",
    "test_df = pd.read_parquet('/home/exx/myCode/horse-racing/FoxRiverAIRacing/data/parquet/test_sequences.parquet')\n",
    "validation_df = pd.read_parquet('/home/exx/myCode/horse-racing/FoxRiverAIRacing/data/parquet/val_sequences.parquet')\n",
    "\n",
    "# Preprocess the data\n",
    "# Assuming 'features' is a column with the input features and 'label' is the target column\n",
    "X_train = train_df['features'].tolist()\n",
    "y_train = train_df['label'].tolist()\n",
    "X_test = test_df['features'].tolist()\n",
    "y_test = test_df['label'].tolist()\n",
    "X_val = validation_df['features'].tolist()\n",
    "y_val = validation_df['label'].tolist()\n",
    "\n",
    "# Convert the data into TensorFlow datasets\n",
    "def create_dataset(X, y):\n",
    "    X = tf.ragged.constant(X).to_tensor()\n",
    "    y = tf.constant(y)\n",
    "    return tf.data.Dataset.from_tensor_slices((X, y))\n",
    "\n",
    "train_dataset = create_dataset(X_train, y_train).batch(32)\n",
    "test_dataset = create_dataset(X_test, y_test).batch(32)\n",
    "val_dataset = create_dataset(X_val, y_val).batch(32)\n",
    "\n",
    "# Define the LSTM model\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.LSTM(64, input_shape=(None, X_train[0].shape[1]), return_sequences=True),\n",
    "    tf.keras.layers.LSTM(64),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')  # Adjust the output layer based on your problem (e.g., regression or classification)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_dataset, validation_data=val_dataset, epochs=10)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(test_dataset)\n",
    "print(f'Test Loss: {loss}, Test Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf56395",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
