{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f96c21c8",
   "metadata": {},
   "source": [
    "# Proposed Ensemble Models\n",
    "\n",
    "Given the constraints and objectives, I will consider the following models for the ensemble:\n",
    "\t\n",
    "    1.\tModel 1: LSTM Network on Raw GPS Data\n",
    "    \n",
    ">•\tInput Data: Sequences of raw GPS data (speed, progress, stride_frequency, etc.).\n",
    "\n",
    ">•\tArchitecture: An LSTM network designed to capture temporal dependencies and patterns in the sequential data.\n",
    "\n",
    ">•\tAdvantage: LSTMs are well-suited for time-series data and can learn complex temporal dynamics without the need for hand-engineered features like acceleration.\n",
    "\n",
    "    2.\tModel 2: 1D Convolutional Neural Network (1D-CNN)\n",
    "\t\n",
    ">•\tInput Data: The same raw GPS sequences as in Model 1.\n",
    "\n",
    ">•\tArchitecture: A 1D-CNN that applies convolutional filters across the time dimension to detect local patterns.\n",
    "\n",
    ">•\tAdvantage: CNNs can capture spatial hierarchies and are effective in recognizing patterns in sequences, potentially identifying features like sudden changes in speed or stride frequency.\n",
    "\n",
    "    3.\tModel 3: Transformer-based Model\n",
    "\t\n",
    ">•\tInput Data: Raw GPS sequences and possibly sectionals data.\n",
    "\n",
    ">•\tArchitecture: A Transformer model that uses self-attention mechanisms to weigh the importance of different parts of the sequence.\n",
    "\n",
    ">•\tAdvantage: Transformers can model long-range dependencies and focus on the most relevant parts of the sequence for prediction.\n",
    "\n",
    "## Additional Models (Optional):\n",
    "\n",
    "    4.\tModel 4: Gated Recurrent Unit (GRU) Network\n",
    "\n",
    ">•\tSimilar to LSTMs but with a simpler architecture, GRUs can be more efficient and may perform better on certain datasets.\n",
    "\n",
    ">•\tModel 5: Temporal Convolutional Network (TCN)\n",
    "\n",
    ">•\tTCNs are designed for sequential data and can capture long-term dependencies using causal convolutions and residual connections.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f703df",
   "metadata": {},
   "source": [
    "## Load Parquet Train, Test, and Validaion (VAL) Data:\n",
    "\n",
    "/home/exx/myCode/horse-racing/FoxRiverAIRacing/data/parquet/train_sequences.parquet\n",
    "\n",
    "/home/exx/myCode/horse-racing/FoxRiverAIRacing/data/parquet/test_sequences.parquet\n",
    "\n",
    "/home/exx/myCode/horse-racing/FoxRiverAIRacing/data/parquet/val_sequences.parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a60982",
   "metadata": {},
   "outputs": [],
   "source": [
    "#spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1cf56395",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-30 15:06:03,543 - INFO - Environment setup initialized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark session created successfully.\n"
     ]
    }
   ],
   "source": [
    "# Set Environment\n",
    "import os\n",
    "import pyspark.sql.functions as F\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pyspark.sql import DataFrame\n",
    "from pyspark.sql.functions import col, size, when, count\n",
    "from src.data_preprocessing.data_prep1.data_utils import (\n",
    "    save_parquet, gather_statistics, initialize_environment,\n",
    "    load_config, initialize_logging, initialize_spark, \n",
    "    identify_and_impute_outliers, identify_and_remove_outliers, process_merged_results_sectionals,\n",
    "    identify_missing_and_outliers\n",
    ")\n",
    "\n",
    "try:\n",
    "    spark, jdbc_url, jdbc_properties, queries, parquet_dir, log_file = initialize_environment()\n",
    "    # input(\"Press Enter to continue...\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during initialization: {e}\")\n",
    "    logging.error(f\"An error occurred during initialization: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96ddf3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sequences = os.path.join(parquet_dir, \"train_sequences.parquet\")\n",
    "train_sequences = spark.read.parquet(train_sequences)\n",
    "test_sequences = os.path.join(parquet_dir, \"test_sequences.parquet\")\n",
    "test_sequences = spark.read.parquet(test_sequences)\n",
    "val_sequences = os.path.join(parquet_dir, \"val_sequences.parquet\")\n",
    "val_sequences = spark.read.parquet(val_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1eb72401",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- race_date: date (nullable = true)\n",
      " |-- race_number: integer (nullable = true)\n",
      " |-- horse_id: integer (nullable = true)\n",
      " |-- label: integer (nullable = true)\n",
      " |-- gate_index: integer (nullable = true)\n",
      " |-- course_cd_ohe: array (nullable = true)\n",
      " |    |-- element: double (containsNull = true)\n",
      " |-- equip_ohe: array (nullable = true)\n",
      " |    |-- element: double (containsNull = true)\n",
      " |-- surface_ohe: array (nullable = true)\n",
      " |    |-- element: double (containsNull = true)\n",
      " |-- trk_cond_ohe: array (nullable = true)\n",
      " |    |-- element: double (containsNull = true)\n",
      " |-- weather_ohe: array (nullable = true)\n",
      " |    |-- element: double (containsNull = true)\n",
      " |-- med_ohe: array (nullable = true)\n",
      " |    |-- element: double (containsNull = true)\n",
      " |-- stk_clm_md_ohe: array (nullable = true)\n",
      " |    |-- element: double (containsNull = true)\n",
      " |-- turf_mud_mark_ohe: array (nullable = true)\n",
      " |    |-- element: double (containsNull = true)\n",
      " |-- race_type_ohe: array (nullable = true)\n",
      " |    |-- element: double (containsNull = true)\n",
      " |-- scaled_features: vector (nullable = true)\n",
      " |-- aggregated_struct: struct (nullable = true)\n",
      " |    |-- ohe_flat: array (nullable = true)\n",
      " |    |    |-- element: double (containsNull = true)\n",
      " |    |-- avg_speed_agg: double (nullable = true)\n",
      " |    |-- max_speed_agg: double (nullable = true)\n",
      " |    |-- final_speed_agg: double (nullable = true)\n",
      " |    |-- avg_accel_agg: double (nullable = true)\n",
      " |    |-- fatigue_agg: double (nullable = true)\n",
      " |    |-- sectional_time_agg: double (nullable = true)\n",
      " |    |-- running_time_agg: double (nullable = true)\n",
      " |    |-- distance_back_agg: double (nullable = true)\n",
      " |    |-- distance_ran_agg: double (nullable = true)\n",
      " |    |-- strides_agg: double (nullable = true)\n",
      " |    |-- max_speed_overall: double (nullable = true)\n",
      " |    |-- min_speed_overall: double (nullable = true)\n",
      " |-- past_races_sequence: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- ohe_flat: array (nullable = true)\n",
      " |    |    |    |-- element: double (containsNull = true)\n",
      " |    |    |-- avg_speed_agg: double (nullable = true)\n",
      " |    |    |-- max_speed_agg: double (nullable = true)\n",
      " |    |    |-- final_speed_agg: double (nullable = true)\n",
      " |    |    |-- avg_accel_agg: double (nullable = true)\n",
      " |    |    |-- fatigue_agg: double (nullable = true)\n",
      " |    |    |-- sectional_time_agg: double (nullable = true)\n",
      " |    |    |-- running_time_agg: double (nullable = true)\n",
      " |    |    |-- distance_back_agg: double (nullable = true)\n",
      " |    |    |-- distance_ran_agg: double (nullable = true)\n",
      " |    |    |-- strides_agg: double (nullable = true)\n",
      " |    |    |-- max_speed_overall: double (nullable = true)\n",
      " |    |    |-- min_speed_overall: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_sequences.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84e0d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_sequences.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1e22727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_sequences.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd513365",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|label|count|\n",
      "+-----+-----+\n",
      "|    2| 5984|\n",
      "|    3| 5955|\n",
      "|    1| 5840|\n",
      "|    4| 5738|\n",
      "|    0| 5662|\n",
      "|    7| 5065|\n",
      "|    5| 4928|\n",
      "|    6| 3640|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# If your label column is named \"label\":\n",
    "train_sequences.groupBy(\"label\").count().orderBy(\"count\", ascending=False).show()\n",
    "\n",
    "# This shows how many examples you have in each label category.\n",
    "# If it's a multi-class problem (e.g., finishing position 0,1,2,...),\n",
    "# you'll see how many rows for each class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8163ebaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+------------------+\n",
      "|label|count|        percentage|\n",
      "+-----+-----+------------------+\n",
      "|    2| 5984| 13.97738951695786|\n",
      "|    3| 5955|13.909651499579557|\n",
      "|    1| 5840|13.641035223769038|\n",
      "|    4| 5738|13.402784266093617|\n",
      "|    0| 5662|13.225263944688406|\n",
      "|    7| 5065|  11.8307951041764|\n",
      "|    5| 4928|11.510791366906476|\n",
      "|    6| 3640| 8.502289077828646|\n",
      "+-----+-----+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyspark.sql.functions as F\n",
    "\n",
    "label_counts = (\n",
    "    train_sequences.groupBy(\"label\")\n",
    "      .agg(F.count(\"*\").alias(\"count\"))\n",
    ")\n",
    "\n",
    "total_count = train_sequences.count()\n",
    "\n",
    "label_distribution = (\n",
    "    label_counts\n",
    "    .withColumn(\"percentage\", (F.col(\"count\") / total_count) * 100)\n",
    "    .orderBy(F.desc(\"count\"))\n",
    ")\n",
    "\n",
    "label_distribution.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5e41fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of course codes\n",
    "# train_sequences.groupBy(\"course_cd_ohe\").count().orderBy(F.desc(\"count\")).show(50, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "81d6108a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_sequences.groupBy(\"race_type_ohe\").count().orderBy(F.desc(\"count\")).show(50, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "72cb1dea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-------------------+\n",
      "|distinct_tracks|distinct_race_types|\n",
      "+---------------+-------------------+\n",
      "|             26|                 13|\n",
      "+---------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_sequences.agg(\n",
    "    F.countDistinct(\"course_cd_ohe\").alias(\"distinct_tracks\"),\n",
    "    F.countDistinct(\"race_type_ohe\").alias(\"distinct_race_types\")\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "10a44d62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+-----+\n",
      "|year|month|count|\n",
      "+----+-----+-----+\n",
      "|2022|3    |80   |\n",
      "|2022|4    |576  |\n",
      "|2022|5    |1051 |\n",
      "|2022|6    |1266 |\n",
      "|2022|7    |1606 |\n",
      "|2022|8    |1942 |\n",
      "|2022|9    |2469 |\n",
      "|2022|10   |2683 |\n",
      "|2022|11   |3096 |\n",
      "|2022|12   |3261 |\n",
      "|2023|1    |2945 |\n",
      "|2023|2    |3289 |\n",
      "|2023|3    |3976 |\n",
      "|2023|4    |4335 |\n",
      "|2023|5    |5090 |\n",
      "|2023|6    |5147 |\n",
      "+----+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_sequences.groupBy(F.year(\"race_date\").alias(\"year\"), F.month(\"race_date\").alias(\"month\"))\\\n",
    "  .count()\\\n",
    "  .orderBy(\"year\", \"month\")\\\n",
    "  .show(48, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "728c1701",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Convert to Pandas DataFrame\n",
    "train_sequences_pd = train_sequences.toPandas()\n",
    "val_sequences_pd = val_sequences.toPandas()\n",
    "test_sequences_pd = test_sequences.toPandas()\n",
    "\n",
    "horse_ids_train = train_sequences_pd[\"horse_id\"].values  # Extract horse_id for training\n",
    "horse_ids_val = val_sequences_pd[\"horse_id\"].values  # Extract horse_id for validation\n",
    "horse_ids_test = test_sequences_pd[\"horse_id\"].values  # Extract horse_id for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0fca647b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------+\n",
      "|size(past_races_sequence)|\n",
      "+-------------------------+\n",
      "|                       10|\n",
      "+-------------------------+\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(train_sequences.select(F.size(\"past_races_sequence\")).distinct().show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e78edfb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Row(label=1, count=5840), Row(label=6, count=3640), Row(label=3, count=5955), Row(label=5, count=4928), Row(label=4, count=5738), Row(label=7, count=5065), Row(label=2, count=5984), Row(label=0, count=5662)]\n"
     ]
    }
   ],
   "source": [
    "label_distribution = train_sequences.groupBy(\"label\").count().collect()\n",
    "print(label_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "779dec92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...\n",
       "1    [([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...\n",
       "2    [([0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...\n",
       "3    [([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0...\n",
       "4    [([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0...\n",
       "Name: past_races_sequence, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sequences_pd[\"past_races_sequence\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "04b82223",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def flatten_sequence(sequence):\n",
    "    \"\"\"\n",
    "    Flattens a sequence of race data into a single NumPy array.\n",
    "    Ensures uniform array shapes for each time step in the sequence.\n",
    "    \"\"\"\n",
    "    ohe_length = 43 + 26 + 10 + 2 + 8 + 7 + 5 + 4 + 4 + 14  # Total OHE length\n",
    "    aggregator_length = len(aggregator_cols)  # Length of aggregator columns\n",
    "\n",
    "    flattened_sequence = []\n",
    "    for step in sequence:\n",
    "        # Extract `ohe_flat` or default to zero array\n",
    "        ohe_flat = step[\"ohe_flat\"] if \"ohe_flat\" in step else [0.0] * ohe_length\n",
    "\n",
    "        # Ensure `ohe_flat` has the correct length\n",
    "        if len(ohe_flat) != ohe_length:\n",
    "            ohe_flat = [0.0] * ohe_length\n",
    "\n",
    "        # Extract aggregator values or default to -999.0\n",
    "        aggregator_values = [step[agg] if agg in step else -999.0 for agg in aggregator_cols]\n",
    "\n",
    "        # Concatenate `ohe_flat` and aggregator values\n",
    "        flattened_step = np.array(ohe_flat + aggregator_values)\n",
    "\n",
    "        # Verify the length of the flattened step\n",
    "        if len(flattened_step) != (ohe_length + aggregator_length):\n",
    "            raise ValueError(f\"Flattened step has inconsistent length: {len(flattened_step)}\")\n",
    "\n",
    "        flattened_sequence.append(flattened_step)\n",
    "\n",
    "    return np.array(flattened_sequence)\n",
    "\n",
    "aggregator_cols = [\n",
    "    \"avg_speed_agg\", \"max_speed_agg\", \"final_speed_agg\", \"avg_accel_agg\", \n",
    "    \"fatigue_agg\", \"sectional_time_agg\", \"running_time_agg\", \"distance_back_agg\", \n",
    "    \"distance_ran_agg\", \"strides_agg\", \"max_speed_overall\", \"min_speed_overall\"\n",
    "]\n",
    "\n",
    "X_train = np.array([flatten_sequence(seq) for seq in train_sequences_pd[\"past_races_sequence\"]])\n",
    "y_train = train_sequences_pd[\"label\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c0ee064c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array([flatten_sequence(seq) for seq in train_sequences_pd[\"past_races_sequence\"]])\n",
    "y_train = train_sequences_pd[\"label\"].values\n",
    "\n",
    "X_val = np.array([flatten_sequence(seq) for seq in val_sequences_pd[\"past_races_sequence\"]])\n",
    "y_val = val_sequences_pd[\"label\"].values\n",
    "\n",
    "X_test = np.array([flatten_sequence(seq) for seq in test_sequences_pd[\"past_races_sequence\"]])\n",
    "y_test = test_sequences_pd[\"label\"].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "09a71c0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (42812, 10, 135)\n",
      "y_train shape: (42812,)\n"
     ]
    }
   ],
   "source": [
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9fc17a27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6 7]\n"
     ]
    }
   ],
   "source": [
    " # Label targets\n",
    "print(np.unique(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "10c190a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|label|count|\n",
      "+-----+-----+\n",
      "|    0| 5662|\n",
      "|    1| 5840|\n",
      "|    2| 5984|\n",
      "|    3| 5955|\n",
      "|    4| 5738|\n",
      "|    5| 4928|\n",
      "|    6| 3640|\n",
      "|    7| 5065|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "label_dist = train_sequences.groupBy(\"label\").count().orderBy(\"label\")\n",
    "label_dist.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a21ba9a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|label|count|\n",
      "+-----+-----+\n",
      "|    0| 1473|\n",
      "|    1| 1591|\n",
      "|    2| 1528|\n",
      "|    3| 1536|\n",
      "|    4| 1437|\n",
      "|    5| 1261|\n",
      "|    6|  940|\n",
      "|    7| 1487|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "label_dist = val_sequences.groupBy(\"label\").count().orderBy(\"label\")\n",
    "label_dist.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "382e23df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|label|count|\n",
      "+-----+-----+\n",
      "|    0| 1055|\n",
      "|    1| 1115|\n",
      "|    2| 1130|\n",
      "|    3| 1107|\n",
      "|    4| 1073|\n",
      "|    5|  943|\n",
      "|    6|  821|\n",
      "|    7| 1224|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "label_dist = test_sequences.groupBy(\"label\").count().orderBy(\"label\")\n",
    "label_dist.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "42173d97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (42812, 10, 135), y_train shape: (42812,), horse_ids_train shape: (42812,)\n",
      "X_val shape: (11253, 10, 135), y_val shape: (11253,), horse_ids_val shape: (11253,)\n",
      "X_test shape: (8468, 10, 135), y_test shape: (8468,), horse_ids_test shape: (8468,)\n"
     ]
    }
   ],
   "source": [
    "print(f\"X_train shape: {X_train.shape}, y_train shape: {y_train.shape}, horse_ids_train shape: {horse_ids_train.shape}\")\n",
    "print(f\"X_val shape: {X_val.shape}, y_val shape: {y_val.shape}, horse_ids_val shape: {horse_ids_val.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}, y_test shape: {y_test.shape}, horse_ids_test shape: {horse_ids_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "88a2ee2d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (42812, 10, 135), horse_ids_train: (42812,), y_train: (42812,)\n",
      "X_val: (11253, 10, 135), horse_ids_val: (11253,), y_val: (11253,)\n"
     ]
    }
   ],
   "source": [
    "print(f\"X_train: {X_train.shape}, horse_ids_train: {horse_ids_train.shape}, y_train: {y_train.shape}\")\n",
    "print(f\"X_val: {X_val.shape}, horse_ids_val: {horse_ids_val.shape}, y_val: {y_val.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cdb17aa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_features      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">135</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">401,408</span> │ input_features[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">197,120</span> │ dropout_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">49,408</span> │ dropout_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_horse_id      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">12,416</span> │ dropout_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_1         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">339,072</span> │ input_horse_id[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embedding_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ flatten_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │ concatenate_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">520</span> │ dropout_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_features      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m135\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_4 (\u001b[38;5;33mLSTM\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │    \u001b[38;5;34m401,408\u001b[0m │ input_features[\u001b[38;5;34m0\u001b[0m… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ lstm_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_5 (\u001b[38;5;33mLSTM\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │    \u001b[38;5;34m197,120\u001b[0m │ dropout_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ lstm_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_6 (\u001b[38;5;33mLSTM\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │     \u001b[38;5;34m49,408\u001b[0m │ dropout_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_7 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ lstm_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_horse_id      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_7 (\u001b[38;5;33mLSTM\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │     \u001b[38;5;34m12,416\u001b[0m │ dropout_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_1         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │    \u001b[38;5;34m339,072\u001b[0m │ input_horse_id[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_8 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ lstm_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ embedding_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dropout_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ flatten_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m4,160\u001b[0m │ concatenate_1[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_9 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)         │        \u001b[38;5;34m520\u001b[0m │ dropout_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,004,104</span> (3.83 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,004,104\u001b[0m (3.83 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,004,104</span> (3.83 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,004,104\u001b[0m (3.83 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Embedding, Concatenate, Dropout, Flatten\n",
    "\n",
    "# Define the input shapes\n",
    "time_steps = X_train.shape[1]  # Number of time steps in sequences\n",
    "features = X_train.shape[2]    # Number of features per time step\n",
    "num_horses = len(np.unique(horse_ids_train))  # Number of unique horse IDs\n",
    "\n",
    "# 1. Input layers\n",
    "input_features = Input(shape=(time_steps, features), name='input_features')\n",
    "input_horse_id = Input(shape=(1,), name='input_horse_id')\n",
    "\n",
    "# 2. Embedding layer for horse_id\n",
    "embedding = Embedding(input_dim=num_horses, output_dim=32)(input_horse_id)\n",
    "embedding = Flatten()(embedding)  # Flatten embedding\n",
    "\n",
    "# 3. LSTM layers for sequential data\n",
    "x = LSTM(256, return_sequences=True)(input_features)\n",
    "x = Dropout(0.2)(x)\n",
    "x = LSTM(128, return_sequences=True)(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = LSTM(64, return_sequences=True)(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = LSTM(32, return_sequences=False)(x)\n",
    "x = Dropout(0.2)(x)\n",
    "\n",
    "# 4. Concatenate the final LSTM output with the horse embedding\n",
    "concat = Concatenate()([x, embedding])\n",
    "\n",
    "# 5. Dense layers\n",
    "dense_out = Dense(64, activation='relu')(concat)\n",
    "dense_out = Dropout(0.2)(dense_out)\n",
    "\n",
    "# 6. Final output layer for 8-class classification\n",
    "num_classes = 8\n",
    "output = Dense(num_classes, activation='softmax')(dense_out)\n",
    "\n",
    "# Compile with sparse_categorical_crossentropy for integer labels\n",
    "# Define the model\n",
    "model_lstm = Model(inputs=[input_features, input_horse_id], outputs=output)\n",
    "\n",
    "# Compile the model with binary_crossentropy\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "# Compile with sparse_categorical_crossentropy for integer labels\n",
    "model_lstm = Model(inputs=[input_features, input_horse_id], outputs=output)\n",
    "model_lstm.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',  # works with integer labels\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "model_lstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "787fa0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_scheduler = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6\n",
    ")\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', patience=10, restore_best_weights=True\n",
    ")\n",
    "\n",
    "model_checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath='best_model.keras',\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7d22444e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Counts: {0: 5662, 1: 5840, 2: 5984, 3: 5955, 4: 5738, 5: 4928, 6: 3640, 7: 5065}\n",
      "Class Weights: {0: 0.9451607205934299, 1: 0.9163527397260274, 2: 0.8943014705882353, 3: 0.898656591099916, 4: 0.9326420355524573, 5: 1.0859375, 6: 1.4701923076923078, 7: 1.0565646594274432}\n",
      "{0: 0.9451607205934299, 1: 0.9163527397260274, 2: 0.8943014705882353, 3: 0.898656591099916, 4: 0.9326420355524573, 5: 1.0859375, 6: 1.4701923076923078, 7: 1.0565646594274432}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Label distribution\n",
    "unique, counts = np.unique(y_train, return_counts=True)\n",
    "train_counts = dict(zip(unique, counts))\n",
    "\n",
    "print(\"Label Counts:\", train_counts)\n",
    "\n",
    "# Total samples and number of unique classes\n",
    "total_samples = np.sum(counts)\n",
    "num_classes = len(unique)\n",
    "\n",
    "# Calculate class weights\n",
    "class_weight = {label: (total_samples / (num_classes * count)) for label, count in train_counts.items()}\n",
    "\n",
    "print(\"Class Weights:\", class_weight)\n",
    "# # Train label counts from your distribution\n",
    "# train_counts = np.array([580, 621, 604, 594, 1889])\n",
    "# total = train_counts.sum()  # 18164\n",
    "# n_classes = len(train_counts)  # 5\n",
    "\n",
    "# class_weight = {}\n",
    "# for i, count_i in enumerate(train_counts):\n",
    "#     class_weight[i] = float(total) / (n_classes * count_i)\n",
    "\n",
    "print(class_weight)\n",
    "# Example output:\n",
    "# {0: 1.463870..., 1: 1.416..., 2: 1.426..., 3: 1.446..., 4: 0.45...}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f748f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ee588f9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m669/669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.1911 - loss: 2.0044 - val_accuracy: 0.1600 - val_loss: 2.0706 - learning_rate: 2.5000e-04\n",
      "Epoch 2/50\n",
      "\u001b[1m669/669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.1899 - loss: 1.9908 - val_accuracy: 0.1592 - val_loss: 2.0726 - learning_rate: 2.5000e-04\n",
      "Epoch 3/50\n",
      "\u001b[1m669/669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.1923 - loss: 1.9854 - val_accuracy: 0.1621 - val_loss: 2.0749 - learning_rate: 2.5000e-04\n",
      "Epoch 4/50\n",
      "\u001b[1m669/669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.1969 - loss: 1.9782 - val_accuracy: 0.1587 - val_loss: 2.0782 - learning_rate: 2.5000e-04\n",
      "Epoch 5/50\n",
      "\u001b[1m669/669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.1929 - loss: 1.9769 - val_accuracy: 0.1589 - val_loss: 2.0814 - learning_rate: 2.5000e-04\n",
      "Epoch 6/50\n",
      "\u001b[1m669/669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.1992 - loss: 1.9684 - val_accuracy: 0.1613 - val_loss: 2.0836 - learning_rate: 2.5000e-04\n",
      "Epoch 7/50\n",
      "\u001b[1m669/669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.1962 - loss: 1.9648 - val_accuracy: 0.1620 - val_loss: 2.0847 - learning_rate: 1.2500e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m669/669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.1994 - loss: 1.9589 - val_accuracy: 0.1581 - val_loss: 2.0869 - learning_rate: 1.2500e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m669/669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.1964 - loss: 1.9610 - val_accuracy: 0.1633 - val_loss: 2.0882 - learning_rate: 1.2500e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m669/669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.2002 - loss: 1.9577 - val_accuracy: 0.1608 - val_loss: 2.0898 - learning_rate: 1.2500e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m669/669\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.1987 - loss: 1.9568 - val_accuracy: 0.1612 - val_loss: 2.0927 - learning_rate: 1.2500e-04\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "\n",
    "history = model_lstm.fit(\n",
    "    [X_train, horse_ids_train],\n",
    "    y_train,\n",
    "    epochs=50,  \n",
    "    batch_size=64,  # 64,\n",
    "    validation_data=([X_val, horse_ids_val], y_val),\n",
    "    callbacks=[\n",
    "        lr_scheduler, \n",
    "        early_stopping,\n",
    "        model_checkpoint\n",
    "    ],\n",
    "    #class_weight=class_weight,\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0c647b19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1610 - loss: 2.0683\n",
      "Validation Loss: 2.070622205734253, Validation Accuracy: 0.15995734930038452\n"
     ]
    }
   ],
   "source": [
    "val_loss, val_accuracy = model_lstm.evaluate([X_val, horse_ids_val], y_val)\n",
    "print(f'Validation Loss: {val_loss}, Validation Accuracy: {val_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d24823de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m352/352\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of multiclass and multilabel-indicator targets",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m val_preds \u001b[38;5;241m=\u001b[39m (model_lstm\u001b[38;5;241m.\u001b[39mpredict([X_val, horse_ids_val]) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.5\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Generate a classification report\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mclassification_report\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_preds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mNot 1st\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m1st\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Display a confusion matrix\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(confusion_matrix(y_val, val_preds))\n",
      "File \u001b[0;32m~/anaconda3/envs/mamba_env/envs/tf_310/lib/python3.10/site-packages/sklearn/utils/_param_validation.py:216\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    211\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    212\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    213\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    214\u001b[0m         )\n\u001b[1;32m    215\u001b[0m     ):\n\u001b[0;32m--> 216\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    222\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    223\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    224\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    225\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    226\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/mamba_env/envs/tf_310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:2671\u001b[0m, in \u001b[0;36mclassification_report\u001b[0;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n\u001b[1;32m   2563\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Build a text report showing the main classification metrics.\u001b[39;00m\n\u001b[1;32m   2564\u001b[0m \n\u001b[1;32m   2565\u001b[0m \u001b[38;5;124;03mRead more in the :ref:`User Guide <classification_report>`.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2667\u001b[0m \u001b[38;5;124;03m<BLANKLINE>\u001b[39;00m\n\u001b[1;32m   2668\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2670\u001b[0m y_true, y_pred \u001b[38;5;241m=\u001b[39m attach_unique(y_true, y_pred)\n\u001b[0;32m-> 2671\u001b[0m y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2673\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2674\u001b[0m     labels \u001b[38;5;241m=\u001b[39m unique_labels(y_true, y_pred)\n",
      "File \u001b[0;32m~/anaconda3/envs/mamba_env/envs/tf_310/lib/python3.10/site-packages/sklearn/metrics/_classification.py:107\u001b[0m, in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m    104\u001b[0m     y_type \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(y_type) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 107\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    108\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClassification metrics can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt handle a mix of \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m targets\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    109\u001b[0m             type_true, type_pred\n\u001b[1;32m    110\u001b[0m         )\n\u001b[1;32m    111\u001b[0m     )\n\u001b[1;32m    113\u001b[0m \u001b[38;5;66;03m# We can't have more than one value on y_type => The set is no more needed\u001b[39;00m\n\u001b[1;32m    114\u001b[0m y_type \u001b[38;5;241m=\u001b[39m y_type\u001b[38;5;241m.\u001b[39mpop()\n",
      "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of multiclass and multilabel-indicator targets"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Predict on validation data\n",
    "val_preds = (model_lstm.predict([X_val, horse_ids_val]) > 0.5).astype(int)\n",
    "\n",
    "# Generate a classification report\n",
    "print(classification_report(y_val, val_preds, target_names=[\"Not 1st\", \"1st\"]))\n",
    "\n",
    "# Display a confusion matrix\n",
    "print(confusion_matrix(y_val, val_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d936d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "#model.save('/path/to/save/model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686865bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lstm.get_layer(\"embedding_6\").get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284c5de2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
